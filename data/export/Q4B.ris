TY  - JOUR
TI  - Safely Learn to Fly Aircraft From Human: An Offline-Online Reinforcement Learning Strategy and Its Application to Aircraft Stall Recovery
AU  - Jiang, H.
AU  - Xiong, H.
AU  - Zeng, W.
AU  - Ou, Y.
T2  - IEEE Transactions on Aerospace and Electronic Systems
AB  - Researchers have made many attempts to apply Reinforcement Learning (RL) to learn to fly aircraft in recent years. However, existing RL strategies usually are not safe (e.g., can lead to crash) in the initial stage of the training of an RL-based policy. For increasingly complex piloting tasks whose representative models are hard to establish, it is not safe to apply the existing RL strategies to learn an RL-based policy by interacting with an aircraft. To enhance the safety and feasibility of applying an RL-based policy to an aircraft, this study develops an Offline-Online RL strategy. The Offline-Online RL strategy learns an effective initialization for an RL-based flight control policy from human pilots without interacting with an aircraft through offline RL. Then, the Offline-Online RL strategy can further improve the RL-based flight control policy safely without leading to crash by interacting with the aircraft according to regular online RL, requiring no or very little intervention performed by a human pilot. To demonstrate and evaluate the Offline-Online RL strategy, the strategy is utilized to address the stall recovery problem of aircraft based on a flight simulator. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TAES.2023.3299913
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166762622&doi=10.1109%2fTAES.2023.3299913&partnerID=40&md5=cfa300d5e1358906d4ad138b78d6e265
DB  - Scopus
KW  - Reinforcement learning
KW  - Task analysis
KW  - reinforcement learning
KW  - Training
KW  - Behavioral science
KW  - Behavioral sciences
KW  - Behavioral research
KW  - Job analysis
KW  - E-learning
KW  - Reinforcement learnings
KW  - safety
KW  - Recovery
KW  - Aircraft
KW  - Aerospace control
KW  - Aerospace electronics
KW  - Aircraft accidents
KW  - Aircraft control
KW  - Atmospheric modeling
KW  - Flight simulators
KW  - human pilot
KW  - Human pilots
KW  - Learning strategy
KW  - Offline
KW  - stall recovery
KW  - Stall recovery
KW  - Training aircraft
ER  - 

TY  - CHAP
TI  - Key Dimensions of Algorithmic Management, Machine Learning and Big Data in Differing Large Sociotechnical Systems, with Implications for Systemwide Safety Management
AU  - Roe, E.
AU  - Fortmann-Roe, S.
T2  - SpringerBriefs in Applied Sciences and Technology
AB  - The time is ripe for more case-by-case analyses of “big data”, “machine learning” and “algorithmic management”. A significant portion of current discussion on these topics occurs under the rubric of Automation (or, artificial intelligence) and in terms of broad political, social and economic factors said to be at work. We instead focus on identifying sociotechnical concerns arising out of software development in the topic areas. In so doing, we identify trade-offs and at least one longer-term system safety concern not typically included alongside notable political, social and economic considerations. This is the system safety concern of obsolescence. We end with a speculation on how skills in making these trade-offs might be noteworthy when system safety has been breached in emergencies. © 2023, The Author(s).
DA  - 2023///
PY  - 2023
VL  - Part F1246
SP  - 21
EP  - 28
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168771391&doi=10.1007%2f978-3-031-32633-2_3&partnerID=40&md5=27c6a59fb999d883bc3bb9eb75acd5cb
DB  - Scopus
KW  - Machine learning
KW  - Automation
KW  - Sociotechnical systems
KW  - Machine-learning
KW  - Economic and social effects
KW  - Big data
KW  - System safety
KW  - Algorithmic management
KW  - Algorithmics
KW  - Commerce
KW  - Information management
KW  - Key dimensions
KW  - Large socio-technical systems
KW  - Obsolescence
KW  - Safety concerns
KW  - Safety management
KW  - Software design
KW  - Trade off
ER  - 

TY  - JOUR
TI  - Robust Elective Hospital Admissions With Contextual Information
AU  - Wang, R.
AU  - Liu, X.
AU  - Xie, X.
AU  - Li, L.
T2  - IEEE Transactions on Automation Science and Engineering
AB  - Increasing demand for hospitalization requires hospitals to optimize the admission schedules of elective patients to minimize operation cost and improve service quality. In this study, we propose a robust predict-then-optimize methodology to address the elective patient admission scheduling problem under uncertainty. The objective is to minimize total cost associated with postponement and daily bed over-utilization considering uncertain patients&#x2019; length of stay (LOS). Starting from prediction models, we first predict patients&#x2019; LOS using elaborate clusterwise regression methods. Considering the distributions of the regression residuals, we propose two-stage stochastic programming (SP) and distributionally robust optimization (DRO) approaches to model and solve the elective patient admission scheduling problem. We reformulate the proposed DRO model and construct a column-and-constraint generation algorithm to solve it efficiently. Finally, using real-world data, we conduct extensive numerical experiments comparing the performance of our proposed DRO model with benchmark methods, and discuss insights and implications for elective patient admission scheduling. The results show that our proposed DRO model can help hospitals manage high quality care, i.e., proper bed occupancy rates, at a reduced cost. <italic>Note to Practitioners</italic>&#x2014;This article is motivated by our collaborations with a tertiary hospital in Beijing, China. From the perspective of hospital admission centers, we consider an elective patient admission scheduling problem that must decide the admission time for elective patients within a specified planning horizon. However, this is a challenging optimization problem due to patients&#x2019; uncertain LOS. Additionally, it is difficult to accurately describe the probability distribution of patients&#x2019; LOS. The managers find it difficult to give high-quality admission schedules to patients when they are registered which may reduce patients&#x2019; satisfaction. Therefore, we propose a predict-then-optimize framework to solve this problem. In particular, a two-phase approach that consists of LOS prediction and a two-stage optimization model is designed. We show that the methods presented in this article can be used as a practical tool to help hospital managers obtain more reasonable elective patient admission scheduling solutions that can improve service quality. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TASE.2023.3311432
SP  - 1
EP  - 19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171793903&doi=10.1109%2fTASE.2023.3311432&partnerID=40&md5=0d3b6e3ac9b68f31d11b3e94c3ac251c
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Predictive models
KW  - Machine-learning
KW  - Forecasting
KW  - Regression analysis
KW  - Surveys
KW  - Uncertainty
KW  - Quality of service
KW  - Optimisations
KW  - Benchmarking
KW  - Optimization
KW  - Robust optimization
KW  - Costs
KW  - Stochastic models
KW  - Stochastic systems
KW  - Hospitals
KW  - distributionally robust optimization
KW  - Distributionally robust optimization
KW  - Inpatient admission
KW  - inpatients admission
KW  - Numerical methods
KW  - OR in health service
KW  - OR in health services
KW  - Probability distributions
KW  - regression residuals
KW  - Regression residuals
KW  - Schedule
KW  - Schedules
KW  - Stochastic programming
ER  - 

TY  - JOUR
TI  - Human-Guided Reinforcement Learning With Sim-to-Real Transfer for Autonomous Navigation
AU  - Wu, J.
AU  - Zhou, Y.
AU  - Yang, H.
AU  - Huang, Z.
AU  - Lv, C.
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - Reinforcement learning (RL) is a promising approach in unmanned ground vehicles (UGVs) applications, but limited computing resource makes it challenging to deploy a well-behaved RL strategy with sophisticated neural networks. Meanwhile, the training of RL on navigation tasks is difficult, which requires a carefully-designed reward function and a large number of interactions, yet RL navigation can still fail due to many corner cases. This shows the limited intelligence of current RL methods, thereby prompting us to rethink combining RL with human intelligence. In this paper, a human-guided RL framework is proposed to improve RL performance both during learning in the simulator and deployment in the real world. The framework allows humans to intervene in RL&#x0027;s control progress and provide demonstrations as needed, thereby improving RL&#x0027;s capabilities. An innovative human-guided RL algorithm is proposed that utilizes a series of mechanisms to improve the effectiveness of human guidance, including human-guided learning objective, prioritized human experience replay, and human intervention-based reward shaping. Our RL method is trained in simulation and then transferred to the real world, and we develop a denoised representation for domain adaptation to mitigate the simulation-to-real gap. Our method is validated through simulations and real-world experiments to navigate UGVs in diverse and dynamic environments based only on tiny neural networks and image inputs. Our method performs better in goal-reaching and safety than existing learning- and model-based navigation approaches and is robust to changes in input features and ego kinetics. Furthermore, our method allows small-scale human demonstrations to be used to improve the trained RL agent and learn expected behaviors online. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPAMI.2023.3314762
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171531773&doi=10.1109%2fTPAMI.2023.3314762&partnerID=40&md5=213ee3846632eadf5c500e5900fd77df
DB  - Scopus
KW  - Safety
KW  - Task analysis
KW  - Feature extraction
KW  - reinforcement learning
KW  - Training
KW  - Behavioral sciences
KW  - Navigation
KW  - Heuristic algorithms
KW  - Human guidance
KW  - navigation
KW  - sim-to-real transfer
KW  - unmanned ground vehicle
ER  - 

TY  - JOUR
TI  - Deep adaptive control: Deep reinforcement learning-based adaptive vehicle trajectory control algorithms for different risk levels
AU  - He, Y.
AU  - Liu, Y.
AU  - Yang, L.
AU  - Qu, X.
T2  - IEEE Transactions on Intelligent Vehicles
AB  - In this study, we explore the problem of adaptive vehicle trajectory control for different risk levels. Firstly, we introduce a sliding window-based car-following scenario extraction method, propose a new alternative traffic conflict assessment metric, and build a comprehensive traffic scenario library. Secondly, based on deep reinforcement learning (RL), we design an adaptive car-following trajectory control algorithm, which is called <italic>Deep Adaptive Control</italic>, to cope with different traffic risk levels. Thirdly, we design five metrics in terms of safety, comfort, and energy consumption, and experimentally compare <italic>Deep Adaptive Control</italic> with human drivers and RL benchmarks. The experimental results show the superiority of <italic>Deep Adaptive Control</italic> compared to human drivers and existing RL methods, which can follow the preceding vehicle closely in low-risk situations to improve traffic efficiency, keep distance from the preceding vehicle in high-risk situations to improve safety and be optimal in terms of comfort and fuel consumption metrics. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TIV.2023.3303408
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167779283&doi=10.1109%2fTIV.2023.3303408&partnerID=40&md5=649859c2b28cd7f7b60e898d82aa8cfa
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Safety
KW  - Mathematical models
KW  - Vehicles
KW  - Measurement
KW  - Trajectory
KW  - Data models
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Risk assessment
KW  - Adaptive control systems
KW  - Safety engineering
KW  - Energy utilization
KW  - Trajectories
KW  - Adaptation models
KW  - Adaptive Control
KW  - Car following
KW  - Intelligent and connected vehicle
KW  - intelligent and connected vehicles
KW  - Libraries
KW  - Risk levels
KW  - Trajectory control
KW  - Vehicle trajectories
KW  - vehicle trajectory control
KW  - Vehicle trajectory control
ER  - 

TY  - CHAP
TI  - Impact of Data Sampling on Performance and Robustness of Machine Learning Models in Production Engineering
AU  - Conrad, F.
AU  - Boos, E.
AU  - Mälzer, M.
AU  - Wiemer, H.
AU  - Ihlenfeldt, S.
T2  - Lecture Notes in Production Engineering
AB  - The application of machine learning models in production systems is continuously growing. Hence, ensuring a reliable estimation of the model performance is crucial, as all following decisions regarding the deployment of the machine learning models are based on this aspect. Especially when modelling with datasets of small sample sizes, commonly used train-test split variation techniques and model evaluation strategies encompass a high variance on the model’s performance. This difficulty arises, as the available amount of meaningful data is severely limited in production engineering and can lead to the model's actual performance being greatly over- or underestimated. This work provides an experimental overview on different train-test splitting techniques and model evaluation strategies. Sophisticated statistical sampling methods are compared to simple random sampling, and their impact on performance evaluation in production datasets is analysed. The aim is to ensure a high robustness of the model performance evaluation, even when working with small datasets. Hence, the decision process for the deployment of machine learning models in production systems will be improved. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
VL  - Part F1163
SP  - 463
EP  - 472
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166617411&doi=10.1007%2f978-3-031-18318-8_47&partnerID=40&md5=40a9a89f075267aebafd10a2b56e130e
DB  - Scopus
KW  - Machine learning
KW  - Performance
KW  - Machine learning models
KW  - Data sampling
KW  - Evaluation strategies
KW  - Model evaluation
KW  - Modeling performance
KW  - Performance evaluation
KW  - Performances evaluation
KW  - Production system
KW  - Sampling
KW  - Train-test-split
KW  - Usable artificial intelligence
ER  - 

TY  - CONF
TI  - Safety Ensured Machine Learning Framework for Energy System Operation in Data Centers
AU  - Olowolaju, J.
AU  - Livani, H.
AU  - Nasr, E.
T2  - 2023 IEEE Kansas Power and Energy Conference, KPEC 2023
AB  - With the increasing demand for web-based services and the growing amount of data generated and stored, data centers are becoming more vital for organizations of all sizes. Unfortunately, climate and abrupt weather changes can compromise data center conditions and cause costly and inconvenient performance issues. Therefore, it is imperative to maintain appropriate environmental conditions within data centers to ensure the equipment's safety and efficiency, as well as the comfort and safety of the workers. Monitoring and managing the temperature and relative humidity within a data center can minimize the risk of equipment failure and employee discomfort, ensuring the reliability and productivity of the facility. This paper examines machine-learning (ML) models' applicability for handling near-real-time emergency airflow control in data centers during extreme weather events. ML models are built in Python and evaluated using mean absolute error (MAE), root mean square error (RMSE), and coefficient of determination R2 metrics. In addition, energy plus simulates the environment of a data center. Finally, the data center cooler settings, IT equipment load level, and outdoor air conditions are used to manage the facility's requirements. The seventh-order polynomial model had the highest R2 score and the lowest errors during training and testing. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/KPEC58008.2023.10215455
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170646325&doi=10.1109%2fKPEC58008.2023.10215455&partnerID=40&md5=5a8613e43994cbeb6b7f67bad9b9e0e9
DB  - Scopus
KW  - Machine learning
KW  - Machine Learning
KW  - Machine-learning
KW  - Machine learning models
KW  - Personnel training
KW  - Safety engineering
KW  - Errors
KW  - Learning frameworks
KW  - Python
KW  - Air
KW  - Air flow control
KW  - Airflow Control
KW  - Data Center
KW  - Datacenter
KW  - Energy systems
KW  - EnergyPlus
KW  - Mean square error
KW  - Systems operation
KW  - Weather change
KW  - Web-based service
ER  - 

TY  - JOUR
TI  - Learning From Noisy Labels Via Dynamic Loss Thresholding
AU  - Yang, H.
AU  - Jin, Y.
AU  - Li, Z.
AU  - Wang, D.
AU  - Geng, X.
AU  - Zhang, M.
T2  - IEEE Transactions on Knowledge and Data Engineering
AB  - Numerous researches have proved that deep neural networks (DNNs) can fit almost everything even given data with noisy labels, and result in poor generalization performance. However, recent studies suggest that DNNs tend to gradually memorize the data, moving from correct data to mislabeled data. Inspired by this finding, we propose a novel method named <italic>Dynamic Loss Thresholding (DLT)</italic>. During the training process, DLT records the loss value of each sample and calculates dynamic loss thresholds. Specifically, DLT compares the loss value of each sample with the current loss threshold. Samples with smaller losses can be considered as clean samples with higher probability and vice versa. Then, DLT discards the potentially corrupted labels and further leverages self-training semi-supervised learning techniques. Experiments on CIFAR-10/100, WebVision and Clothing1M demonstrate substantial improvements over recent state-of-the-art methods. In addition, we investigate two real-world problems. Firstly, we propose a novel approach to estimate the noise rates of datasets based on the loss difference between the early and late training stages of DNNs. Secondly, we explore the effect of hard samples (which are difficult to be distinguished) on the process of learning from noisy labels. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TKDE.2023.3313604
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171528884&doi=10.1109%2fTKDE.2023.3313604&partnerID=40&md5=e14cea8b8cc944e7e9d83a3bca018bdf
DB  - Scopus
KW  - Deep learning
KW  - semi-supervised learning
KW  - Data models
KW  - Training
KW  - Robustness
KW  - dynamic loss thresholding
KW  - Entropy
KW  - Fitting
KW  - learning from noisy labels
KW  - Noise measurement
KW  - Semisupervised learning
ER  - 

TY  - CONF
TI  - Development of a bearing test-bed for acquiring data for robust and transferable machine learning
AU  - Schnur, C.
AU  - Robin, Y.
AU  - Goodarzi, P.
AU  - Dorst, T.
AU  - Schutze, A.
AU  - Schneider, T.
T2  - Conference Record - IEEE Instrumentation and Measurement Technology Conference
AB  - Developing test-beds to test products and procedures and gain further insights is a common approach in science and industry. During the testing, data is often recorded to provide further insights to the analysts. Since the rise of machine learning and data-driven approaches, these test-beds often get over-instrumented to record as much data as possible. After that, the data is analyzed, and tailored algorithms are applied to achieve a machine learning model with high accuracy. However, many of these models later fail when applied in the real world because they lose their validity due to dataset or domain shift. This means that certain cross-influences were not, or not in their complete range, covered within the recorded data. In this contribution, a test-bed for cylindrical roller bearings has been developed where multiple cross-influences can be varied. It is designed for subsequent leave-one-group-out cross-validation to evaluate the robustness and transferability of machine learning models. Noteworthy features of the test-bed are the possibility of changing the position of the bearing in the test-bed without disassembling it from the shaft (perhaps causing unintentional damages) and that each bearing is measured in its undamaged condition as well before damaging it. In a first measurement campaign, three experiments had been carried out with an automated machine learning toolbox to evaluate the performance of the test-bed design. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/I2MTC53148.2023.10176017
VL  - 2023-May
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166375402&doi=10.1109%2fI2MTC53148.2023.10176017&partnerID=40&md5=600f3e58e5bf51c8b73177574a2e1b46
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Transfer learning
KW  - Machine-learning
KW  - Machine learning models
KW  - bearing test-bed
KW  - Bearing test-bed
KW  - Bearing tests
KW  - Data transfer
KW  - Equipment testing
KW  - robust data
KW  - Robust datum
KW  - Roller bearings
KW  - Statistical methods
KW  - Test bed
KW  - Test procedures
KW  - Test products
KW  - Testing data
KW  - transfer learning
ER  - 

TY  - JOUR
TI  - Safety Is Our Friend: A Federated Learning Framework Toward Driver’s State and Behavior Detection
AU  - Khoa, T.A.
AU  - Trac, N.D.
AU  - Tinh, V.P.
AU  - Nam, N.H.
AU  - Dang, D.N.M.
AU  - Son, H.H.
AU  - Lam, P.D.
T2  - IEEE Transactions on Computational Social Systems
AB  - &#x201C;Safety is our friend, accidents our enemy&#x201D; is the propaganda social information on traffic safety in several countries. This proves that safety is a top priority when using vehicles when participating in traffic. There have been several studies on driver behavior/state detection using machine learning (ML). In addition, in ML generally, the data must be provided to the server for training in a centralized setting. Sharing data will therefore expose data information to external interference and corruption, bringing many risks. Federated learning (FL) recently emerged as new research to solve the tricky problems above. Our research is one of the few first studies that applies longitudinal physiological sensor measurements in a naturalistic driving environment using the FL framework to assess driver behavior/state. The novelty of this study includes the following. First, we use techniques such as synthetic minority oversampling technique (SMOTE) to enrich and balance the Harmony dataset. The purpose is to increase the accuracy and improve the reliability of the assessment. Second, we incorporate essential deep learning (DL) models into the FL framework, including multilayer perceptron (MLP), long short-term memory (LSTM), 1-D convolutional neural network (1-D CNN), CNN-LSTM, and convolutional LSTM (ConvLSTM) models. By evaluating these models, we show that in the FL environment, the use of compact, lightweight models such as MLP provides higher efficiency than other large, complex models and is suitable for consistent research. Finally, our framework has higher results than other basic models such as support vector machines and decision trees while remaining highly competitive to other DL models with respect to network size, execution time, and stability. Primarily, our idea is the trend of the future. It can be practically applied in transportation, taxis, and self-driving car companies; each car is considered a client, and companies can manage their drivers instead of using a third-party service, which will cause data loss and privacy. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TCSS.2023.3273727
SP  - 1
EP  - 19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162725303&doi=10.1109%2fTCSS.2023.3273727&partnerID=40&md5=e1809c792f8725974b0140286e08a139
DB  - Scopus
KW  - Decision trees
KW  - Deep learning
KW  - Safety
KW  - Machine learning
KW  - Urban areas
KW  - Accidents
KW  - Vehicles
KW  - Data models
KW  - Behavioral science
KW  - Behavioral sciences
KW  - Automobile drivers
KW  - Behavioral research
KW  - Machine-learning
KW  - Convolution
KW  - Long short-term memory
KW  - Deep learning (DL)
KW  - Federated learning
KW  - federated learning (FL)
KW  - machine learning (ML)
KW  - Multilayer perceptron
KW  - multilayer perceptron (MLP)
KW  - Multilayers
KW  - Multilayers perceptrons
KW  - Over sampling
KW  - synthetic minority oversampling
KW  - Synthetic minority oversampling
KW  - Wearable computers
ER  - 

TY  - JOUR
TI  - From Naturalistic Traffic Data to Learning-Based Driving Policy: A Sim-to-Real Study
AU  - Yuan, M.
AU  - Shan, J.
AU  - Mi, K.
T2  - IEEE Transactions on Vehicular Technology
AB  - Reinforcement learning (RL) is a promising way to achieve human- like autonomous driving (HAD) in complex and dynamic traffic, but faces challenges such as low sample efficiency, partial observability, and sim2real transfer. In light of this, a comprehensive solution for RL-driven HAD is established. First, an efficient training scheme called Deep Recurrent Q-learning from demonstration algorithm (DRQfD) is proposed for lane-changing decision-making to address the low sample efficiency in RL and the poor generalization capability in Imitation Learning (IL). The inherent LSTM structure potentially learns to predict future states of surrounding vehicles, helping to address the partially observable problem in autonomous driving (AD). Second, to reduce the sim2real gap, a twin high-fidelity simulator is built based on ROS-Gazebo for simulating LiDAR sensing, model training, and evaluations. Domain randomization is used to improve the robustness and generalization ability, making it easier for the model to be transferred to real-world scenarios. In addition, for the multi-objective optimization and imbalanced data issues in this scenario, a hierarchical decision-making framework is proposed to decompose the complex decision-making problem into several subtasks, making the driving policies easier to converge. To avoid the excessive dependence of the decision-making module on the output of perception module in modular systems, we train each modularized skill in an end-to-end manner. Moreover, we compare our method with a vanilla RL method to show improvement in learning efficiency. Comparisons between RL-based model and IL baseline in terms of safety, travel efficiency, and human-likeness are also given. To further validate the generalization ability of our model, we test the model on real traffic dataset. Finally, we implement the RL model on physical cars to demonstrate the performance of sim2real transfer. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TVT.2023.3307409
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168746084&doi=10.1109%2fTVT.2023.3307409&partnerID=40&md5=f23657d17f0723b9140bc86c3553ac3c
DB  - Scopus
KW  - Safety
KW  - Task analysis
KW  - Decision making
KW  - reinforcement learning
KW  - Trajectory
KW  - Training
KW  - Behavioral sciences
KW  - Imitation learning
KW  - Human- like driving behavior modeling
KW  - Laser radar
KW  - sim2real
ER  - 

TY  - JOUR
TI  - Scalable-MADDPG-Based Cooperative Target Invasion for a Multi-USV System
AU  - Wang, C.
AU  - Wang, Y.
AU  - Shi, P.
AU  - Wang, F.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - This article concentrates on proposing a scalable deep reinforcement learning (DRL) method for a multiple unmanned surface vehicle (multi-USV) system to operate cooperative target invasion. The multi-USV system, which is made up of multiple invaders, needs to invade target areas in a specified time. A novel scalable reinforcement learning (RL) method called Scalable-MADDPG is proposed for the first time. In this method, the scale of the multi-USV system can be changed at any time without interrupting the training process. Then, to mitigate the policy oscillation after applying Scalable-MADDPG, a bi-directional long&#x2013;short-term memory (Bi-LSTM) network is constructed. Moreover, an improved <inline-formula> <tex-math notation="LaTeX">$\epsilon$</tex-math> </inline-formula>-greedy strategy is proposed to help balance the exploration and exploitation in RL. Furthermore, to enhance the robustness of the optimal policy, Ornstein&#x2013;Uhlenbeck (OU) noise is added in this improved <inline-formula> <tex-math notation="LaTeX">$\epsilon$</tex-math> </inline-formula>-greedy strategy during the training process. Finally, the scalable RL method is used to help the multi-USV system perform cooperative target invasion under complex marine environments. The effectiveness of Scalable-MADDPG is demonstrated through three experiments. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3309689
SP  - 1
EP  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171566744&doi=10.1109%2fTNNLS.2023.3309689&partnerID=40&md5=e6e1695c8f78c4c50c484cdfc09a498d
DB  - Scopus
KW  - Reinforcement learning
KW  - Task analysis
KW  - Training
KW  - Reinforcement learnings
KW  - Personnel training
KW  - Long short-term memory
KW  - Robustness
KW  - > $\epsilon$ -greedy strategy
KW  - $\epsilon$ -greedy strategy
KW  - cooperative target invasion
KW  - Cooperative target invasion
KW  - Cooperative targets
KW  - Greedy strategies
KW  - Long–short-term memory
KW  - long–short-term memory (LSTM)
KW  - Multiple unmanned surface vehicle  system
KW  - multiple unmanned surface vehicle (multi-USV) systems
KW  - Oscillators
KW  - Scalability
KW  - Scalable deep reinforcement learning
KW  - scalable deep reinforcement learning (DRL)
KW  - Space stations
KW  - State space methods
KW  - Unmanned surface vehicle systems
KW  - Xmlns:mml="
KW  - Xmlns:xlink="
KW  - Xmlns:xsi="
ER  - 

TY  - JOUR
TI  - Deep Statistical Solver for Distribution System State Estimation
AU  - Habib, B.
AU  - Isufi, E.
AU  - Breda, W.V.
AU  - Jongepier, A.
AU  - Cremer, J.L.
T2  - IEEE Transactions on Power Systems
AB  - Implementing accurate Distribution System State Estimation (DSSE) faces several challenges, among which the lack of observability and the high density of the distribution system. While data-driven alternatives based on Machine Learning models could be a choice, they suffer in DSSE because of the lack of labeled data. In fact, measurements in the distribution system are often noisy, corrupted, and unavailable. To address these issues, we propose the Deep Statistical Solver for Distribution System State Estimation (DSS2), a deep learning model based on graph neural networks (GNNs) that accounts for the network structure of the distribution system and the governing power flow equations&#x00A0;of the problem. DSS2 is based on GNN and leverages hypergraphs to model the network as a graph into the deep-learning algorithm and to represent the heterogeneous components of the distribution systems. A weakly supervised learning approach is put forth to train the DSS2: by enforcing the GNN output into the power flow equations, we force the DSS2 to respect the physics of the distribution system. This strategy enables learning from noisy measurements and alleviates the need for ideal labeled data. Extensive experiments with case studies on the IEEE 14-bus, 70-bus, and 179-bus networks showed the DSS2 outperforms the conventional Weighted Least Squares algorithm in accuracy, convergence, and computational time while being more robust to noisy, erroneous, and missing measurements. The DSS2 achieves a competing, yet lower, performance compared with the supervised models that rely on the unrealistic assumption of having all the true labels. Author
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPWRS.2023.3290358
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163752460&doi=10.1109%2fTPWRS.2023.3290358&partnerID=40&md5=08f90923b7ced1fbcc474d4eef93e4b7
DB  - Scopus
KW  - Deep learning
KW  - Mathematical models
KW  - Data models
KW  - Training
KW  - Deep Learning
KW  - Supervised learning
KW  - Learning algorithms
KW  - Robustness
KW  - Quadratic programming
KW  - Electric load flow
KW  - Neural-networks
KW  - Distribution System
KW  - Distribution system state estimations
KW  - Distribution systems
KW  - Electric power distribution
KW  - Flow graphs
KW  - Graph Neural Network
KW  - Graph neural networks
KW  - Labeled data
KW  - Physic-informed neural network
KW  - Physic-Informed Neural Network
KW  - State estimation
KW  - State Estimation
KW  - weakly supervised learning
KW  - Weakly supervised learning
ER  - 

TY  - JOUR
TI  - Multi-Agent Distributed Optimal Control for Tracking Large-Scale Multi-Target Systems in Dynamic Environments
AU  - Abdulghafoor, A.Z.
AU  - Bakolas, E.
T2  - IEEE Transactions on Cybernetics
AB  - This article considers the problem of motion coordination for a multiagent (MA) network whose goal is to track a large-scale multitarget (MT) system in a region populated by dynamic obstacles. We first characterize a density path which corresponds to the expected evolution of the macroscopic state of the MT system, which is represented by the probability density function (PDF) of a time-varying Gaussian mixture (GM). We compute this density path by using an adaptive optimal control method which accounts for the distribution of the (possibly moving) obstacles over the environment described by a time-varying obstacle map function. We show that each target of the MT system can find microscopic inputs that can collectively realize the density path while guaranteeing obstacle avoidance at all times. Subsequently, we propose a Voronoi distributed motion coordination algorithm which determines the individual microscopic control inputs of each agent of the MA network so that the latter can track the MT system while avoiding collisions with obstacles and their teammates. The proposed algorithm relies on a distributed move-to-centroid control law in which the density over the Voronoi cell of each agent is determined by the estimated macroscopic state evolution of the MT system. Finally, simulation results are presented to showcase the effectiveness of our proposed approach. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TCYB.2023.3302288
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168672870&doi=10.1109%2fTCYB.2023.3302288&partnerID=40&md5=1f4888694ff471df0e3210e743e9ecec
DB  - Scopus
KW  - Reinforcement learning
KW  - Safety
KW  - Motion planning
KW  - Target tracking
KW  - Collision avoidance
KW  - Human resource management
KW  - Collisions avoidance
KW  - Reinforcement learnings
KW  - Optimization
KW  - Multi agent systems
KW  - Microscopy
KW  - reinforcement learning (RL)
KW  - Heuristic algorithms
KW  - obstacle avoidance
KW  - Obstacles avoidance
KW  - Aerodynamics
KW  - Distributed control
KW  - Distributed parameter control systems
KW  - Distributed-control
KW  - dynamic coverage
KW  - Dynamic coverages
KW  - dynamic obstacles
KW  - Dynamic obstacles
KW  - Gaussian mixture
KW  - Gaussian mixtures (GMs)
KW  - Gaussian-mixtures
KW  - Heuristics algorithm
KW  - Multi-target-tracking
KW  - multiagent (MA) networks
KW  - Multiagent networks
KW  - multitarget (MT) tracking
KW  - Probability density function
KW  - Targets tracking
ER  - 

TY  - JOUR
TI  - Deep Reinforcement Learning Based Active Network Management and Emergency Load-Shedding Control for Power Systems
AU  - Zhang, H.
AU  - Sun, X.
AU  - Lee, M.H.
AU  - Moon, J.
T2  - IEEE Transactions on Smart Grid
AB  - This paper presents two novel deep reinforcement learning (DRL) approaches aimed at solving complex power system control problems in a data-driven sense to maintain the stability of power systems. Specifically, we propose, respectively, SACPER (Soft Actor-Critic (SAC) with Prioritized Experience Replay (PER)) and Constrained Variational Policy Optimization (CVPO) DRL algorithms to address the sequential decision-making problem of active network management (ANM) in distributed power systems and optimizing emergency load shedding (ELS) control problems. First, we propose SACPER for the ANM problem, which prioritizes the training of samples with large errors and poor policy performance. Evaluation of SACPER in terms of stability improvement and convergence speed shows that the ANM problem is optimized and energy loss and operational constraint violations are minimized. Next, we introduce CVPO for the ELS control problem, which is formulated as the Safe Reinforcement Learning (SRL) framework to address safety constraint prioritization issues in power systems. We consider additional voltage variables in the network as strong constraints for SRL to achieve fast voltage recovery and minimize unnecessary energy loss, while ensuring good training performance and efficiency. To demonstrate the performances of SACPER, we apply it to ANM6-Easy environment. The CVPO algorithm is applied to IEEE 39-Bus and IEEE 300-Bus systems. The simulation results of SACPER and CVPO are validated through extensive comparisons with other state-of-the-art DRL approaches. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TSG.2023.3302846
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167775967&doi=10.1109%2fTSG.2023.3302846&partnerID=40&md5=7bfab9dfbec34f4ed8be3b65c9ca4988
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Safety
KW  - Task analysis
KW  - Decision making
KW  - Training
KW  - Job analysis
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Constrained optimization
KW  - Power
KW  - Safe reinforcement learning
KW  - Information management
KW  - safe reinforcement learning
KW  - Electric power system control
KW  - active network management
KW  - Active network management
KW  - Electric load shedding
KW  - Electric power plant loads
KW  - emergency control
KW  - Emergency control
KW  - Energy dissipation
KW  - Energy management systems
KW  - Inference algorithm
KW  - Inference algorithms
KW  - load shedding
KW  - Load-shedding
KW  - Network management
KW  - Power system
KW  - Power system stability
KW  - Power systems
KW  - Power systems stability
KW  - Voltage control
ER  - 

TY  - CHAP
TI  - Safety in a Digital Age: Old and New Problems—Algorithms, Machine Learning, Big Data and Artificial Intelligence
AU  - Le Coze, J.-C.
AU  - Antonsen, S.
T2  - SpringerBriefs in Applied Sciences and Technology
AB  - Digital technologies including machine learning, artificial intelligence and big data are leading to dramatic changes, in both the workplace and our private lives. These trends raise concerns, ranging from the pragmatic to the philosophical, regarding the nature of work, the professional identity of workers, our privacy, the distribution of power within organizations and societies. They also represent both opportunities and challenges for the work of producing safety in high-hazard systems. We highlight a number of pressing issues related to these evolutions and analyze the extent to which existing lenses from sociotechnical theory can help understand them. © 2023, The Author(s).
DA  - 2023///
PY  - 2023
VL  - Part F1246
SP  - 1
EP  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168765563&doi=10.1007%2f978-3-031-32633-2_1&partnerID=40&md5=b9cff1b27a002d784be06e18cf999875
DB  - Scopus
KW  - Safety
KW  - Machine learning
KW  - AI
KW  - Regulation
KW  - Accident prevention
KW  - E-learning
KW  - Machine-learning
KW  - Philosophical aspects
KW  - Big data
KW  - Power
KW  - Algorithmic management
KW  - Algorithmics
KW  - Digital technologies
KW  - Digital age
KW  - Problem algorithms
KW  - Professional identity
KW  - Workers'
ER  - 

TY  - JOUR
TI  - Robustness Analysis of Discrete State-Based Reinforcement Learning Models in Traffic Signal Control
AU  - Xu, D.
AU  - Li, C.
AU  - Wang, D.
AU  - Gao, G.
T2  - IEEE Transactions on Intelligent Transportation Systems
AB  - With the growing traffic congestion problem, more and more deep reinforcement learning (DRL) methods have been applied in traffic signals control(TSC). But researches show that DRL is very fragile with abnormal data. In this paper, special traffic state abnormal data (TSAD) are simulated, based on which the robustness of DRL is analyzed and improved for traffic signals control. Firstly, the perturbation noise is generated based on the Discrete Carlin&Wagner attack, which is then added to the normal data to simulate the TSAD. Secondly, under different type of TSAD, the robustness of DRL models for traffic signals control is explored, which are demonstrated to have certain vulnerability, especially with high traffic flows. Finally, induction model based on reward detection (IMR) and mask the activation values of decision neurons (MVN) are proposed to effectively improve the robustness of DRL models for traffic signals control. © 2000-2011 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TITS.2022.3221107
VL  - 24
IS  - 2
SP  - 1727
EP  - 1738
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142842635&doi=10.1109%2fTITS.2022.3221107&partnerID=40&md5=cea20849e9d07f6e2288b577fd6f756c
DB  - Scopus
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - robustness
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Traffic signals
KW  - Robustness (control systems)
KW  - Robustness
KW  - Robust control
KW  - Neural-networks
KW  - Road
KW  - deep reinforcement learning
KW  - Abnormal data
KW  - Discrete carlini&wagn attack
KW  - discrete Carlini&Wagner attack
KW  - Green products
KW  - Perturbation method
KW  - Perturbation techniques
KW  - Street traffic control
KW  - Traffic congestion
KW  - Traffic signal control
KW  - Traffic state
KW  - traffic state abnormal data
KW  - Traffic state abnormal data
ER  - 

TY  - CONF
TI  - A Reinforcement-Learning-based Agent to discover Safety-Critical States in Smart Grid Environments
AU  - Santorsola, A.
AU  - Maci, A.
AU  - Delvecchio, P.
AU  - Coscia, A.
T2  - International Conference on Electrical, Computer, Communications and Mechatronics Engineering, ICECCME 2023
AB  - The complexity of industrial systems and processes has grown significantly in recent years, due to the integration of Information Technology (IT) and Operational Technology (OT) to monitor and control interconnected equipment in critical infrastructures, improving their production processes. Smart Grids are one of the possible examples of technology enabled by IT/OT integration. However, such energy distribution systems are exposed to several vulnerabilities that make them particularly susceptible to cyber threats with critical implications for human safety. Sophisticated attacks against OT infrastructures show few observable indicators in a large timeframe and traditional fault detection methods are ineffective in discovering safety-critical states, especially in large observation and action spaces.This paper presents a methodology to identify safety-critical command patterns within a Smart Grid ICS network. In particular, a modular simulation framework that embeds physical processes simulation, industrial-specific control protocols virtualization, as well as a Reinforcement Learning algorithm has been developed. The preliminary results in training and test cases have demonstrated the modeling and learning capability of the proposed approach.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICECCME57830.2023.10252540
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174032170&doi=10.1109%2fICECCME57830.2023.10252540&partnerID=40&md5=7f14d3da77d1114f3e679316e0d29a36
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Accident prevention
KW  - Reinforcement learnings
KW  - Electric power transmission networks
KW  - Smart grid
KW  - Smart power grids
KW  - Fault detection
KW  - Electric power distribution
KW  - and Distribution
KW  - And distribution
KW  - Critical-state
KW  - Cyber security
KW  - Cyber Security & Safety
KW  - Cyber-safety
KW  - Cybersecurity
KW  - Electric power transmission
KW  - Energy transmission
KW  - Energy Transmission
KW  - Grid environments
KW  - Mathematical modeling
KW  - Mathematical Modelling
KW  - Operational technologies
KW  - Reinforcement Learning
KW  - Smart Grid
ER  - 

TY  - JOUR
TI  - Research on Personalized AEB Strategies Based on Self-Supervised Contrastive Learning
AU  - Li, H.
AU  - Jin, H.
T2  - IEEE Transactions on Intelligent Transportation Systems
AB  - In this paper, a driving style recognition method based on self-supervised contrastive learning was developed. Traditional machine learning models cannot directly accept time series data of variables as inputs, and therefore, artificially constructed statistical variables are required. The driving style recognition model proposed in this paper can directly input the raw time-series data, which can more fully preserve the driving information. On the basis of three driving styles recognition, a style factor model was designed to make the driving style continuous, and the forgetting factor was introduced to synthesize the style factor under the most recent data and the style factor under the historical data. The implementation of personalized AEB strategies involved three steps: First, using the emergency factor as an indicator, the aggressive braking strategy line was obtained statistically. Then, according to the data from calm drivers and moderate drivers, the corresponding encoder-decoder models were established to predict the longitudinal relative distance and longitudinal relative velocity. Finally, based on the aggressive braking strategy line and the encoder-decoder models, the calm braking strategy and the moderate braking strategy were designed. The proposed AEB strategies achieved a higher rate of collision avoidance than the classic Mazda, Honda, and Berkeley strategies. When the risk of collision is eliminated from test samples, on average, compared with the aggressive strategy, the calm strategy is 1.05 s earlier, while the moderate strategy is 0.58 s earlier. Such results are more in line with the expectations of different drivers, and the personalized AEB system can improve driver acceptance. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TITS.2023.3317361
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174837927&doi=10.1109%2fTITS.2023.3317361&partnerID=40&md5=d4e80d2b528a4424890eaf344edc6e2f
DB  - Scopus
KW  - Safety
KW  - Predictive models
KW  - Vehicles
KW  - Data models
KW  - Analytical models
KW  - Collision avoidance
KW  - Learning systems
KW  - Collisions avoidance
KW  - Learning models
KW  - AEB strategy
KW  - Brakes
KW  - Braking strategies
KW  - Decoding
KW  - Driving style
KW  - Driving styles
KW  - Encoder-decoder
KW  - encoder-decoder model
KW  - Encoder-decoder model
KW  - self-supervised contrastive learning model
KW  - Self-supervised contrastive learning model
KW  - Signal encoding
KW  - Time series
KW  - Time-series data
ER  - 

TY  - JOUR
TI  - Prior Knowledge Incorporated Large-Scale Multiagent Deep Reinforcement Learning for Load Frequency Control of Isolated Microgrid Considering Multi-Structure Coordination
AU  - Li, J.
AU  - Zhou, T.
T2  - IEEE Transactions on Industrial Informatics
AB  - In load frequency control (LFC) of island microgrids, the objectives of the controller and power distributor are inconsistent, which increases the frequency deviation and total generation cost. To solve this problem, a data-driven multi-input multioutput LFC (MIMO-LFC) method is proposed. Furthermore, an innate-oriented large-scale multiagent double delayed deep deterministic policy gradient algorithm is proposed for this method. The design of the algorithm is based on a human cognitive mechanism, whereby <italic>a priori</italic> knowledge is delivered to the agent before prelearning to guide the learning of the agent more effectively, thus improving the robustness of MIMO-LFC. This method integrates the controller and distributor into one agent and solves the cooperative control problem arising between the controller and power distributor by outputting the command of each unit directly. An experiment on the Zhuzhou Island microgrid verifies the effectiveness of the proposed method. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TII.2023.3316253
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174831705&doi=10.1109%2fTII.2023.3316253&partnerID=40&md5=c66d1485dd260fa74d16da47b0f28c26
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Mathematical models
KW  - Regulation
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Controllers
KW  - Robustness (control systems)
KW  - Robustness
KW  - Multi agent systems
KW  - Costs
KW  - Microgrid
KW  - Electric power system control
KW  - Co-operative control
KW  - Control methods
KW  - Cooperative control
KW  - Data driven
KW  - Data-driven multi-input multioutput load frequency control  method
KW  - data-driven multi-input multioutput load frequency control (MIMO-LFC) method
KW  - deep reinforcement learning (DRL)
KW  - effective exploration
KW  - Effective exploration
KW  - Electric control equipment
KW  - Electric frequency control
KW  - Frequency control
KW  - island microgrid
KW  - Island microgrid
KW  - Load-frequency control
KW  - Microgrids
KW  - Multi-input multi-output
KW  - Power control
KW  - Power generation
KW  - Power- generations
KW  - Press load control
ER  - 

TY  - JOUR
TI  - A Discrepancy Aware Framework for Robust Anomaly Detection
AU  - Cai, Y.
AU  - Liang, D.
AU  - Luo, D.
AU  - He, X.
AU  - Yang, X.
AU  - Bai, X.
T2  - IEEE Transactions on Industrial Informatics
AB  - Defect detection is a critical research area in artificial intelligence. Recently, synthetic data-based self-supervised learning has shown great potential on this task. Although many sophisticated synthesizing strategies exist, little research has been done to investigate the robustness of models when faced with different strategies. In this article, we focus on this issue and find that existing methods are highly sensitive to them. To alleviate this issue, we present a discrepancy aware framework (DAF), which demonstrates robust performance consistently with simple and cheap strategies across different anomaly detection benchmarks. We hypothesize that the high sensitivity to synthetic data of existing self-supervised methods arises from their heavy reliance on the visual appearance of synthetic data during decoding. In contrast, our method leverages an appearance-agnostic cue to guide the decoder in identifying defects, thereby alleviating its reliance on synthetic appearance. To this end, inspired by existing knowledge distillation methods, we employ a teacher-student network, which is trained based on synthesized outliers, to compute the discrepancy map as the cue. Extensive experiments on two challenging datasets prove the robustness of our method. Under the simple synthesis strategies, it outperforms existing methods by a large margin. Furthermore, it also achieves the state-of-the-art localization performance. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TII.2023.3318302
SP  - 1
EP  - 10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174819201&doi=10.1109%2fTII.2023.3318302&partnerID=40&md5=d67ed69e94513df294a49a8610cfedcb
DB  - Scopus
KW  - Artificial intelligence
KW  - Data models
KW  - Training
KW  - robustness
KW  - Supervised learning
KW  - Anomaly detection
KW  - Benchmarking
KW  - Robustness
KW  - Simple++
KW  - Decoding
KW  - Critical researches
KW  - Defect detection
KW  - Defects
KW  - Distillation
KW  - Head
KW  - Image reconstruction
KW  - Images reconstruction
KW  - self-supervised learning
KW  - Self-supervised learning
KW  - Synthetic data
ER  - 

TY  - JOUR
TI  - On the Optimality, Stability, and Feasibility of Control Barrier Functions: An Adaptive Learning-Based Approach
AU  - Chriat, A.E.
AU  - Sun, C.
T2  - IEEE Robotics and Automation Letters
AB  - Safety has been a critical issue for the deployment of learning-based approaches in real-world applications. To address this issue, control barrier function (CBF) and its variants have attracted extensive attention for safety-critical control. However, due to the myopic one-step nature of CBF and the lack of principled methods to design the class-K functions, there are still fundamental limitations of current CBFs: optimality, stability, and feasibility. In this paper, we proposed a novel and unified approach to address these limitations with Adaptive Multi-step Control Barrier Function (AM-CBF), where we parameterize the class-K function by a neural network and train it together with the reinforcement learning policy. Moreover, to mitigate the myopic nature, we propose a novel <italic>multi-step training and single-step execution paradigm to make CBF farsighted while the execution</italic> remains solving a single-step convex quadratic program. Our method is evaluated on the first and second-order systems in various scenarios, where our approach outperforms the conventional CBF both qualitatively and quantitatively. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/LRA.2023.3322088
SP  - 1
EP  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174852486&doi=10.1109%2fLRA.2023.3322088&partnerID=40&md5=574dc570557b865564eeee4b1aa84bdb
DB  - Scopus
KW  - Reinforcement learning
KW  - Safety
KW  - Measurement
KW  - Training
KW  - Reinforcement learnings
KW  - Adaptive control systems
KW  - Safety engineering
KW  - Barriers functions
KW  - Control barriers
KW  - Quadratic programming
KW  - Optimality
KW  - Dynamical systems
KW  - Lyapunov methods
KW  - Lyapunov's methods
KW  - Reinforcement Learning
KW  - Aienabled robotic
KW  - AIEnabled Robotics
KW  - Learning-based approach
KW  - Programming
KW  - Robot programming
KW  - Robot safety
KW  - Robot Safety
ER  - 

TY  - JOUR
TI  - Robust Wind-Resistant Hovering Control of Quadrotor UAVs Using Deep Reinforcement Learning
AU  - Xue, J.
AU  - Liu, Z.
AU  - Liu, G.
AU  - Zhou, Z.
AU  - Zhang, K.
AU  - Tang, Y.
AU  - Wang, J.
T2  - IEEE Transactions on Intelligent Vehicles
AB  - Unmanned Aerial Vehicles (UAVs) have extensive applications such as logistics transportation and aerial photography. However, UAVs are sensitive to winds. Traditional control methods, such as proportional- integral-derivative controllers, generally fail to work well when the strength and direction of winds are changing frequently. In this work deep reinforcement learning algorithms are combined with a domain randomization method to learn robust wind-resistant hovering policies. A novel reward function is designed to guide learning. This reward function uses a constant reward to maintain a continuous flight of a UAV as well as a weight of the horizontal distance error to ensure the stability of the UAV at altitude. A five-dimensional representation of actions instead of the traditional four dimensions is designed to strengthen the coordination of wings of a UAV. We theoretically explain the rationality of our reward function based on the theories of Q-learning and reward shaping. Experiments in the simulation and real-world application both illustrate the effectiveness of our method. To the best of our knowledge, it is the first paper to use reinforcement learning and domain randomization to explore the problem of robust wind-resistant hovering control of quadrotor UAVs, providing a new way for the study of wind-resistant hovering and flying of UAVs. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TIV.2023.3324687
SP  - 1
EP  - 10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174856965&doi=10.1109%2fTIV.2023.3324687&partnerID=40&md5=7649349ca4f73c3ccd5d3f35cee78d2f
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Task analysis
KW  - Training
KW  - UAV
KW  - robustness
KW  - Job analysis
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Robustness
KW  - Proportional control systems
KW  - Stochastic systems
KW  - Unmanned aerial vehicles (UAV)
KW  - Heuristic algorithms
KW  - Antennas
KW  - Autonomous aerial vehicles
KW  - Heuristics algorithm
KW  - Aerial photography
KW  - Aerial vehicle
KW  - domain randomization
KW  - Domain randomization
KW  - hovering
KW  - Hovering
KW  - Quad rotors
KW  - Quadrotors
KW  - Random processes
KW  - Randomisation
KW  - Two term control systems
KW  - Unmanned aerial vehicle
KW  - Wind
ER  - 

TY  - JOUR
TI  - Label-weighted Graph-based Learning for Semi-supervised Classification under Label Noise
AU  - Liang, N.
AU  - Yang, Z.
AU  - Chen, J.
AU  - Li, Z.
AU  - Xie, S.
T2  - IEEE Transactions on Big Data
AB  - Graph-based semi-supervised learning (GSSL) is a quite important technology due to its effectiveness in practice. Existing GSSL works often treat the given labels equally and ignore the unbalance importance of labels. In some inaccurate systems, the collected labels usually contain noise (noisy labels) and the methods treating labels equally suffer from the label noise. In this paper, we propose a novel label-weighted learning method on graph for semi-supervised classification under label noise, which allows considering the contribution differences of labels. In particular, the label dependency of data is revealed by graph constraints. With the help of this label dependency, the proposed method develops the strategy of adaptive label weight, where label weights are assigned to labels adaptively. Accordingly, an efficient algorithm is developed to solve the proposed optimization objective, where each subproblem has a closed-form solution. Experimental results on a synthetic dataset and several real-world datasets show the advantage of the proposed method, compared to the state-of-the-art methods. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TBDATA.2023.3319249
SP  - 1
EP  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173024338&doi=10.1109%2fTBDATA.2023.3319249&partnerID=40&md5=e595d10ed5529421d9a7a0c1311b9ed6
DB  - Scopus
KW  - Deep learning
KW  - Big Data
KW  - Optimization
KW  - Robustness
KW  - Adaptation models
KW  - Noise measurement
KW  - Synthetic data
KW  - adaptive label weight
KW  - Graph-based learning
KW  - label noise
KW  - semi-supervised classification
ER  - 

TY  - CHAP
TI  - Enhancing Children's Fire Safety Skills with Machine Learning-Powered Virtual Reality Training System
AU  - Ali, Y.W.
AU  - Abdel-Basset, M.K.
AU  - Ghaly, M.T.
AU  - Amin, L.A.
AU  - Mousa, A.A.
AU  - Sayed, G.I.
T2  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Fires, regardless of whether they are small or huge, can have a profound effect on anyone, especially children. They can cause not only some serious physical harm but also could lead to long-term psychological trauma to them. The old-fashioned training ways, either tutorials or a real fire simulation cannot be suitable for children. In this paper, a new fire safety training system based on using virtual reality (VR) and machine learning for training children how to deal with fire is proposed. The proposed system consists of two main parts working in parallel, the first part is called the VR simulator, and the second part is called the Non-Player Character (NPC) recommendation system. Two well-known machine learning algorithms are used and evaluated. These algorithms are support vector machine (SVM) and neural networks. The experimental results revealed SVM with polynomial obtained the best result. The proposed system obtained overall accuracy of 90.8%, precision of 90.7%, recall of 90.8%, and f-score of 90.7%. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
VL  - 184
SP  - 542
EP  - 551
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172412295&doi=10.1007%2f978-3-031-43247-7_47&partnerID=40&md5=565e9dd5d56e7dcf94ce8af4fd4717a2
DB  - Scopus
KW  - Recommender systems
KW  - Machine learning
KW  - Support vector machines
KW  - Virtual reality
KW  - Learning systems
KW  - Learning algorithms
KW  - E-learning
KW  - Machine-learning
KW  - Fire drill
KW  - Fire safety
KW  - Fire simulation
KW  - Fires
KW  - Psychological traumata
KW  - Real fire
KW  - Recommendation system
KW  - Support vectors machine
KW  - Training Systems
KW  - Virtual fire drill
KW  - Virtual Fire Drills
KW  - Virtual Reality
KW  - Virtual reality training
ER  - 

TY  - JOUR
TI  - Making algorithms safe for workers: occupational risks associated with work managed by artificial intelligence
AU  - Todolí-Signes, A
T2  - TRANSFER-EUROPEAN REVIEW OF LABOUR AND RESEARCH
AB  - It is increasingly common for companies to use artificial intelligence mechanisms to manage work. This study examines the health hazards caused by these new forms of technological management. Occupational risks can be reduced if they are taken into account when programming an algorithm. This study confirms the need for algorithms to be correctly programmed, taking account of these occupational risks. In the same way as supervisors have to be trained in risk prevention to be able to perform their work, the algorithm must be programmed to weigh up the occupational risks - and when such features do not exist, steps must be taken to prevent the algorithm being used to direct workers. The algorithm must assess all (known) factors posing a risk to workers' health and safety. It therefore seems necessary to incorporate a mandatory risk assessment performed by specialists in the programming of algorithms so that all ascertained risks can be taken into account.
DA  - 2021/11//undefined
PY  - 2021
DO  - 10.1177/10242589211035040
VL  - 27
IS  - 4
SP  - 433
EP  - 452
SN  - 1024-2589
AN  - WOS:000683965500001
ER  - 

TY  - CONF
TI  - Uncertainty Wrappers for Data-Driven Models Increase the Transparency of AI/ML-Based Models Through Enrichment with Dependable Situation-Aware Uncertainty Estimates
AU  - Kläs, M
AU  - Sembach, L
T2  - COMPUTER SAFETY, RELIABILITY, AND SECURITY, SAFECOMP 2019
A2  - Romanovsky, A
A2  - Troubitsyna, E
A2  - Gashi, I
A2  - Schoitsch, E
A2  - Bitsch, F
AB  - In contrast to established safety-critical software components, we can neither prove nor assume that the outcomes of components containing models based on artificial intelligence (AI) or machine learning (ML) will be correct in any situation. Thus, uncertainty is an inherent part of decision-making when using the outcomes of data-driven models created by AI/ML algorithms. In order to deal with this - especially in the context of safety-related systems - we need to make uncertainty transparent via dependable statistical statements. This paper introduces both a conceptual model and the related mathematical foundation of an uncertainty wrapper solution for data-driven models. The wrapper enriches existing data-driven models such as provided by ML or other AI techniques with case-individual and sound uncertainty estimates. The task of traffic sign recognition is used to illustrate the approach, which considers uncertainty not only in terms of model fit but also in terms of data quality and scope compliance.
DA  - 2019///
PY  - 2019
DO  - 10.1007/978-3-030-26250-1_29
VL  - 11699
SP  - 358
EP  - 364
SN  - 0302-9743
AN  - WOS:000561031400032
KW  - Artificial intelligence
KW  - Machine learning
KW  - Decision making
KW  - Pattern recognition
KW  - Learning systems
KW  - Systems engineering
KW  - Traffic signs
KW  - Safety engineering
KW  - Uncertainty analysis
KW  - Computer privacy
KW  - Data quality
KW  - Dependability
KW  - Embedded systems
KW  - Estimation
KW  - Machine components
KW  - Mathematical foundations
KW  - Model validation
KW  - Operational design
KW  - Operational design domain
KW  - Reactor cores
KW  - Safety critical software
KW  - Safety-related systems
KW  - Software reliability
KW  - Traffic sign recognition
ER  - 

TY  - JOUR
TI  - Safe Model-Based Off-Policy Reinforcement Learning for Eco-Driving in Connected and Automated Hybrid Electric Vehicles
AU  - Zhu, ZX
AU  - Pivaro, N
AU  - Gupta, S
AU  - Gupta, A
AU  - Canova, M
T2  - IEEE TRANSACTIONS ON INTELLIGENT VEHICLES
AB  - Deep Reinforcement Learning (DRL) has recently been applied to eco-driving to intelligently reduce fuel consumption and travel time. While previous studies synthesize simulators and model-free DRL (MFDRL), this work proposes a Safe Off-policy Model-Based Reinforcement Learning (SMORL) algorithm for eco-driving. SMORL integrates three key components, namely a computationally efficient model-based trajectory optimizer, a value function learned off-policy and a learned safe set. The advantages over the existing literature are three-fold. First, the combination of off-policy learning and the use of a physics-based model improves the sample efficiency. Second, the training does not require any extrinsic rewarding mechanism for constraint satisfaction. Third, the feasibility of trajectory is guaranteed by using a safe set approximated by deep generative models. The performance of SMORL is benchmarked over 100 trips against a baseline controller representing human drivers, a non-learning-based optimal controller, a previously designed MFDRL strategy, and the wait-and-see optimal solution. In simulation, SMORL reduces the fuel consumption by more than 21% while keeping the average speed comparable while compared to the baseline controller and demonstrates a better fuel economy while driving faster compared to the MFDRL agent and the non-learning-based optimal controller.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1109/TIV.2022.3150668
VL  - 7
IS  - 2
SP  - 387
EP  - 398
SN  - 2379-8858
AN  - WOS:000838544400024
KW  - Deep learning
KW  - Reinforcement learning
KW  - Biological system modeling
KW  - generative models
KW  - Automated vehicles
KW  - Controllers
KW  - Safety engineering
KW  - Optimization
KW  - Computational modelling
KW  - Vehicle's dynamics
KW  - Model-based reinforcement learning
KW  - Travel time
KW  - Connected and automated vehicle
KW  - Fuel economy
KW  - Safety critical applications
KW  - Generative model
KW  - Load modeling
KW  - connected and automated vehicles
KW  - Biological systems
KW  - Fuels
KW  - Hybrid vehicles
KW  - Policy model
KW  - safety-critical applications
ER  - 

TY  - JOUR
TI  - Using Crowdsourced Data to Improve Models of Traffic Crash Propensity: Tennessee Highway Patrol Case Study
AU  - Flynn, DFB
AU  - Gilmore, MM
AU  - Dolan, JP
AU  - Teicher, P
AU  - Sudderth, EA
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Crowdsourced mobile applications such as Waze can provide real-time and historical data about roadway conditions, when and where users are active. In a previous study, we demonstrated that statewide crash models based on integrated Waze, traffic volume, census, and weather data give reliable hourly estimates of police-reportable crashes in 1-mi area grids at 1-h timescales. Here, we extend our analytical methods to test an application of Waze traffic alerts to a crash prediction model used to guide law enforcement resource allocation. The Crash Reduction Analyzing Statistical History (CRASH) model is used by the Tennessee Highway Patrol (THP) to prioritize patrol locations. The model combines historical data such as fatal crashes with current data, including weather forecasts and scheduled special events, to identify areas with a high likelihood of crashes. To more accurately target locations and times with a high crash propensity, we assessed the potential for Waze alerts to improve the temporal and spatial resolution of the CRASH model. We found that with Waze data, we increased the spatial resolution of crash estimates from 42 to 1 mi(2) and the temporal resolution from 4- to 1-h time windows, while improving accuracy. The model provides a high-resolution option for the allocation of patrols, which will help THP to optimize the allocation of troopers to the highest-risk locations. Beyond the current implementation in Tennessee, the model's incorporation of crowdsourced data has shown potential for similar types of data-driven safety approaches elsewhere.
DA  - 2022/08//undefined
PY  - 2022
DO  - 10.1177/03611981221083305
VL  - 2676
IS  - 8
SP  - 267
EP  - 278
SN  - 0361-1981
AN  - WOS:000775757600001
ER  - 

TY  - JOUR
TI  - Toward Trustworthy AI: Blockchain-Based Architecture Design for Accountability and Fairness of Federated Learning Systems
AU  - Lo, SK
AU  - Liu, Y
AU  - Lu, QH
AU  - Wang, C
AU  - Xu, XW
AU  - Paik, HY
AU  - Zhu, LM
T2  - IEEE INTERNET OF THINGS JOURNAL
AB  - Federated learning is an emerging privacy-preserving AI technique where clients (i.e., organizations or devices) train models locally and formulate a global model based on the local model updates without transferring local data externally. However, federated learning systems struggle to achieve trustworthiness and embody responsible AI principles. In particular, federated learning systems face accountability and fairness challenges due to multistakeholder involvement and heterogeneity in client data distribution. To enhance the accountability and fairness of federated learning systems, we present a blockchain-based trustworthy federated learning architecture. We first design a smart contract-based data-model provenance registry to enable accountability. Additionally, we propose a weighted fair data sampler algorithm to enhance fairness in training data. We evaluate the proposed approach using a COVID-19 X-ray detection use case. The evaluation results show that the approach is feasible to enable accountability and improve fairness. The proposed algorithm can achieve better performance than the default federated learning setting in terms of the model's generalization and accuracy.
DA  - 2023/02/15/
PY  - 2023
DO  - 10.1109/JIOT.2022.3144450
VL  - 10
IS  - 4
SP  - 3276
EP  - 3284
SN  - 2327-4662
AN  - WOS:000965596000001
ER  - 

TY  - JOUR
TI  - Model-Free Safe Reinforcement Learning Through Neural Barrier Certificate
AU  - Yang, YJ
AU  - Jiang, YX
AU  - Liu, YC
AU  - Chen, JY
AU  - Li, SE
T2  - IEEE ROBOTICS AND AUTOMATION LETTERS
AB  - Safety is a critical concern when applying reinforcement learning (RL) to real-world control tasks. However, existing safe RL works either only consider expected safety constraint violations and fail to maintain safety guarantees, or use overly conservative safety certificate tools borrowed from safe control theory, which sacrifices reward optimization and relies on analytic system models. This letter proposes a model-free safe RL algorithm that achieves near-zero constraint violations with high rewards. Our key idea is to jointly learn a policy and a neural barrier certificate under stepwise state constraint setting. The barrier certificate is learned in a model-free manner by minimizing the violations of appropriate barrier properties on transition data collected by the policy. We extend the single-step invariant property of the barrier certificate to a multi-step version and construct the corresponding multi-step invariant loss. This loss balances the bias and variance of the barrier certificate and enhances both the safety and performance of the policy. The policy is optimized under the constraint of the multi-step invariant property using the Lagrangian method. We optimize the policy in a model-free manner by introducing an importance sampling weight in the constraint. We test our algorithm on multiple problems, including classic control tasks, robot collision avoidance, and autonomous driving. Results show that our algorithm achieves near-zero constraint violations and high performance compared to the baselines. Moreover, the learned barrier certificates successfully identify the feasible regions on multiple tasks.
DA  - 2023/03//undefined
PY  - 2023
DO  - 10.1109/LRA.2023.3238656
VL  - 8
IS  - 3
SP  - 1295
EP  - 1302
SN  - 2377-3766
AN  - WOS:000923839100012
KW  - Reinforcement learning
KW  - Task analysis
KW  - Robots
KW  - reinforcement learning
KW  - Analytical models
KW  - Job analysis
KW  - Reinforcement learnings
KW  - Computation theory
KW  - Model free
KW  - Computational modelling
KW  - Robot safety
KW  - Barrier certificates
KW  - Constraint violation
KW  - Control task
KW  - Importance sampling
KW  - Multisteps
KW  - neural barrier certificate
KW  - Neural barrier certificate
ER  - 

TY  - JOUR
TI  - Safety-Integrated Online Deep Reinforcement Learning for Mobile Energy Storage System Scheduling and Volt/VAR Control in Power Distribution Networks
AU  - Jeon, S
AU  - Nguyen, HT
AU  - Choi, DH
T2  - IEEE ACCESS
AB  - In coupled power distribution and transportation (CPT) system, a joint scheduling framework for mobile energy storage systems (MESSs) and Volt/VAR control (VVC) ensures reliable power distribution grid operations while supporting electric vehicle loads at electric vehicle charging stations (EVCSs). However, conventional model-based optimization methods for MESS scheduling and VVC may yield suboptimal solutions and greater computation times because of MESS operation and VVC in uncertain environment of CPT systems. To resolve this issue, this study proposes a model-free deep reinforcement learning (DRL) framework. In this framework, smart inverters of MESSs and solar photovoltaic (PV) systems cooperate to minimize the real power loss and mitigate the violations of both MESSs' state of charge (SOC) and voltage in the power distribution network, while MESSs travel via the transportation network to satisfy EV loads at EVCSs. A MESS routing algorithm based on Dijkstra's algorithm is developed to determine the optimal destinations of the MESSs. In addition, two safety modules are developed to ensure that neither SOC nor voltage violations occur by adjusting real and/or reactive power of MESSs and PV systems during the training process. The developed MESS routing algorithm and safety modules are integrated into the proposed DRL framework, wherein the DRL agent performs the desired MESS scheduling and VVC through safe exploration during the training procedure. The proposed approach is tested in coupled IEEE 33-bus power distribution and 15-node transportation systems and coupled IEEE 57-bus power distribution and 42-node transportation systems. Numerical examples demonstrate the advantages of the proposed approach in terms of training convergence, real power loss, and SOC/voltage violation.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ACCESS.2023.3264687
VL  - 11
SP  - 34440
EP  - 34455
SN  - 2169-3536
AN  - WOS:000970535100001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Transportation system
KW  - E-learning
KW  - Online systems
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Power distributions
KW  - Electric inverters
KW  - Electric power system control
KW  - Electric power distribution
KW  - Power control
KW  - Reactive power
KW  - Solar power generation
KW  - Safe exploration
KW  - Storage systems
KW  - Electric loads
KW  - Electric network analysis
KW  - Coupled power
KW  - coupled power distribution and transportation system
KW  - Coupled power distribution and transportation system
KW  - Energy storage
KW  - Inverter
KW  - Load modeling
KW  - mobile energy storage system
KW  - Mobile energy storage system
KW  - Power-distribution system
KW  - safe exploration
KW  - smart inverter
KW  - Smart inverters
KW  - VAR control
KW  - Volt/VAR control
ER  - 

TY  - JOUR
TI  - Grand challenges for ambient intelligence and implications for design contexts and smart societies
AU  - Streitz, N
AU  - Charitos, D
AU  - Kaptein, M
AU  - Böhlen, M
T2  - JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS
AB  - This paper highlights selected grand challenges that concern especially the social and the design dimensions of research and development in Ambient Intelligence (AmI) and Smart Environments (SmE). Due to the increasing deployment and usage of 'smart' technologies determining a wide range of everyday life activities, there is an urgent need to reconsider their societal implications and how to address these implications with appropriate design methods. The paper presents four perspectives on the subject grounded in different approaches. First, introducing and reflecting on the implications of the 'smart-everything' paradigm, the resulting design trade-offs and their application to smart cities. Second, discussing the potential of non-verbal communication for informing the design of spatial interfaces for AmI design practices. Third, reflecting on the role of new data categories such as 'future data' and the role of uncertainty and their implications for the next generation of AmI environments. Finally, debating the merits and shortfalls of the world's largest professional engineering community effort to craft a global standards body on ethically aligned design for autonomous and intelligent systems. The paper benefits from taking different perspectives on common issues, provides commonalities and relationships between them and provides anchor points for important challenges in the field of ambient intelligence.
DA  - 2019///
PY  - 2019
DO  - 10.3233/AIS-180507
VL  - 11
IS  - 1
SP  - 87
EP  - 107
SN  - 1876-1364
AN  - WOS:000457824700006
KW  - Artificial intelligence
KW  - Machine learning
KW  - Intelligent systems
KW  - GDPR
KW  - Human in the loop
KW  - Learning systems
KW  - Smart city
KW  - Learning algorithms
KW  - Economic and social effects
KW  - Uncertainty
KW  - Privacy by design
KW  - Commerce
KW  - Design
KW  - Data science
KW  - Ethically aligned design
KW  - Data Science
KW  - Self-aware
KW  - Algorithmic transparency
KW  - Ambient intelligence
KW  - Autonomous intelligent systems
KW  - Citizen-centered design
KW  - Communication interface
KW  - Design trade-offs
KW  - Design tradeoff
KW  - Future data
KW  - General artificial intelligence
KW  - General data protection regulations
KW  - Governance of technology
KW  - Human control
KW  - Human-in-the-loop
KW  - Humane and sociable AmI
KW  - Hybrid city
KW  - Iodine compounds
KW  - Multi-armed bandit problem
KW  - Non-verbal communication
KW  - Non-verbal communications
KW  - Opaque AI
KW  - Samarium compounds
KW  - Self-aware city
KW  - Smart environment
KW  - Smart environments
KW  - Smart-everything
KW  - Spatial communication interfaces
KW  - Traceability of algorithms
ER  - 

TY  - JOUR
TI  - Safe Reinforcement Learning for Model-Reference Trajectory Tracking of Uncertain Autonomous Vehicles With Model-Based Acceleration
AU  - Hu, YF
AU  - Fu, JJ
AU  - Wen, GH
T2  - IEEE TRANSACTIONS ON INTELLIGENT VEHICLES
AB  - Applying reinforcement learning (RL) algorithms to control systems design remains a challenging task due to the potential unsafe exploration and the low sample efficiency. In this paper, we propose a novel safe model-based RL algorithm to solve the collision-free model-reference trajectory tracking problem of uncertain autonomous vehicles (AVs). Firstly, a new type of robust control barrier function (CBF) condition for collision-avoidance is derived for the uncertain AVs by incorporating the estimation of the system uncertainty with Gaussian process (GP) regression. Then, a robust CBF-based RL control structure is proposed, where the nominal control input is composed of the RL policy and a model-based reference control policy. The actual control input obtained from the quadratic programming problem can satisfy the constraints of collision-avoidance, input saturation and velocity boundedness simultaneously with a relatively high probability. Finally, within this control structure, a Dyna-style safe model-based RL algorithm is proposed, where the safe exploration is achieved through executing the robust CBF-based actions and the sample efficiency is improved by leveraging the GP models. The superior learning performance of the proposed RL control structure is demonstrated through simulation experiments.
DA  - 2023/03//undefined
PY  - 2023
DO  - 10.1109/TIV.2022.3233592
VL  - 8
IS  - 3
SP  - 2332
EP  - 2344
SN  - 2379-8858
AN  - WOS:000981348100029
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - autonomous vehicle
KW  - Predictive models
KW  - Collision avoidance
KW  - Autonomous Vehicles
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Uncertainty
KW  - Efficiency
KW  - Model predictive control
KW  - Robust control
KW  - Barriers functions
KW  - Control barriers
KW  - Quadratic programming
KW  - Safe reinforcement learning
KW  - Trajectories
KW  - Heuristic algorithms
KW  - safe reinforcement learning
KW  - Control barrier function
KW  - Trajectory-tracking
KW  - Heuristics algorithm
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Gaussian process
KW  - Gaussian Processes
KW  - control barrier function
KW  - Model reference control
KW  - model-based reinforcement learning
KW  - Model-based reinforcement learning
KW  - Model-reference control
ER  - 

TY  - JOUR
TI  - Distributed safe formation maneuver control of Euler-Lagrange multi-agent systems in a partially unknown environment by safe reinforcement learning
AU  - Golmisheh, FM
AU  - Shamaghdari, S
T2  - ROBOTICS AND AUTONOMOUS SYSTEMS
AB  - This paper describes a multi-layer approach to the problem of safe formation control. The agents' and the leader's dynamics are considered unknown Euler-Lagrange (E-L) systems. In addition, the environment is partially unknown. We propose a novel layered approach to reach the predefined target while preserving a designed, safe, optimal formation pattern along a planned optimal path. By satisfying the safety constraints, safe reinforcement learning (RL) is introduced to ensure the leader reaches the desired destination without collision. Maintaining a constant formation pattern is unsafe for followers since they are not familiar with the surroundings. Thus, we define the formation maneuver control problem, which can adjust formation geomatical patterns dynamically depending on the environment. A proposed algorithm based on the leader's designed path is defined to solve the problem. Using off-policy RL, the model-free distributed control law is presented to generate a designed formation pattern in a determined optimal path. Finally, we demonstrate that the proposed approach can be applied to the safe formation maneuver problem in an environment with convex obstacles. This paper presents a safe formation control strategy that addresses practical issues, such as model uncertainty, without requiring sensor measurements in an unknown, static environment without uncertainty. Simulation demonstrates the effectiveness of the suggested approaches for a group of Uncrewed Surface Vehicles (USVs). & COPY; 2023 Elsevier B.V. All rights reserved.
DA  - 2023/09//undefined
PY  - 2023
DO  - 10.1016/j.robot.2023.104486
VL  - 167
SN  - 0921-8890
AN  - WOS:001034709300001
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Uncertainty analysis
KW  - Multi agent systems
KW  - Lagrange multipliers
KW  - Barriers functions
KW  - Control barriers
KW  - Safe reinforcement learning
KW  - Control barrier function
KW  - Distributed parameter control systems
KW  - Euler-Lagrange
KW  - Euler–lagrange multi-agent system
KW  - Euler–Lagrange multi-agent system
KW  - Formation maneuver
KW  - Formation maneuver control
KW  - Multi-layer approach
KW  - Multi-layers
KW  - Off-policy reinforcement learning
ER  - 

TY  - JOUR
TI  - On the Safety of Machine Learning: Cyber-Physical Systems, Decision Sciences, and Data Products
AU  - Varshney, KR
AU  - Alemzadeh, H
T2  - BIG DATA
AB  - Machine learning algorithms increasingly influence our decisions and interact with us in all parts of our daily lives. Therefore, just as we consider the safety of power plants, highways, and a variety of other engineered socio-technical systems, we must also take into account the safety of systems involving machine learning. Heretofore, the definition of safety has not been formalized in a machine learning context. In this article, we do so by defining machine learning safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. We then use this definition to examine safety in all sorts of applications in cyber-physical systems, decision sciences, and data products. We find that the foundational principle of modern statistical machine learning, empirical risk minimization, is not always a sufficient objective. We discuss how four different categories of strategies for achieving safety in engineering, including inherently safe design, safety reserves, safe fail, and procedural safeguards can be mapped to a machine learning context. We then discuss example techniques that can be adopted in each category, such as considering interpretability and causality of predictive models, objective functions beyond expected prediction accuracy, human involvement for labeling difficult or rare examples, and user experience design of software and open data.
DA  - 2017/09//undefined
PY  - 2017
DO  - 10.1089/big.2016.0051
VL  - 5
IS  - 3
SP  - 246
EP  - 255
SN  - 2167-6461
AN  - WOS:000425010500008
KW  - machine learning
KW  - Safety
KW  - Decision Making
KW  - Machine Learning
KW  - Algorithms
KW  - safety
KW  - algorithm
KW  - decision making
KW  - cyber-physical systems
KW  - data products
KW  - decision science
KW  - economics
ER  - 

TY  - JOUR
TI  - Behavioral, data-driven, agent-based evacuation simulation for building safety design using machine learning and discrete choice models
AU  - Zhu, RH
AU  - Becerik-Gerber, B
AU  - Lin, J
AU  - Li, N
T2  - ADVANCED ENGINEERING INFORMATICS
AB  - To improve occupant safety during building emergencies, evacuation simulations have been widely used for building safety design. Since occupant behavior is a determining factor for the outcome of building emergencies, accurately capturing how occupants make decisions and integrating occupants' decision-making processes in evacuation simulations is important. In this study, based on the results of fire evacuation experiments in a virtual metro station, how different social (crowd flow) and environmental (visual access and vertical movement) factors would affect individuals' wayfinding behavior was predicted using machine learning and discrete choice models. The trained models were further employed in agent-based evacuation simulations to examine crowd evacuation performance under different building design scenarios. Both the machine learning and discrete choice models could accurately predict individuals' directional choices during emergency evacuations. Different building attributes could collectively influence occupant behavior, leading to distinct exit choices and evacuation times. While both the trained machine learning and discrete choice models generated similar results, the discrete choice model had better interpretability. Moreover, by comparing the trained models in this study with a model developed in a prior study, it was found that agents had significantly distinct responses to different building designs. Critical factors (e.g., type and size of buildings, occupants' familiarity with the building) for the applicability of evacuation models were identified. Furthermore, recommendations were provided for future research that aims at employing evacuation simulations for building design evaluation and optimization.
DA  - 2023/01//undefined
PY  - 2023
DO  - 10.1016/j.aei.2022.101827
VL  - 55
SN  - 1474-0346
AN  - WOS:000895039900003
KW  - Machine learning
KW  - Decision making
KW  - Machine-learning
KW  - Subway stations
KW  - Data driven
KW  - Building safety
KW  - Architectural design
KW  - Agent-based evacuations
KW  - Building design
KW  - Building safety design
KW  - Data-driven
KW  - Discrete choice model
KW  - Discrete choice models
KW  - Evacuation simulation
KW  - Occupants behaviours
KW  - Safety design
ER  - 

TY  - JOUR
TI  - Safe Off-Policy Deep Reinforcement Learning Algorithm for Volt-VAR Control in Power Distribution Systems
AU  - Wang, W
AU  - Yu, NP
AU  - Gao, YQ
AU  - Shi, J
T2  - IEEE TRANSACTIONS ON SMART GRID
AB  - Volt-VAR control is critical to keeping distribution network voltages within allowable range, minimizing losses, and reducing wear and tear of voltage regulating devices. To deal with incomplete and inaccurate distribution network models, we propose a safe off-policy deep reinforcement learning algorithm to solve Volt-VAR control problems in a model-free manner. The Volt-VAR control problem is formulated as a constrained Markov decision process with discrete action space, and solved by our proposed constrained soft actor-critic algorithm. Our proposed reinforcement learning algorithm achieves scalability, sample efficiency, and constraint satisfaction by synergistically combining the merits of the maximum-entropy framework, the method of multiplier, a device-decoupled neural network structure, and an ordinal encoding scheme. Comprehensive numerical studies with the IEEE distribution test feeders show that our proposed algorithm outperforms the existing reinforcement learning algorithms and conventional optimization-based approaches on a large feeder.
DA  - 2020/07//undefined
PY  - 2020
DO  - 10.1109/TSG.2019.2962625
VL  - 11
IS  - 4
SP  - 3008
EP  - 3018
SN  - 1949-3053
AN  - WOS:000542571700022
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - Markov processes
KW  - Constrained Markov decision process
KW  - safe reinforcement learning
KW  - Constraint Satisfaction
KW  - Actor-critic algorithm
KW  - Value engineering
KW  - Maximum entropy methods
KW  - Volt-VAR control
KW  - model-free
KW  - Conventional optimization
KW  - Maximum entropy frameworks
KW  - Neural network structures
KW  - off-policy
KW  - Power distribution system
KW  - Voltage regulating devices
ER  - 

TY  - CONF
TI  - Safety and Performance, Why not Both? Bi-Objective Optimized Model Compression toward AI Software Deployment
AU  - Zhu, J
AU  - Wang, LY
AU  - Han, X
T2  - PROCEEDINGS OF THE 37TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE 2022
AB  - The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, which hinders the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in the big model may be inherited by the compressed one. Such defects may be easily leveraged by attackers, since the compressed models are usually deployed in a large number of devices without adequate protection. In this paper, we try to address the safe model compression problem from a safety-performance co-optimization perspective. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as the safety test, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm. Further, considering a representative attack, i.e., membership inference attack (MIA), we develop a concrete safe model compression mechanism, called MIA-SafeCompress. Extensive experiments are conducted to evaluate MIA-SafeCompress on five datasets for both computer vision and natural language processing tasks. The results verify the effectiveness and generalization of our method. We also discuss how to adapt SafeCompress to other attacks besides MIA, demonstrating the flexibility of SafeCompress.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3551349.3556906
SN  - 1527-1366
AN  - WOS:001062775200014
ER  - 

TY  - JOUR
TI  - The promise of artificial intelligence in chemical engineering: Is it here, finally?
AU  - Venkatasubramanian, V
T2  - AICHE JOURNAL
DA  - 2019/02//undefined
PY  - 2019
DO  - 10.1002/aic.16489
VL  - 65
IS  - 2
SP  - 466
EP  - 478
SN  - 0001-1541
AN  - WOS:000459660200001
KW  - machine learning
KW  - AI
KW  - design
KW  - safety
KW  - optimization
KW  - data science
KW  - predictive analytics
KW  - control
KW  - diagnosis
KW  - materials science
ER  - 

TY  - CONF
TI  - SafeOps: a concept of continuous safety
AU  - Fayollas, C
AU  - Bonnin, H
AU  - Flebus, O
T2  - 2020 16TH EUROPEAN DEPENDABLE COMPUTING CONFERENCE (EDCC 2020)
AB  - Improved safety is one of the key benefits expected from autonomous vehicles. This can only be achieved if the autonomous vehicles are guaranteed to be safe enough. This paper proposes a potential approach contributing to this safety improvement: it describes and investigates "SafeOps", a concept of "continuous safety", based on the DevOps approach, unifying development and operations. DevOps consists in a set of practices intended to reduce the time between committing a change to a system and the change being deployed into production, while ensuring high quality. DevOps benefits to system development and delivery by enabling software continuous delivery, faster changes management with faster issues resolution, and improved reliability. SafeOps key principle is to monitor the system in operation and to use this information for validating and certifying a certain safety assurance level. Following this approach, a system could be compliant to a first safety assurance level when it's first delivered and compliant to higher ones when validated in operation.
DA  - 2020///
PY  - 2020
DO  - 10.1109/EDCC51268.2020.00020
SP  - 65
EP  - 68
SN  - 978-1-7281-8936-9
AN  - WOS:000630473500010
KW  - Artificial Intelligence
KW  - Autonomous vehicles
KW  - Machine Learning
KW  - Safety engineering
KW  - Software reliability
KW  - Functional Safety
KW  - Safety assurance
KW  - Safety improvement
KW  - High quality
KW  - DevOps
KW  - System development
KW  - CI/CD
KW  - Cloud-Native Systems
KW  - Continuous Deployment
KW  - Continuous Integration
KW  - Data-intensive Systems
KW  - Development and operations
ER  - 

TY  - CONF
TI  - Diagnosing and Addressing Emergent Harms in the Design Process of Public AI and Algorithmic Systems
AU  - Nouws, SJJ
AU  - de Troya, IMD
AU  - Dobbe, RIJ
AU  - Janssen, MFWHA
T2  - TOGETHER IN THE UNSTABLE WORLD: DIGITAL GOVERNMENT AND SOLIDARITY
A2  - Sabatini, N
A2  - Hagen, L
A2  - Liao, HC
A2  - Cid, DD
AB  - Algorithmic and data-driven systems are increasingly used in the public sector to improve the efficiency of existing services or to provide new services through the newfound capacity to process vast volumes of data. Unfortunately, certain instances also have negative consequences for citizens, in the form of discriminatory outcomes, arbitrary decisions, lack of recourse, and more. These have serious impacts on citizens ranging from material to psychological harms. These harms partly emerge from choices and interactions in the design process. Existing critical and reflective frameworks for technology design do not address several aspects that are important to the design of systems in the public sector, namely protection of citizens in the face of potential algorithmic harms, the design of institutions to ensure system safety, and an understanding of how power relations affect the design, development, and deployment of these systems. The goal of this workshop is to develop these three perspectives and take the next step towards reflective design processes within public organisations. The workshop will be divided into two parts. In the first half we will elaborate the conceptual foundations of these perspectives in a series of short talks. Workshop participants will learn new ways of protecting against algorithmic harms in sociotechnical systems through understanding what institutions can support system safety, and how power relations influence the design process. In the second half, participants will get a chance to apply these lenses by analysing a real world case, and reflect on the challenges in applying conceptual frameworks to practice.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3598469.3598557
SP  - 679
EP  - 681
SN  - 979-8-4007-0837-4
AN  - WOS:001048270700086
ER  - 

TY  - JOUR
TI  - From Reality to World. A Critical Perspective on AI Fairness
AU  - John-Mathews, JM
AU  - Cardon, D
AU  - Balagué, C
T2  - JOURNAL OF BUSINESS ETHICS
AB  - Fairness of Artificial Intelligence (AI) decisions has become a big challenge for governments, companies, and societies. We offer a theoretical contribution to consider AI ethics outside of high-level and top-down approaches, based on the distinction between "reality" and "world" from Luc Boltanski. To do so, we provide a new perspective on the debate on AI fairness and show that criticism of ML unfairness is "realist", in other words, grounded in an already instituted reality based on demographic categories produced by institutions. Second, we show that the limits of "realist" fairness corrections lead to the elaboration of "radical responses" to fairness, that is, responses that radically change the format of data. Third, we show that fairness correction is shifting to a "domination regime" that absorbs criticism, and we provide some theoretical and practical avenues for further development in AI ethics. Using an ad hoc critical space stabilized by reality tests alongside the algorithm, we build a shared responsibility model which is compatible with the radical response to fairness issues. Finally, this paper shows the fundamental contribution of pragmatic sociology theories, insofar as they afford a social and political perspective on AI ethics by giving an active role to material actors such as database formats on ethical debates. In a context where data are increasingly numerous, granular, and behavioral, it is essential to renew our conception of AI ethics on algorithms in order to establish new models of responsibility for companies that take into account changes in the computing paradigm.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.1007/s10551-022-05055-8
VL  - 178
IS  - 4
SP  - 945
EP  - 959
SN  - 0167-4544
AN  - WOS:000761895600002
KW  - Artificial intelligence
KW  - Machine learning
KW  - Fairness
KW  - Big data
KW  - Business ethics
KW  - Pragmatic sociology
KW  - Responsibility model
ER  - 

TY  - JOUR
TI  - Representation Bias in Data: A Survey on Identification and Resolution Techniques
AU  - Shahbazi, N
AU  - Lin, Y
AU  - Asudeh, A
AU  - Jagadish, HV
T2  - ACM COMPUTING SURVEYS
AB  - Data-driven algorithms are only as good as the data they work with, while datasets, especially social data, often fail to represent minorities adequately. Representation Bias in data can happen due to various reasons, ranging from historical discrimination to selection and sampling biases in the data acquisition and preparation methods. Given that "bias in, bias out," one cannot expect AI-based solutions to have equitable outcomes for societal applications, without addressing issues such as representation bias. While there has been extensive study of fairness in machine learning models, including several review papers, bias in the data has been less studied. This article reviews the literature on identifying and resolving representation bias as a feature of a dataset, independent of how consumed later. The scope of this survey is bounded to structured (tabular) and unstructured (e.g., image, text, graph) data. It presents taxonomies to categorize the studied techniques based on multiple design dimensions and provides a side-by-side comparison of their properties.
There is still a long way to fully address representation bias issues in data. The authors hope that this survey motivates researchers to approach these challenges in the future by observing existing work within their respective domains.
DA  - 2023/12//undefined
PY  - 2023
DO  - 10.1145/3588433
VL  - 55
IS  - 13S
SN  - 0360-0300
AN  - WOS:001056300600031
KW  - Machine learning
KW  - Machine-learning
KW  - Data acquisition
KW  - AI-ready data
KW  - Data centric
KW  - Data equity system
KW  - data equity systems
KW  - data-centric AI
KW  - Data-centric AI
KW  - Data-driven algorithm
KW  - fairness in machine learning
KW  - Fairness in machine learning
KW  - Identification techniques
KW  - Resolution techniques
KW  - Responsible data science
ER  - 

TY  - JOUR
TI  - Optimal energy system scheduling using a constraint-aware reinforcement learning algorithm
AU  - Shengren, H
AU  - Vergara, PP
AU  - Duque, EMS
AU  - Palensky, P
T2  - INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS
AB  - The massive integration of renewable-based distributed energy resources (DERs) inherently increases the energy system's complexity, especially when it comes to defining its operational schedule. Deep reinforcement learning (DRL) algorithms arise as a promising solution due to their data-driven and model-free features. However, current DRL algorithms fail to enforce rigorous operational constraints (e.g., power balance, ramping up or down constraints) limiting their implementation in real systems. To overcome this, in this paper, a DRL algorithm (namely MIP-DQN) is proposed, capable of strictly enforcing all operational constraints in the action space, ensuring the feasibility of the defined schedule in real-time operation. This is done by leveraging recent optimization advances for deep neural networks (DNNs) that allow their representation as a MIP formulation, enabling further consideration of any action space constraints. Comprehensive numerical simulations show that the proposed algorithm outperforms existing state-of-the-art DRL algorithms, obtaining a lower error when compared with the optimal global solution (upper boundary) obtained after solving a mathematical programming formulation with perfect forecast information; while strictly enforcing all operational constraints (even in unseen test days).
DA  - 2023/10//undefined
PY  - 2023
DO  - 10.1016/j.ijepes.2023.109230
VL  - 152
SN  - 0142-0615
AN  - WOS:001012564600001
KW  - Reinforcement learning
KW  - Machine learning
KW  - Deep neural networks
KW  - Learning systems
KW  - Learning algorithms
KW  - Machine-learning
KW  - Reinforcement learnings
KW  - Safe reinforcement learning
KW  - Energy systems
KW  - Reinforcement learning algorithms
KW  - Energy management systems
KW  - Action spaces
KW  - Distributed computer systems
KW  - Distributed energy system
KW  - Distributed energy systems
KW  - Energy resources
KW  - Nonlinear programming
KW  - Operational constraints
KW  - Optimal energy
KW  - System scheduling
ER  - 

TY  - JOUR
TI  - Establishing Data Provenance for Responsible Artificial Intelligence Systems
AU  - Werder, K
AU  - Ramesh, B
AU  - Zhang, RG
T2  - ACM TRANSACTIONS ON MANAGEMENT INFORMATION SYSTEMS
AB  - Data provenance, a record that describes the origins and processing of data, offers new promises in the increasingly important role of artificial intelligence (AI)-based systems in guiding human decision making. To avoid disastrous outcomes that can result from bias-laden Al systems, responsible Al builds on four important characteristics: fairness, accountability, transparency, and explainability. To stimulate further research on data provenance that enables responsible Al, this study outlines existing biases and discusses possible implementations of data provenance to mitigate them. We first review biases stemming from the data's origins and pre-processing. We then discuss the current state of practice, the challenges it presents, and corresponding recommendations to address them. We present a summary highlighting how our recommendations can help establish data provenance and thereby mitigate biases stemming from the data's origins and pre-processing to realize responsible AI-based systems. We conclude with a research agenda suggesting further research avenues.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1145/3503488
VL  - 13
IS  - 2
SN  - 2158-656X
AN  - WOS:000774377100011
ER  - 

TY  - JOUR
TI  - Humanizing AI in medical training: ethical framework for responsible design
AU  - Sqalli, MT
AU  - Aslonov, B
AU  - Gafurov, M
AU  - Nurmatov, S
T2  - FRONTIERS IN ARTIFICIAL INTELLIGENCE
AB  - The increasing use of artificial intelligence (AI) in healthcare has brought about numerous ethical considerations that push for reflection. Humanizing AI in medical training is crucial to ensure that the design and deployment of its algorithms align with ethical principles and promote equitable healthcare outcomes for both medical practitioners trainees and patients. This perspective article provides an ethical framework for responsibly designing AI systems in medical training, drawing on our own past research in the fields of electrocardiogram interpretation training and e-health wearable devices. The article proposes five pillars of responsible design: transparency, fairness and justice, safety and wellbeing, accountability, and collaboration. The transparency pillar highlights the crucial role of maintaining the explainabilty of AI algorithms, while the fairness and justice pillar emphasizes on addressing biases in healthcare data and designing models that prioritize equitable medical training outcomes. The safety and wellbeing pillar however, emphasizes on the need to prioritize patient safety and wellbeing in AI model design whether it is for training or simulation purposes, and the accountability pillar calls for establishing clear lines of responsibility and liability for AI-derived decisions. Finally, the collaboration pillar emphasizes interdisciplinary collaboration among stakeholders, including physicians, data scientists, patients, and educators. The proposed framework thus provides a practical guide for designing and deploying AI in medicine generally, and in medical training specifically in a responsible and ethical manner.
DA  - 2023/05/16/
PY  - 2023
DO  - 10.3389/frai.2023.1189914
VL  - 6
SN  - 2624-8212
AN  - WOS:000997052000001
ER  - 

TY  - JOUR
TI  - Quantifying the Extent to Which Connected and Autonomous Vehicles Reduce Accidents at Railroad Grade Crossings: A Machine Learning Approach
AU  - Mathew, J
AU  - Benekohal, RF
T2  - TRANSPORTATION RESEARCH RECORD
AB  - This paper quantifies the safety benefits of a proposed near real-time traffic control system for highway-rail grade crossing (HRGC) utilizing emerging safety technologies in connected and autonomous vehicles (CAV). The connected-vehicle technologies that have applications at a railroad crossing include vehicle-based technologies (railroad crossing violation warning, automated or semi-automated braking system, drowsiness/distracted driver alert) and technologies that require cooperation from the railroad industry (advanced warnings to trains about an occupied crossing). This paper provides a methodology to quantify the reduction in crashes as safety technologies become prevalent. It first identifies crash characteristics that enable the classification of crashes as preventable crashes or not. This classification is used to train machine learning models to estimate the likelihood of a potential crash being preventable. The machine learning model is used along with the zero inflated negative binomial with empirical Bayes system (ZINEBS) model to estimate the expected accident count at a crossing when a percentage of vehicles in the traffic stream is CAV. This paper presents case studies for three crossings to show the reduction in crashes with the increase in the percentage of connected vehicles in the traffic stream. It also presents the general trend in the reduction expected by analyzing 50 crossings of each warning device type.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1177/03611981221076116
VL  - 2676
IS  - 6
SP  - 731
EP  - 742
SN  - 0361-1981
AN  - WOS:000769393700001
ER  - 

TY  - JOUR
TI  - Feature-Contrastive Graph Federated Learning: Responsible AI in Graph Information Analysis
AU  - Zeng, XJ
AU  - Zhou, T
AU  - Bao, ZC
AU  - Zhao, HW
AU  - Chen, LM
AU  - Wang, X
AU  - Wang, FY
T2  - IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
AB  - Federated learning enables multiple clients to learn a general model without sharing local data, and the federated learning system also improves information security and advances responsible artificial intelligence (AI). However, the data of different clients in the system are non-independently and identically distributed (IID), which results in weight divergence, especially for complex graph data extraction. This article proposes a novel feature-contrastive graph federated (FcgFed) learning approach to improve the robustness of the federated learning system in graph data. First, we design an architecture for FcgFed learning systems to analyze graph information. Furthermore, we present a graph federated learning method based on contrastive learning to alleviate the weight divergence in federated learning. The experiments in node classification and graph classification demonstrate that our method achieves better performance than model-contrastive federated learning (MOON) and federated average (FedAvg). We also test the adaptability of our method in image classification, and the results demonstrate that weight similarity evaluation works for other frameworks and tasks.
DA  - 2022/12/29/
PY  - 2022
DO  - 10.1109/TCSS.2022.3230987
SN  - 2329-924X
AN  - WOS:000910550800001
KW  - Artificial intelligence
KW  - Data models
KW  - Training
KW  - Learning systems
KW  - Security of data
KW  - Federated learning
KW  - Servers
KW  - Graph neural networks
KW  - Responsible artificial intelligence
KW  - Federated learning system
KW  - Graph information
KW  - graph neural networks
KW  - responsible artificial intelligence (AI)
KW  - Similarity evaluation
KW  - weight divergence
KW  - Weight divergence
KW  - weight similarity evaluation
KW  - Weight similarity evaluation
ER  - 

TY  - JOUR
TI  - How Responsible Is AI? Identification of Key Public Concerns Using Sentiment Analysis and Topic Modeling
AU  - Dwivedi, DN
AU  - Mahanty, G
AU  - Vemareddy, A
T2  - INTERNATIONAL JOURNAL OF INFORMATION RETRIEVAL RESEARCH
AB  - Many businesses around the world are adopting AI with the hope of increasing their top-line and bottom-line numbers. The COVID-19 pandemic has further accelerated the journey. While AI technology promises to bring enormous benefits, the challenges come in similar proportions. In the current form, the requirements for transparency and trust are relatively low for AI systems. On the other hand, there is a lot of regulatory pressure for AI systems to be trustworthy and responsible. Challenges still exist both on the methods and theory side and how explanations are used in practice. The objective of this paper is to analyze Twitter data to extract sentiments and opinions in unstructured text. The authors attempted to use contextual text analytics to categorize the twitter data to understand the positive or negative sentiments and feelings for the AI ethical challenges and highlight the key concerns. Text clustering has also been performed on positive and negative sentiments to understand the key themes behind people's concerns.
DA  - 2022///
PY  - 2022
DO  - 10.4018/IJIRR.298646
VL  - 12
IS  - 1
SN  - 2155-6377
AN  - WOS:000836676500019
ER  - 

TY  - JOUR
TI  - Localization for Intelligent Systems Using Unsupervised Learning and Prediction Approaches
AU  - Mirdita, P
AU  - Khaliq, Z
AU  - Hussein, AR
AU  - Wang, XB
T2  - IEEE CANADIAN JOURNAL OF ELECTRICAL AND COMPUTER ENGINEERING
AB  - This article proposes the manifold alignment algorithm, followed by learning models for prediction in indoor localization within intelligent systems. Processing data to and from multiple data sets can lead to increased time complexity and a greater demand for disk space and memory if the system is not properly scaled. Herein, the proposed manifold alignment algorithm introduces dimensionality reduction in order to account for the inefficiency caused by the inclusion of multiple data sets in such intelligent systems. Furthermore, data obtained from an indoor localization application can include discrepancies due to the dependence on access points (APs) that vary according to their external environment. In this scope, the indoor localization technique is based on the received signal strength indicator (RSSI). This is regarded as a popular method in localization due to its low overhead and computational requirements though its accuracy tends to weaken in larger applications. To account for the abovementioned disadvantages, eight statistical methods and machine learning models [autoregressive integrated moving average (ARIMA), support vector machine (SVM), multilayer perceptron (MLP), decision tree, random forests, eXtreme Gradient Boosting (XGBoost), long short-term memory (LSTM), and gated recurrent unit (GRU)] are evaluated to generate accurate RSSI predictions based on previous RSSI readings and their positions. Having measured the root mean square error (RMSE) and time complexities of each model, the MLP model had outperformed the other models with the best RMSE value and a relatively low execution time.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICJECE.2021.3062971
VL  - 44
IS  - 4
SP  - 443
EP  - 455
SN  - 2694-1783
AN  - WOS:000733162400007
ER  - 

TY  - JOUR
TI  - SafeCool: Safe and Energy-Efficient Cooling Management in Data Centers With Model-Based Reinforcement Learning
AU  - Wan, JX
AU  - Duan, YD
AU  - Gui, X
AU  - Liu, CY
AU  - Li, LX
AU  - Ma, ZQ
T2  - IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
AB  - Optimizing the cooling system plays a central role for capping the data center power consumption. However, the performance of traditional cooling management strategies is not satisfactory due to the complexity of thermodynamic process. Recently, several works leveraged Reinforcement Learning (RL) to improve the energy efficiency of data center cooling system. While they demonstrated that it is possible to reduce the cooling power consumption via RL, there are still some key challenges that have to be addressed before field deployment, such as safe operation guarantee and sample complexity, etc. In this paper, we propose SafeCool, an actor-critic Model-Based Reinforcement Learning (MBRL) algorithm for data center cooling management. SafeCool incorporates two system models, i.e., a transition model to predict the future system state and a risk model to estimate the negative effect of executing an action. The safety of proposed algorithm is ensured by Model Predictive Control (MPC) and risk-guided exploration. In addition, by employing the MBRL framework, SafeCool achieves higher sample efficiency and accelerated convergence. Simulations using real-world workload trace reveal that SafeCool saves up to 13.18% cooling power compared with state-of-the-art MBRL data center cooling solutions.
DA  - 2023/01/18/
PY  - 2023
DO  - 10.1109/TETCI.2023.3234545
SN  - 2471-285X
AN  - WOS:000920555700001
KW  - Reinforcement learning
KW  - Data models
KW  - Reinforcement learnings
KW  - Risk perception
KW  - Risk assessment
KW  - Energy efficiency
KW  - Model predictive control
KW  - Predictive control systems
KW  - Electric power utilization
KW  - Atmospheric modeling
KW  - Information management
KW  - Datacenter
KW  - Servers
KW  - Electric power distribution
KW  - Green computing
KW  - Cooling
KW  - Data center cooling
KW  - Temperature distribution
KW  - model-based reinforcement learning
KW  - Model-based reinforcement learning
KW  - Cooling systems
KW  - Thermoelectric equipment
KW  - Data centers
KW  - Power demand
KW  - Power demands
KW  - Cooling power
KW  - Data center cooling management
KW  - Safe operation
KW  - safe operation and exploration
KW  - Safe operation and exploration
ER  - 

TY  - JOUR
TI  - Learning a Low-Dimensional Representation of a Safe Region for Safe Reinforcement Learning on Dynamical Systems
AU  - Zhou, ZH
AU  - Oguz, OS
AU  - Leibold, M
AU  - Buss, M
T2  - IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB  - For the safe application of reinforcement learning algorithms to high-dimensional nonlinear dynamical systems, a simplified system model is used to formulate a safe reinforcement learning (SRL) framework. Based on the simplified system model, a low-dimensional representation of the safe region is identified and used to provide safety estimates for learning algorithms. However, finding a satisfying simplified system model for complex dynamical systems usually requires a considerable amount of effort. To overcome this limitation, we propose a general data-driven approach that is able to efficiently learn a low-dimensional representation of the safe region. By employing an online adaptation method, the low-dimensional representation is updated using the feedback data to obtain more accurate safety estimates. The performance of the proposed approach for identifying the low-dimensional representation of the safe region is illustrated using the example of a quadcopter. The results demonstrate a more reliable and representative low-dimensional representation of the safe region compared with previous works, which extends the applicability of the SRL framework.
DA  - 2023/05//undefined
PY  - 2023
DO  - 10.1109/TNNLS.2021.3106818
VL  - 34
IS  - 5
SP  - 2513
EP  - 2527
SN  - 2162-237X
AN  - WOS:000733505000001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - article
KW  - Adaptive control systems
KW  - Dynamical systems
KW  - Nonlinear dynamical systems
KW  - Heuristic algorithms
KW  - Computational modelling
KW  - Heuristics algorithm
KW  - Data-driven model
KW  - reinforcement learning (machine learning)
KW  - Data-driven model order reduction
KW  - Deep learning in robotic and automation
KW  - deep learning in robotics and automation
KW  - Learning and adaptive system
KW  - learning and adaptive systems
KW  - Model order reduction
KW  - Probabilistic logics
KW  - Safe reinforcement learning .
KW  - safe reinforcement learning (SRL)
ER  - 

TY  - JOUR
TI  - Driving Maneuver Classification Using Domain Specific Knowledge and Transfer Learning
AU  - Sarker, S
AU  - Haque, MM
AU  - Dewan, MAA
T2  - IEEE ACCESS
AB  - With the increasing number of vehicles, the usage of technology has also been increased in the transportation system. Although automobile companies are using advanced technologies to develop high performing transports, traffic safety still remains to be a concerning issue. Drivers' driving behavior is considered as one of the key factors of the traffic safety, which could be monitored from their individual driving maneuvers. In this paper, we present a supervised learning model and a semi-supervised transfer learning model for the classification of driving maneuvers from the sensor fusion time series data. The semi-supervised model consists of an unsupervised long-short term memory (LSTM) autoencoder and a supervised LSTM classifier. The supervised model consists of a supervised LSTM model. Because of using LSTM, both of the models can analyze time-series data. In the semi-supervised model, the LSTM encoder learns from unlabeled data as a compressed low dimensional feature vector, which then transfers the learning to the supervised LSTM classifier to classify the driving maneuvers. With the proposed models, we use domain specific knowledge data of the driving environment, such as data changing rules of various driving maneuvers as well as the temporal features over time. We use class functions for seven driving maneuver types and convert those into binary feature vector to use with the LSTM models. We present a comparative analysis of the per class accuracy of the proposed semi-supervised and supervised models with and without using domain-specific knowledge, where the models with the domain specific knowledge outperform. Our proposed semi-supervised and supervised models are compared with the other existing approaches, where our models trained with the domain specific knowledge provided better performance. We also compared the per class accuracy for both the supervised and semi-supervised models, where all the maneuver class accuracy for supervised model was above 98% and semi-supervised model was above 95%. Although the supervised model outperforms the semi-supervised model, the semi-supervised model would be more beneficial in applications where the labeled driving maneuvers data are hard to capture or insufficient.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3089660
VL  - 9
SP  - 86590
EP  - 86606
SN  - 2169-3536
AN  - WOS:000673374600001
ER  - 

TY  - JOUR
TI  - Technology readiness and the organizational journey towards AI adoption: An empirical study
AU  - Uren, V
AU  - Edwards, JS
T2  - INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT
AB  - Artificial Intelligence (AI) is viewed as having potential for significant economic and social impact. However, its history of boom and bust cycles can make potential adopters wary. A cross-sectional, qualitative study was carried out, with a purposive sample of AI experts from research, development and business functions, to gain a deeper understanding of the adoption process. Technology Readiness Levels were used as a benchmark against which the experts could align their experiences. A model of AI adoption is proposed which embeds an extended version of the People, Processes, Technology lens, incorporating Data. The model suggests that people, process and data readiness are required in addition to technology readiness to achieve long term operational success with AI. The findings further indicate that innovative organizations should build bridges between technical and business functions.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1016/j.ijinfomgt.2022.102588
VL  - 68
SN  - 0268-4012
AN  - WOS:000862470600002
ER  - 

TY  - JOUR
TI  - A Hierarchical Deep Reinforcement Learning Framework With High Efficiency and Generalization for Fast and Safe Navigation
AU  - Zhu, W
AU  - Hayashibe, M
T2  - IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
AB  - We present a hierarchical deep reinforcement learning (DRL) framework with prominent sampling efficiency and sim-to-real transfer ability for fast and safe navigation: the low-level DRL policy enables the robot to move toward the target position and keep a safe distance to obstacles simultaneously; the high-level DRL policy is supplemented to further enhance the navigation safety. We select a waypoint located on the path from the robot to the ultimate goal as the subgoal to reduce the state space and avoid sparse reward. Moreover, the path is generated based on either a local or a global map, which can significantly improve the sampling efficiency, safety, and generalization ability of the proposed DRL framework. Additionally, a target-directed representation for the action space can be derived based on the subgoal to improve the motion efficiency and reduce the action space. In order to demonstrate the eminent sampling efficiency, motion performance, obstacle avoidance, and generalization ability of the proposed framework, we implement sufficient comparisons with the nonlearning navigation methods and DRL-based baselines, with videos, data, code, and other supplemental material shown on our website.
DA  - 2023/05//undefined
PY  - 2023
DO  - 10.1109/TIE.2022.3190850
VL  - 70
IS  - 5
SP  - 4962
EP  - 4971
SN  - 0278-0046
AN  - WOS:000965697200001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Neural networks
KW  - Collision avoidance
KW  - Navigation
KW  - Collisions avoidance
KW  - Reinforcement learnings
KW  - Efficiency
KW  - Mobile robots
KW  - Learning frameworks
KW  - Neural-networks
KW  - Fast and safe navigation
KW  - Hierarchical deep reinforcement learning
KW  - hierarchical deep reinforcement learning (HDRL)
KW  - Safe navigations
KW  - sampling efficiency
KW  - Sampling efficiency
KW  - sim-to-real
KW  - Sim-to-real
ER  - 

TY  - JOUR
TI  - Perspectives on AI-driven systems for multiple sensor data fusion
AU  - Koch, W
T2  - TM-TECHNISCHES MESSEN
AB  - Artificially intelligent automation has not only impact on sensor technologies, but also on comprehensive multiple sensor systems for assisting situational awareness and decision-making. This is particularly true for integrated Manned-unManned-Teaming (MuM-T), for example. From a systems engineering perspective which does not exclude applications in the defence domain, three tasks need to be fulfilled: (1) Design artificially intelligent automation in a way that human beings are mentally and emotionally able to master each situation. (2) Identify technical design principles to facilitate the responsible use of AI in ethically critical applications. (3) Guarantee that human decision makers always have full superiority of information, decision-making, and options of action. Our discussion of AI-driven systems for multiple sensor data fusion results in recommendations and key results. We are addressing the algorithms needed, the data to be processed, the programming skills required, the computing devices to be used, the inevitable anthropocentric design, the reviewing of R & D efforts necessary, and the integration of different dimensions in a systems-of-systems point of view.
DA  - 2023/03/28/
PY  - 2023
DO  - 10.1515/teme-2022-0094
VL  - 90
IS  - 3
SP  - 166
EP  - 176
SN  - 0171-8096
AN  - WOS:000931960500001
ER  - 

TY  - JOUR
TI  - Towards a data collection methodology for Responsible Artificial Intelligence in health: A prospective and qualitative study in pregnancy
AU  - Oprescu, AM
AU  - Miró-Amarante, G
AU  - García-Díaz, L
AU  - Rey, VE
AU  - Chimenea-Toscano, A
AU  - Martínez-Martínez, R
AU  - Romero-Ternero, MC
T2  - INFORMATION FUSION
AB  - A medical field that is increasingly benefiting from Artificial Intelligence applications is Gyne- cology and Obstetrics. In previous work, we exposed that Artificial Intelligence (AI) technology and obstetric control by physicians can enhance pregnancy health, leading to better pregnancy outcomes and overall better experience, also reducing any possible long-term effects that can be produced by complications. This work presents a data collection methodology for responsible AI in Health and a case study in the pregnancy domain. It is a qualitative descriptive study on the preferences and expectations expressed by pregnant women regarding responsible AI and affective computing. A 41-items structured interview was distributed among 150 pregnant pa- tients attending prenatal care at Hospital Virgen del Rocio and the Clinic Victoria Rey (Seville, Spain) during the months of October and November 2020. A substantial interest in intelligent pregnancy solutions among pregnant women has been revealed in this study. Participants with a lower level of interest reported privacy concerns and lack of trust towards AI solutions. Re- garding affective computing based intelligent solutions specifically, most participants reported positively and no significant difference was found between women having a healthy or a high risk pregnancy on this matter. Our findings also suggest that a high demand of personalized intelligent solutions exists among participants. On the topic of sharing pregnancy data with the healthcare provider in favor of scientific research, pregnant women assisting public health- care services were found to be more likely to share their data when the provider was a public healthcare system rather than a private entity. Pregnant women who are interested in using an AI pregnancy application share a strong idea that it needs to be responsible, trustworthy, useful, and safe. Likewise, we found that pregnant women would change their mind about their concerns and they would feel more confident if the intelligent solution gives explanations about the system decisions and recommendations, as XAI approach promotes.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.1016/j.inffus.2022.03.011
VL  - 83
SP  - 53
EP  - 78
SN  - 1566-2535
AN  - WOS:000792198800003
ER  - 

TY  - JOUR
TI  - Machine learning models, trusted research environments and UK health data: ensuring a safe and beneficial future for AI development in healthcare
AU  - Kerasidou, C
AU  - Malone, M
AU  - Daly, A
AU  - Tava, F
T2  - JOURNAL OF MEDICAL ETHICS
AB  - Digitalisation of health and the use of health data in artificial intelligence, and machine learning (ML), including for applications that will then in turn be used in healthcare are major themes permeating current UK and other countries' healthcare systems and policies. Obtaining rich and representative data is key for robust ML development, and UK health data sets are particularly attractive sources for this. However, ensuring that such research and development is in the public interest, produces public benefit and preserves privacy are key challenges. Trusted research environments (TREs) are positioned as a way of balancing the diverging interests in healthcare data research with privacy and public benefit. Using TRE data to train ML models presents various challenges to the balance previously struck between these societal interests, which have hitherto not been discussed in the literature. These challenges include the possibility of personal data being disclosed in ML models, the dynamic nature of ML models and how public benefit may be (re)conceived in this context. For ML research to be facilitated using UK health data, TREs and others involved in the UK health data policy ecosystem need to be aware of these issues and work to address them in order to continue to ensure a 'safe' health and care data environment that truly serves the public.
DA  - 2023/03/30/
PY  - 2023
DO  - 10.1136/jme-2022-108696
SN  - 0306-6800
AN  - WOS:000969274500001
KW  - machine learning
KW  - policy
KW  - privacy
KW  - artificial intelligence
KW  - ethics
KW  - article
KW  - ecosystem
KW  - ethics- medical
KW  - ethics- research
KW  - health care system
KW  - health data
KW  - identifiable information
KW  - information technology
ER  - 

TY  - JOUR
TI  - Towards a semantic Construction Digital Twin: Directions for future research
AU  - Boje, C
AU  - Guerriero, A
AU  - Kubicki, S
AU  - Rezgui, Y
T2  - AUTOMATION IN CONSTRUCTION
AB  - As the Architecture, Engineering and Construction sector is embracing the digital age, the processes involved in the design, construction and operation of built assets are more and more influenced by technologies dealing with value-added monitoring of data from sensor networks, management of this data in secure and resilient storage systems underpinned by semantic models, as well as the simulation and optimisation of engineering systems. Aside from enhancing the efficiency of the value chain, such information-intensive models and associated technologies play a decisive role in minimising the lifecycle impacts of our buildings. While Building Information Modelling provides procedures, technologies and data schemas enabling a standardised semantic representation of building components and systems, the concept of a Digital Twin conveys a more holistic socio-technical and process-oriented characterisation of the complex artefacts involved by leveraging the synchronicity of the cyber-physical bi-directional data flows. Moreover, BIM lacks semantic completeness in areas such as control systems, including sensor networks, social systems, and urban artefacts beyond the scope of buildings, thus requiring a holistic, scalable semantic approach that factors in dynamic data at different levels. The paper reviews the multi-faceted applications of BIM during the construction stage and highlights limits and requirements, paving the way to the concept of a Construction Digital Twin. A definition of such a concept is then given, described in terms of underpinning research themes, while elaborating on areas for future research.
DA  - 2020/06//undefined
PY  - 2020
DO  - 10.1016/j.autcon.2020.103179
VL  - 114
SN  - 0926-5805
AN  - WOS:000526785800022
ER  - 

TY  - JOUR
TI  - Robustness with respect to class imbalance in artificial intelligence classification algorithms
AU  - Lian, JY
AU  - Freeman, L
AU  - Hong, YL
AU  - Deng, XW
T2  - JOURNAL OF QUALITY TECHNOLOGY
AB  - Artificial intelligence (AI) algorithms, such as deep learning and XGboost, are used in numerous applications including autonomous driving, manufacturing process optimization and medical diagnostics. The robustness of AI algorithms is of great interest as inaccurate prediction could result in safety concerns and limit the adoption of AI systems. In this paper, we propose a framework based on design of experiments to systematically investigate the robustness of AI classification algorithms. A robust classification algorithm is expected to have high accuracy and low variability under different application scenarios. The robustness can be affected by a wide range of factors such as the imbalance of class labels in the training dataset, the chosen prediction algorithm, the chosen dataset of the application, and a change of distribution in the training and test datasets. To investigate the robustness of AI classification algorithms, we conduct a comprehensive set of mixture experiments to collect prediction performance results. Then statistical analyses are conducted to understand how various factors affect the robustness of AI classification algorithms. We summarize our findings and provide suggestions to practitioners in AI applications.
DA  - 2021/10/20/
PY  - 2021
DO  - 10.1080/00224065.2021.1963200
VL  - 53
IS  - 5
SP  - 505
EP  - 525
SN  - 0022-4065
AN  - WOS:000691157600001
KW  - Deep learning
KW  - deep learning
KW  - Prediction algorithms
KW  - Autonomous driving
KW  - Diagnosis
KW  - Forecasting
KW  - Optimization
KW  - Statistical tests
KW  - Prediction performance
KW  - Classification algorithm
KW  - Robust classification
KW  - Design of experiments
KW  - Application scenario
KW  - AI assurance
KW  - design of experiments
KW  - distribution shift
KW  - Manufacturing process
KW  - Medical diagnostics
KW  - safety of AI systems
ER  - 

TY  - JOUR
TI  - Colonization by Algorithms in the Fourth Industrial Revolution
AU  - Lambrechts, W
AU  - Sinha, S
AU  - Mosoetsa, S
T2  - IEEE ACCESS
AB  - Data gathering and information processing have evolved to where it is almost unfathomable how much exists in digital form today. The generation thereof also no longer involves an explicit instruction from human to machine but can happen in real-time without human intervention. Artificial intelligence, machine learning, and cognitive computing are being utilized to mine data from a variety of sources. One such (profitable) source is human beings. Digital algorithms are designed to harness the power of technology to gather information. There has always been a sense of secrecy regarding some information (classified, top secret, confidential, etc.) but the Fourth Industrial Revolution has created the means to gather extremely large amounts of data, unknown to its sources. Anthropological value systems should become a fundamental foundation of digital algorithms. Such an approach could prevent software from exploiting its sources, especially minorities. Value systems together with ethics are guided by people's culture. In ethically aligned algorithm design, value systems and digital technologies intersect and govern how algorithms are developed, the way data is engaged, and further the discipline of digital humanities.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3145236
VL  - 10
SP  - 11057
EP  - 11064
SN  - 2169-3536
AN  - WOS:000750407600001
ER  - 

TY  - JOUR
TI  - A Real-World Reinforcement Learning Framework for Safe and Human-Like Tactical Decision-Making
AU  - Yavas, MU
AU  - Kumbasar, T
AU  - Ure, NK
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Lane-change decision-making for vehicles is a challenging task for many reasons, including traffic rules, safety, and the stochastic nature of driving. Because of its success in solving complex problems, deep reinforcement learning (DRL) has been suggested for addressing these issues. However, the studies on DRL to date have gone no further than validation in simulation and failed to address what are arguably the most critical issues, namely, the mismatch between simulation and reality, human-likeness, and safety. This paper introduces a real-world DRL framework for decision-making to design safe and human-like agents that can operate in the real world without extra tuning. We propose a new learning paradigm for DRL integrated with Real2Sim transfer, which comprises training, validation, and testing phases. The approach involves two simulator environments with different levels of fidelity, which are parameterized via real-world data. Within the framework, a large amount of randomized experience is generated with a low-fidelity simulator, whereupon the learned skills are validated regularly in a high-fidelity simulator to avoid overfitting. Finally, in the testing phase, the agent is examined concerning safety and human-like decision-making. Extensive simulation and real-world evaluations show the superiority of the proposed approach. To the best of the authors' knowledge, this is the first application of DRL lane-changing policy in the real world.
DA  - 2023/07/25/
PY  - 2023
DO  - 10.1109/TITS.2023.3292981
SN  - 1524-9050
AN  - WOS:001040652400001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Safety
KW  - artificial intelligence
KW  - intelligent vehicles
KW  - Task analysis
KW  - Decision making
KW  - Measurement
KW  - reinforcement learning
KW  - Training
KW  - Testing
KW  - Behavioral science
KW  - Behavioral sciences
KW  - Autonomous Vehicles
KW  - Behavioral research
KW  - Decisions makings
KW  - Job analysis
KW  - Accident prevention
KW  - Intelligent vehicle highway systems
KW  - Reinforcement learnings
KW  - Real-world
KW  - Learning frameworks
KW  - Tactical decision makings
KW  - Stochastic systems
KW  - Safety testing
KW  - Human like
KW  - Testing phase
ER  - 

TY  - JOUR
TI  - Real World Object Detection Dataset for Quadcopter Unmanned Aerial Vehicle Detection
AU  - Pawelczyk, ML
AU  - Wojtyra, M
T2  - IEEE ACCESS
AB  - Recent years have shown a noticeable rise in the number of incidents with drones, related to both civilian and military installations. While drone neutralization techniques have become increasingly effective, detection most often relies on professional equipment, which is too expensive to be used for all critical nodes and applications. Therefore, there is a need for drone detection systems that could work on low performance hardware. Its critical component consists of an object detection system. In this article, we introduce a new object detection dataset, built entirely to train computer vision based object detection machine learning algorithms for a task of binary object detection to enable automated, industrial camera based detection of multiple drone objects using camera feed. The dataset expands existing multiclass image classification and object detection datasets (ImageNet, MS-COCO, PASCAL VOC, anti-UAV) with a diversified dataset of drone images. In order to maximize the effectiveness of the model, real world footage was utilized, transformed into images and hand-labelled to create a custom set of 56821 images and 55539 bounding boxes. Additionally, semi-automated labelling was proposed, tested and proved to be very useful for object detection applications. The dataset was divided into train and test subsets for further processing and used to generate 603 easily deployable Haar Cascades as well as 819 high performing Deep Neural Networks based models. They were used to test different object detection methods to determine the long term feasibility of a large scale drone detection system utilizing machine learning algorithms. The study has shown that Haar Cascade can be used as the Minimum Viable Product model for mediocre performance but fails to scale up effectively for a larger dataset compared to the Deep Neural Network model.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3026192
VL  - 8
SP  - 174394
EP  - 174409
SN  - 2169-3536
AN  - WOS:000575898400001
ER  - 

TY  - JOUR
TI  - Deep Learning-Based Raindrop Quantity Detection for Real-Time Vehicle-Safety Application
AU  - Wang, SH
AU  - Hsia, SC
AU  - Zheng, MJ
T2  - IEEE TRANSACTIONS ON CONSUMER ELECTRONICS
AB  - The raindrops on the glass will affect driving safety, such as rear-view camera, outside mirror and windshield, etc. This article proposed a robust raindrop detection using deep learning on embedded platform with AI accelerator for real-time implementation. A training model is established through a convolution neural network (CNN)-like architecture to classify the images by the vehicle camera into three classes: no rain, heavy rain, and light rain. The classification results are used to control the speed of the motor to implement an automatic wiper control system. The training model, ResNet, is used to classify the image with good tradeoff between the computational cost and accuracy. For real-time application, the camera module on the Google Coral Dev board on embedded system platform is used to test the video stream and to estimate the performance of this system. Results show that the recognition accuracy reaches 95%, and the processing speed can achieve 20 frames per second (fps) on the embedded system.
DA  - 2021/11//undefined
PY  - 2021
DO  - 10.1109/TCE.2021.3127494
VL  - 67
IS  - 4
SP  - 266
EP  - 274
SN  - 0098-3063
AN  - WOS:000732981500010
KW  - Deep learning
KW  - deep learning
KW  - artificial intelligence
KW  - Deep neural networks
KW  - Vehicles
KW  - Computer architecture
KW  - Image classification
KW  - Convolution
KW  - Computer vision
KW  - Cameras
KW  - Network architecture
KW  - Embedded systems
KW  - computer vision
KW  - Real time control
KW  - Neural-networks
KW  - Computational modelling
KW  - Embedded-system
KW  - AI accelerator
KW  - vehicle safety
KW  - ADAS
KW  - Convolution neural network
KW  - Resnet
KW  - ResNet
KW  - AI accelerator.
KW  - convolution neural network
KW  - Drops
KW  - embedded system
KW  - Raindrop detection
ER  - 

TY  - JOUR
TI  - Intelligent Energy-Efficient Train Trajectory Optimization Approach Based on Supervised Reinforcement Learning for Urban Rail Transits
AU  - Li, GN
AU  - Or, SW
AU  - Chan, KW
T2  - IEEE ACCESS
AB  - Artificial intelligence of things (AIoT)-enabled intelligent automatic train operation (iATO) is an urgently needed technology to expand the capability of ATO in addressing the real-time responsiveness and dynamic online challenges to energy-efficient train trajectory optimization (TTO) and its associated ride-comfort, punctuality, and safety issues in modern urban rail transit networks. This paper proposes a three-step supervised reinforcement learning-based intelligent energy-efficient train trajectory optimization (SRL-IETTO) approach for iATO by hybrid-integrating deep reinforcement learning (DRL) and supervised learning. First, multiple objectives are formulated based on real-time train operation and systematically integrated into the RL algorithm by a binary function-based goal-directed reward design method. Second, an IETTO model is established to handle uncertain disturbances in real-time train operation and generate optimal energy-efficient train trajectories online by optimizing energy efficiency and receiving supervisory information from trajectories of pre-trained TTO models. Finally, numerical simulations are implemented to validate the effectiveness of the SRL-IETTO using in-service subway line data. The results demonstrate the superiority and improved energy saving of the proposed approach and confirm its adaptability to online trip time adjustments within the practical running time range under uncertain disturbances with less trip time error compared to other intelligent TTO algorithms.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ACCESS.2023.3261900
VL  - 11
SP  - 31508
EP  - 31521
SN  - 2169-3536
AN  - WOS:000967468800001
ER  - 

TY  - CONF
TI  - Women Safety Device Designed using IoT and Machine Learning
AU  - Muskan
AU  - Khandelwal, T
AU  - Khandelwal, M
AU  - Pandey, PS
T2  - 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI)
A2  - Wang, G
A2  - Han, Q
A2  - Bhuiyan, MZA
A2  - Ma, X
A2  - Loulergue, F
A2  - Li, P
A2  - Roveri, M
A2  - Chen, L
AB  - Women safety is a very important issue due to rising crimes against women these days. Presently there is indeed no good solution to this problem. The existing applications and devices are not much effective as they need lot of human interaction to operate. These existing devices use to read the human temperature and heartbeat to generate alarm in case of emergency. When a person runs, every human may have different body temperature and heartbeat pattern and thus keeping a fixed threshold for finding out emergency situation and then generating alarm is not correct way and this is where the existing devices are failing to correctly generate alarm in case of emergency. In this paper the device are customized to learn the individual pattern of temperature and heartbeat and then it finds out the threshold for generating alarm. Thus this paper deals to design a wearable women safety device that automatically reads and create patterns such as body temperature and pulse rate during running. If readings are higher than the normal readings then it will automatically call and message more than one person along with the location so that actions can be taken. We have used temperature and pulse sensors that will detect the activity of the woman and that data of sensors will be sent to cloud where machine learning algorithm is applied to analyse the data generated. The data is first collected by sensors in non-danger conditions to train the algorithm, after that data is used for testing to gauge the accuracy and how close it is to our trained data. More is the accuracy more is the surety of danger and the emergency alarm will be there on emergency contacts. Thirdly, this paper deals with scenarios where there is no internet facility. To overcome the problem of internet we have used ZigBee mesh network, which helped the device to send the data to multiple hop distance.
DA  - 2018///
PY  - 2018
DO  - 10.1109/SmartWorld.2018.00210
SP  - 1204
EP  - 1210
SN  - 978-1-5386-9380-3
AN  - WOS:000458742900174
KW  - Artificial intelligence
KW  - Data analysis
KW  - Machine Learning
KW  - Learning systems
KW  - Internet of things
KW  - Smart city
KW  - Learning algorithms
KW  - Regression analysis
KW  - Alarm systems
KW  - Big data
KW  - Safety devices
KW  - Data reduction
KW  - Physiology
KW  - Logistic regression
KW  - Distributed computer systems
KW  - Cloud computing
KW  - Trusted computing
KW  - Ubiquitous computing
KW  - Logistic regressions
KW  - Danger prediction
KW  - Mesh generation
KW  - Automatic danger detection
KW  - Body temperature
KW  - Body Temperature
KW  - Customized device
KW  - Danger detection
KW  - Emergency alarm
KW  - Emergency Alarm
KW  - Pulse sensor
KW  - Women safety device
KW  - Work without internet
KW  - Zigbee
KW  - Zigbee mesh network
KW  - Zigbee mesh networks
ER  - 

TY  - JOUR
TI  - General Diagnostic Framework Based on Non-axiomatic Logic for Aviation Safety Event Analysis
AU  - Jiang, Y
AU  - Wang, H
AU  - Feng, XJ
T2  - CHINESE JOURNAL OF ELECTRONICS
AB  - To achieve causality reasoning of aviation safety events based on big data of cross-media network, a data-driven general diagnostic framework based on nonaxiomatic logic is designed and implemented. On the basis of this framework, the uncertain causality between aviation safety events and faults is expressed in the form of binary non-axiomatic incident experience at first. A general expression for calculating the attribution and confidence degrees in the non-axiomatic incident experience is given based on records of aviation safety historical incident. A concept of non-axiomatic incident experience graph is proposed, a diagnosis algorithm for aviation safety events is given with the combination of revision and deduction rules in non-axiomatic logic. Experimental results of a Version 1.0 beta demo show that this framework can effectively diagnose all potential faults according to aviation safety events; compared with other machine learning frameworks, it has higher reliability (especially scalability) under the premise of ensuring diagnosis accuracy.
DA  - 2019/11//undefined
PY  - 2019
DO  - 10.1049/cje.2019.07.010
VL  - 28
IS  - 6
SP  - 1152
EP  - 1157
SN  - 1022-4653
AN  - WOS:000524255900010
ER  - 

TY  - JOUR
TI  - Outdoor Clothing Design for Traffic Safety Based on Big Data and Artificial Intelligence
AU  - Zhou, Y
AU  - Shi, Y
T2  - JOURNAL OF ADVANCED TRANSPORTATION
AB  - With the development of technologies in various fields, more and more technologies have been applied to safety clothing, which has led to the rapid development of safety clothing. The improvement of living standards is accompanied by the change of consumption concepts. Consumers' requirements for clothing products have become more artistic, healthier, and more ecological, and they look forward to more and better safety clothing to meet their health needs. In this context, this article studies traffic safety outdoor clothing design based on big data (BD) and AI. This article introduces the design method of outdoor safety clothing for traffic based on BD and machine learning in artificial intelligence (AI) and did two experiments. To this end, this paper adopts a Deep Belief Network (DBN), which is trained layer by layer through Restricted Boltzmann Machine (RBM), and successfully solves the problems of lack of a large number of labeled samples and easy to fall into local optimum. The first experiment is to test the accuracy of various machine learning algorithms for clothing size measurement. The results obtained are as follows: the predicted value of the DBN neural network is the closest to the actual value, the average prediction accuracy of DBN for the cuff size is 90%, and the average prediction accuracy for the neck circumference is 91.5%. The second experiment is to investigate the functional needs and performance concerns of children and outdoor workers. The results of the experiment are as follows: for children, 79.9% of people want clothing to have a positioning function, which accounts for the highest proportion. For outdoor workers, the most important clothing function they need is eye-catching style, and 90.1% of those choose this option. In terms of clothing performance concerns, most people choose to care very much, and the second most people choose to care about comfort.
DA  - 2022/07/07/
PY  - 2022
DO  - 10.1155/2022/8697421
VL  - 2022
SN  - 0197-6729
AN  - WOS:000840989300001
ER  - 

TY  - JOUR
TI  - AI for Aerospace and Electronic Systems: Technical Dimensions of Responsible Design
AU  - Koch, W
T2  - IEEE AEROSPACE AND ELECTRONIC SYSTEMS MAGAZINE
AB  - There are still no lessons to be learned from the brutality of the war in Ukraine, except perhaps one: Does not the flood of news show the difference between "combat power " and "combat value "? Even in this modern war, not only the countable and measurable technical material is important. Soldiers who are willing and able to fight, i.e., "citizens in uniform, " also "count "- those who know what they are fighting for, who know their homeland, who know how to defend themselves and their own with quantitatively inferior but technically adequate situation pictures and effective means. What does this insight mean for the complex "technosphere " of aerospace and electronic systems, which are critical in modern warfare and can only be controlled by humans through the world of algorithms, i.e., by artificially intelligent automation?
DA  - 2023/01/01/
PY  - 2023
DO  - 10.1109/MAES.2022.3228300
VL  - 38
IS  - 1
SP  - 106
EP  - 111
SN  - 0885-8985
AN  - WOS:000922643100018
ER  - 

TY  - JOUR
TI  - Machine learning techniques and research framework in foodborne disease surveillance system
AU  - Du, Y
AU  - Guo, YC
T2  - FOOD CONTROL
AB  - Based on the verified application in China's National Foodborne Disease Outbreak Surveillance System, machine learning techniques have been indicated to have very positive effects. We summarize current positive attempts on improving case reporting, helping diagnosing and outbreak prediction. Based on the attempts, we propose a general framework to facilitate future improvements for a more intelligent foodborne disease surveillance system, which can greatly help human health.
DA  - 2022/01//undefined
PY  - 2022
DO  - 10.1016/j.foodcont.2021.108448
VL  - 131
SN  - 0956-7135
AN  - WOS:000691225000007
KW  - Machine learning
KW  - Big data
KW  - Food safety
KW  - Foodborne diseases
KW  - Research framework
KW  - Surveillance system
ER  - 

TY  - JOUR
TI  - Intelligent fault diagnosis approach with unsupervised feature learning by stacked denoising autoencoder
AU  - Xia, M
AU  - Li, T
AU  - Liu, LZ
AU  - Xu, L
AU  - de Silva, CW
T2  - IET SCIENCE MEASUREMENT & TECHNOLOGY
AB  - Condition monitoring and fault diagnosis are important for maintaining the system performance and guaranteeing the operational safety. The traditional data-driven approaches mostly incorporate well-defined features and methodologies such as supervised artificial intelligence algorithms. Prior knowledge of possible features and a large quantity of labelled condition data are needed. Besides, many traditional approaches require rebuilding or a retraining of the original model to diagnosis new conditions. The present study proposes an intelligent fault diagnosis approach that uses a deep neural network (DNN) based on stacked denoising autoencoder. Representative features are learned by applying the denoising autoencoder to the unlabelled data in an unsupervised manner. A DNN is then constructed and fine-tuned with just a few items of labelled data. The trained DNN achieves high performance in fault classification. Furthermore, new conditions can be correctly classified by simply fine-tuning the trained DNN model using a small amount of labelled data under the new conditions. The effectiveness of the proposed approach is evaluated using a case study of fault diagnosis of a bearing unit. The results indicate that the proposed method can extract representative features from massive unlabelled data on the system condition and achieve high performance in fault diagnosis.
DA  - 2017/09//undefined
PY  - 2017
DO  - 10.1049/iet-smt.2016.0423
VL  - 11
IS  - 6
SP  - 687
EP  - 695
SN  - 1751-8822
AN  - WOS:000410154600002
ER  - 

TY  - CONF
TI  - TRAINIFY: A CEGAR-Driven Training and Verification Framework for Safe Deep Reinforcement Learning
AU  - Jin, P
AU  - Tian, JX
AU  - Zhi, DP
AU  - Wen, XJ
AU  - Zhang, M
T2  - COMPUTER AIDED VERIFICATION (CAV 2022), PT I
A2  - Shoham, S
A2  - Vizel, Y
AB  - Deep Reinforcement Learning (DRL) has demonstrated its strength in developing intelligent systems. These systems shall be formally guaranteed to be trustworthy when applied to safety-critical domains, which is typically achieved by formal verification performed after training. This train-then-verify process has two limits: (i) trained systems are difficult to formally verify due to their continuous and infinite state space and inexplicable AI components (i.e., deep neural networks), and (ii) the ex post facto detection of bugs increases both the time- and money-wise cost of training and deployment. In this paper, we propose a novel verification-in-the-loop training framework called Trainify for developing safe DRL systems driven by counterexample-guided abstraction and refinement. Specifically, Trainify trains a DRL system on a finite set of coarsely abstracted but efficiently verifiable state spaces. When verification fails, we refine the abstraction based on returned counterexamples and train again on the finer abstract states. The process is iterated until all predefined properties are verified against the trained system. We demonstrate the effectiveness of our framework on six classic control systems. The experimental results show that our framework yields more reliable DRL systems with provable guarantees without sacrificing system performance such as cumulative reward and robustness than conventional DRL approaches.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13185-1_10
VL  - 13371
SP  - 193
EP  - 218
SN  - 0302-9743
AN  - WOS:000870304500010
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - Intelligent systems
KW  - Learning systems
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Safety engineering
KW  - Model checking
KW  - Formal verification
KW  - Safety-critical domain
KW  - Models checking
KW  - Abstracting
KW  - ACTL
KW  - CEGAR
KW  - Continuous State Space
KW  - Program debugging
KW  - Reinforcement learning systems
KW  - Training framework
KW  - Verification framework
ER  - 

TY  - JOUR
TI  - Leveraging Artificial Intelligence and Fleet Sensor Data towards a Higher Resolution Road Weather Model
AU  - Bogaerts, T
AU  - Watelet, S
AU  - De Bruyne, N
AU  - Thoen, C
AU  - Coopman, T
AU  - Van den Bergh, J
AU  - Reyniers, M
AU  - Seynaeve, D
AU  - Casteels, W
AU  - Latré, S
AU  - Hellinckx, P
T2  - SENSORS
AB  - Road weather conditions such as ice, snow, or heavy rain can have a significant impact on driver safety. In this paper, we present an approach to continuously monitor the road conditions in real time by equipping a fleet of vehicles with sensors. Based on the observed conditions, a physical road weather model is used to forecast the conditions for the following hours. This can be used to deliver timely warnings to drivers about potentially dangerous road conditions. To optimally process the large data volumes, we show how artificial intelligence is used to (1) calibrate the sensor measurements and (2) to retrieve relevant weather information from camera images. The output of the road weather model is compared to forecasts at road weather station locations to validate the approach.
DA  - 2022/04//undefined
PY  - 2022
DO  - 10.3390/s22072732
VL  - 22
IS  - 7
SN  - 1424-8220
AN  - WOS:000783124800001
KW  - machine learning
KW  - artificial intelligence
KW  - Machine learning
KW  - Fleet operations
KW  - Roads and streets
KW  - Road condition
KW  - road safety
KW  - Road safety
KW  - Weather forecasting
KW  - nowcasting
KW  - Nowcasting
KW  - Road weather condition
KW  - road weather conditions
KW  - Road weather model
KW  - road weather models
KW  - Road weather service
KW  - road weather services
KW  - smart sensors
KW  - vehicle data
KW  - Vehicle data
KW  - Weather modeling
KW  - Weather services
KW  - weather warnings
KW  - Weather warnings
ER  - 

TY  - JOUR
TI  - Optimization Techniques and Formal Verification for the Software Design of Boolean Algebra Based Safety-Critical Systems
AU  - Perez, J
AU  - Flores, JL
AU  - Blum, C
AU  - Cerquides, J
AU  - Abuin, A
T2  - IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB  - Artificial intelligence, and the ability to learn optimized solutions that comply with a set of safety rules, could facilitate the human-based design process of safety-critical systems. However, the reconciliation of state-of-the-art artificial intelligence technology with current safety standards and safety engineering processes is a challenge to be addressed. In this article, this publication describes a method based on optimization and on formal verification for the design of safety-critical systems that are defined by Boolean algebra. Several diverse optimization techniques and a hybrid of these approaches are used to find an optimized design that considers performance requirements, availability rules, and complies with all defined safety rules. Subsequently, this solution is translated into an alternative knowledge representation that can be formally verified and developed in compliance with currently considered safety standards. This method is evaluated with a simplified safety-critical case study.
DA  - 2022/01//undefined
PY  - 2022
DO  - 10.1109/TII.2021.3074394
VL  - 18
IS  - 1
SP  - 620
EP  - 630
SN  - 1551-3203
AN  - WOS:000704130600064
ER  - 

TY  - BOOK
TI  - Proposing a regional 'soft' normative framework for the safer deployment of AI-enabled autonomous weapon systems in Southeast Asia
AU  - Wyatt, A
AU  - Wyatt, A
T2  - DISRUPTIVE IMPACT OF LETHAL AUTONOMOUS WEAPONS SYSTEMS DIFFUSION: Modern Melians and the Dawn of Robotic Warriors
DA  - 2022///
PY  - 2022
SP  - 179
SN  - 978-1-032-00155-5
AN  - WOS:000863721800009
ER  - 

TY  - CONF
TI  - Engineering of an Artificial Intelligence Safety Data Sheet Document Processing System for Environmental, Health, and Safety Compliance
AU  - Fenton, K
AU  - Simske, S
T2  - PROCEEDINGS OF THE 21ST ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG '21)
AB  - Chemical Safety Data Sheets (SDS) are the primary method by which chemical manufacturers communicate the ingredients and hazards of their products to the public. These SDSs are used for a wide variety of purposes ranging from environmental calculations to occupational health assessments to emergency response measures. Although a few companies have provided direct digital data transfer platforms using xml or equivalent schemata, the vast majority of chemical ingredient and hazard communication to product users still occurs through the use of millions of PDF documents that are largely loaded through manual data entry into downstream user databases. This research focuses on the reverse engineering of SDS document types to adapt to various layouts and the harnessing of meta-algorithmic and neural network approaches to provide a means of moving industrial institutions towards a digital universal SDS processing methodology. The complexities of SDS documents including the lack of format standardization, text and image combinations, and multi-lingual translation needs, combined, limit the accuracy and precision of optical character recognition tools.
The approach in this document is to translate entire SDSs from thousands of chemical vendors, each with distinct formatting, to machine-encoded text with a high degree of accuracy and precision. Then the system will "read" and assess these documents as a human would; that is, ensuring that the documents are compliant, determining whether chemical formulations have changed, ensuring reported values are within expected thresholds, and comparing them to similar products for more environmentally friendly alternatives.
DA  - 2021///
PY  - 2021
DO  - 10.1145/3469096.3474933
SN  - 978-1-4503-8596-1
AN  - WOS:000744481000024
ER  - 

TY  - JOUR
TI  - Safe Reinforcement Learning via a Model-Free Safety Certifier
AU  - Modares, A
AU  - Sadati, N
AU  - Esmaeili, B
AU  - Yaghmaie, FA
AU  - Modares, H
T2  - IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB  - This article presents a data-driven safe reinforcement learning (RL) algorithm for discrete-time nonlinear systems. A data-driven safety certifier is designed to intervene with the actions of the RL agent to ensure both safety and stability of its actions. This is in sharp contrast to existing model-based safety certifiers that can result in convergence to an undesired equilibrium point or conservative interventions that jeopardize the performance of the RL agent. To this end, the proposed method directly learns a robust safety certifier while completely bypassing the identification of the system model. The nonlinear system is modeled using linear parameter varying (LPV) systems with polytopic disturbances. To prevent the requirement for learning an explicit model of the LPV system, data-based $\lambda$ -contractivity conditions are first provided for the closed-loop system to enforce robust invariance of a prespecified polyhedral safe set and the system's asymptotic stability. These conditions are then leveraged to directly learn a robust data-based gain-scheduling controller by solving a convex program. A significant advantage of the proposed direct safe learning over model-based certifiers is that it completely resolves conflicts between safety and stability requirements while assuring convergence to the desired equilibrium point. Data-based safety certification conditions are then provided using Minkowski functions. They are then used to seemingly integrate the learned backup safe gain-scheduling controller with the RL controller. Finally, we provide a simulation example to verify the effectiveness of the proposed approach.
DA  - 2023/04/13/
PY  - 2023
DO  - 10.1109/TNNLS.2023.3264815
SN  - 2162-237X
AN  - WOS:000973264800001
KW  - Reinforcement learning
KW  - Safety
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Controllers
KW  - Nonlinear systems
KW  - Safe control
KW  - Closed loop systems
KW  - reinforcement learning (RL)
KW  - Heuristic algorithms
KW  - Optimal control
KW  - Optimal controls
KW  - Heuristics algorithm
KW  - Stability criteria
KW  - System stability
KW  - System Dynamics
KW  - Discrete time control systems
KW  - Convex optimization
KW  - Asymptotic stability
KW  - Data-driven control
KW  - Gain scheduling control
KW  - gain-scheduling control
KW  - safe control
KW  - Stability criterions
KW  - System dynamics
ER  - 

TY  - JOUR
TI  - Robust Face Alignment via Deep Progressive Reinitialization and Adaptive Error-Driven Learning
AU  - Shao, XH
AU  - Xing, JL
AU  - Lyu, JJ
AU  - Zhou, XD
AU  - Shi, Y
AU  - Maybank, S
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - Regression-based face alignment involves learning a series of mapping functions to predict the true landmarks from an initial estimation of the alignment. Most existing approaches focus on learning efficacious mapping functions from some feature representations to improve performance. The issues related to the initial alignment estimation and the final learning objective, however, receive less attention. This work proposes a deep regression architecture with progressive reinitialization and a new error-driven learning loss function to explicitly address the above two issues. Given an image with a rough face detection result, the full face region is first mapped by a supervised spatial transformer network to a normalized form and trained to regress coarse positions of landmarks. Then, different face parts are further respectively reinitialized to their own normalized states, followed by another regression sub-network to refine the landmark positions. To deal with the inconsistent annotations in existing training datasets, we further propose an adaptive landmark-weighted loss function. It dynamically adjusts the importance of different landmarks according to their learning errors during training without depending on any hyper-parameters manually set by trial and error. A high level of robustness to annotation inconsistencies is thus achieved. The whole deep architecture permits training from end to end, and extensive experimental analyses and comparisons demonstrate its effectiveness and efficiency. The source code, trained models, and experimental results are made available at https://github.com/shaoxiaohu/Face_Alignment_DPR.git.
DA  - 2022/09/01/
PY  - 2022
DO  - 10.1109/TPAMI.2021.3073593
VL  - 44
IS  - 9
SP  - 5488
EP  - 5502
SN  - 0162-8828
AN  - WOS:000836666600070
KW  - Deep learning
KW  - article
KW  - comparative effectiveness
KW  - Feature representation
KW  - Network architecture
KW  - Mapping
KW  - learning
KW  - Errors
KW  - Face recognition
KW  - Alignment
KW  - loss of function mutation
KW  - Face alignment
KW  - adaptive learning
KW  - body weight
KW  - deep architecture
KW  - Effectiveness and efficiencies
KW  - Error-driven learning
KW  - Experimental comparison
KW  - Improve performance
KW  - Initial estimation
KW  - Learning objectives
KW  - regression model
KW  - supervised spatial transformer network
KW  - Weighted loss function
ER  - 

TY  - JOUR
TI  - Machine learning driven smart fire safety design of false ceiling and emergency response
AU  - Khan, AA
AU  - Zhang, TH
AU  - Huang, XY
AU  - Usmani, A
T2  - PROCESS SAFETY AND ENVIRONMENTAL PROTECTION
AB  - In modern buildings, false ceilings are widely used for building services systems and aesthetic purposes, but they also pose challenges in terms of fire safety. A fire accident typically results from the failure of multiple safety measures or components. In many fire accidents, fire and smoke reached the false ceiling and kept spreading in the interstitial space without any detection. This study first generates a numerical database of false ceiling fire scenarios by varying the room dimensions, false-ceiling leakage area, fire size and locations. Then, a smart model based on machine learning to predict the fire smoke motion below and above the false ceiling is developed. The trained model is capable to predict the activation time of fire detectors and sprinklers for any given false ceiling design and fire scenario. This methodology enables a designer to generate multiple fire scenarios and determine the available safe egress time (ASET) for performance-based fire engineering designs especially in terms of fire detection time. In case of a real fire, with the data feed from the fire sensor network, the trained machine learning model can further predict the critical building fire events with the false ceiling, such as multi-compartment fires, smoke in the evacuation path, and structural failures. This work proposes a smart framework for improving the building fire safety design of false ceilings and the sensor-driven fire forecast to support firefighting.It enhances the emergency response processes by enabling dynamic risk assessment through prediction of critical events.
DA  - 2023/09//undefined
PY  - 2023
DO  - 10.1016/j.psep.2023.07.068
VL  - 177
SP  - 1294
EP  - 1306
SN  - 0957-5820
AN  - WOS:001054066600001
KW  - Artificial intelligence
KW  - Machine learning
KW  - Machine-learning
KW  - Forecasting
KW  - Data driven
KW  - Fires
KW  - Building safety
KW  - Data-driven forecast
KW  - Emergency services
KW  - False ceilings
KW  - Fire detection
KW  - Fire extinguishers
KW  - Fire protection
KW  - Fire safety designs
KW  - Fire scenarios
KW  - Fire smoke
KW  - Fracture mechanics
KW  - Hose
KW  - Sensor networks
KW  - Smart firefighting
KW  - Smoke
ER  - 

TY  - CONF
TI  - Battery Diagnosis: A Lifelong Learning Framework for Electric Vehicles
AU  - Zhao, JY
AU  - Nan, JR
AU  - Wang, JB
AU  - Ling, HP
AU  - Lian, YB
AU  - Burke, A
AU  - IEEE
T2  - 2022 IEEE VEHICLE POWER AND PROPULSION CONFERENCE (VPPC)
AB  - Expending manufacturing capacity and development of high-energy batteries greatly stimulate the growth and applications of electric vehicles (EVs). However, battery diagnostics and prognostics related to capacity degradation (referred as state of health, SOH) and safety issues (referred as state of safety, SOS) in real-world applications is still a big deal. Due to the uncertainties in materials and manufacturing, dynamic operation conditions as well as a lack of plentiful, high-quality on-road data, accurate diagnosis of battery performance for "real EVs" is very challenging. Considering the difficulty in accurately predicting battery behaviors in real-world applications, brand-new control area networks (CAN) and cloud-based solution could have considerable benefits. An AI-powered cloud-based framework integrating longitudinal electronic health records with real-world data enables continuous battery performance evaluation for EVs. This offers opportunities for combining data generation with data-driven approaches to predict the behavior of complex, time-varying electrochemical systems. It is hoped that this paper will be of reference value to the EV and battery industries for ameliorating some of the hurdles for battery diagnostics and prognostics under realistic EV conditions.
DA  - 2022///
PY  - 2022
DO  - 10.1109/VPPC55846.2022.10003378
SN  - 1938-8756
AN  - WOS:000925907200078
KW  - machine learning
KW  - Machine learning
KW  - Machine-learning
KW  - safety
KW  - Real-world
KW  - framework
KW  - Electric vehicles
KW  - Battery
KW  - Cloud-based
KW  - Data driven
KW  - cloud
KW  - State of health
KW  - data-driven
KW  - Life long learning
KW  - battery
KW  - Battery performance
KW  - Diagnostics and prognostics
KW  - failure
KW  - Failure (mechanical)
KW  - Framework
KW  - SOH
ER  - 

TY  - JOUR
TI  - Utilising blockchain technology to provide safety for smart home networks
AU  - Kumar, TS
AU  - Andrews, LJB
AU  - Madhini, M
AU  - Hemalatha, K
T2  - INTERNATIONAL JOURNAL OF ELECTRONIC SECURITY AND DIGITAL FORENSICS
AB  - Bitcoin, other cryptocurrencies, and the trading of digital assets were among the first uses for blockchain technology. However, blockchain has many other advantages as well. This paper details the application of blockchain technology to the problem of domestic safety. In order to demonstrate how blockchain technology can be used to secure mobile agents in the IoT, this paper will make use of Ethereum and a smart contract. Malicious mobile agents that attempt to infiltrate internet of things (IoT) systems can be identified through blockchain transactions. The blockchain centre is the central repository for all records, guaranteeing their verifiability and making it impossible to forge them. The outcomes of the evaluations show that the proposed security solutions are superior to the ones currently in use. Our research suggests that the proposed blockchain-enabled solution can enhance smart home security while also allowing for more nuanced user input.
DA  - 2023///
PY  - 2023
DO  - 10.1504/IJESDF.2023.133193
VL  - 15
IS  - 5
SP  - 532
EP  - 540
SN  - 1751-911X
AN  - WOS:001062152000006
ER  - 

TY  - JOUR
TI  - Journalism Ethics for the Algorithmic Era
AU  - Paik, S
T2  - DIGITAL JOURNALISM
AB  - In an era characterized by the widespread use of algorithmic systems and platforms in news production and distribution practices, the ethical practices of journalists face significant challenges. Drawing on Floridi's onlife framework, this study aims to shed light on journalist-machine interactions and explores new ways to rearchitect journalism ethical standards through an integrative, object-oriented approach. In-depth interviews with local news workers throughout the U.S. reveal a range of issues related to decontextualization in algorithmic platform design, the hidden price of platform partnerships, and the growing reliance on automated tools that foreshadow ethical issues to come. These algorithmically-induced challenges appear to be particularly pronounced in local newsrooms, highlighting the disproportionate impact of algorithmic systems on under-served media sectors. Discussions are made around the constant push-and-pull over editorial power dynamics apparent in local news workers' use of algorithmic systems. A distributed responsibility model is proposed as a practical way to hold multiple actors, including both humans and algorithms, accountable for journalism's ethical standards in the algorithmic era.
DA  - 2023/04/09/
PY  - 2023
DO  - 10.1080/21670811.2023.2200195
SN  - 2167-0811
AN  - WOS:000983089000001
ER  - 

TY  - JOUR
TI  - Machine Learning Framework for Real-Time Assessment of Traffic Safety Utilizing Connected Vehicle Data
AU  - Mussah, AR
AU  - Adu-Gyamfi, Y
T2  - SUSTAINABILITY
AB  - Assessment of roadway safety in real-time is a necessary component for providing proactive safety countermeasures to ensure the continued safety and efficiency of roadways. A framework for utilizing data from connected vehicles and other probe sources is proposed in this study. Connected vehicles present an opportunity to provide live fingerprinting and activity monitoring on roadways. Taking advantage of high-resolution trajectory data streaming directly from connected vehicles, variables are extracted and the relationship with crashes are explored utilizing statistical and machine learning models. Hard acceleration events, in conjunction with segment miles are shown to have strong positive correlations with historical crash outcomes as proven by OLS, Poisson and Gradient Booster regression models. An XGBoost classification model is then trained to predict the real-time instances of crash outcomes at 5 min temporal bins with high levels of accuracy when trained with data including the real-time segment speed, reference speed, segment miles, a segment crash risk factor and other variables related to the difference in speeds between consecutive segments as well as the hour of the day. A weighted ensemble model achieved the best performance with an accuracy of 0.95. The results present evidence that the framework can capitalize on the richness of data available via connected vehicles and is implementable as a component in Advanced Traffic Management Systems for the analysis of safety critical situations in real-time.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.3390/su142215348
VL  - 14
IS  - 22
SN  - 2071-1050
AN  - WOS:000887631300001
KW  - machine learning
KW  - travel behavior
KW  - safety
KW  - classification
KW  - transportation safety
KW  - risk factor
KW  - connected vehicle big data analysis
KW  - driver behavior analysis
KW  - environmental monitoring
KW  - intelligent transportation system
KW  - intelligent transportation systems services
KW  - probe
KW  - real time
KW  - road safety data collection and analysis
KW  - road traffic safety management
KW  - trajectory
ER  - 

TY  - JOUR
TI  - Towards a More Reliable Interpretation of Machine Learning Outputs for Safety-Critical Systems Using Feature Importance Fusion
AU  - Rengasamy, D
AU  - Rothwell, BC
AU  - Figueredo, GP
T2  - APPLIED SCIENCES-BASEL
AB  - When machine learning supports decision-making in safety-critical systems, it is important to verify and understand the reasons why a particular output is produced. Although feature importance calculation approaches assist in interpretation, there is a lack of consensus regarding how features' importance is quantified, which makes the explanations offered for the outcomes mostly unreliable. A possible solution to address the lack of agreement is to combine the results from multiple feature importance quantifiers to reduce the variance in estimates and to improve the quality of explanations. Our hypothesis is that this leads to more robust and trustworthy explanations of the contribution of each feature to machine learning predictions. To test this hypothesis, we propose an extensible model-agnostic framework divided in four main parts: (i) traditional data pre-processing and preparation for predictive machine learning models, (ii) predictive machine learning, (iii) feature importance quantification, and (iv) feature importance decision fusion using an ensemble strategy. Our approach is tested on synthetic data, where the ground truth is known. We compare different fusion approaches and their results for both training and test sets. We also investigate how different characteristics within the datasets affect the quality of the feature importance ensembles studied. The results show that, overall, our feature importance ensemble framework produces 15% less feature importance errors compared with existing methods. Additionally, the results reveal that different levels of noise in the datasets do not affect the feature importance ensembles' ability to accurately quantify feature importance, whereas the feature importance quantification error increases with the number of features and number of orthogonal informative features. We also discuss the implications of our findings on the quality of explanations provided to safety-critical systems.
DA  - 2021/12//undefined
PY  - 2021
DO  - 10.3390/app112411854
VL  - 11
IS  - 24
SN  - 2076-3417
AN  - WOS:000735850600001
KW  - Accountability
KW  - Interpretability
KW  - Deep learning
KW  - Explainable artificial intelligence
KW  - Machine learning
KW  - Responsible artificial intelligence
KW  - Data fusion
KW  - Ensemble feature importance
ER  - 

TY  - JOUR
TI  - Machine Learning for Detection of Safety Signals From Spontaneous Reporting System Data: Example of Nivolumab and Docetaxel
AU  - Bae, JH
AU  - Baek, YH
AU  - Lee, JE
AU  - Song, I
AU  - Lee, JH
AU  - Shin, JY
T2  - FRONTIERS IN PHARMACOLOGY
AB  - Introduction: Various methods have been implemented to detect adverse drug reaction (ADR) signals. However, the applicability of machine learning methods has not yet been fully evaluated.
Objective: To evaluate the feasibility of machine learning algorithms in detecting ADR signals of nivolumab and docetaxel, new and old anticancer agents.
Methods: We conducted a safety surveillance study of nivolumab and docetaxel using the Korea national spontaneous reporting database from 2009 to 2018. We constructed a novel input dataset for each study drug comprised of known ADRs that were listed in the drug labels and unknown ADRs. Given the known ADRs, we trained machine learning algorithms and evaluated predictive performance in generating safety signals of machine learning algorithms (gradient boosting machine [GBM] and random forest [RF]) compared with traditional disproportionality analysis methods (reporting odds ratio [ROR] and information component [IC]) by using the area under the curve (AUC). Each method then was implemented to detect new safety signals from the unknown ADR datasets.
Results: Of all methods implemented, GBM achieved the best average predictive performance (AUC: 0.97 and 0.93 for nivolumab and docetaxel). The AUC achieved by each method was 0.95 and 0.92 (RF), 0.55 and 0.51 (ROR), and 0.49 and 0.48 (IC) for respective drug. GBM detected additional 24 and nine signals for nivolumab and 82 and 76 for docetaxel compared to ROR and IC, respectively, from the unknown ADR datasets.
Conclusion: Machine learning algorithm based on GBM performed better and detected more new ADR signals than traditional disproportionality analysis methods.
DA  - 2021/01/14/
PY  - 2021
DO  - 10.3389/fphar.2020.602365
VL  - 11
SN  - 1663-9812
AN  - WOS:000615714700001
KW  - machine learning
KW  - prediction
KW  - female
KW  - human
KW  - male
KW  - algorithm
KW  - Article
KW  - major clinical study
KW  - random forest
KW  - drug safety
KW  - mental disease
KW  - side effect
KW  - adverse drug reaction
KW  - machine learning algorithms
KW  - signal detection
KW  - feasibility study
KW  - application site reaction
KW  - biliary tract disease
KW  - bleeding
KW  - blood clotting disorder
KW  - cardiovascular disease
KW  - central nervous system disease
KW  - clinical evaluation
KW  - collagen disease
KW  - disproportionality analysis
KW  - docetaxel
KW  - drug intoxication
KW  - drug labeling
KW  - endocardial disease
KW  - endocrine disease
KW  - erythrocyte disorder
KW  - gastrointestinal disease
KW  - gradient boosting machine
KW  - gynecologic disease
KW  - hearing disorder
KW  - heart arrhythmia
KW  - information component
KW  - leukocyte disorder
KW  - liver disease
KW  - male genital system disease
KW  - malignant neoplasm
KW  - metabolic disorder
KW  - musculoskeletal disease
KW  - myocardial disease
KW  - nivolumab
KW  - nutritional disorder
KW  - pericardial disease
KW  - peripheral neuropathy
KW  - reporting odds ratio
KW  - respiratory tract disease
KW  - sensory dysfunction
KW  - skin appendage disease
KW  - skin disease
KW  - thrombocyte disorder
KW  - valvular heart disease
KW  - vascular disease
KW  - vestibular disorder
KW  - visual disorder
ER  - 

TY  - JOUR
TI  - Safe Reinforcement Learning for Single Train Trajectory Optimization via Shield SARSA
AU  - Zhao, ZC
AU  - Xun, J
AU  - Wen, XG
AU  - Chen, JQ
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - The single train trajectory optimization, also known as speed profile optimization (SPO), is a traditional problem to minimize the traction energy consumption of trains. As a kind of optimal method, reinforcement learning (RL) has been used to solve the SPO problem. In the learning process of a common RL algorithm, a soft constraint (punishment) is always used to keep the agent away from unsafe states. However, a soft constraint can not guarantee and explain the safety of the result. For the SPO problem, it means that the optimized speed profile obtained by a simple RL may break the speed limit which is unacceptable in reality. This paper proposes a protection mechanism called Shield and constructs a Shield SARSA (S-SARSA) algorithm to protect the learning process of the high-speed train. Four different reward functions are used to compare the protective efficacy between the proposed algorithm and the soft constraint. The numerical experiments based on the line data from Wuxi East to Suzhou North verify the protective efficacy and effectiveness.
DA  - 2023/01//undefined
PY  - 2023
DO  - 10.1109/TITS.2022.3218705
VL  - 24
IS  - 1
SP  - 412
EP  - 428
SN  - 1524-9050
AN  - WOS:000881972100001
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Energy efficiency
KW  - Railroads
KW  - Optimization
KW  - Energy utilization
KW  - Safe reinforcement learning
KW  - Trajectories
KW  - Railroad cars
KW  - Heuristic algorithms
KW  - Railroad transportation
KW  - Optimal controls
KW  - Aerodynamics
KW  - Heuristics algorithm
KW  - Energy efficient
KW  - trajectory optimization
KW  - Trajectory optimization
KW  - energy efficient
KW  - Shield SARSA
KW  - Speed profile
ER  - 

TY  - JOUR
TI  - Maritime Traffic Route Detection Framework Based on Statistical Density Analysis From AIS Data Using a Clustering Algorithm
AU  - Lee, JS
AU  - Lee, HT
AU  - Cho, IS
T2  - IEEE ACCESS
AB  - Maritime traffic routes by ships navigation vary according to country and geographic characteristics, and they differ according to the characteristics of the ships. In ocean areas adjacent to coasts, regulated routes are present, e.g., traffic separation scheme for ships entering and leaving; however, most ocean areas do not have such routes. Maritime traffic route research has been conducted based on computer engineering to create routes; however, ship characteristics were not considered. Thus, this article proposes a framework to generate maritime traffic routes using statistical density analysis. Here, automatic identification system (AIS) data are used to derive quantitative traffic routes. Preprocessing is applied to the AIS data, and a similar ship trajectory pattern is decomposed into a matrix based on the Hausdorff-distance algorithm and then stored in a database. A similar pattern makes the AIS trajectory simple using the Douglas-Peucker algorithm. In addition, density-based spatial clustering of applications with noise (DBSCAN) is performed to identify the waypoints of vessels then create routes by connecting waypoints. The width of maritime routes created based on a similar ship trajectory is subjected to kernel density estimation analysis (KDE). Then, waypoints evaluation of the main route is performed from the results of KDE 75% and 90% considering the statistical in the total maritime traffic, and the results applied to the targeted ocean area are compared. Finally, the result of KDE 90% of maritime traffic with framework analyzed the safety route, which can be a basis for developing routes for maritime autonomous surface ships.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3154363
VL  - 10
SP  - 23355
EP  - 23366
SN  - 2169-3536
AN  - WOS:000766575800001
ER  - 

TY  - JOUR
TI  - Applying an interpretable machine learning framework to the traffic safety order analysis of expressway exits based on aggregate driving behavior data
AU  - Qi, H
AU  - Yao, Y
AU  - Zhao, XH
AU  - Guo, JF
AU  - Zhang, YL
AU  - Bi, CF
T2  - PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS
AB  - In light of the increasing amount of traffic disorder at road traffic hubs, to improve traffic safety, it is essential to detect road risks in advance and analyze the causes after its occurrence. In this study, interpretable machine learning (ML) is employed to analyze the traffic order by using a set of multi-source data comprising traffic conditions, traffic control devices, road conditions, and external conditions. Data were collected from the exits of some Beijing expressways via navigation and field investigations. The traffic order index (TOI) based on aggregate driving behavior data is used as a new surrogate index to evaluate the safety risk. A traffic order prediction model is then constructed by adapting the eXtreme Gradient Boosting (XGBoost) ML method. In addition, SHapley Additive exPlanation (SHAP) is employed to interpret the results and explore the relationships between the influencing factors and the traffic order. The results indicate that XGBoost could predict the traffic order levels well, and achieved an accuracy, precision, recall, and F-1-score of 92.62%, 92.67%, 92.62%, and 92.63%, respectively. The congestion index was found to have a great influence on traffic order. Furthermore, the number of lanes, advance guide signs, and weather conditions can have different effects on the traffic order under different traffic conditions. (C) 2022 Elsevier B.V. All rights reserved.
DA  - 2022/07/01/
PY  - 2022
DO  - 10.1016/j.physa.2022.127277
VL  - 597
SN  - 0378-4371
AN  - WOS:000806160500009
KW  - Machine learning
KW  - SHAP
KW  - Interpretable machine learning
KW  - XGBoost
KW  - Accident prevention
KW  - Roads and streets
KW  - Motor transportation
KW  - Traffic signs
KW  - Traffic safety
KW  - Driving behaviour
KW  - Traffic congestion
KW  - Shapley additive explanation
KW  - Safety analysis
KW  - Shapley
KW  - Aggregates
KW  - Xgboost
KW  - Traffic conditions
KW  - Traffic order level
KW  - Traffic order levels
KW  - Traffic safety analyse
KW  - Traffic safety analysis
ER  - 

TY  - CHAP
TI  - Using Computational Intelligence for the Safety Assessment of Oil and Gas Pipelines: A Survey
AU  - Mohamed, A
AU  - Hamdi, MS
AU  - Tahar, S
T2  - DATA SCIENCE AND BIG DATA: AN ENVIRONMENT OF COMPUTATIONAL INTELLIGENCE
A2  - Pedrycz, W
A2  - Chen, SM
AB  - The applicability of intelligent techniques for the safety assessment of oil and gas pipelines is investigated in this study. Crude oil and natural gas are usually transmitted through metallic pipelines. Working under unforgiving environments, these pipelines may extend to hundreds of kilometers, which make them very susceptible to physical damage such as dents, cracks, corrosion, etc. These defects, if not managed properly, can lead to catastrophic consequences in terms of both financial losses and human life. Thus, effective and efficient systems for pipeline safety assessment that are capable of detecting defects, estimating defects sizes, and classifying defects are urgently needed. Such systems often require collecting diagnostic data that are gathered using different monitoring tools such as ultrasound, magnetic flux leakage, and Closed Circuit Television (CCTV) surveys. The volume of the data collected by these tools is staggering. Relying on traditional pipeline safety assessment techniques to analyze such huge data is neither efficient nor effective. Intelligent techniques such as data mining techniques, neural networks, and hybrid neuro-fuzzy systems are promising alternatives. In this paper, different intelligent techniques proposed in the literature are examined; and their merits and shortcomings are highlighted.
DA  - 2017///
PY  - 2017
VL  - 24
SP  - 189
EP  - 207
SN  - 2197-6503
AN  - WOS:000419727100010
ER  - 

TY  - JOUR
TI  - Model-augmented safe reinforcement learning for Volt-VAR control in power distribution networks
AU  - Gao, YQ
AU  - Yu, NP
T2  - APPLIED ENERGY
AB  - Volt-VAR control (VVC) is a critical tool to manage voltage profiles and reactive power flow in power distribution networks by setting voltage regulating and reactive power compensation device status. To facilitate the adoption of VVC, many physical model-based and data-driven algorithms have been proposed. However, most of the physical model-based methods rely on distribution network parameters, whereas the data-driven algorithms lack safety guarantees. In this paper, we propose a data-driven safe reinforcement learning (RL) algorithm for the VVC problem. We introduce three innovations to improve the learning efficiency and the safety. First, we train the RL agent using a learned environment model to improve the sample efficiency. Second, a safety layer is added to the policy neural network to enhance operational constraint satisfactions for both initial exploration phase and convergence phase. Finally, to improve the algorithm's performance when learning from limited data, we propose a novel mutual information regularization neural network for the safety layer. Simulation results on IEEE distribution test feeders show that the proposed algorithm improves constraint satisfactions compared to existing data-driven RL methods. With a modest amount of historical data, it is able to approximately maintain constraint satisfactions during the entire course of training. Asymptotically, it also yields similar level of performance of an ideal physical model-based benchmark. One possible limitation is that the proposed framework assumes a time-invariant distribution network topology and zero load transfer from other circuits. This is also an opportunity for future research.
DA  - 2022/05/01/
PY  - 2022
DO  - 10.1016/j.apenergy.2022.118762
VL  - 313
SN  - 0306-2619
AN  - WOS:000793751900002
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - algorithm
KW  - Efficiency
KW  - Benchmarking
KW  - Electric load flow
KW  - Model-based OPC
KW  - Data driven
KW  - reinforcement
KW  - Data-driven algorithm
KW  - Multilayer neural networks
KW  - distribution system
KW  - Reactive power
KW  - Static Var compensators
KW  - Constraint Satisfaction
KW  - control system
KW  - Safe exploration
KW  - Value engineering
KW  - Data-driven
KW  - VAR control
KW  - Physical modelling
KW  - exploration
KW  - Pathwise derivative
KW  - Power distribution network
KW  - Volt-VAR control
ER  - 

TY  - JOUR
TI  - Lane detection method based on lane structural analysis and CNNs
AU  - Ye, YY
AU  - Hao, XL
AU  - Chen, HJ
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - Advanced driving assistance systems (ADASs) play a vital role in the safety of transportation. The detection of lane markings is a very important part of ADASs. For the safety of autonomous vehicles and vehicles driven by human drivers, accurate detection results are necessary. In this study, the authors propose a novel algorithm based on lane structural analysis and convolutional neural networks (CNNs) for lane marking detection. First, a pre-processing stage is used to remove the pavement that constitutes the background of the lane markings. Next, a set of local waveforms from local images is used to generate a region of interest and a CNN classifier is employed to detect lane marking candidates. Finally, a lane geometry analysis stage determines whether or not the candidate is a part of a lane marking. The major contributions of this study can be summarised as follows. First, they propose a novel method to describe a road using waveforms. Second, they analyse the local and global characteristics of the road geometry to detect the lane markings. Third, they provide an effective method to obtain training data for the proposed machine learning method. Experimental results demonstrate that the proposed method outperforms conventional methods.
DA  - 2018/08//undefined
PY  - 2018
DO  - 10.1049/iet-its.2017.0143
VL  - 12
IS  - 6
SP  - 513
EP  - 520
SN  - 1751-956X
AN  - WOS:000437188000015
ER  - 

TY  - JOUR
TI  - Islanding detection method for microgrid based on extracted features from differential transient rate of change of frequency
AU  - Hashemi, F
AU  - Mohammadi, M
AU  - Kargarian, A
T2  - IET GENERATION TRANSMISSION & DISTRIBUTION
AB  - One of the most important challenges in microgrid operation is the unintentional islanding occurrence. Unintentional islanding can cause serious safety hazards and technical issues. Islanding detection methods can be classified into active and passive methods. The main disadvantages of the passive methods are large non-detection zone as well as determination of suitable threshold value to avoid unwanted distributed generations tripping in normal network events. In order to overcome these drawbacks, this study proposes a novel, fast, and reliable method to identify islanding conditions. The proposed method calculates different transient states in the rate of change of frequency signal in two consecutive cycles. Various features of the differential signal are extracted. The extracted feature vectors associated with different operation conditions such as islanding and non-islanding events are used to train artificial neural networks (ANNs). The performances of different structures of ANNs and also other machine learning methods such as support vector machine and adaptive neuro fuzzy inference system are evaluated for islanding detection purposes. The simulation results indicate that the proposed method provides more accurate and faster responses compared with other conventional islanding detection methods.
DA  - 2017/03/09/
PY  - 2017
DO  - 10.1049/iet-gtd.2016.0795
VL  - 11
IS  - 4
SP  - 891
EP  - 904
SN  - 1751-8687
AN  - WOS:000398589300009
ER  - 

TY  - CONF
TI  - Evidence-driven Data Requirements Engineering and Data Uncertainty Assessment of Machine Learning-based Safety-critical Systems
AU  - Dey, S
T2  - 2022 30TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2022)
A2  - Knauss, E
A2  - Mussbacher, G
A2  - Arora, C
A2  - Bano, M
A2  - Schneider, JG
AB  - Reliance on data-centric machine learning (ML) models in complex systems has posed numerous challenges in the software engineering process, especially when the system is deployed in a high-risk environment Due to the inherent uncertainty of such ML models, the safety assurance of these systems is now a primary concern. Recently, many researchers are focusing on assuring safe outcomes of ML models. However, not enough attention is paid to evaluating the training data uncertainty before indulging in ML training. Currently, there are no specific guidelines on how to perceive, elicit and specify data requirements and assure the data quality depending on the ML objective and problem domain. To address these gaps, this research provides guidelines for a systematic data requirements engineering and data uncertainty assessment process involving diverse stakeholders. A three-layered framework is proposed that helps to explore the data space and elicit verifiable data requirements. Such requirements can facilitate the evaluation of the collective confidence of the experts in data quality. To accommodate epistemic uncertainty of such assessment (inconclusive due to lack of knowledge) Dempster Shafer's theory of evidence is used. The application of this theory within the proposed framework aims to address the identified research gaps.
DA  - 2022///
PY  - 2022
DO  - 10.1109/RE54965.2022.00027
SP  - 219
EP  - 224
SN  - 978-1-6654-7000-1
AN  - WOS:000931050900020
KW  - machine learning
KW  - Machine learning
KW  - Machine-learning
KW  - Machine learning models
KW  - Safety engineering
KW  - Uncertainty analysis
KW  - Data quality
KW  - Security systems
KW  - Safety critical systems
KW  - Data centric
KW  - Software engineering
KW  - data requirements
KW  - Data requirements
KW  - Requirement engineering
KW  - Requirements engineering
KW  - data uncertainty
KW  - Data uncertainty
KW  - safety critical systems
KW  - Software engineering process
KW  - Uncertainty assessment
ER  - 

TY  - JOUR
TI  - Comprehensive Bird Preservation at Wind Farms
AU  - Gradolewski, D
AU  - Dziak, D
AU  - Martynow, M
AU  - Kaniecki, D
AU  - Szurlej-Kielanska, A
AU  - Jaworski, A
AU  - Kulesza, WJ
T2  - SENSORS
AB  - Wind as a clean and renewable energy source has been used by humans for centuries. However, in recent years with the increase in the number and size of wind turbines, their impact on avifauna has become worrisome. Researchers estimated that in the U.S. up to 500,000 birds die annually due to collisions with wind turbines. This article proposes a system for mitigating bird mortality around wind farms. The solution is based on a stereo-vision system embedded in distributed computing and IoT paradigms. After a bird's detection in a defined zone, the decision-making system activates a collision avoidance routine composed of light and sound deterrents and the turbine stopping procedure. The development process applies a User-Driven Design approach along with the process of component selection and heuristic adjustment. This proposal includes a bird detection method and localization procedure. The bird identification is carried out using artificial intelligence algorithms. Validation tests with a fixed-wing drone and verifying observations by ornithologists proved the system's desired reliability of detecting a bird with wingspan over 1.5 m from at least 300 m. Moreover, the suitability of the system to classify the size of the detected bird into one of three wingspan categories, small, medium and large, was confirmed.
DA  - 2021/01//undefined
PY  - 2021
DO  - 10.3390/s21010267
VL  - 21
IS  - 1
SN  - 1424-8220
AN  - WOS:000606059700001
ER  - 

TY  - JOUR
TI  - An Unsupervised Sentiment Classification Method Based on Multi-Level Fuzzy Computing and Multi-Criteria Fusion
AU  - Wang, BK
AU  - He, WN
AU  - Yang, Z
AU  - Xiong, SF
T2  - IEEE ACCESS
AB  - With the rapid growth of user-generated content, unsupervised methods that do not require label training data have gradually become a research focus in the field of sentiment classification and natural language processing. But the performance of unsupervised methods is unsatisfactory. This is because the ambiguity of sentiment polarity and the fuzziness of sentiment intensity are usually ignored in existing unsupervised methods. To address these problems, we propose an unsupervised sentiment classification method based on multi-level fuzzy computing and multi-criteria fusion which involves three innovations. Firstly, we come up with a multi-level computing model to compute the sentiment intensity of reviews for partly reducing the ambiguity of sentiment polarity. Secondly, to further decrease the ambiguity of sentiment polarity, a multi-criteria fusion strategy based on sentiment category credibility and domain category representativeness is proposed. Thirdly, a fuzzy classifier is constructed to solve the fuzziness of sentiment intensity. Furthermore, a self-supervised method using pseudo-labeled training data is proposed to learn the optimum parameters of the fuzzy classifier. Experimental results in three different domain balanced datasets and one unbalanced dataset proved that our method improves 12.35% more accuracy than the competitive baselines in sentiment classification.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3014849
VL  - 8
SP  - 145422
EP  - 145434
SN  - 2169-3536
AN  - WOS:000560335100001
ER  - 

TY  - JOUR
TI  - eXplainable and Reliable Against Adversarial Machine Learning in Data Analytics
AU  - Vaccari, I
AU  - Carlevaro, A
AU  - Narteni, S
AU  - Cambiaso, E
AU  - Mongelli, M
T2  - IEEE ACCESS
AB  - Machine learning (ML) algorithms are nowadays widely adopted in different contexts to perform autonomous decisions and predictions. Due to the high volume of data shared in the recent years, ML algorithms are more accurate and reliable since training and testing phases are more precise. An important concept to analyze when defining ML algorithms concerns adversarial machine learning attacks. These attacks aim to create manipulated datasets to mislead ML algorithm decisions. In this work, we propose new approaches able to detect and mitigate malicious adversarial machine learning attacks against a ML system. In particular, we investigate the Carlini-Wagner (CW), the fast gradient sign method (FGSM) and the Jacobian based saliency map (JSMA) attacks. The aim of this work is to exploit detection algorithms as countermeasures to these attacks. Initially, we performed some tests by using canonical ML algorithms with a hyperparameters optimization to improve metrics. Then, we adopt original reliable AI algorithms, either based on eXplainable AI (Logic Learning Machine) or Support Vector Data Description (SVDD). The obtained results show how the classical algorithms may fail to identify an adversarial attack, while the reliable AI methodologies are more prone to correctly detect a possible adversarial machine learning attack. The evaluation of the proposed methodology was carried out in terms of good balance between FPR and FNR on real world application datasets: Domain Name System (DNS) tunneling, Vehicle Platooning and Remaining Useful Life (RUL). In addition, a statistical analysis was performed to improve the robustness of the trained models, including evaluating their performance in terms of runtime and memory consumption.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3197299
VL  - 10
SP  - 83949
EP  - 83970
SN  - 2169-3536
AN  - WOS:000842742900001
ER  - 

TY  - CONF
TI  - Towards Data Driven Traffic Modelling: Safe Driving Based on Reinforcement Learning
AU  - Kyriazopoulos, V
AU  - Orfanou, F
AU  - Vlahogianni, EI
AU  - Yannis, G
AU  - IEEE
T2  - 2021 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE (ITSC)
AB  - In recent years, the evolution of technology has allowed the introduction of automation in vehicles, that improve road safety by reducing the contribution of the human factor to the driving process. The objective of this research is to propose a reinforcement learning algorithm for controlling driving behaviour with the aim to improve safety and comfort. The learning is based on detailed trajectory data from a highly visited signalized arterial in the Athens downtown area. The safe and comfortable driving profiles are identified from the trajectory data. Next, a simple Q-learning algorithm is developed and various combinations of the exploration rate, the discount factor. and the learning rate were tested for the optimal parameterization. The final Q-Table can be used inside vehicles for collision avoidance in order to improve road safety. Results indicate that the algorithm converges fast and is trained efficiently to response to unseen conditions. Further training in extreme events or adverse weather conditions will increase the generalisability of the proposed safe driving assistance framework.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ITSC48978.2021.9564829
SP  - 3156
EP  - 3161
SN  - 2153-0009
AN  - WOS:000841862503025
KW  - Reinforcement learning
KW  - Intelligent systems
KW  - Learning algorithms
KW  - Accident prevention
KW  - Reinforcement learnings
KW  - Roads and streets
KW  - Motor transportation
KW  - Driving behaviour
KW  - Safety factor
KW  - Simple++
KW  - Reinforcement learning algorithms
KW  - Safe driving
KW  - Data driven
KW  - Road safety
KW  - Evolution of technology
KW  - Traffic modeling
KW  - Trajectories datum
ER  - 

TY  - JOUR
TI  - Physics-informed machine learning-aided framework for prediction of minimum film boiling temperature
AU  - Kim, KM
AU  - Hurley, P
AU  - Duarte, JP
T2  - INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER
AB  - Minimum film boiling temperature (T-MFB) is a crucial parameter in post-critical heat flux (CHF) condition by determining the collapse of stable vapor film on overheated surface. Although many correlations have been suggested with a wide range of experimental data to predict the T-MFB considering various parameters, they have failed to accommodate the universal quenching data due to limited regression capability addressing effects of multivariate parameters. Even though several data-driven machine learning models (DDML) showed improved prediction performance, their performance are dramatically degraded in extrapolation conditions, which are unincluded in the training process. To overcome the inherent problems of conventional correlations and DDMLs, physics-informed machine learning-aided frameworks (PIMLAF) for T-MFB were developed in this study by combining the conventional correlations (Henry model and Groeneveld-Stewart correlation) and machine learning techniques (multi-layer perceptron and random forest) to overcome their limited regression capability and 'black-box' characteristics. For the interpolation condition, it was observed that the Groeneveld-Stewart correlation provides better baseline for T-MFB than Henry model, and random forest (RF) model has advantage discovering the pattern between T-MFB and input variables with tuning capability. Through benchmark studies corresponding to extrapolation condition of the training dataset, it was concluded that hybrid approach of RF model and Groeneveld-Stewart correlation exhibits the best performance on T-MFB prediction for both interpolation and extrapolation conditions compared to standalone machine learning models, Groeneveld-Stewart correlation, and MLP-based PIMLAF. The suggested RF-based PIMLAF is expected to enhance the T-MFB prediction performance during reflood phase of loss of coolant accidents in light water reactors. (C) 2022 Elsevier Ltd. All rights reserved.
DA  - 2022/08/01/
PY  - 2022
DO  - 10.1016/j.ijheatmasstransfer.2022.122839
VL  - 191
SN  - 0017-9310
AN  - WOS:000792177900007
KW  - Decision trees
KW  - Machine learning
KW  - Interpolation
KW  - Forecasting
KW  - Condition
KW  - Benchmarking
KW  - Heat flux
KW  - Data driven
KW  - Extrapolation
KW  - Data-driven machine learning
KW  - Boiling point
KW  - Boiling temperature
KW  - Coolants
KW  - Evaporation
KW  - Film boiling
KW  - Groeneveld
KW  - Light water reactors
KW  - Loss of coolant accidents
KW  - Minimum film boiling temperature
KW  - Nuclear safety
KW  - Physic-informed machine learning-aided framework
KW  - Physics-informed machine learning-aided framework
KW  - Post-CHF
KW  - Post-critical heat flux
ER  - 

TY  - JOUR
TI  - Clean and Safe Drinking Water Systems via Metagenomics Data and Artificial Intelligence: State-of-the-Art and Future Perspective
AU  - Mahajna, A
AU  - Dinkla, IJT
AU  - Euverink, GJW
AU  - Keesman, KJ
AU  - Jayawardhana, B
T2  - FRONTIERS IN MICROBIOLOGY
AB  - The use of next-generation sequencing technologies in drinking water distribution systems (DWDS) has shed insight into the microbial communities' composition, and interaction in the drinking water microbiome. For the past two decades, various studies have been conducted in which metagenomics data have been collected over extended periods and analyzed spatially and temporally to understand the dynamics of microbial communities in DWDS. In this literature review, we outline the findings which were reported in the literature on what kind of occupancy-abundance patterns are exhibited in the drinking water microbiome, how the drinking water microbiome dynamically evolves spatially and temporally in the distribution networks, how different microbial communities co-exist, and what kind of clusters exist in the drinking water ecosystem. While data analysis in the current literature concerns mainly with confirmatory and exploratory questions pertaining to the use of metagenomics data for the analysis of DWDS microbiome, we present also future perspectives and the potential role of artificial intelligence (AI) and mechanistic models to address the predictive and mechanistic questions. The integration of meta-omics, AI, and mechanistic models transcends metagenomics into functional metagenomics, enabling deterministic understanding and control of DWDS for clean and safe drinking water systems of the future.
DA  - 2022/05/05/
PY  - 2022
DO  - 10.3389/fmicb.2022.832452
VL  - 13
SN  - 1664-302X
AN  - WOS:000798700400001
ER  - 

TY  - JOUR
TI  - An environment safety monitoring system for agricultural production based on artificial intelligence, cloud computing and big data networks
AU  - Wei, YX
AU  - Han, C
AU  - Yu, ZL
T2  - JOURNAL OF CLOUD COMPUTING-ADVANCES SYSTEMS AND APPLICATIONS
AB  - Monitoring the agricultural production environment is crucial for optimal crop growth and resource efficiency. Cloud Computing, Artificial Intelligence (AI), and Big Data have revolutionized traditional agriculture, promising improved output and product quality. The popularity of these technologies drives their application in safety monitoring. This system facilitates data collection and transmission among equipment, overcoming challenges of traditional systems like investment, costs, and maintenance. In this paper, cloud computing-based AI optimization technology and big data network were proposed to monitor the safety of the agricultural production environment, and the shortcomings of traditional distance vector hop (DV hop) positioning algorithms were analyzed in depth. RSSI (Received Signal Strength Indication) technology improved the traditional DV Hop location method. The paper analyses direct and indirect transmission for data transmission between WSN and cloud nodes and favors indirect transmission because it consumes less invalid energy. Finally, the article compares several evaluations of alternative algorithms for monitoring system performance, including data transmission reliability, data reception rate, and data delay. The experimental results in this paper showed that in the data reception rate test, the data reception rate of System 2 was 97% at the lowest and 99% at the highest, both exceeding 95%.
DA  - 2023/06/08/
PY  - 2023
DO  - 10.1186/s13677-023-00463-1
VL  - 12
IS  - 1
SN  - 2192-113X
AN  - WOS:001003483500001
ER  - 

TY  - CONF
TI  - Natural Language Process: A New Kind of Nuclear Quality Assurance Management Tool
AU  - Guan, YQ
AU  - Sun, Y
AU  - Wang, ZY
AU  - Zheng, QY
T2  - INTERNATIONAL YOUTH NUCLEAR CONGRESS 2016, IYNC2016
A2  - Capriotti, L
A2  - Cao, L
A2  - Jimenez, G
AB  - Quality Assurance Management is imperative in nuclear engineering. And quality assurance language is a rigorous and highly logical language in workplaces. We build machine-learning models of natural language process about quality assurance management activities to extract valuable information from texts for management intelligently. As technological means, the primary purpose of NLP tools here is that converting massive unstructured data (text) to structured data (data attribute relationship). The tasks include event classification, named entity recognition (NER) of engineering, event domain judgment, automatic summarization and event similarity computing. We focus on Labeled-LDA and SVMs algorithms to perform short text classification. And using them as primary content, we can perform more advanced nuclear quality assurance management in future. (C) 2017 The Authors. Published by Elsevier Ltd.
DA  - 2017///
PY  - 2017
DO  - 10.1016/j.egypro.2017.08.096
VL  - 127
SP  - 201
EP  - 219
SN  - 1876-6102
AN  - WOS:000426883700024
KW  - machine learning
KW  - artificial intelligence
KW  - Artificial intelligence
KW  - Pattern recognition
KW  - AI
KW  - Learning systems
KW  - Text classification
KW  - Classification (of information)
KW  - topic models
KW  - Expert systems
KW  - Natural language processing systems
KW  - Text processing
KW  - Information management
KW  - Engineering education
KW  - Classification algorithm
KW  - text classification
KW  - Knowledge management
KW  - Character recognition
KW  - Quality assurance
KW  - Nuclear safety
KW  - SVM
KW  - NLP
KW  - Professional aspects
KW  - quality assurance
KW  - Topic model
KW  - experience feedback
KW  - Experience feedback
KW  - Chinese word segmentation
KW  - classification algorithms
KW  - corpus management
KW  - CRF
KW  - Enterprise resource management
KW  - enterprise resource planning
KW  - Enterprise resource planning
KW  - ERP
KW  - event classification
KW  - Event classification
KW  - expert system
KW  - knowledge management
KW  - Labeled-LDA
KW  - natural language process
KW  - Natural language process
KW  - nuclear engineering
KW  - Nuclear engineering
KW  - nuclear safety
KW  - Pattern Recognition
KW  - Pattern recognition systems
KW  - sequence labelling
KW  - unstructured data
KW  - Unstructured data
ER  - 

TY  - JOUR
TI  - A machine learning based approach for efficient safety evaluation of the high speed train and short span bridge system
AU  - Li, HL
AU  - Wu, G
AU  - Cui, MD
T2  - LATIN AMERICAN JOURNAL OF SOLIDS AND STRUCTURES
AB  - The dynamic responses of the high-speed railway bridge under the train passage can greatly affect the safety of the entire high-speed train and bridge system. Traditionally, these responses are obtained using either field measurement or numerical analysis. Both tools have their own limitations. For instance, the coupling dynamic train-bridge analysis is generally complicated and time-consuming. This paper proposes a novel machine learning based approach for efficient safety evaluation of the high speed train and short span bridge system. Artificial neural networks are established to map the complicated train-bridge system and to attain the critical bridge displacements. The proposed approach incorporates a complete numerical train-bridge system model to produce reliable data for the neural network training, considering multiple significant random features in the train-bridge system. Various neural network architectures are investigated and compared to find optimal ones that have considerable potentials in realizing online response prediction and safety evaluation. Although the proposed approach focuses on the high-speed train and short span bridge, the methodology is general and can also be applied to other scenarios associated with the vehicle-bridge systems.
DA  - 2020///
PY  - 2020
DO  - 10.1590/1679-78256238
VL  - 17
IS  - 7
SN  - 1679-7825
AN  - WOS:000579515100009
KW  - Machine learning
KW  - Neural networks
KW  - Speed
KW  - Railroads
KW  - Network architecture
KW  - Safety assessment
KW  - High speed train (HST)
KW  - Railroad cars
KW  - Turing machines
KW  - Railroad transportation
KW  - Safety evaluations
KW  - Backpropagation neural network
KW  - Bridge displacement
KW  - High-speed railway bridge
KW  - High-speed railway bridges
KW  - Neural network training
KW  - Railroad bridges
KW  - Response prediction
KW  - Structural dynamic analysis
KW  - Train-bridge interaction
KW  - Train-bridge systems
KW  - Vehicle-bridge system
ER  - 

TY  - JOUR
TI  - 5G Intelligence Underpinning Railway Safety in the COVID-19 Era
AU  - Alawad, H
AU  - Kaewunruen, S
T2  - FRONTIERS IN BUILT ENVIRONMENT
DA  - 2021/02/24/
PY  - 2021
DO  - 10.3389/fbuil.2021.639753
VL  - 7
SN  - 2297-3362
AN  - WOS:000626890400001
ER  - 

TY  - JOUR
TI  - Current progress in network research: toward reference networks for key model organisms
AU  - Srinivasan, BS
AU  - Shah, NH
AU  - Flannick, JA
AU  - Abeliuk, E
AU  - Novak, AF
AU  - Batzoglou, S
T2  - BRIEFINGS IN BIOINFORMATICS
AB  - The collection of multiple genome-scale datasets is now routine, and the frontier of research in systems biology has shifted accordingly. Rather than clustering a single dataset to produce a static map of functional modules, the focus today is on data integration, network alignment, interactive visualization and ontological markup. Because of the intrinsic noisiness of high-throughput measurements, statistical methods have been central to this effort. In this review, we briefly survey available datasets in functional genomics, review methods for data integration and network alignment, and describe recent work on using network models to guide experimental validation. We explain how the integration and validation steps spring from a Bayesian description of network uncertainty, and conclude by describing an important near-term milestone for systems biology: the construction of a set of rich reference networks for key model organisms.
DA  - 2007/09//undefined
PY  - 2007
DO  - 10.1093/bib/bbm038
VL  - 8
IS  - 5
SP  - 318
EP  - 332
SN  - 1467-5463
AN  - WOS:000251034700005
KW  - machine learning
KW  - Machine learning
KW  - Animals
KW  - review
KW  - prediction
KW  - Humans
KW  - Computational Biology
KW  - Forecasting
KW  - protein expression
KW  - medical research
KW  - information processing
KW  - Computer Simulation
KW  - cluster analysis
KW  - Protein Interaction Mapping
KW  - Bayesian learning
KW  - data analysis
KW  - sequence alignment
KW  - Data integration
KW  - Network alignment
KW  - validation process
KW  - Models, Biological
KW  - systems biology
KW  - Systems biology
KW  - protein database
KW  - Research
KW  - computer program
KW  - experimental model
KW  - Gene Expression Profiling
KW  - gene sequence
KW  - high throughput screening
KW  - network learning
KW  - online analytical processing
KW  - Pathways
KW  - protein interaction
KW  - Proteome
KW  - reference database
KW  - Reference networks
KW  - Signal Transduction
ER  - 

TY  - JOUR
TI  - A Hybrid RNN-HMM Approach for Weakly Supervised Temporal Action Segmentation
AU  - Kuehne, H
AU  - Richard, A
AU  - Gall, J
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - Action recognition has become a rapidly developing research field within the last decade. But with the increasing demand for large scale data, the need of hand annotated data for the training becomes more and more impractical. One way to avoid frame-based human annotation is the use of action order information to learn the respective action classes. In this context, we propose a hierarchical approach to address the problem of weakly supervised learning of human actions from ordered action labels by structuring recognition in a coarse-to-fine manner. Given a set of videos and an ordered list of the occurring actions, the task is to infer start and end frames of the related action classes within the video and to train the respective action classifiers without any need for hand labeled frame boundaries. We address this problem by combining a framewise RNN model with a coarse probabilistic inference. This combination allows for the temporal alignment of long sequences and thus, for an iterative training of both elements. While this system alone already generates good results, we show that the performance can be further improved by approximating the number of subactions to the characteristics of the different action classes as well as by the introduction of a regularizing length prior. The proposed system is evaluated on two benchmark datasets, the Breakfast and the Hollywood extended dataset, showing a competitive performance on various weak learning tasks such as temporal action segmentation and action alignment.
DA  - 2020/04/01/
PY  - 2020
DO  - 10.1109/TPAMI.2018.2884469
VL  - 42
IS  - 4
SP  - 765
EP  - 779
SN  - 0162-8828
AN  - WOS:000526541100001
ER  - 

TY  - JOUR
TI  - Addressing the Responsibility Gap in Data Protection by Design: Towards a More Future-oriented, Relational, and Distributed Approach
AU  - Colonna, L
T2  - TILBURG LAW REVIEW-JOURNAL OF INTERNATIONAL AND EUROPEAN LAW
AB  - This paper explores the extent to which technology providers are responsible to end users for embedding data protection rules in the AI systems they design and develop, so as to safeguard the fundamental rights to privacy and data protection. The main argument set forth is that a relational rationale, requiring a broader range of actors in the supply chain to share legal responsibility for Data Protection by Design (DPbD) is better suited to address infringements to these fundamental rights than the current model that assigns responsibility mainly to the data controller or data processor. Reconceptualizing the law in a more future-oriented, relational, and distributed way would make it possible to adapt legal rules - including those within the GDPR and the continuously evolving EU acquis - to the complex reality of technology development, at least partly addressing the responsibility gap in DPbD. A future-oriented conception of responsibility would require technology providers to adopt more proactive approaches to DPbD, even where they are unlikely to qualify as a controller. A relational approach to DPbD would require technology providers to bear greater responsibilities to those individuals or groups that are affected by their design choices. A distributed approach to DPbD would allow for downstream actors in the supply chain to bear part of the legal responsibility for DPbD by relying on legal requirements that are applicable to various actors in the supply chain supporting DPbD such as those found in contract law, liability law, and the emerging EU acquis governing AI, data, and information security.
DA  - 2022///
PY  - 2022
DO  - 10.5334/tilr.274
VL  - 27
IS  - 1
SP  - 1
EP  - 21
SN  - 2211-0046
AN  - WOS:001000908400001
ER  - 

TY  - JOUR
TI  - Application of data mining in assessing the level of corporate social responsibility disclosure compliant with financial performance and accounting criteria
AU  - Darani, AA
AU  - Salehi, MA
AU  - Amiri, H
AU  - Boroujeni, FZ
T2  - INTERNATIONAL JOURNAL OF NONLINEAR ANALYSIS AND APPLICATIONS
AB  - Utilizing new models instead of traditional statistical models can be quite useful in this field. Examples include data mining, which possesses both high speed and accuracy as well as nonlinear and non-parametric properties Therefore, in the present study, the effects of performance criteria on social responsibility disclosure level was investigated and analyzed via utilization of data mining, Henceforth, a model will be presented aiming to estimate/project the optimal level of social responsibility disclosure grounded on performance criteria. The present study is applied in terms of its nature and purpose/objective as well as based on the field research method of data collection. The statistical population are companies listed on the Tehran Stock Exchange and the required data were collected and analyzed using six data mining methods during the 2013-2019 period. The findings reveal it is possible to classify and predict the optimal level of corporate social responsibility disclosure within the Iranian economic circumstances/environment. Moreover, the utilization of the classification algorithm in the vicinity of the nearest neighbor can accurately predict the optimal level of corporate social responsibility disclosure based on performance criteria. The findings of this study indicate that performance metrics can be a positive predictor of the optimal level of corporate social responsibility disclosure. In addition, due to the potent strength of the proposed model, the used model in this research can be utilized to rank/rate the level of corporate social responsibility disclosure.
DA  - 2022///
PY  - 2022
DO  - 10.22075/ijnaa.2022.6290
VL  - 13
IS  - 2
SP  - 1937
EP  - 1951
SN  - 2008-6822
AN  - WOS:000864089700036
ER  - 

TY  - JOUR
TI  - Behavior-Based Ethical Understanding in Chinese Social News
AU  - Feng, X
AU  - Gu, TL
AU  - Bao, XG
AU  - Li, L
T2  - IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
AB  - Ethical understanding aims at morally analyzing and discriminating ethical scenarios described in natural language. By classifying behaviors that occur in ethical scenarios as ethical or unethical, ethical understanding empowers artificial intelligence systems to understand human values so as to discern right from wrong morally. However, most existing ethical understanding methods lack fine-grained analysis and cannot handle the problem that an ethical scenario may contain multiple behaviors with multiple polarities. In this paper, we introduce a novel natural language processing task, behavior-based ethical understanding (BEU), for mining the purpose relation(s) and ethical polarity of a specific behavior from the social news. It contains three subtasks: behavior term extraction (BTE) to extracts behavior terms, purpose relation inference (PRI) to identifies purposive relations among behaviors, and polarity discrimination (PD) to predicts the ethical polarities of behaviors, respectively. To perform this task, we constructed a Chinese BEU dataset, named FG-ETHICS. Besides, we propose a three-stage framework, BEU-BERT, based on the pre-trained language model BERT and deliberately designed downstream models for three subtasks. Experimental results show that the proposed framework achieves the best performance from the BTE and PD tasks, and achieves a promising performance of 75% on the PRI task.
DA  - 2023/07//undefined
PY  - 2023
DO  - 10.1109/TAFFC.2022.3160745
VL  - 14
IS  - 3
SP  - 2349
EP  - 2360
SN  - 1949-3045
AN  - WOS:001075041900048
ER  - 

TY  - JOUR
TI  - Ethics and governance of trustworthy medical artificial intelligence
AU  - Zhang, J
AU  - Zhang, ZM
T2  - BMC MEDICAL INFORMATICS AND DECISION MAKING
AB  - BackgroundThe growing application of artificial intelligence (AI) in healthcare has brought technological breakthroughs to traditional diagnosis and treatment, but it is accompanied by many risks and challenges. These adverse effects are also seen as ethical issues and affect trustworthiness in medical AI and need to be managed through identification, prognosis and monitoring.MethodsWe adopted a multidisciplinary approach and summarized five subjects that influence the trustworthiness of medical AI: data quality, algorithmic bias, opacity, safety and security, and responsibility attribution, and discussed these factors from the perspectives of technology, law, and healthcare stakeholders and institutions. The ethical framework of ethical values-ethical principles-ethical norms is used to propose corresponding ethical governance countermeasures for trustworthy medical AI from the ethical, legal, and regulatory aspects.ResultsMedical data are primarily unstructured, lacking uniform and standardized annotation, and data quality will directly affect the quality of medical AI algorithm models. Algorithmic bias can affect AI clinical predictions and exacerbate health disparities. The opacity of algorithms affects patients' and doctors' trust in medical AI, and algorithmic errors or security vulnerabilities can pose significant risks and harm to patients. The involvement of medical AI in clinical practices may threaten doctors 'and patients' autonomy and dignity. When accidents occur with medical AI, the responsibility attribution is not clear. All these factors affect people's trust in medical AI.ConclusionsIn order to make medical AI trustworthy, at the ethical level, the ethical value orientation of promoting human health should first and foremost be considered as the top-level design. At the legal level, current medical AI does not have moral status and humans remain the duty bearers. At the regulatory level, strengthening data quality management, improving algorithm transparency and traceability to reduce algorithm bias, and regulating and reviewing the whole process of the AI industry to control risks are proposed. It is also necessary to encourage multiple parties to discuss and assess AI risks and social impacts, and to strengthen international cooperation and communication.
DA  - 2023/01/13/
PY  - 2023
DO  - 10.1186/s12911-023-02103-9
VL  - 23
IS  - 1
SN  - 1472-6947
AN  - WOS:000912721600001
ER  - 

TY  - JOUR
TI  - Detecting diabetic retinopathy through machine learning on electronic health record data from an urban, safety net healthcare system
AU  - Ogunyemi, OI
AU  - Gandhi, M
AU  - Lee, M
AU  - Teklehaimanot, S
AU  - Daskivich, LP
AU  - Hindman, D
AU  - Lopez, K
AU  - Taira, RK
T2  - JAMIA OPEN
AB  - Objective: Clinical guidelines recommend annual eye examinations to detect diabetic retinopathy (DR) in patients with diabetes. However, timely DR detection remains a problem in medically underserved and under-resourced settings in the United States. Machine learning that identifies patients with latent/undiagnosed DR could help to address this problem.
Materials and Methods: Using electronic health record data from 40 631 unique diabetic patients seen at Los Angeles County Department of Health Services healthcare facilities between January 1, 2015 and December 31, 2017, we compared ten machine learning environments, including five classifier models, for assessing the presence or absence of DR. We also used data from a distinct set of 9300 diabetic patients seen between January 1, 2018 and December 31, 2018 as an external validation set.
Results: Following feature subset selection, the classifier with the best AUC on the external validation set was a deep neural network using majority class undersampling, with an AUC of 0.8, the sensitivity of 72.17%, and specificity of 74.2%.
Discussion: A deep neural network produced the best AUCs and sensitivity results on the test set and external validation set. Models are intended to be used to screen guideline noncompliant diabetic patients in an urban safety-net setting.
Conclusion: Machine learning on diabetic patients' routinely collected clinical data could help clinicians in safety-net settings to identify and target unscreened diabetic patients who potentially have undiagnosed DR.
DA  - 2021/07//undefined
PY  - 2021
DO  - 10.1093/jamiaopen/ooab066
VL  - 4
IS  - 3
SN  - 2574-2531
AN  - WOS:000731864500035
KW  - machine learning
KW  - deep learning
KW  - artificial intelligence
KW  - deep neural network
KW  - adult
KW  - controlled study
KW  - female
KW  - human
KW  - male
KW  - middle aged
KW  - comparative study
KW  - Article
KW  - cross validation
KW  - diagnostic test accuracy study
KW  - major clinical study
KW  - sensitivity and specificity
KW  - artificial neural network
KW  - random forest
KW  - support vector machine
KW  - practice guideline
KW  - feature selection
KW  - classifier
KW  - k nearest neighbor
KW  - electronic health record
KW  - area under the curve
KW  - insulin dependent diabetes mellitus
KW  - non insulin dependent diabetes mellitus
KW  - health care system
KW  - predictive value
KW  - recursive feature elimination
KW  - diabetic patient
KW  - diabetic retinopathy
KW  - diabetic retinopathy diagnosis
KW  - diagnostic accuracy
KW  - extreme gradient boosting
KW  - eye examination
KW  - health care facility
KW  - health service
KW  - medicaid
KW  - medically underserved
KW  - medicare
KW  - private health insurance
KW  - safety net health care
KW  - safety net providers
KW  - urban hospital
ER  - 

TY  - JOUR
TI  - Learning mixtures of point distribution models with the EM algorithm
AU  - Al-Shaher, AA
AU  - Hancock, ER
T2  - PATTERN RECOGNITION
AB  - This paper demonstrates how the EM algorithm can be used for learning and matching mixtures of point distribution models. We make two contributions. First, we show how shape-classes can be learned in an unsupervised manner. We present a fast procedure for training point distribution models using the EM algorithm. Rather than estimating the class means and covariance matrices needed to construct the PDM, the method iteratively refines the eigenvectors of the covariance matrix using a gradient ascent technique. Second, we show how recognition by alignment can be realised by fitting a mixture of linear shape deformations. We evaluate the method on the problem of learning the class-structure and recognising Arabic characters. (C) 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.
DA  - 2003/12//undefined
PY  - 2003
DO  - 10.1016/S0031-3203(03)00139-0
VL  - 36
IS  - 12
SP  - 2805
EP  - 2818
SN  - 0031-3203
AN  - WOS:000186024700006
KW  - Pattern recognition
KW  - Algorithms
KW  - Iterative methods
KW  - Unsupervised learning
KW  - Matrix algebra
KW  - Alignment
KW  - pattern recognition
KW  - Arabic character
KW  - Expectation maximization algorithm
KW  - Point distribution models
KW  - Shape deformation
KW  - Shape recognition
ER  - 

TY  - JOUR
TI  - Transferring Structured Knowledge in Unsupervised Domain Adaptation of a Sleep Staging Network
AU  - Yoo, C
AU  - Lee, HW
AU  - Kang, JW
T2  - IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
AB  - Automatic sleep staging based on deep learning (DL) has been attracting attention for analyzing sleep quality and determining treatment effects. It is challenging to acquire long-term sleep data from numerous subjects and manually labeling them even though most DL-based models are trained using large-scale sleep data to provide state-of-the-art performance. One way to overcome this data shortage is to create a pre-trained network with an existing large-scale dataset (source domain) that is applicable to small cohorts of datasets (target domain); however, discrepancies in data distribution between the domains prevent successful refinement of this approach. In this paper, we propose an unsupervised domain adaptation method for sleep staging networks to reduce discrepancies by re-aligning the domains in the same space and producing domain-invariant features. Specifically, in addition to a classical domain discriminator, we introduce local discriminators - subject and stage - to maintain the intrinsic structure of sleep data to decrease local misalignments while using adversarial learning to play a minimax game between the feature extractor and discriminators. Moreover, we present several optimization schemes during training because the conventional adversarial learning is not effective to our training scheme. We evaluate the performance of the proposed method by examining the staging performances of a baseline network compared with direct transfer (DT) learning in various conditions. The experimental results demonstrate that the proposed domain adaptation significantly improves the performance though it needs no labeled sleep data in target domain.
DA  - 2022/03//undefined
PY  - 2022
DO  - 10.1109/JBHI.2021.3103614
VL  - 26
IS  - 3
SP  - 1273
EP  - 1284
SN  - 2168-2194
AN  - WOS:000766665300036
ER  - 

TY  - JOUR
TI  - Learning-Based Synthesis of Robust Linear Time-Invariant Controllers
AU  - Beaudoin, MA
AU  - Boulet, B
T2  - IEEE TRANSACTIONS ON INTELLIGENT VEHICLES
AB  - Recent advances in learning for control allow to synthesize vehicle controllers from learned system dynamics and maintain robust stability guarantees. However, no approach is well-suited for training robustly-stabilizing linear time-invariant (LTI) controllers using arbitrary learned models of the dynamics. This article introduces a method to do so. It uses a robust control framework to derive robust stability criteria. It also uses simulated policy rollouts to obtain gradients on the controller parameters, which serve to improve the closed-loop performance. By formulating the stability criteria as penalties with computable gradients, they can be used to guide the controller parameters toward robust stability during gradient descent. The approach is flexible as it does not restrict the type of learned model for the simulated rollouts. The robust control framework ensures that the controller is already robustly stabilizing when first implemented on the actual system and no data is yet collected. It also ensures that the system stays stable in the event of a shift in dynamics, given the system behavior remains within assumed uncertainty bounds. We demonstrate the approach by synthesizing a controller for simulated autonomous lane-change maneuvers. This work thus presents a flexible approach to learning robustly stabilizing LTI controllers that takes advantage of modern machine learning techniques.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1109/TIV.2022.3174029
VL  - 8
IS  - 2
SP  - 1742
EP  - 1750
SN  - 2379-8858
AN  - WOS:000966282200001
ER  - 

TY  - JOUR
TI  - Burst Pressure Prediction of Cylindrical Vessels Using Artificial Neural Network
AU  - Zolfaghari, A
AU  - Izadi, M
T2  - JOURNAL OF PRESSURE VESSEL TECHNOLOGY-TRANSACTIONS OF THE ASME
AB  - Pressure vessel plays an important role in wide range of applications to store gas or liquid substances. In order to design a pressure vessel safely, one of the main factors which has to be considered is selection of proper burst pressure perdition criterion. Due to large range of available materials in manufacturing of the vessels under different working conditions, several criteria to forecast burst pressure of the vessels have been developed and used by designers. Choosing the most proper criterion based on working condition and the material is a vital task to meet design requirements because inappropriate criterion may lead to unsafe vessel or over design. This issue makes not only pressure vessel design more complex but also maintenance planning, especially for designers who do not have enough experience, is a challenging task. Therefore, lack of a burst pressure predictor model, which is able to determine the pressure more accurately for wide range of materials and applications, has been remained unsolved. To evaluate machine learning techniques in prediction of burst pressure of pressure vessels, in this paper, a new model based on artificial neural network (ANN) has been proposed and developed. Input parameters of the model include internal and outer diameter, thickness, ultimate and yield strength; output is burst pressure. The obtained results showed that the constructed model has a good potential to be used as more applicable model compared to current models in design of pressure vessels.
DA  - 2020/06/01/
PY  - 2020
DO  - 10.1115/1.4045729
VL  - 142
IS  - 3
SN  - 0094-9930
AN  - WOS:000534229700003
ER  - 

TY  - JOUR
TI  - MultiDIAL: Domain Alignment Layers for (Multisource) Unsupervised Domain Adaptation
AU  - Carlucci, FM
AU  - Porzi, L
AU  - Caputo, B
AU  - Ricci, E
AU  - Bulo, SR
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - One of the main challenges for developing visual recognition systems working in the wild is to devise computational models immune from the domain shift problem, i.e., accurate when test data are drawn from a (slightly) different data distribution than training samples. In the last decade, several research efforts have been devoted to devise algorithmic solutions for this issue. Recent attempts to mitigate domain shift have resulted into deep learning models for domain adaptation which learn domain-invariant representations by introducing appropriate loss terms, by casting the problem within an adversarial learning framework or by embedding into deep network specific domain normalization layers. This paper describes a novel approach for unsupervised domain adaptation. Similarly to previous works we propose to align the learned representations by embedding them into appropriate network feature normalization layers. Opposite to previous works, our Domain Alignment Layers are designed not only to match the source and target feature distributions but also to automatically learn the degree of feature alignment required at different levels of the deep network. Differently from most previous deep domain adaptation methods, our approach is able to operate in a multi-source setting. Thorough experiments on four publicly available benchmarks confirm the effectiveness of our approach.
DA  - 2021/12/01/
PY  - 2021
DO  - 10.1109/TPAMI.2020.3001338
VL  - 43
IS  - 12
SP  - 4441
EP  - 4452
SN  - 0162-8828
AN  - WOS:000714203900021
ER  - 

TY  - JOUR
TI  - Real-Time Pedestrian Conflict Prediction Model at the Signal Cycle Level Using Machine Learning Models
AU  - Zhang, SL
AU  - Abdel-Aty, M
T2  - IEEE OPEN JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Compared with traditional traffic studies, real-time safety analyses can be better incorporated into proactive traffic management strategies to improve traffic safety. However, few studies have investigated the real-time pedestrian safety model. Intersections usually have mixed traffic conditions with more pedestrian-vehicle interactions. This paper uses conflict indicators, PET (Post Encroachment Time) and TTC (Time to Collision) to identify pedestrians' conflicts from CCTV (closed-circuit television) videos. The high-resolution traffic data from the Automated Traffic Signal Performance Measures (ATSPM) system are used to derive traffic flow-related variables. The pedestrian exposure is also estimated. Pedestrians' conflicts are predicted using multiple machine learning models and Logistic Regression. The resampling methods, random over-sampling, and random under-sampling are compared. The best model, Extreme Gradient Boosting (XGBT) with random over-sampling method can achieve AUC (area under the ROC curve) value of 0.841 and recall value of 0.739 on the test data set. The proposed model can predict pedestrians' conflicts one cycle ahead, which can be 2-3 min. The proposed model has the potential to be implemented in the Connected and Automated Vehicles (CAV) environment to adjust signal timing accordingly and enhance traffic safety.
DA  - 2022///
PY  - 2022
DO  - 10.1109/OJITS.2022.3155126
VL  - 3
SP  - 176
EP  - 186
SN  - 2687-7813
AN  - WOS:000769971400002
ER  - 

TY  - JOUR
TI  - BALLU2: A Safe and Affordable Buoyancy Assisted Biped
AU  - Chae, H
AU  - Ahn, MS
AU  - Noh, D
AU  - Nam, H
AU  - Hong, DN
T2  - FRONTIERS IN ROBOTICS AND AI
AB  - This work presents the first full disclosure of BALLU, Buoyancy Assisted Lightweight Legged Unit, and describes the advantages and challenges of its concept, the hardware design of a new implementation (BALLU2), a motion analysis, and a data-driven walking controller. BALLU is a robot that never falls down due to the buoyancy provided by a set of helium balloons attached to the lightweight body, which solves many issues that hinder current robots from operating close to humans. The advantages gained also lead to the platform's distinct difficulties caused by severe nonlinearities and external forces such as buoyancy and drag. The paper describes the nonconventional characteristics of BALLU as a legged robot and then gives an analysis of its unique behavior. Based on the analysis, a data-driven approach is proposed to achieve non-teleoperated walking: a statistical process using Spearman Correlation Coefficient is proposed to form low-dimensional state vectors from the simulation data, and an artificial neural network-based controller is trained on the same data. The controller is tested both on simulation and on real-world hardware. Its performance is assessed by observing the robot's limit cycles and trajectories in the Cartesian coordinate. The controller generates periodic walking sequences in simulation as well as on the real-world robot even without additional transfer learning. It is also shown that the controller can deal with unseen conditions during the training phase. The resulting behavior not only shows the robustness of the controller but also implies that the proposed statistical process effectively extracts a state vector that is low-dimensional yet contains the essential information of the high-dimensional dynamics of BALLU's walking.
DA  - 2021/12/08/
PY  - 2021
DO  - 10.3389/frobt.2021.730323
VL  - 8
SN  - 2296-9144
AN  - WOS:000732725100001
KW  - machine learning
KW  - robot safety
KW  - bipedal locomotion
KW  - data-driven control
KW  - dimension reduction
KW  - low-cost robot
KW  - nonlinear modeling
KW  - underactuated system
ER  - 

TY  - JOUR
TI  - Multi-Modal Entity Alignment Using Uncertainty Quantification for Modality Importance
AU  - Hama, K
AU  - Matsubara, T
T2  - IEEE ACCESS
AB  - The knowledge graphs are structured data utilized for information retrieval purposes. Entity alignment using multi-modal supplementary information plays an important role in knowledge graph integration. However, if the supplementary information is missing or incorrect, it can negatively impact the retrieval of information. If we can quantify the usefulness of the information for retrieval as a degree of importance, the influence of unimportant supplementary information can be reduced. In this study, we proposed a method that quantifies the importance of each piece of information by using a probability distribution. Our proposed method improves an existing method by 7.7% and 7.3% in H@1 on two datasets (FB15K-DB15K, FB15K-YAGO15K). Qualitative experiments also showed that the importance of information quantified by uncertainty successfully captured data that was not useful for information retrieval. Our qualitative experiments also show that the importance of information, quantified by uncertainty, effectively captures data that is not beneficial for information retrieval.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ACCESS.2023.3259987
VL  - 11
SP  - 28479
EP  - 28489
SN  - 2169-3536
AN  - WOS:000965714800001
KW  - Artificial intelligence
KW  - Information retrieval
KW  - Task analysis
KW  - Knowledge graphs
KW  - Job analysis
KW  - Uncertainty
KW  - Multi-modal
KW  - Data visualization
KW  - Uncertainty analysis
KW  - Search engines
KW  - Probability distributions
KW  - Probability: distributions
KW  - Knowledge-representation
KW  - Knowledge graph
KW  - entity alignment
KW  - Entity alignment
KW  - information retrieval
KW  - knowledge representation
KW  - knowledge-based systems
KW  - Knowledge-based systems
KW  - multi-modal learning
KW  - Multi-modal learning
KW  - Supplementary information
ER  - 

TY  - JOUR
TI  - Safe Reinforcement Learning Using Wasserstein Distributionally Robust MPC and Chance Constraint
AU  - Kordabad, AB
AU  - Wisniewski, R
AU  - Gros, S
T2  - IEEE ACCESS
AB  - In this paper, we address the chance-constrained safe Reinforcement Learning (RL) problem using the function approximators based on Stochastic Model Predictive Control (SMPC) and Distributionally Robust Model Predictive Control (DRMPC). We use Conditional Value at Risk (CVaR) to measure the probability of constraint violation and safety. In order to provide a safe policy by construction, we first propose using parameterized nonlinear DRMPC at each time step. DRMPC optimizes a finite-horizon cost function subject to the worst-case constraint violation in an ambiguity set. We use a statistical ball around the empirical distribution with a radius measured by the Wasserstein metric as the ambiguity set. Unlike the sample average approximation SMPC, DRMPC provides a probabilistic guarantee of the out-of-sample risk and requires lower samples from the disturbance. Then the Q-learning method is used to optimize the parameters in the DRMPC to achieve the best closed-loop performance. Wheeled Mobile Robot (WMR) path planning with obstacle avoidance will be considered to illustrate the efficiency of the proposed method.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3228922
VL  - 10
SP  - 130058
EP  - 130067
SN  - 2169-3536
AN  - WOS:000902044600001
KW  - Reinforcement learning
KW  - Risk management
KW  - Motion planning
KW  - Reinforcement learnings
KW  - Cost functions
KW  - Risk assessment
KW  - Safety engineering
KW  - Robust optimization
KW  - model predictive control
KW  - Model predictive control
KW  - Predictive control systems
KW  - Predictive control
KW  - Robust control
KW  - Mobile robots
KW  - Stochastic models
KW  - Stochastic systems
KW  - Constrained optimization
KW  - Safe reinforcement learning
KW  - distributionally robust optimization
KW  - Distributionally robust optimization
KW  - Model-predictive control
KW  - Robot programming
KW  - Random processes
KW  - Conditional Value-at-Risk
KW  - Chance constraint
KW  - Stochastic control systems
KW  - Q-learning
KW  - Risks management
KW  - chance constraint
KW  - conditional value at risk
KW  - Motion estimation
ER  - 

TY  - JOUR
TI  - Principle-based recommendations for big data and machine learning in food safety: the P-SAFETY model
AU  - Sapienza, S
AU  - Vedder, A
T2  - AI & SOCIETY
AB  - Big data and Machine learning Techniques are reshaping the way in which food safety risk assessment is conducted. The ongoing 'datafication' of food safety risk assessment activities and the progressive deployment of probabilistic models in their practices requires a discussion on the advantages and disadvantages of these advances. In particular, the low level of trust in EU food safety risk assessment framework highlighted in 2019 by an EU-funded survey could be exacerbated by novel methods of analysis. The variety of processed data raises unique questions regarding the interplay of multiple regulatory systems alongside food safety legislation. Provisions aiming to preserve the confidentiality of data and protect personal information are juxtaposed to norms prescribing the public disclosure of scientific information. This research is intended to provide guidance for data governance and data ownership issues that unfold from the ongoing transformation of the technical and legal domains of food safety risk assessment. Following the reconstruction of technological advances in data collection and analysis and the description of recent amendments to food safety legislation, emerging concerns are discussed in light of the individual, collective and social implications of the deployment of cutting-edge Big Data collection and analysis techniques. Then, a set of principle-based recommendations is proposed by adapting high-level principles enshrined in institutional documents about Artificial Intelligence to the realm of food safety risk assessment. The proposed set of recommendations adopts Safety, Accountability, Fairness, Explainability, Transparency as core principles (SAFETY), whereas Privacy and data protection are used as a meta-principle.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1007/s00146-021-01282-1
VL  - 38
IS  - 1
SP  - 5
EP  - 20
SN  - 0951-5666
AN  - WOS:000706033500001
KW  - Machine learning
KW  - Machine-learning
KW  - Risk assessment
KW  - Data governance
KW  - Safety engineering
KW  - Big data
KW  - Laws and legislation
KW  - Machine learning techniques
KW  - Assessment activities
KW  - Data acquisition
KW  - Data collection
KW  - Data governances
KW  - Data ownership
KW  - Data privacy
KW  - Food safety
KW  - Food-safety
KW  - Metadata
KW  - Risks assessments
KW  - Safety legislation
KW  - Safety risk assessments
ER  - 

TY  - JOUR
TI  - AFCMiner: Finding Absolute Fair Cliques From Attributed Social Networks for Responsible Computational Social Systems
AU  - Hao, F
AU  - Yang, YX
AU  - Shang, JX
AU  - Park, DS
T2  - IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
AB  - Cohesive subgraph mining on attributed social networks is attracting much attention in the realm of graph mining and analysis. Most existing studies on cohesive subgraph mining over attributed social networks neglect the fairness of attributes, which lead to difficulties in deploying responsible applications. Toward this end, this article formulates a new problem by introducing fairness into cliques model to mine the absolute fair cliques from attributed social networks. Specifically, this article adopts formal concept analysis (FCA) methodology to represent the given attributed social network, and extracts a set of special attributed equiconcepts to further return the absolute fair maximal cliques. Then, we develop an efficient absolute fair cliques detection algorithm AFCMiner for the cases of single-dimensional attributed social networks, multivalued attributed social networks, as well as multidimensional attributed social networks. Extensive experiments are conducted for demonstrating that the proposed AFCMiner algorithm can significantly reduce the time for finding absolute fair cliques with the correctness guarantee. Finally, a case study is also presented for uncovering the usefulness of our model.
DA  - 2023/02/23/
PY  - 2023
DO  - 10.1109/TCSS.2023.3245075
SN  - 2329-924X
AN  - WOS:000940194200001
KW  - Machine learning
KW  - Feature extraction
KW  - Predictive models
KW  - Data mining
KW  - Fairness
KW  - fairness
KW  - Learning systems
KW  - responsible AI
KW  - Features extraction
KW  - Online systems
KW  - Machine-learning
KW  - Responsible AI
KW  - Social networking (online)
KW  - Collaboration
KW  - Absolute fair clique
KW  - attributed social network
KW  - Attributed social network
KW  - Formal concept analyse
KW  - Formal concept analysis
KW  - formal concept analysis (FCA)
KW  - Formal concepts analysis
ER  - 

TY  - JOUR
TI  - A Machine Learning Study on the Role of Behavioral and Demographic Factors in Mining Injuries
AU  - Ravikumar, A
AU  - Raju, GY
AU  - Gupta, S
T2  - INTERNATIONAL JOURNAL OF RELIABILITY QUALITY AND SAFETY ENGINEERING
AB  - Predictive models for work-related injuries in mines are complicated, with personal, technical, and societal aspects all playing a role. Numerous studies have reported that human behavior is a significant factor in mine injuries. Many researchers have opined that maintaining a high level of safe human behavior is a challenging task. In Indian mines, the risk management team uses hierarchy control charts to avoid incidents, but managing human behavioral factors which lead to injury is more challenging. Owing to these constraints, we attempted to find the significant human behavioral factors that lead to injury in mines. In this work, we try to develop predictive models using behavioral and demographic factors to predict mine workers' injury status and evaluate the most significant factor. To investigate the relevance of behavioral characteristics in work-related injuries, we employed three machine learning models (neural networks, random forest, and K-NN) as well as two classic statistical approaches (linear and logistic regression) to compare their results and see which method performs better. We have collected data of six factors and injury status of 186 workers through a questionnaire survey. After data analysis, a detailed comparison between machine learning models and traditional methods shows that random forest performs better than other models. This study also found that demographic features and job dissatisfaction attitude are the leading influencing factors to work-related injuries. This work is beneficial to mine management in the present Indian mining scenario to devise appropriate countermeasures.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1142/S0218539322500073
VL  - 29
IS  - 03
SN  - 0218-5393
AN  - WOS:000832605600007
KW  - machine learning
KW  - Decision trees
KW  - Machine learning
KW  - Predictive models
KW  - Risk management
KW  - Data handling
KW  - Behavioral research
KW  - Human resource management
KW  - Human behaviors
KW  - Machine-learning
KW  - Machine learning models
KW  - Surveys
KW  - Information analysis
KW  - Random forests
KW  - data analysis
KW  - predictive modeling
KW  - Population statistics
KW  - Behavioral factors
KW  - Behavioral safety
KW  - Behavioural safety
KW  - Demographic factors
KW  - Learning studies
KW  - Work-related Injuries
ER  - 

TY  - JOUR
TI  - Building engineering safety risk assessment and early warning mechanism construction based on distributed machine learning algorithm
AU  - Liu, HM
AU  - Tian, GL
T2  - SAFETY SCIENCE
AB  - Cloud computing has become a hot topic in the industry and academic circles. Large-scale data processing is realized by centralizing system management of network resources, computing resources, and storage resources. Among them, the distributed computing platform greatly improves the productivity of programmers by abstracting the implementation details of distributed computing, and is widely used in building safety assessment. In this study, the construction safety evaluation index system was established for the construction site of common accidents, and the index weight was determined by the analytic hierarchy process. For the safety index evaluation task, an early warning mechanism based on distributed computing and extension theory to build cloud security management is established, which saves the overall calculation time and quantitatively evaluates the security status of the construction site. Finally, the method is verified by engineering examples, and the results show that the method is practical and effective. The method is convenient for computer programming, easy to operate and implement, and has strong applicability. Based on distributed computing and extended cloud model, not only can the overall state of construction safety be judged, but also potential security problems can be identified based on information feedback. The objective existence of hazards in the construction process can be grasped, which has important guiding significance for the construction process.
DA  - 2019/12//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2019.08.022
VL  - 120
SP  - 764
EP  - 771
SN  - 0925-7535
AN  - WOS:000496335100074
KW  - machine learning
KW  - Machine learning
KW  - risk assessment
KW  - Data handling
KW  - Learning algorithms
KW  - quantitative analysis
KW  - article
KW  - software
KW  - theoretical study
KW  - Risk assessment
KW  - calculation
KW  - Safety engineering
KW  - Computation theory
KW  - Computer programming
KW  - Digital storage
KW  - Information management
KW  - Cloud computing
KW  - accident
KW  - Construction
KW  - Distributed machine learning
KW  - Cloud security managements
KW  - Cloud theory
KW  - Distributed computation
KW  - Distributed computations
KW  - Distributed computing platform
KW  - Early-warning models
KW  - Engineering safety
KW  - Engineering Safety risk control
KW  - Evaluation and early warning model
KW  - Extension cloud theory
KW  - Large-scale data processing
ER  - 

TY  - JOUR
TI  - Comparative Performance Evaluation of Intrusion Detection Based on Machine Learning in In-Vehicle Controller Area Network Bus
AU  - Moulahi, T
AU  - Zidi, S
AU  - Alabdulatif, A
AU  - Atiquzzaman, M
T2  - IEEE ACCESS
AB  - Communication between the nodes in a vehicle is performed using many protocols. The most common of these is known as the Controller Area Network (CAN). The functionality of the CAN protocol is based on sending messages from one node to all others throughout a bus. Messages are sent without either source or destination addresses. Consequently, it is simple for an attacker to inject malicious messages. This may lead to some nodes malfunctioning or total system failure, which can affect the safety of the driver as well as the vehicle. Detecting intrusions is a challenging problem in the context of using CAN bus for in-vehicle communication. Most existing work focuses on the physical aspects without taking into consideration the data itself. Machine Learning (ML) tools, especially classification techniques, have been widely used to address similar problems. In this paper, we use and compare several ML techniques to deal with the problem of detecting intrusions in in-vehicle communication. An experimental study is performed using a real dataset extracted from a KIA Soul car. Compared to previous work, which focuses on detecting intrusions based on the physical aspect, this paper aims to concentrate on the application of data analysis and statistical learning techniques. Furthermore, the paper provides a comparative study of the most common ML techniques. The results show that the techniques under consideration in this paper outperform other techniques that have been used previously.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3095962
VL  - 9
SP  - 99595
EP  - 99605
SN  - 2169-3536
AN  - WOS:000675184200001
ER  - 

TY  - JOUR
TI  - Intelligent Safe Driving Methods Based on Hybrid Automata and Ensemble CART Algorithms for Multihigh-Speed Trains
AU  - Cheng, RJ
AU  - Yu, W
AU  - Song, YD
AU  - Chen, DW
AU  - Ma, XP
AU  - Cheng, Y
T2  - IEEE TRANSACTIONS ON CYBERNETICS
AB  - Considering both the tracking safety of multi-HSTs and the operational efficiency of a single HST, intelligent safe driving methods (ISDMs) are proposed to obtain better speed-distance curves by integrating hybrid automata (HA) with data mining algorithms in this paper. To begin with, an intelligent safe distance controller is established by using HA to ensure the tracking safety of multi-HSTs' operation in real time. Then, data-driven intelligent driving methods based on ensemble algorithms (Bagging or Adaboost.R) and classification and regression tree (CART) are proposed to discover the potential driving rules from the field driving data. Furthermore, because of the continuous rise of HST's operation mileage, the driving data collected from HST has increased tremendously compared with the subways. So, an iterative pruning error minimization algorithm is designed to reduce the redundancy of the driving data and improve the computational speed of the learning process. Finally, compared with the automatic train operation (ATO) method, the energy consumption of B-CART, A-CART, and S-A-CART algorithms can be decreased by 3.32%, 3.80%, and 4.30%, respectively.
DA  - 2019/10//undefined
PY  - 2019
DO  - 10.1109/TCYB.2019.2915191
VL  - 49
IS  - 10
SP  - 3816
EP  - 3826
SN  - 2168-2267
AN  - WOS:000473443900018
KW  - Machine learning
KW  - Data mining
KW  - Learning systems
KW  - Learning algorithms
KW  - article
KW  - controlled study
KW  - Intelligent trains
KW  - Railroads
KW  - Automata theory
KW  - learning
KW  - energy consumption
KW  - Energy utilization
KW  - Iterative methods
KW  - data mining
KW  - velocity
KW  - Automatic train control
KW  - Automatic train operation (ATO)
KW  - Automatic train operations
KW  - High speed train (HST)
KW  - high-speed train
KW  - intelligent train control
KW  - machine learning algorithm
KW  - Railroad cars
KW  - sparse algorithm
KW  - Sparse algorithms
KW  - system safety
KW  - System safety
KW  - Trees (mathematics)
ER  - 

TY  - JOUR
TI  - Highly accurate and explainable detection of specimen mix-up using a machine learning model
AU  - Mitani, T
AU  - Doi, S
AU  - Yokota, S
AU  - Imai, T
AU  - Ohe, K
T2  - CLINICAL CHEMISTRY AND LABORATORY MEDICINE
AB  - Background: Delta check is widely used for detecting specimen mix-ups. Owing to the inadequate specificity and sparseness of the absolute incidence of mix-ups, the positive predictive value (PPV) of delta check is considerably low as it is labor consuming to identify true mix-up errors among a large number of false alerts. To overcome this problem, we developed a new accurate detection model through machine learning.
Methods: Inspired by delta check, we decided to conduct comparisons with the past examinations and broaden the time range. Fifteen common items were selected from complete blood cell counts and biochemical tests. We considered examinations in which >= 11 among the 15 items were measured simultaneously in our hospital; we created individual partial time-series data of the consecutive examinations with a sliding window size of 4. The last examinations of the partial time-series data were shuffled to generate artificial mix-up cases. After splitting the dataset into development and validation sets, we allowed a gradient-boosting-decision-tree (GBDT) model to learn using the development set to detect whether the last examination results of the partial time-series data were artificial mixed-up results. The model's performance was evaluated on the validation set.
Results: The area under the receiver operating characteristic curve (ROC AUC) of our model was 0.9983 (bootstrap confidence interval [bsCI]: 0.9983-0.9985).
Conclusions: The GBDT model was more effective in detecting specimen mix-up. The improved accuracy will enable more facilities to perform more efficient and centralized mix-up detection, leading to improved patient safety.
DA  - 2020/03//undefined
PY  - 2020
DO  - 10.1515/cclm-2019-0534
VL  - 58
IS  - 3
SP  - 375
EP  - 383
SN  - 1434-6621
AN  - WOS:000512994400020
KW  - machine learning
KW  - Machine Learning
KW  - anomaly detection
KW  - human
KW  - Humans
KW  - Article
KW  - major clinical study
KW  - priority journal
KW  - receiver operating characteristic
KW  - patient safety
KW  - accuracy
KW  - decision tree
KW  - time series analysis
KW  - predictive value
KW  - artifact
KW  - Artifacts
KW  - blood cell count
KW  - data-mining
KW  - delta-check method
KW  - laboratory information system
KW  - specimen handling
KW  - Specimen Handling
ER  - 

TY  - JOUR
TI  - Research and Education Towards Smart and Sustainable World
AU  - Riekki, J
AU  - Mämmela, Ä
T2  - IEEE ACCESS
AB  - We propose a vision for directing research and education in the field of information and communications technology (ICT). Our Smart and Sustainable World vision targets prosperity for the people and the planet through better awareness and control of both human-made and natural environments. The needs of society, individuals, and industries are fulfilled with intelligent systems that sense their environment, make proactive decisions on actions advancing their goals, and perform the actions on the environment. We emphasize artificial intelligence, feedback loops, human acceptance and control, intelligent use of basic resources, performance parameters, mission-oriented interdisciplinary research, and a holistic systems view complementing the conventional analytical reductive view as a research paradigm, especially for complex problems. To serve a broad audience, we explain these concepts and list the essential literature. We suggest planning research and education by specifying, in a step-wise manner, scenarios, performance criteria, system models, research problems, and education content, resulting in common goals and a coherent project portfolio as well as education curricula. Research and education produce feedback to support evolutionary development and encourage creativity in research. Finally, we propose concrete actions for realizing this approach.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3069902
VL  - 9
SP  - 53156
EP  - 53177
SN  - 2169-3536
AN  - WOS:000639873400001
KW  - security
KW  - Intelligent systems
KW  - reliability
KW  - safety
KW  - decision making
KW  - optimization
KW  - performance
KW  - Feedback
KW  - Sustainable development
KW  - innovation
KW  - sustainable development goals
KW  - energy efficiency
KW  - education
KW  - history
KW  - Internet of Things (IoT)
KW  - artificial intelligence (AI)
KW  - availability
KW  - basic resources
KW  - closed-loop feedback control
KW  - computational intelligence (CI)
KW  - constraints
KW  - degree of centralization
KW  - dependability
KW  - distributed systems
KW  - emergence
KW  - Evolutionary development
KW  - experimental-inductive method
KW  - functionality
KW  - hierarchy
KW  - hypothetico-deductive method
KW  - Information and communications technology
KW  - integrative learning
KW  - Interdisciplinary research
KW  - Natural environments
KW  - open-loop control
KW  - Performance criterion
KW  - Performance parameters
KW  - Project portfolio
KW  - reductive view
KW  - research
KW  - Research problems
KW  - Smart world vision
KW  - systems view
ER  - 

TY  - JOUR
TI  - A comparative study of patient and staff safety evaluation using tree-based machine learning algorithms
AU  - Simsekler, MCE
AU  - Rodrigues, C
AU  - Qazi, A
AU  - Ellahham, S
AU  - Ozonoff, A
T2  - RELIABILITY ENGINEERING & SYSTEM SAFETY
AB  - Medical errors constitute a significant challenge affecting patient and staff safety in complex and dynamic healthcare systems. While various organizational factors may contribute to such errors, limited studies have addressed patient and staff safety issues simultaneously in the same study setting. To evaluate this, we conduct an exploratory analysis using two types of tree-based machine learning algorithms, random forests and gradient boosting, and the hospital-level aggregate staff experience survey data from UK hospitals. Based on staff views and priorities, the results from both algorithms suggest that "health and wellbeing" is the leading theme associated with the number of reported errors and near misses harming patient and staff safety. Specifically, "work-related stress" is the most important survey item associated with safety outcomes. With respect to prediction accuracy, both algorithms provide similar results with comparable values in error metrics. Based on the analytical results, healthcare risk managers and decision-makers can develop and implement policies and practices that address staff experience and prioritize resources effectively to improve patient and staff safety.
DA  - 2021/04//undefined
PY  - 2021
DO  - 10.1016/j.ress.2020.107416
VL  - 208
SN  - 0951-8320
AN  - WOS:000613176700030
KW  - Decision trees
KW  - Machine learning
KW  - Decision making
KW  - Data analytics
KW  - Human resource management
KW  - Gradient boosting
KW  - Surveys
KW  - Safety engineering
KW  - Adaptive boosting
KW  - Health care
KW  - Errors
KW  - Patient safety
KW  - Random forests
KW  - Healthcare operations
KW  - Hospitals
KW  - Random forest
KW  - Safety evaluations
KW  - Analytical results
KW  - Comparative studies
KW  - Exploratory analysis
KW  - Health-care system
KW  - Medical errors
KW  - Organizational factors
KW  - Prediction accuracy
KW  - Staff safety
KW  - Work-related stress
ER  - 

TY  - JOUR
TI  - Road traffic accident trauma: A model for road safety management utilizing the artificial intelligence with geo-mapping and geospatial data in Pakistan
AU  - Ali, SMH
AU  - Aasim, N
AU  - Malik, A
T2  - JOURNAL OF THE PAKISTAN MEDICAL ASSOCIATION
DA  - 2022/03//undefined
PY  - 2022
DO  - 10.47391/JPMA.22-017
VL  - 72
IS  - 3
SP  - 400
EP  - 403
SN  - 0030-9982
AN  - WOS:000766739300001
ER  - 

TY  - JOUR
TI  - Modeling driver?s evasive behavior during safety-critical lane changes: Two-dimensional time-to-collision and deep reinforcement learning
AU  - Guo, HY
AU  - Xie, K
AU  - Keyvan-Ekbatani, M
T2  - ACCIDENT ANALYSIS AND PREVENTION
AB  - Lane changes are complex driving behaviors and frequently involve safety-critical situations. This study aims to develop a lane-change-related evasive behavior model, which can facilitate the development of safety-aware traffic simulations and predictive collision avoidance systems. Large-scale connected vehicle data from the Safety Pilot Model Deployment (SPMD) program were used for this study. A new surrogate safety measure, two-dimensional time-to-collision (2D-TTC), was proposed to identify the safety-critical situations during lane changes. The validity of 2D-TTC was confirmed by showing a high correlation between the detected conflict risks and the archived crashes. A deep deterministic policy gradient (DDPG) algorithm, which could learn the sequential decision-making process over continuous action spaces, was used to model the evasive behaviors in the identified safety-critical situations. The results showed the superiority of the proposed model in replicating both the longitudinal and lateral evasive behaviors.
DA  - 2023/06//undefined
PY  - 2023
DO  - 10.1016/j.aap.2023.107063
VL  - 186
SN  - 0001-4575
AN  - WOS:000975988400001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Safety
KW  - Decision making
KW  - Learning
KW  - Data analytics
KW  - Algorithms
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - safety
KW  - Automobile Driving
KW  - car driving
KW  - human
KW  - Humans
KW  - algorithm
KW  - Accidents, Traffic
KW  - prevention and control
KW  - traffic accident
KW  - Safety engineering
KW  - Big data
KW  - learning
KW  - Big data analytics
KW  - Data Analytics
KW  - Time to collision
KW  - Two-dimensional
KW  - awareness
KW  - Awareness
KW  - Big data analytic
KW  - Evasive behavior
KW  - Lane change
KW  - Safety measures
KW  - Surrogate safety measure
ER  - 

TY  - JOUR
TI  - Topical review of artificial intelligence national policies: A mixed method analysis
AU  - Saheb, T
AU  - Saheb, T
T2  - TECHNOLOGY IN SOCIETY
AB  - A number of countries have adopted national policies and directives to balance the advantages and disadvantages of innovative technologies. The purpose of this paper is to identify the most prominent topics addressed by national AI policies, as well as their relative importance across nations. This paper integrates the results of a topic modeling analysis of 30 national AI policies with a qualitative content analysis of the policies. Based on this analysis, fourteen main common themes have been identified among national AI policies, which predominantly relate to educational, technological, government, ethical/legal, and social good concerns. Following this, we conducted a co-occurrence analysis of topics across countries to determine the extent of topic prioritization in each country. In this investigation, several marginalized AI policy topics were also identified. In general, the challenges and concerns of the majority of policies pertain to education, technology, and the government. Governments refer to real-world projects and investments in AI technologies without developing shared digital governance platforms that promote responsible and sustainable AI among technology titans and mitigate the negative effects of surveillance capitalism. Although governments acknowledge the ethical and legal aspects of AI development and frequently cite the GDPR, they limit their discussion to the data level, particularly data sharing, and marginalize ethical algorithms and other phases of data and AI management and design. In addition, government policies marginalize AI startups and the API economy, even though they play a crucial role in fostering the AI ecosystem. The paper contributes to the existing literature on AI policy and will serve as a guide for AI policymakers to help them better understand the topical similarities across countries and the neglected or marginalized challenges that require further attention.
DA  - 2023/08//undefined
PY  - 2023
DO  - 10.1016/j.techsoc.2023.102316
VL  - 74
SN  - 0160-791X
AN  - WOS:001048159600001
ER  - 

TY  - JOUR
TI  - Algorithmic bias: review, synthesis, and future research directions
AU  - Kordzadeh, N
AU  - Ghasemaghaei, M
T2  - EUROPEAN JOURNAL OF INFORMATION SYSTEMS
AB  - As firms are moving towards data-driven decision making, they are facing an emerging problem, namely, algorithmic bias. Accordingly, algorithmic systems can yield socially-biased outcomes, thereby compounding inequalities in the workplace and in society. This paper reviews, summarises, and synthesises the current literature related to algorithmic bias and makes recommendations for future information systems research. Our literature analysis shows that most studies have conceptually discussed the ethical, legal, and design implications of algorithmic bias, whereas only a limited number have empirically examined them. Moreover, the mechanisms through which technology-driven biases translate into decisions and behaviours have been largely overlooked. Based on the reviewed papers and drawing on theories such as the stimulus-organism-response theory and organisational justice theory, we identify and explicate eight important theoretical concepts and develop a research model depicting the relations between those concepts. The model proposes that algorithmic bias can affect fairness perceptions and technology-related behaviours such as machine-generated recommendation acceptance, algorithm appreciation, and system adoption. The model also proposes that contextual dimensions (i.e., individual, task, technology, organisational, and environmental) can influence the perceptual and behavioural manifestations of algorithmic bias. These propositions highlight the significant gap in the literature and provide a roadmap for future studies.
DA  - 2022/05/04/
PY  - 2022
DO  - 10.1080/0960085X.2021.1927212
VL  - 31
IS  - 3
SP  - 388
EP  - 409
SN  - 0960-085X
AN  - WOS:000658203000001
ER  - 

TY  - CONF
TI  - Application of Inertial Measurement Units for Advanced Safety Surveillance System using Individualized Sensor Technology (ASSIST): A Data Fusion and Machine Learning Approach
AU  - Baghdadi, A
AU  - IEEE Comp Soc
T2  - 2018 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI)
AB  - Fatigue in the workplace, as a prevalent health and economic issue, can be controlled by monitoring and timely detection through the utilization of wearable sensors. An accurate detection with the optimal number of sensors through the estimation of whole body kinematics as well as single sensor analysis for the detection of lower extremity muscle fatigue as a root cause of slip-induced falls is important. Kalman filter was used to estimate the hip acceleration and trunk posture in gait by a posteriori data from ankle and a priori data using Fourier series approximation to relate the body kinematics considering the periodic nature of gait. The segmented gait step kinematic data from the single sensor at the ankle using a novel stepwise search-based segmentation algorithm was used for fatigue classification through a template matching pattern recognition technique (1$ Recognizer) and support vector machine (SVM). Considering 20 subject data, the best results showed the error rates of 6.5% and 3.12% for hip acceleration and trunk posture estimations, respectively. In addition, fatigue classification utilizing gait step features resulted in 90% accuracy. This study provides a framework with the use of a minimal set of sensors and data for kinematics estimation and fatigue monitoring.
DA  - 2018///
PY  - 2018
DO  - 10.1109/ICHI.2018.00097
SP  - 450
EP  - 451
SN  - 2575-2634
AN  - WOS:000853207500090
KW  - Support vector machines
KW  - Classification (of information)
KW  - Image segmentation
KW  - Health care
KW  - Wearable sensors
KW  - Kinematics
KW  - Classification
KW  - Kalman filter
KW  - Kalman filters
KW  - Physical fatigues
KW  - Data fusion
KW  - Sensor data fusion
KW  - Fourier series
KW  - Bio-mechanical models
KW  - Biomechanical model
KW  - Change-point analysis
KW  - Gait kinematics
KW  - Inertial measurement unit (IMU)
KW  - Inertial Measurement Unit (IMU)
KW  - Physical fatigue
KW  - Template matching
ER  - 

TY  - JOUR
TI  - Robust Inference of Principal Road Paths for Intelligent Transportation Systems
AU  - Agamennoni, G
AU  - Nieto, JI
AU  - Nebot, EM
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Over the last few years, electronic vehicle guidance systems have become increasingly more popular. However, despite their ubiquity, performance will always be subject to availability of detailed digital road maps. Most current digital maps are still inadequate for advanced applications in unstructured environments. Lack of up-to-date information and insufficient refinement of the road geometry are among the most important shortcomings. The massive use of inexpensive Global Positioning System (GPS) receivers, combined with the rapidly increasing availability of wireless communication infrastructure, suggests that large amounts of data combining both modalities will be available in the near future. The approach presented here draws on machine-learning techniques and processes logs of position traces to consistently build a detailed and fine-grained representation of the road network by extracting the principal paths followed by the vehicles. Although this work addresses the road-building problem in dynamic environments such as open-pit mines, it is also applicable to urban environments. New contributions include a fully unsupervised segmentation method for sampling roads and inferring the network topology, which is a general technique for extracting detailed information about road splits, merges, and intersections, as well as a robust algorithm that articulates these two. Experimental results with data from large mining operations are presented to validate the new algorithm.
DA  - 2011/03//undefined
PY  - 2011
DO  - 10.1109/TITS.2010.2069097
VL  - 12
IS  - 1
SP  - 298
EP  - 308
SN  - 1524-9050
AN  - WOS:000287867000029
KW  - machine learning
KW  - Data mining
KW  - Intelligent systems
KW  - Intelligent transportation systems
KW  - Learning systems
KW  - Algorithms
KW  - Accident prevention
KW  - Intelligent vehicle highway systems
KW  - Traffic control
KW  - Roads and streets
KW  - Motor transportation
KW  - Dynamic environments
KW  - road safety
KW  - Image segmentation
KW  - Navigation systems
KW  - On-machines
KW  - Network topology
KW  - Wireless communications
KW  - Tracking (position)
KW  - Mining
KW  - Robust algorithm
KW  - Large amounts of data
KW  - Global positioning system
KW  - Urban environments
KW  - Electric network topology
KW  - Global Positioning System (GPS)
KW  - Wireless telecommunication systems
KW  - Unstructured environments
KW  - Electronic guidance systems
KW  - Advanced applications
KW  - Digital map
KW  - Digital road map
KW  - digital road maps
KW  - Electronic vehicles
KW  - Global positioning
KW  - Global positioning system receivers
KW  - Mining operations
KW  - Open pit mines
KW  - Road geometry
KW  - Road network
KW  - Robust inference
KW  - Unsupervised segmentation method
ER  - 

TY  - JOUR
TI  - Automotive ECU Data-Based Driver's Propensity Learning Using Evolutionary Random Forest
AU  - Lee, JH
AU  - Lim, S
AU  - Ahn, CW
T2  - IEEE ACCESS
AB  - Driving assistance systems in the automotive industry are constantly evolving and are already commercialized in various areas to provide consumers with safety and convenience. The recognition of driver's propensity is a key factor that can greatly affect the performance of such a driving assist system, but it still has numbers of technical limitations. This paper presents an evolutionary machine learning algorithm for recognizing driver's propensity by effectively learning a vast amount of ECU sensor data in the vehicle, and its performance is verified through system construction, data collection, analysis, and comparison test. The experiments showed that the proposed algorithm achieves a classification accuracy of 92.48% in a large amount of ECU data and reaches 7.03% higher accuracy than the average classification accuracy of existing classifiers. In addition, a scenario for a new safe driving assistance system is presented. The system can recognize the driver's propensity in real time using only the ECU information without attaching additional sensors, such as cameras and biometric information. It is expected that this system will help to recognize the driver's tendency shift, thereby inducing safe driving.
DA  - 2019///
PY  - 2019
DO  - 10.1109/ACCESS.2019.2911704
VL  - 7
SP  - 51899
EP  - 51906
SN  - 2169-3536
AN  - WOS:000466738800001
KW  - machine learning
KW  - Decision trees
KW  - Machine learning
KW  - Vehicle safety
KW  - Learning systems
KW  - Learning algorithms
KW  - Accident prevention
KW  - Intelligent vehicle highway systems
KW  - Automotive industry
KW  - Man machine systems
KW  - Evolutionary algorithms
KW  - Classification accuracy
KW  - Random forests
KW  - Driving assistance systems
KW  - Big data learning
KW  - Biometric informations
KW  - driving propensity recognition
KW  - evolutionary computation
KW  - evolutionary random forest
KW  - Safe-driving assistance
KW  - Technical limitations
KW  - vehicle safety assistant systems
ER  - 

TY  - JOUR
TI  - Real-time crash prediction on urban expressways: identification of key variables and a hybrid support vector machine model
AU  - Sun, J
AU  - Sun, J
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - The traffic safety on expressways is crucial for the efficient operation of the expressway system, and there is a close relationship between traffic states and crashes on expressways, and the occurrence of crashes may be influenced by the interaction of different combinations of traffic states upstream and downstream of the crash location. Based on the crash data and the corresponding traffic flow detector data collected on expressways in Shanghai, this study proposes a hybrid model combining a support vector machine (SVM) model with a k-means clustering algorithm to predict the likelihood of crashes. The random forest (RF) model is employed to select the important and significant variables for model construction from the data of the traffic flow 5-10 min before the crash occurred. Then, the cross-validation and transferability of different models (SVM model without variable selection, SVM model with variable selection, and hybrid SVM model with variable selection) are determined using 577 crashes and 5794 matched non-crash events. The results show that the crash prediction model along with the four most important variables selected using the RF model can obtain a satisfactory prediction performance for crashes. With the combination of the clustering algorithm and SVM model, the accuracy of the crash prediction model can be as high as 78.0%. Moreover, the results of the transferability of the three different models imply that the variable selection and clustering algorithm both have an advantage for crash prediction.
DA  - 2016/06//undefined
PY  - 2016
DO  - 10.1049/iet-its.2014.0288
VL  - 10
IS  - 5
SP  - 331
EP  - 337
SN  - 1751-956X
AN  - WOS:000378801600005
ER  - 

TY  - JOUR
TI  - AI explainability framework for environmental management research
AU  - Arashpour, M
T2  - JOURNAL OF ENVIRONMENTAL MANAGEMENT
AB  - Deep learning networks powered by AI are essential predictive tools relying on image data availability and processing hardware advancements. However, little attention has been paid to explainable AI (XAI) in appli- cation fields, including environmental management. This study develops an explainability framework with a triadic structure to focus on input, AI model and output. The framework provides three main contributions. (1) A context-based augmentation of input data to maximize generalizability and minimize overfitting. (2) A direct monitoring of AI model layers and parameters to use leaner (lighter) networks suitable for edge device deployment, (3) An output explanation procedure focusing on interpretability and robustness of predictive de- cisions by AI networks. These contributions significantly advance state of the art in XAI for environmental management research, offering implications for improved understanding and utilization of AI networks in this field.
DA  - 2023/09/15/
PY  - 2023
DO  - 10.1016/j.jenvman.2023.118149
VL  - 342
SN  - 0301-4797
AN  - WOS:001006180900001
KW  - deep learning
KW  - artificial intelligence
KW  - language
KW  - article
KW  - numerical model
KW  - Conservation of Natural Resources
KW  - Environmental crisis
KW  - environmental management
KW  - Environmental management research
KW  - environmental protection
KW  - Explainable AI (XAI)
KW  - Management and valorization of solid waste
KW  - Multimodal and generative pre-trained transformers
KW  - parameterization
KW  - Responsible and fair artificial intelligence
KW  - solid waste
KW  - valorization
KW  - vision
KW  - Vision-language deep learning models
ER  - 

TY  - JOUR
TI  - Privacy-preserving AI-enabled video surveillance for social distancing: responsible design and deployment for public spaces
AU  - Sugianto, N
AU  - Tjondronegoro, D
AU  - Stockdale, R
AU  - Yuwono, EI
T2  - INFORMATION TECHNOLOGY & PEOPLE
AB  - Purpose The paper proposes a privacy-preserving artificial intelligence-enabled video surveillance technology to monitor social distancing in public spaces. Design/methodology/approach The paper proposes a new Responsible Artificial Intelligence Implementation Framework to guide the proposed solution's design and development. It defines responsible artificial intelligence criteria that the solution needs to meet and provides checklists to enforce the criteria throughout the process. To preserve data privacy, the proposed system incorporates a federated learning approach to allow computation performed on edge devices to limit sensitive and identifiable data movement and eliminate the dependency of cloud computing at a central server. Findings The proposed system is evaluated through a case study of monitoring social distancing at an airport. The results discuss how the system can fully address the case study's requirements in terms of its reliability, its usefulness when deployed to the airport's cameras, and its compliance with responsible artificial intelligence. Originality/value The paper makes three contributions. First, it proposes a real-time social distancing breach detection system on edge that extends from a combination of cutting-edge people detection and tracking algorithms to achieve robust performance. Second, it proposes a design approach to develop responsible artificial intelligence in video surveillance contexts. Third, it presents results and discussion from a comprehensive evaluation in the context of a case study at an airport to demonstrate the proposed system's robust performance and practical usefulness.
DA  - 2021/07/15/
PY  - 2021
DO  - 10.1108/ITP-07-2020-0534
SN  - 0959-3845
AN  - WOS:000674687100001
ER  - 

TY  - CONF
TI  - An Adaptive TinyML Unsupervised Online Learning Algorithm for Driver Behavior Analysis
AU  - Silva, M
AU  - Medeiros, T
AU  - Azevedo, M
AU  - Medeiros, M
AU  - Themoteo, M
AU  - Gois, T
AU  - Silva, I
AU  - Costa, DG
AU  - IEEE
T2  - 2023 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR AUTOMOTIVE, METROAUTOMOTIVE
AB  - The Internet of Things (IoT) has significantly impacted various industries, particularly the automotive sector, due to the growing integration of IoT technologies in vehicles. As a result, the volume of data generated by vehicular sensors has increased, leading to a surge in studies focusing on driver behavior to enhance road safety and optimize transportation networks. However, traditional approaches to analyzing driver behavior have relied on supervised offline learning models, which are unsuitable for handling data streams in online learning environments. This study introduces an unsupervised online k-fix AutoCloud algorithm for detecting driver behavior patterns, leveraging the concepts of typicity and eccentricity while considering the historical-temporal relationships between samples. Furthermore, the algorithm autonomously and adaptively evolves without requiring a supervised training phase, making it compatible with the TinyML concept, encompassing Artificial Intelligence algorithms designed for low-power IoT devices. To validate the proposed method, a real case study was conducted over four days using a vehicle to compare the quantity and quality of clusters generated by the algorithm. The findings demonstrate the potential of the proposed approach for optimizing data processing with minimal computational power.
DA  - 2023///
PY  - 2023
DO  - 10.1109/MetroAutomotive57488.2023.10219125
SP  - 199
EP  - 204
SN  - 979-8-3503-2187-6
AN  - WOS:001065471600037
KW  - Learning systems
KW  - Internet of things
KW  - Internet of Things
KW  - Behavioral research
KW  - Learning algorithms
KW  - Accident prevention
KW  - E-learning
KW  - Automotive industry
KW  - Roads and streets
KW  - Motor transportation
KW  - road safety
KW  - Driver's behavior
KW  - data processing
KW  - Online learning
KW  - Computer aided instruction
KW  - Clustering algorithms
KW  - online learning
KW  - Unsupervised learning
KW  - unsupervised learning
KW  - Road safety
KW  - Automotive sector
KW  - driver behavior
KW  - Driver behaviour analysis
KW  - Internet of things technologies
KW  - k-fix AutoCloud algorithm
KW  - K-fix autocloud algorithm
KW  - Online learning algorithms
KW  - Tinyml
KW  - TinyML
KW  - Unsupervised online learning
ER  - 

TY  - CONF
TI  - The Legal Debate about Personal Data Privacy at a Time of Big Data Mining and Searching Making Big Data Researchers Cooperating with Lawmakers to Find Solutions for the Future
AU  - Rousseaux, F
AU  - Saurel, P
AU  - IEEE
T2  - 2016 FIRST IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND THE INTERNET (ICCCI 2016)
AB  - At the same time as Big Data technologies are being constantly refined, the legislation relating to data privacy is changing. The invalidation by the Court of Justice of the European Union on October 6, 2015, of the agreement known as "Safe Harbor", negotiated by the European Commission on behalf of the European Union with the United States has two consequences. The first is to announce its replacement by a new, still fragile, program, the "Privacy Shield", which isn't yet definitive and which could also later be repealed by the Court of Justice of the European Union. For example, we are expecting to hear the opinion in mid-April 2016 of the group of data protection authorities for the various states of the European Union, known as G29. The second is to mobilize the Big Data community to take control of the question of data privacy management and to put in place an adequate internal program.
DA  - 2016///
PY  - 2016
SP  - 354
EP  - 357
SN  - 978-1-4673-8515-2
AN  - WOS:000390712100077
KW  - machine learning
KW  - privacy
KW  - Data mining
KW  - Learning systems
KW  - Big data
KW  - data mining
KW  - Laws and legislation
KW  - Data privacy
KW  - Data preservations
KW  - Data technologies
KW  - data-driven intelligent predictive systems
KW  - European Commission
KW  - European union
KW  - International law
KW  - personal data preservation
KW  - Predictive systems
KW  - privacy by design
KW  - Privacy management
KW  - privacy shield
KW  - safe harbor
ER  - 

TY  - CONF
TI  - In light of the legal debate over personal data privacy at a time of globalized Big Data Making Big Data researchers cooperating with lawmakers to find solutions for the future
AU  - Rousseaux, F
AU  - Saurel, P
T2  - 2016 INT IEEE CONFERENCES ON UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING AND COMMUNICATIONS, CLOUD AND BIG DATA COMPUTING, INTERNET OF PEOPLE, AND SMART WORLD CONGRESS (UIC/ATC/SCALCOM/CBDCOM/IOP/SMARTWORLD)
A2  - ElBaz, D
A2  - Bourgeois, J
AB  - At the same time as Big Data technologies are being constantly refined, the legislation relating to data privacy is changing. The invalidation by the Court of Justice of the European Union on October 6, 2015, of the agreement known as "Safe Harbor", negotiated by the European Commission on behalf of the European Union with the United States has two consequences. The first is to announce its replacement by a new, still fragile, program, the "Privacy Shield", which isn't yet definitive and which could also later be repealed by the Court of Justice of the European Union. For example, we are expecting to hear the opinion in mid-April 2016 of the group of data protection authorities for the various states of the European Union, known as G29. The second is to mobilize the Big Data community to take control of the question of data privacy management and to put in place an adequate internal program.
DA  - 2016///
PY  - 2016
DO  - 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.50
SP  - 398
EP  - 403
SN  - 978-1-5090-2771-2
AN  - WOS:000393306500052
ER  - 

TY  - CONF
TI  - Rolling Bag Station Motor Decoupling Control Based on Multi-agent on Automobile Safety Airbag
AU  - Zhang, NN
AU  - Wang, GL
T2  - MECHANICAL COMPONENTS AND CONTROL ENGINEERING III
A2  - Ge, W
AB  - This paper based on multi-agent technology, according to automobile safety airbag roll bag station production technology, at first adopt TS fuzzy neural regression network to distributed modeling for the controlled object, the methods of combining supervision learning and reinforcement learning are used, according to multi-agent external reinforcement signals and the value function of evaluate network, using adaptive genetic co-evolution algorithm to optimize the action network, so can adapt to the mutational environment, and engineering application supply the proof about the effectiveness of the control strategy.
DA  - 2014///
PY  - 2014
DO  - 10.4028/www.scientific.net/AMM.668-669.370
VL  - 668-669
SP  - 370
EP  - 373
SN  - 1660-9336
AN  - WOS:000348898100083
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Adaptive control systems
KW  - Safety engineering
KW  - Evolutionary algorithms
KW  - Multi agent systems
KW  - Multi agent
KW  - Genetic algorithms
KW  - Genetic algorithm
KW  - Engineering applications
KW  - Distributed modeling
KW  - Distributed reinforcement learning
KW  - Distributed reinforcement learning algorithm
KW  - Multi-agent
KW  - Multi-agent technologies
KW  - Production technology
KW  - Reinforcement signal
KW  - Safety airbag
KW  - Supervision learning
ER  - 

TY  - JOUR
TI  - Classification and identification of electric shock current for safety operation in power distribution network
AU  - Liu, YM
AU  - Du, SH
AU  - Sheng, WX
T2  - IET CYBER-PHYSICAL SYSTEMS: THEORY & APPLICATIONS
AB  - Electric shock current identification is essential for the safety in power distribution network. Moreover, as different categories of object have different electric shock current characteristic, a classification model for shock current is essential to be proposed before identification. Therefore, the authors proposed a two-stage framework, including the AdaBoost for the classification and an improved support vector machine (SVM) method for the identification. In the classification stage, the AdaBoost learns the hidden pattern of different electric shock current and generates a predictive model for current classification. Based on the classification results, a fusion method called SVM-NN is proposed in the identification stage, which is based on SVM and neural network (NN) to make fusion determination. The SVM-NN takes advantages of SVM and NN for integration analysis. Based on real data, these classification and identification methods are evaluated. Results show that the proposed method can significantly improve the identification accuracy of electric shock current signal comparing to traditional methods.
DA  - 2020/06//undefined
PY  - 2020
DO  - 10.1049/iet-cps.2019.0072
VL  - 5
IS  - 2
SP  - 145
EP  - 152
SN  - 2398-3396
AN  - WOS:000620780800002
ER  - 

TY  - JOUR
TI  - A machine learning-based framework for efficacy and safety analysis of PD-1PD-L1 inhibitor application in gynaecological cancer on incomplete post-marketing surveillance dataset
AU  - Liu, X
AU  - Li, X
T2  - ANNALS OF ONCOLOGY
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.annonc.2021.08.1244
VL  - 32
SP  - S763
EP  - S763
SN  - 0923-7534
AN  - WOS:000700527701267
ER  - 

TY  - JOUR
TI  - Incentive Mechanism Design for Responsible Data Governance: A Large-scale Field Experiment
AU  - Timko, C
AU  - Niederstadt, M
AU  - Goel, N
AU  - Faltings, B
T2  - ACM JOURNAL OF DATA AND INFORMATION QUALITY
AB  - A crucial building block of responsible artificial intelligence is responsible data governance, including data collection. Its importance is also underlined in the latest EU regulations. The data should be of high quality, foremost correct and representative, and individuals providing the data should have autonomy over what data is collected. In this article, we consider the setting of collecting personally measured fitness data (physical activity measurements), in which some individuals may not have an incentive to measure and report accurate data. This can significantly degrade the quality of the collected data. On the other hand, high-quality collective data of this nature could be used for reliable scientific insights or to build trustworthy artificial intelligence applications. We conduct a framed field experiment (N = 691) to examine the effect of offering fixed and quality-dependent monetary incentives on the quality of the collected data. We use a peer-based incentive-compatible mechanism for the quality-dependent incentives without spot-checking or surveilling individuals. We find that the incentive-compatible mechanism can elicit good-quality data while providing a good user experience and compensating fairly, although, in the specific study context, the data quality does not necessarily differ under the two incentive schemes. We contribute new design insights from the experiment and discuss directions that future field experiments and applications on explainable and transparent data collection may focus on.
DA  - 2023/06//undefined
PY  - 2023
DO  - 10.1145/3592617
VL  - 15
IS  - 2
SN  - 1936-1955
AN  - WOS:001020404600007
ER  - 

TY  - JOUR
TI  - Tensor-Based Baum-Welch Algorithms in Coupled Hidden Markov Model for Responsible Activity Prediction
AU  - Zhang, SL
AU  - Yang, LT
AU  - Zhang, Y
AU  - Lu, ZX
AU  - Yu, J
AU  - Cui, ZM
T2  - IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
AB  - The development and applications of artificial intelligence (AI) have brought unprecedented opportunities to humans, but also brought many challenges and concerns such as unfairness, immorality, distrust, illegality, and discrimination. Responsible AI provides a new solution to effectively address these AI potential threats by integrating social/physical rules into AI systems. However, these rules are high-level regulations and ethical principles, which are difficult to be formalized. To this end, we attempt to use the data generated in various AI systems such as cyber-physical-social systems (CPSS) to discover and reflect these rules to provide more responsible services for humans. In this article, we first propose a data-driven responsible CPSS framework. Its core idea is to mine valuable rules through perception, fusion, processing, and analysis of CPSS data, and then use these rules to adaptively optimize CPSS. Based on this framework, three tensor-based couple hidden Markov models (T-CHMMs) are constructed to integrate three responsible features (i.e., timing, periodicity, and correlation) for mining potential and valuable rules. Then, the corresponding tensor-based Baum-Welch (TBW) algorithms are designed to solve their learning problems. Finally, the predictive accuracy and computational efficiency of the proposed models and algorithms are verified on three open datasets. The experimental results show that proposed methods have the best performances for various scenarios, which reflects that our methods are more promising and responsible than existing methods.
DA  - 2023/04/10/
PY  - 2023
DO  - 10.1109/TCSS.2022.3227458
SN  - 2329-924X
AN  - WOS:000972294700001
KW  - Artificial intelligence
KW  - Prediction algorithms
KW  - Data models
KW  - Analytical models
KW  - Learning systems
KW  - responsible AI
KW  - Learning algorithms
KW  - Forecasting
KW  - Learning problem
KW  - Responsible artificial intelligence
KW  - Artificial intelligence systems
KW  - Computational efficiency
KW  - Tensors
KW  - Hidden Markov models
KW  - Hidden-Markov models
KW  - Activity prediction
KW  - Activity predictions
KW  - Algebra
KW  - Baum-Welch algorithms
KW  - Baum–Welch algorithm
KW  - Learning problem of tensor-based couple hidden markov model
KW  - learning problem of tensor-based couple hidden Markov model (T-CHMM)
KW  - tensor algebra
KW  - Tensor algebra
ER  - 

TY  - JOUR
TI  - Learning Reasoning-Decision Networks for Robust Face Alignment
AU  - Liu, H
AU  - Lu, JW
AU  - Guo, MH
AU  - Wu, SP
AU  - Zhou, J
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - In this paper, we propose an end-to-end reasoning-decision networks (RDN) approach for robust face alignment via policy gradient. Unlike the conventional coarse-to-fine approaches which likely lead to bias prediction due to poor initialization, our approach aims to learn a policy by leveraging raw pixels to reason a subset of shape candidates, sequentially making plausible decisions to remove outliers for robust initialization. To achieve this, we formulate face alignment as a Markov decision process by defining an agent, which typically interacts with a trajectory of states, actions, state transitions and rewards. The agent seeks an optimal shape searching policy over the whole shape space by maximizing a discounted sum of the received values. To further improve the alignment performance, we develop an LSTM-based value function to evaluate the shape quality. During the training procedure, we adjust the gradient of our value function in directions of the policy gradient. This prevents our training goal from being trapped into local optima entangled by both the pose deformations and appearance variations especially in unconstrained environments. Experimental results show that our proposed RDN consistently outperforms most state-of-the-art approaches on four widely-evaluated challenging datasets.
DA  - 2020/03/01/
PY  - 2020
DO  - 10.1109/TPAMI.2018.2885298
VL  - 42
IS  - 3
SP  - 679
EP  - 693
SN  - 0162-8828
AN  - WOS:000525365300012
ER  - 

TY  - JOUR
TI  - Using machine learning algorithms to predict the risk of small Unmanned Aircraft System violations in the National Airspace System
AU  - Truong, D
AU  - Choi, W
T2  - JOURNAL OF AIR TRANSPORT MANAGEMENT
AB  - The increasing number of small Unmanned Aircraft System (sUAS) encounters with manned aircraft or airports increases the risk of collision in the National Airspace System. The purpose of this research is to develop and test predictive models for sUAS violation incidents in NAS using machine learning. This research uses machine learning algorithms to predict the risk of sUAS violation incidents using the FAA's UAS sighting data with a sample size of 2088. Three sUAS violation types are identified: flying above 400 feet, flying with 5 miles from an airport, and flying in restricted airspace. Seven machine learning algorithms were used, including classification regression, decision tree, neural network, gradient boosting, random forest, Bayesian networks, and Memory-Based Reasoning. The results show that Gradient boosting produces the best predictive model. This model can predict the sUAS violation incidents with an accuracy of 95.7 percent. Location, distance to the airport, state, sUAs altitude, airport type, and aircraft type are the most influential predictors to the sUAS violation incidents.
DA  - 2020/07//undefined
PY  - 2020
DO  - 10.1016/j.jairtraman.2020.101822
VL  - 86
SN  - 0969-6997
AN  - WOS:000540243200010
KW  - machine learning
KW  - Machine learning
KW  - risk assessment
KW  - Data mining
KW  - prediction
KW  - algorithm
KW  - unmanned vehicle
KW  - model
KW  - Aviation safety
KW  - Risk prediction
KW  - air transportation
KW  - aircraft
KW  - National airspace system
KW  - Small unmanned aircraft system
ER  - 

TY  - JOUR
TI  - Geometry Optimization of Speed Humps Based on Ride Comfort and Driving-Safety-Based Assessment
AU  - Sheykhfard, A
AU  - Haghighi, F
AU  - Zadkhori, M
AU  - Shaaban, K
AU  - Yoosefi, H
T2  - TRANSPORTATION RESEARCH RECORD
AB  - The present study investigates the speed behaviors of drivers encountering speed humps on urban and suburban roads. The purpose is to optimize the geometric dimensions of different types of speed hump by considering ride comfort and driving safety criteria. Field observations of drivers' behavior were conducted near 90 speed humps in eight cities in Mazandaran Province, Iran. Vehicles speed modeling was carried out using multi-layer perception and normalized radial basis functions artificial networks. The sensitivity analysis results of artificial neural network (ANN) models showed different factors associated with speed humps' performance. While the length of entrance and exit ramps and passage width were the most influential factors in urban roads, speed before the humps' position plays a crucial factor in suburban roads. Finally, the optimum geometry of speed humps was presented by ANN models for different types of roads.
DA  - 2023/08//undefined
PY  - 2023
DO  - 10.1177/03611981231156574
VL  - 2677
IS  - 8
SP  - 270
EP  - 290
SN  - 0361-1981
AN  - WOS:000956798900001
ER  - 

TY  - CONF
TI  - Uncertainty in Machine Learning Applications: A Practice-Driven Classification of Uncertainty
AU  - Kläs, M
AU  - Vollmer, AM
T2  - COMPUTER SAFETY, RELIABILITY, AND SECURITY, SAFECOMP 2018
A2  - Gallina, B
A2  - Skavhaug, A
A2  - Schoitsch, E
A2  - Bitsch, F
AB  - Software-intensive systems that rely on machine learning (ML) and artificial intelligence (AI) are increasingly becoming part of our daily life, e.g., in recommendation systems or semi-autonomous vehicles. However, the use of ML and AI is accompanied by uncertainties regarding their outcomes. Dealing with such uncertainties is particularly important when the actions of these systems can harm humans or the environment, such as in the case of a medical product or self-driving car. To enable a system to make informed decisions when confronted with the uncertainty of embedded AI/ML models and possible safety-related consequences, these models do not only have to provide a defined functionality but must also describe as precisely as possible the likelihood of their outcome being wrong or outside a given range of accuracy. Thus, this paper proposes a classification of major uncertainty sources that is usable and useful in practice: scope compliance, data quality, and model fit. In particular, we highlight the implications of these classes in the development and testing of ML and AI models by establishing links to specific activities during development and testing and means for quantifying and dealing with these different sources of uncertainty.
DA  - 2018///
PY  - 2018
DO  - 10.1007/978-3-319-99229-7_36
VL  - 11094
SP  - 431
EP  - 438
SN  - 0302-9743
AN  - WOS:000458807000036
ER  - 

TY  - CONF
TI  - Deriving Architectural Responsibilities from Textual Requirements
AU  - Rodriguez, G
AU  - Díaz-Pace, JA
AU  - Berdun, L
AU  - Misra, S
T2  - INFORMATICS AND INTELLIGENT APPLICATIONS
A2  - Misra, S
A2  - Oluranti, J
A2  - Damasevicius, R
A2  - Maskeliunas, R
AB  - Natural language is widely used to write software requirements. Generally, software designers start with textual requirements and realize them into a first architectural design. A common problem in this transition is the conceptual gap between the requirements space and the software architecture space. To assist designers in the task, we propose an AI-based approach for deriving high-level architecture descriptions expressed as Use Case Maps (UCMs) from textual requirements. Our approach consists of three steps: (i) identification of responsibilities from functional requirements, (ii) extraction of causal relationships between the responsibilities, and (iii) allocation of the responsibilities to architectural components. Thus, designers can obtain a first view of a software solution that covers both structural and behavioral aspects. This view is useful for assessing architecture alternatives or for further design refinements. The approach relies on NLP and Data Mining techniques. An experimental evaluation with four case studies revealed that our approach detected on average 75% of the responsibilities in term of F-measure.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-95630-1_21
VL  - 1547
SP  - 297
EP  - 310
SN  - 1865-0929
AN  - WOS:000763647900021
ER  - 

TY  - JOUR
TI  - Learning to Operate Distribution Networks With Safe Deep Reinforcement Learning
AU  - Li, HP
AU  - He, HB
T2  - IEEE TRANSACTIONS ON SMART GRID
AB  - In this paper, we propose a safe deep reinforcement learning (SDRL) based method to solve the problem of optimal operation of distribution networks (OODN). We formulate OODN as a constrained Markov decision process (CMDP). The objective is to achieve adaptive voltage regulation and energy cost minimization considering the uncertainty of renewable resources (RSs), nodal loads and energy prices. The control actions include the number of in-operation units of the switchable capacitor banks (SCBs), the tap position of the on-load tap-changers (OLTCs) and voltage regulators (VRs), the active and reactive power of distributed generators (DGs), and the charging and discharging power of battery storage systems (BSSs). To optimize the discrete and continuous actions simultaneously, a stochastic policy built upon a joint distribution of mixed random variables is designed and learned through a neural network approximator. To guarantee that safety constraints are satisfied, constrained policy optimization (CPO) is employed to train the neural network. The proposed approach enables the agent to learn a cost-effective operating strategy through exploring safe scheduling actions. Compared to traditional deep reinforcement learning (DRL) methods that allow agents to freely explore any behaviors during training, the proposed approach is more practical to be applied in a real system. Simulation results on a modified IEEE-34 node system and a modified IEEE-123 node system demonstrate the effectiveness of the proposed method.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.1109/TSG.2022.3142961
VL  - 13
IS  - 3
SP  - 1860
EP  - 1872
SN  - 1949-3053
AN  - WOS:000785772000020
KW  - Deep learning
KW  - Reinforcement learning
KW  - Decision making
KW  - Behavioral research
KW  - Decisions makings
KW  - Uncertainty
KW  - Optimisations
KW  - Markov processes
KW  - Costs
KW  - Cost effectiveness
KW  - Stochastic systems
KW  - Digital storage
KW  - Continuous actions
KW  - Constrained Markov decision process
KW  - Constrained optimization
KW  - Safe deep reinforcement learning
KW  - Distribution systems
KW  - Electric power distribution
KW  - Voltage control
KW  - safe deep reinforcement learning
KW  - Reactive power
KW  - Voltage regulators
KW  - Load modeling
KW  - constrained Markov decision process (MDP)
KW  - Data driven decision
KW  - data-driven decision making
KW  - Data-driven decision making.
KW  - Mixed discrete and continuous action
KW  - mixed discrete and continuous actions
ER  - 

TY  - JOUR
TI  - A Fine-Grained Unsupervised Domain Adaptation Framework for Semantic Segmentation of Remote Sensing Images
AU  - Wang, LH
AU  - Xiao, PF
AU  - Zhang, XL
AU  - Chen, XY
T2  - IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
AB  - Unsupervised domain adaptation (UDA) aims at adapting a model from the source domain to the target domain by tackling the issue of domain shift. Cross-domain segmentation of remote sensing images (RSIs) remains a big challenge due to the unique properties of RSIs. On the one hand, the divergence of data distribution in different local regions leads to negative transfer by directly applying the global alignment method in RSIs. On the other hand, the underlying category-level structure in the target domain is often ignored, which confuses the decision of semantic boundaries on the dispersed category features caused by large intraclass variance and small interclass variance in RSIs. In this study, we propose a novel fine-grained adaptation framework combining two stages of global-local alignment and category-level alignment to solve the above-mentioned problems. In the first stage of global-local adaptation, an attention map is derived from an intermediate discriminator and focuses on hard-to-align regions to mitigate negative transfer due to global adversarial learning. In the second stage of category-level adaptation, the category feature compact module is utilized to address the issue of dispersed features in the target domain attained by the cross-domain network, which will facilitate the fine-grained alignment of categories. Experiments under various scenarios, including geographic location variation and spectral band composition variation, demonstrate that the local adaptation and category-level adaptation of RSIs are complementary in the cross-domain segmentation, and the integrated framework helps achieve outstanding performance for UDA semantic segmentation of RSIs.
DA  - 2023///
PY  - 2023
DO  - 10.1109/JSTARS.2023.3270302
VL  - 16
SP  - 4109
EP  - 4121
SN  - 1939-1404
AN  - WOS:000982912200003
ER  - 

TY  - CONF
TI  - Machine Learning Based Real-Time Vehicle Data Analysis for Safe Driving Modeling
AU  - Yadav, P
AU  - Jung, S
AU  - Singh, D
AU  - Assoc Comp Machinery
T2  - SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING
AB  - This paper identifies a necessity to evaluate the Meta features of vehicles which could be helpful in improving the vehicle driver's skill to prevent accidents and also evaluate the change in the quality of cars over passing time. This paper does an analysis of the vehicle data using supervised learning based linear regression model that is used as an estimator for Driver's Safety Metrics and Economic Driving Metrics. The data collected was obtained from fifteen different drivers over a span of one month which accumulated over 15000 data points. And the metrics that we have devised have potential application in automotive technology analysis for developing an advanced intelligent vehicles. Also, we have presented a system for performing the real-time experiment based on the On-Board-Diagnosis version II (OBD-II) scanner data. Finally, we have analyzed and presented the parameter accuracy over 80% for the driver's safety solution in real-world scenario.
DA  - 2019///
PY  - 2019
DO  - 10.1145/3297280.3297584
SP  - 1355
EP  - 1358
SN  - 978-1-4503-5933-7
AN  - WOS:000474685800186
KW  - Machine learning
KW  - Accidents
KW  - Vehicles
KW  - Supervised learning
KW  - Regression analysis
KW  - Vehicle drivers
KW  - Quality control
KW  - Supervised Learning
KW  - Statistical methods
KW  - Real-world scenario
KW  - Linear regression
KW  - Automotive vehicle
KW  - Linear Regression
KW  - Automotive technology
KW  - Automotive Vehicle Data
KW  - Driver's safety
KW  - Linear regression models
KW  - onboard  diagnosis
KW  - Real-time experiment
KW  - Statistical Analysis
ER  - 

TY  - JOUR
TI  - Person Re-Identification Using Additive Distance Constraint With Similar Labels Loss
AU  - Li, GF
AU  - Huang, LS
AU  - Tang, LW
AU  - Han, CL
AU  - Chen, YY
AU  - Xie, H
AU  - Li, S
AU  - Xu, G
T2  - IEEE ACCESS
AB  - Despite the promising progress made in recent years, person re-identification (Re-ID) remains a challenging task due to the intra-class variations. Most of the current studies used the traditional Softmax loss for solutions, but its discriminative capability encounters a bottleneck. Therefore, how to improve person Re-ID performance is still a challenging task. To address this problem, we proposed a novel loss function, namely additive distance constraint with similar labels loss (ADCSLL). Specifically, we reformulated the Softmax loss by adding a distance constraint to the ground truth label, based on which similar labels were introduced to enhance the learned features to be much more stable and centralized. Experimental evaluations were conducted on two popular datasets (Market-1501 and DukeMTMC-reID) to examine the effectiveness of our proposed method. The results showed that our proposed ADCSLL was more discriminative than most of the other compared state-of-the-art methods. The rank-1 accuracy and the mAP on Market-1501 were 95.0% and 87.0%, respectively. The numbers were 88.6% and 77.2% on DukeMTMC-reID, respectively.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3023948
VL  - 8
SP  - 168111
EP  - 168120
SN  - 2169-3536
AN  - WOS:000572934100001
ER  - 

TY  - JOUR
TI  - SAFETY RISK EVALUATIONS OF DEEP FOUNDATION CONSTRUCTION SCHEMES BASED ON IMBALANCED DATA SETS
AU  - Gong, PS
AU  - Guo, HX
AU  - Huang, YY
AU  - Guo, SY
T2  - JOURNAL OF CIVIL ENGINEERING AND MANAGEMENT
AB  - Safety risk evaluations of deep foundation construction schemes are important to ensure safety. However, the amount of knowledge on these evaluations is large, and the historical data of deep foundation engineering is imbalanced. Some adverse factors influence the quality and efficiency of evaluations using traditional manual evaluation tools. Machine learning guarantees the quality of imbalanced data classifications. In this study, three strategies are proposed to improve the classification accuracy of imbalanced data sets. First, data set information redundancy is reduced using a binary particle swarm optimization algorithm. Then, a classification algorithm is modified using an Adaboost-enhanced support vector machine classifier. Finally, a new classification evaluation standard, namely, the area under the ROC curve, is adopted to ensure the classifier to be impartial to the minority. A transverse comparison experiment using multiple classification algorithms shows that the proposed integrated classification algorithm can overcome difficulties associated with correctly classifying minority samples in imbalanced data sets. The algorithm can also improve construction safety management evaluations, relieve the pressure from the lack of experienced experts accompanying rapid infrastructure construction, and facilitate knowledge reuse in the field of architecture, engineering, and construction.
DA  - 2020///
PY  - 2020
DO  - 10.3846/jcem.2020.12321
VL  - 26
IS  - 4
SP  - 380
EP  - 395
SN  - 1392-3730
AN  - WOS:000530873900005
KW  - Machine learning
KW  - Support vector machines
KW  - Classification (of information)
KW  - Safety engineering
KW  - Quality control
KW  - Adaptive boosting
KW  - Classification algorithm
KW  - Particle swarm optimization (PSO)
KW  - Architecture , engineering , and constructions
KW  - Binary particle swarm optimization
KW  - Classification evaluation
KW  - Construction scheme
KW  - Deep foundation
KW  - Ensemble learning algorithm
KW  - Imbalanced data set
KW  - Information redundancies
KW  - Infrastructure construction
KW  - Integrated classification
KW  - Safety risk evaluation
KW  - Support vector machine classifiers
ER  - 

TY  - JOUR
TI  - Bidirectional Data-Driven Trajectory Prediction for Intelligent Maritime Traffic
AU  - Xiao, Y
AU  - Li, XC
AU  - Yao, W
AU  - Chen, J
AU  - Hu, YP
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Intelligent maritime transportation is one of the most promising enabling technologies for promoting trade efficiency and releasing the physical labor force. The trajectory prediction method is the foundation to guarantee collision avoidance and route optimization for ship transportation. This article proposes a bidirectional data-driven trajectory prediction method based on Automatic Identification System (AIS) spatio-temporal data to improve the accuracy of ship trajectory prediction and reduce the risk of accidents. Our study constructs an encoder-decoder network driven by a forward and reverse comprehensive historical trajectory and then fuses the characteristics of the sub-network to predict the ship trajectory. The AIS historical trajectory data of US West Coast ships are employed to investigate the feasibility of the proposed method. Compared with the current methods, the proposed approach lessens the prediction error by studying the comprehensive historical trajectory, and 60.28% has reduced the average prediction error. The ocean and port trajectory data are analyzed in maritime transportation before and after COVID-19. The prediction error in the port area is reduced by 95.17% than the data before the epidemic. Our work helps the prediction of maritime ship trajectory, provides valuable services for maritime safety, and performs detailed insights for the analysis of trade conditions in different sea areas before and after the epidemic.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1109/TITS.2022.3219998
VL  - 24
IS  - 2
SP  - 1773
EP  - 1785
SN  - 1524-9050
AN  - WOS:000881971300001
ER  - 

TY  - JOUR
TI  - Driver identification using 1D convolutional neural networks with vehicular CAN signals
AU  - Hu, HY
AU  - Liu, JR
AU  - Gao, ZH
AU  - Wang, P
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - This study proposes a deep learning framework for driver identity identification by extracting information from the vehicular controller area network (CAN) bus signals. First, naturalistic driving data of 20 drivers were collected under a fixed testing route with different road types and different traffic conditions. Then, a one-dimensional convolutional neural network was constructed for driver identification, which consists of two convolutional-pooling layers, a fully connected layer, and a SoftMax layer. Model optimisation algorithms were applied to improve accuracy and speed up the training process. Also, the model parameters were optimised by evaluating their influences on the model results. Furthermore, the performance of the proposed algorithm was compared with that of the K-nearest neighbour, support vector machine, multi-layer perceptron, and long shortterm memory model. The authors used the Macro F1 score as an evaluation criterion and the identification score of the authors' proposed model reaches 99.10% under 20 testing subjects where the data time window size is one second and the sample data overlap is 80%. The results show that the model's performance is significantly better than the other algorithms, which can effectively identify driver identities with stability and robustness.
DA  - 2020/12/15/
PY  - 2020
DO  - 10.1049/iet-its.2020.0105
VL  - 14
IS  - 13
SP  - 1799
EP  - 1809
SN  - 1751-956X
AN  - WOS:000619167800007
ER  - 

TY  - JOUR
TI  - COUNTERSAVIOR: AIoMT and IIoT-Enabled Adaptive Virus Outbreak Discovery Framework for Healthcare Informatics
AU  - Pandya, S
AU  - Ghayvat, H
AU  - Reddy, PK
AU  - Gadekallu, TR
AU  - Khan, MA
AU  - Kumar, N
T2  - IEEE INTERNET OF THINGS JOURNAL
AB  - In the current pandemic, global issues have caused health issues as well as economic downturns. At the beginning of every novel virus outbreak, lockdown is the best possible weapon to reduce the virus spread and save human life as the medical diagnosis followed by treatment and clinical approval takes significant time. The proposed COUNTERSAVIOR system aims at an Artificial Intelligence of Medical Things (AIoMT), and an edge line computing enabled and Big data analytics supported tracing and tracking approach that consumes global positioning system (GPS) spatiotemporal data. COUNTERSAVIOR will be a better scientific tool to handle any virus outbreak. The proposed research discovers the prospect of applying an individual's mobility to label mobility streams and forecast a virus such as COVID-19 pandemic transmission. The proposed system is the extension of the previously proposed COUNTERACT system. The proposed system can also identify the alternative saviour path concerning the confirmed subject's cross-path using GPS data to avoid the possibility of infections. In the undertaken study, dynamic meta direct and indirect transmission, meta behavior, and meta transmission saviour models are presented. In conducted experiments, the machine learning and deep learning methodologies have been used with the recorded historical location data for forecasting the behavior patterns of confirmed and suspected individuals and a robust comparative analysis is also presented. The proposed system produces a report specifying people that have been exposed to the virus and notifying users about available pandemic saviour paths. In the end, we have represented 3-D tracker movements of individuals, 3-D contact analysis of COVID-19 and suspected individuals for 24 h, forecasting and risk classification of COVID-19, suspected and safe individuals.
DA  - 2023/03/01/
PY  - 2023
DO  - 10.1109/JIOT.2022.3216108
VL  - 10
IS  - 5
SP  - 4202
EP  - 4212
SN  - 2327-4662
AN  - WOS:000966489000001
ER  - 

TY  - JOUR
TI  - Predictive cruise control of connected and autonomous vehicles via reinforcement learning
AU  - Gao, WN
AU  - Odekunle, A
AU  - Chen, YF
AU  - Jiang, ZP
T2  - IET CONTROL THEORY AND APPLICATIONS
AB  - Predictive cruise control concerns designing controllers for autonomous vehicles using the broadcasted information from the traffic lights such that the idle time around the intersection can be reduced. This study proposes a novel adaptive optimal control approach based on reinforcement learning to solve the predictive cruise control problem of a platoon of connected and autonomous vehicles. First, the reference velocity is determined for each autonomous vehicle in the platoon. Second, a data-driven adaptive optimal control algorithm is developed to estimate the gains of the desired distributed optimal controllers without the exact knowledge of system dynamics. The obtained controller is able to regulate the headway, velocity, and acceleration of each vehicle in a suboptimal sense. The goal of trip time reduction is achieved without compromising vehicle safety and passenger comfort. Numerical simulations are presented to validate the efficacy of the proposed methodology.
DA  - 2019/11/26/
PY  - 2019
DO  - 10.1049/iet-cta.2018.6031
VL  - 13
IS  - 17
SP  - 2849
EP  - 2855
SN  - 1751-8644
AN  - WOS:000499980600015
ER  - 

TY  - JOUR
TI  - A Multi-Intersection Vehicular Cooperative Control Based on End-Edge-Cloud Computing
AU  - Jiang, MZ
AU  - Wu, TH
AU  - Wang, Z
AU  - Gong, Y
AU  - Zhang, L
AU  - Liu, RP
T2  - IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY
AB  - Cooperative Intelligent Transportation Systems (C-ITS) will change the modes of road safety and traffic management, especially at intersections without traffic lights, namely unsignalized intersections. Existing researches focus on vehicle control within a small area around an unsignalized intersection. This paper expands the control domain to a large area with multiple intersections. In particular, a Multi-intersection Vehicular Cooperative Control (MiVeCC) is proposed to enable cooperation among vehicles in a large area with multiple unsignalized intersections. Firstly, a vehicular end-edge-cloud computing framework is proposed to facilitate end-edge-cloud vertical cooperation and horizontal cooperation among vehicles. Under the framework, a two-stage reinforcement learning is implemented to obtain the optimal policy for vehicle control. To support RL in the proposed framework, a multi-vehicle state representation method and a safety-oriented value representation method are designed. The former structures the collected vehicle information, and the latter evaluates the traffic condition. A multi-intersection simulation platform is developed to evaluate the proposed scheme. Simulation results show that the proposed MiVeCC can improve travel efficiency at multiple intersections by up to 4.59 times without collision compared with benchmark methods.
DA  - 2022/03//undefined
PY  - 2022
DO  - 10.1109/TVT.2022.3143828
VL  - 71
IS  - 3
SP  - 2459
EP  - 2471
SN  - 0018-9545
AN  - WOS:000769985100023
ER  - 

TY  - CONF
TI  - Case Study: Safety Verification of an Unmanned Underwater Vehicle
AU  - Lopez, DM
AU  - Musau, P
AU  - Hamilton, N
AU  - Tran, HD
AU  - Jonhson, TT
AU  - IEEE Comp Soc
T2  - 2020 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2020)
AB  - This manuscript evaluates the safety of a neural network controller that seeks to ensure that an Unmanned Underwater Vehicle (UUV) does not collide with a static object in its path. To achieve this, we utilize methods that can determine the exact output reachable set of all the UUV's components through the use of star-sets. The star-set is a computationally efficient set representation adept at characterizing large input spaces. It supports cheap and efficient computation of affine mapping operations and intersections with half-spaces. The system under consideration in this work represents a more complex system than Neural Network Control Systems (NNCS) previously considered in other works, and consists of a total of four components. Our experimental evaluation uses four different scenarios to show that our star-set based methods are scalable and can be efficiently used to analyze the safety of real-world cyber-physical systems (CPS).
DA  - 2020///
PY  - 2020
DO  - 10.1109/SPW50608.2020.00047
SP  - 189
EP  - 195
SN  - 978-1-7281-9346-5
AN  - WOS:000674766800029
KW  - Neural networks
KW  - Autonomous Vehicles
KW  - Safe AI
KW  - Embedded systems
KW  - Stars
KW  - Neural network controllers
KW  - Neural network control
KW  - Computationally efficient
KW  - Safety verification
KW  - Geometry
KW  - Experimental evaluation
KW  - Cyber-Physical Systems
KW  - Cyber-physical systems (CPS)
KW  - Data-driven Methods
KW  - Efficient computation
KW  - Learning-Enabled Components
KW  - Static objects
KW  - Unmanned underwater vehicles
ER  - 

TY  - JOUR
TI  - Safety Monitoring of Neural Networks Using Unsupervised Feature Learning and Novelty Estimation
AU  - Ranjbar, A
AU  - Hornauer, S
AU  - Fredriksson, J
AU  - Yu, SX
AU  - Chan, CY
T2  - IEEE TRANSACTIONS ON INTELLIGENT VEHICLES
AB  - Neural networks are currently suggested to be implemented in several different driving functions of autonomous vehicles. While showing promising results the drawback lies in the difficulty of safety verification and ensuring operation as intended. The aim of this paper is to increase safety when using neural networks, by proposing a monitoring framework based on novelty estimation of incoming driving data. The idea is to use unsupervised instance discrimination to learn a similarity measure across ego-vehicle camera images. By estimating a von Mises-Fisher distribution of expected ego-camera images they can be compared with unexpected novel images. A novelty measurement is inferred through the likelihood of test frames belonging to the expected distribution. The suggested method provides competitive results to several other novelty or anomaly detection algorithms on the CIFAR-10 and CIFAR-100 datasets. It also shows promising results on real world driving scenarios by distinguishing novel driving scenes from the training data of BDD100 k. Applied on the identical training-test data split, the method is also able to predict the performance profile of a segmentation network. Finally, examples are provided on how this method can be extended to find novel segments in images.
DA  - 2022/09//undefined
PY  - 2022
DO  - 10.1109/TIV.2022.3152084
VL  - 7
IS  - 3
SP  - 711
EP  - 721
SN  - 2379-8858
AN  - WOS:000873905600027
KW  - machine learning
KW  - Autonomous vehicles
KW  - Machine learning
KW  - Training data
KW  - Anomaly detection
KW  - Autonomous Vehicles
KW  - Machine-learning
KW  - Cameras
KW  - Image segmentation
KW  - Images segmentations
KW  - Neural-networks
KW  - Monitoring
KW  - monitoring
KW  - Safety monitoring
KW  - Camera images
KW  - Driving functions
KW  - safety systems
KW  - Unsupervised feature learning
ER  - 

TY  - JOUR
TI  - Determination of safe mud weight window based on well logging data using artificial intelligence
AU  - Zahiri, J
AU  - Abdideh, M
AU  - Golab, EG
T2  - GEOSYSTEM ENGINEERING
AB  - Identification of different stresses applied to the environment surrounding wellbore via different processes, and combining these data with mechanical parameters of common formations in hydrocarbon reservoirs comprise a key for addressing a wide range of costly problems and issues in the oil industry. In the present research, first, an attempt was made to construct mechanical earth model based on well logging data, elastic moduli of rock, and appropriate failure criteria for the final purpose of calculating and determining safe mud weight window (SMWW). Finally, appropriate artificial intelligence and machine-learning algorithms were used to establish a relationship between well logging data and SMWW, which could be used to calculate and predict SMWW without using associated relationships with the mechanical earth model. This might end up with a decreased number of required parameters for calculating SMWW, including uniaxial compressive strength. In the present research, the learning process was conducted using datasets from three wells, two of which provided training data, with the other one used as testing data. The prepared model was finally used to predict corresponding pressures to SMWW and baseline pressures for hydraulic fracturing operation. The model gave a coefficient of determination of 0.93 when applied to the testing data using support vector regression algorithm with radial basis function kernel, indicating large capabilities of this algorithm in predicting non-foreseen data.
DA  - 2019/07/04/
PY  - 2019
DO  - 10.1080/12269328.2018.1504697
VL  - 22
IS  - 4
SP  - 193
EP  - 205
SN  - 1226-9328
AN  - WOS:000476917900002
KW  - machine learning
KW  - Machine learning
KW  - Support vector machines
KW  - Learning systems
KW  - Learning algorithms
KW  - Forecasting
KW  - Well logging
KW  - support vector machine
KW  - Mechanical earth models
KW  - Mud weight windows
KW  - Oil well logging
KW  - Radial basis function networks
KW  - Well testing
KW  - Well logging data
KW  - Radial basis function kernels
KW  - Oil wells
KW  - Compressive strength
KW  - Hydrocarbon reservoir
KW  - Mechanical earth model
KW  - Mechanical parameters
KW  - safe mud weight window
KW  - Support vector regression algorithms
KW  - Uniaxial compressive strength
KW  - well logging data
ER  - 

TY  - CONF
TI  - Training Deep Neural Networks in Situ with Neuromorphic Photonics
AU  - Filipovich, MJ
AU  - Guo, ZM
AU  - Marquez, BA
AU  - Morison, HD
AU  - Shastri, BJ
AU  - IEEE
T2  - 2020 IEEE PHOTONICS CONFERENCE (IPC)
AB  - We discuss an optoelectric architecture for executing the direct feedback alignment algorithm for neural network training. Using 1000 microring resonators, we can theoretically obtain speeds of 9.95 tera operations per second.
DA  - 2020///
PY  - 2020
SN  - 2374-0140
AN  - WOS:000612237500062
KW  - Machine Learning
KW  - Training Algorithms
KW  - Direct Feedback Alignment
KW  - Neuromorphic Photonics
ER  - 

TY  - JOUR
TI  - Construct Food Safety Traceability System for People's Health Under the Internet of Things and Big Data
AU  - Zheng, MM
AU  - Zhang, SS
AU  - Zhang, YD
AU  - Hu, BZ
T2  - IEEE ACCESS
AB  - In the context of epidemic prevention and control, food safety monitoring, data analysis and food safety traceability have become more important. At the same time, the most important reason for food safety issues is incomplete, opaque, and asymmetric information. The most fundamental way to solve these problems is to do a good job of traceability, and establish a reasonable and reliable food safety traceability system. The traceability system is currently an important means to ensure food quality and safety and solve the crisis of trust between consumers and the market. Research on food safety traceability systems based on big data, artificial intelligence and the Internet of Things provides ideas and methods to solve the problems of low credibility and difficult data storage in the application of traditional traceability systems. Therefore, this research takes rice as an example and proposes a food safety traceability system based on RFID two-dimensional code technology and big data storage technology in the Internet of Things. This article applies RFID technology to the entire system by analyzing the requirements of the system, designing the system database and database tables, encoding the two-dimensional code and generating the design for information entry. Using RFID radio frequency technology and the data storage function in big data to obtain information in the food production process. Finally, the whole process of food production information can be traced through the design of dynamic query platform and mobile terminal. In this research, the food safety traceability system based on big data and the Internet of Things guarantees the integrity, reliability and safety of traceability information from a technical level. This is an effective solution for enhancing the credibility of traceability information, ensuring the integrity of information, and optimizing the data storage structure.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3078536
VL  - 9
SP  - 70571
EP  - 70583
SN  - 2169-3536
AN  - WOS:000652042300001
ER  - 

TY  - JOUR
TI  - Safe and Sample-Efficient Reinforcement Learning for Clustered Dynamic Environments
AU  - Chen, HY
AU  - Liu, CL
T2  - IEEE CONTROL SYSTEMS LETTERS
AB  - This letter proposes a safe and sample-efficient reinforcement learning (RL) framework to address two major challenges in developing applicable RL algorithms: satisfying safety constraints and efficiently learning with limited samples. To guarantee safety in real-world complex environments, we use the safe set algorithm (SSA) to monitor and modify the nominal controls, and evaluate SSA+RL in a clustered dynamic environment which is challenging to be solved by existing RL algorithms. However, the SSA+RL framework is usually not sample-efficient especially in reward-sparse environments, which has not been addressed in previous safe RL works. To improve the learning efficiency, we propose three techniques: (1) avoiding behaving overly conservative by adapting the SSA; (2) encouraging safe exploration using random network distillation with safety constraints; (3) improving policy convergence by treating SSA as expert demonstrations and directly learn from that. The experimental results show that our framework can achieve better safety performance compare to other safe RL methods during training and solve the task with substantially fewer episodes.
DA  - 2022///
PY  - 2022
DO  - 10.1109/LCSYS.2021.3136486
VL  - 6
SP  - 1928
EP  - 1933
SN  - 2475-1456
AN  - WOS:000735562500002
ER  - 

TY  - JOUR
TI  - Toward Road Safety Recommender Systems: Formal Concepts and Technical Basics
AU  - Boujemaa, KS
AU  - Berrada, I
AU  - Fardousse, K
AU  - Naggar, O
AU  - Bourzeix, F
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Worldwide, traffic accidents are recognized as one of the leading causes of death. This phenomenon leads to significant daily losses affecting both road users and road authorities. Therefore, the need for effective dynamic road security systems is highly considered. Traffic accident data analysis is one of the promising approaches for improving road safety. By taking into account multiple factors (e.g., infrastructure, weather, driver behavior, etc.), it allows measuring the impact of traffic accidents on road security. However, reformulating this impact into practical road safety decisions remains limited and unstructured. To overcome the mentioned limitations, this paper proposes the first end-to-end recommendation framework for road safety. Our framework introduces a three-layered architecture, designed to handle data analysis and action recommendation tasks. For data analysis, we adopt a baseline of state-of-the-art machine and deep learning algorithms to build different traffic accident prediction models. For the action recommendation task, we developed a new approach involving model predictions, model interpretations, actions definition, and road-action interactions matrix annotation. The proposed framework has been successfully experimented and evaluated using two real-world datasets of historical traffic accidents of France (2006-2017) and Morocco (2010-2014), achieving interesting ROC-AUC scores of 0.93 and 0.96, respectively.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1109/TITS.2021.3052771
VL  - 23
IS  - 6
SP  - 5211
EP  - 5230
SN  - 1524-9050
AN  - WOS:000733273800001
KW  - machine learning
KW  - Recommender systems
KW  - Deep learning
KW  - deep learning
KW  - Accidents
KW  - Learning algorithms
KW  - Accident prevention
KW  - Predictive analytics
KW  - Traffic control
KW  - Roads and streets
KW  - Motor transportation
KW  - Accident prediction model
KW  - Effective dynamics
KW  - Layered architecture
KW  - Model interpretations
KW  - Model prediction
KW  - Multiple factors
KW  - Real-world datasets
KW  - recommendation safety systems
KW  - Road authorities
KW  - road safety countermeasures
KW  - Traffic accident analysis
KW  - traffic accident risk prevention
ER  - 

TY  - JOUR
TI  - A transfer learning approach for acoustic emission zonal localization on steel plate-like structure using numerical simulation and unsupervised domain adaptation
AU  - Ai, L
AU  - Zhang, B
AU  - Ziehl, P
T2  - MECHANICAL SYSTEMS AND SIGNAL PROCESSING
AB  - The detection and localization of damage in metallic structures using acoustic emission (AE) monitoring and artificial intelligence technology such as deep learning has been widely studied. However, a current challenge of this approach is the difficulty of obtaining sufficient labeled historical AE signals for the training process of deep learning models. This problem can be approached through the implementation of transfer learning. The innovation of this paper lies in the development of a transfer learning approach for AE source localization on a stainless-steel structure when no historical labeled AE signals are available for training. A finite element model is developed to generate numerical AE signals for the training. Unsupervised domain adaptation (UDA) technology is utilized to reduce the distribution difference between the nu-merical and the realistic AE signals and to derive the localization results of the unlabeled realistic AE signals. The results suggest that the proposed approach is capable of localizing AE signals with high accuracy in the absence of labeled training data.
DA  - 2023/06/01/
PY  - 2023
DO  - 10.1016/j.ymssp.2023.110216
VL  - 192
SN  - 0888-3270
AN  - WOS:000949428700001
KW  - Deep learning
KW  - Learning systems
KW  - Transfer learning
KW  - Learning approach
KW  - Finite element method
KW  - Domain adaptation
KW  - Acoustic emission
KW  - Acoustic emission signal
KW  - Acoustic emission testing
KW  - Acoustic-emissions
KW  - Damage detection
KW  - Element models
KW  - Finite element modeling
KW  - Manifold embedded distribution alignment
KW  - Source localization
KW  - Unsupervised domain adaptation
ER  - 

TY  - JOUR
TI  - Review on big data applications in safety research of intelligent transportation systems and connected/automated vehicles
AU  - Lian, YQ
AU  - Zhang, GQ
AU  - Lee, J
AU  - Huang, HL
T2  - ACCIDENT ANALYSIS AND PREVENTION
AB  - The era of Big Data has arrived. Recently, under the environment of intelligent transportation systems (ITS) and connected/automated vehicles (CAV), Big Data has been applied in various fields in transportation including traffic safety. In this study, we review recent research studies that employed Big Data to analyze traffic safety under the environment of ITS and CAV. The particular topics include crash detection or prediction, discovery of contributing factors to crashes, driving behavior analysis, crash hotspot identification, etc. From the reviewed studies, employing advanced analytics for Big Data has a great potential for understanding and enhancing traffic safety. Big Data application in traffic safety integrates and processes massive multi-source data, breaks through the limitations of the traditional data analytics, and discovers and solves the problems, which cannot be solved by the traditional safety analytics. Lastly, suggestions are provided for future Big Data safety analytics under the environment of ITS and CAV.
DA  - 2020/10//undefined
PY  - 2020
DO  - 10.1016/j.aap.2020.105711
VL  - 146
SN  - 0001-4575
AN  - WOS:000578988400002
KW  - Artificial Intelligence
KW  - Safety
KW  - artificial intelligence
KW  - Machine learning
KW  - Automation
KW  - Data mining
KW  - Intelligent systems
KW  - Intelligent transportation systems
KW  - Accident prevention
KW  - Intelligent vehicle highway systems
KW  - automation
KW  - safety
KW  - Driving behavior
KW  - Automobile Driving
KW  - car driving
KW  - human
KW  - Humans
KW  - Recent researches
KW  - Accidents, Traffic
KW  - traffic accident
KW  - Big Data
KW  - methodology
KW  - Traffic safety
KW  - Transportation
KW  - traffic and transport
KW  - Big data
KW  - Research Design
KW  - Advanced Analytics
KW  - Data Analytics
KW  - Highway traffic control
KW  - Multisource data
KW  - Big data applications
KW  - Connected and automated vehicles
KW  - Contributing factor
KW  - Safety research
ER  - 

TY  - JOUR
TI  - Anticipation model based on a modified fuzzy logic approach
AU  - Bennajeh, A
AU  - Bechikh, S
AU  - Ben Said, L
AU  - Aknine, S
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - Car-following behaviour is an important problem in terms of road safety, since it represents, alone, almost 70% of road accidents caused by not maintaining a safe braking distance between the moving cars. The inappropriate anticipation of drivers to keep safety distance is the main reason for accidents. In this study, the authors present an artificial intelligence anticipation model for car-following problem based on a fuzzy logic approach. This system will estimate the velocity of the leading vehicle in the near future. Moreover, they have replaced the old methods used in the third step of fuzzy logical approach, the defuzzification, by a novel method based on a metaheuristic algorithm, i.e. Tabu search, in order to adapt effectively to the environment's instability. The results of experiments, conducted using the next generation simulation dataset to validate the proposed model, indicate that the vehicle trajectories simulated based on the new model are in compliance with the actual vehicle trajectories in terms of deviation and estimated velocities. Moreover, they show that the proposed model guarantees road safety in terms of harmonisation between the gap distance and the calculated safety distance.
DA  - 2019/02//undefined
PY  - 2019
DO  - 10.1049/iet-its.2018.5156
VL  - 13
IS  - 2
SP  - 330
EP  - 339
SN  - 1751-956X
AN  - WOS:000457717800011
ER  - 

TY  - JOUR
TI  - Ship Collision Risk Assessment Based on Collision Detection Algorithm
AU  - Liu, DD
AU  - Shi, GY
T2  - IEEE ACCESS
AB  - Ningbo Zhoushan port handled 1.08 billion tons cargoes in 2018 which is considered as the one of biggest ports in the world. There are more than 1 000 ships enter or depart the port per day. Therefore, it is of importance to assess the collision risk for ships passing through the harbor area. In this article, a novel approach is initially proposed to assess ship collision risk in the harbor area based on collision detection technology of ship domain using automatic identified system (AIS) data. This study aims to build a unified framework of collision risk assessment which does not need to build different models in accordance with the ship domain we selected. To clean the historical motion data of ships, a method for anomaly detection of ship static information based on autoencoder (AE) is proposed. Based on the above proposed method, the ship collision frequency can be estimated, besides, the risk area can also be determined. The results obtained from the method could provide a reference on furthering enhance the navigational safety for the Maritime and Port Authority.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3013957
VL  - 8
SP  - 161969
EP  - 161980
SN  - 2169-3536
AN  - WOS:000570087400001
ER  - 

TY  - JOUR
TI  - A rule-based neural network approach to model driver naturalistic behavior in traffic
AU  - Chong, LS
AU  - Abbas, MM
AU  - Flintsch, AM
AU  - Higgs, B
T2  - TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES
AB  - This paper proposes a rule-based neural network model to simulate driver behavior in terms of longitudinal and lateral actions in two driving situations, namely car-following situation and safety critical events. A fuzzy rule based neural network is constructed to obtain driver individual driving rules from their vehicle trajectory data. A machine learning method reinforcement learning is used to train the neural network such that the neural network can mimic driving behavior of individual drivers. Vehicle actions by neural network are compared to actions from naturalistic data. Furthermore, this paper applies the proposed method to analyze the heterogeneities of driving behavior from different drivers' data.
Driving data in the two driving situations are extracted from Naturalistic Truck Driving Study and Naturalistic Car Driving Study databases provided by the Virginia Tech Transportation Institute according to pre-defined criteria. Driving actions were recorded in instrumented vehicles that have been equipped with specialized sensing, processing, and recording equipment. (C) 2012 Elsevier Ltd. All rights reserved.
DA  - 2013/07//undefined
PY  - 2013
DO  - 10.1016/j.trc.2012.09.011
VL  - 32
SP  - 207
EP  - 223
SN  - 0968-090X
AN  - WOS:000320346100015
KW  - Reinforcement learning
KW  - Fuzzy neural networks
KW  - Neural networks
KW  - Vehicles
KW  - Learning systems
KW  - Behavioral research
KW  - Driver training
KW  - Driving behavior
KW  - Traffic control
KW  - Neural network model
KW  - Instrumented vehicle
KW  - Machine learning methods
KW  - Safety engineering
KW  - computer simulation
KW  - artificial neural network
KW  - Fuzzy logic
KW  - learning
KW  - transportation safety
KW  - Vehicle trajectories
KW  - numerical model
KW  - Artificial neural network
KW  - Fuzzy inference
KW  - Critical events
KW  - Car following models
KW  - fuzzy mathematics
KW  - car use
KW  - Car-following models
KW  - Naturalistic data
KW  - Safety critical events
KW  - traffic congestion
KW  - Truck transportation
ER  - 

TY  - JOUR
TI  - ATAC-Based Car-Following Model for Level 3 Autonomous Driving Considering Driver's Acceptance
AU  - Tang, TQ
AU  - Gui, Y
AU  - Zhang, J
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - To date, commercial fully autonomous driving is not realized, while level 3 is the next step in the development of autonomous driving. At level 3, the vehicle is driving under the control of the machine, but when feature requests, human driver must take over control. Therefore, autonomous driving control should consider not only efficiency and safety but also human driver's acceptance. This paper develops a car-following (CF) model as a longitudinal control strategy for level 3 autonomous driving based on the automating entropy adjustment on Tsallis actor-critic (ATAC) algorithm. 1641 pairs of CF trajectories extracted from the Next Generation Simulation (NGSIM) data are applied to train the reinforcement learning (RL) agent. Based on the empirical data distributions, we use time margin, time gap, and jerk to construct the reward function and testify the proposed CF model's merits. Simulation results show that the proposed model can enable vehicles to drive safely, efficiently, and comfortably. The proposed model has good stability, and the generated driving behaviors are more acceptable for drivers. This work sheds light on developing a better autonomous driving system from the perspective of human factors.
DA  - 2022/08//undefined
PY  - 2022
DO  - 10.1109/TITS.2021.3090974
VL  - 23
IS  - 8
SP  - 10309
EP  - 10321
SN  - 1524-9050
AN  - WOS:000732108000001
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Safety
KW  - Vehicles
KW  - reinforcement learning
KW  - Trajectory
KW  - Data models
KW  - Autonomous driving
KW  - Reinforcement learning agent
KW  - Driving behavior
KW  - Traffic control
KW  - Digital storage
KW  - Entropy
KW  - Reward function
KW  - Car following models
KW  - car-following
KW  - driver's acceptance.
KW  - Empirical data
KW  - Feature requests
KW  - Good stability
KW  - Longitudinal control
ER  - 

TY  - JOUR
TI  - Towards a safe and efficient clinical implementation of machine learning in radiation oncology by exploring model interpretability, explainability and data-model dependency
AU  - Barragán-Montero, A
AU  - Bibal, A
AU  - Dastarac, MH
AU  - Draguet, C
AU  - Valdés, G
AU  - Nguyen, D
AU  - Willems, S
AU  - Vandewinckele, L
AU  - Holmström, M
AU  - Löfman, F
AU  - Souris, K
AU  - Sterpin, E
AU  - Lee, JA
T2  - PHYSICS IN MEDICINE AND BIOLOGY
AB  - The interest in machine learning (ML) has grown tremendously in recent years, partly due to the performance leap that occurred with new techniques of deep learning, convolutional neural networks for images, increased computational power, and wider availability of large datasets. Most fields of medicine follow that popular trend and, notably, radiation oncology is one of those that are at the forefront, with already a long tradition in using digital images and fully computerized workflows. ML models are driven by data, and in contrast with many statistical or physical models, they can be very large and complex, with countless generic parameters. This inevitably raises two questions, namely, the tight dependence between the models and the datasets that feed them, and the interpretability of the models, which scales with its complexity. Any problems in the data used to train the model will be later reflected in their performance. This, together with the low interpretability of ML models, makes their implementation into the clinical workflow particularly difficult. Building tools for risk assessment and quality assurance of ML models must involve then two main points: interpretability and data-model dependency. After a joint introduction of both radiation oncology and ML, this paper reviews the main risks and current solutions when applying the latter to workflows in the former. Risks associated with data and models, as well as their interaction, are detailed. Next, the core concepts of interpretability, explainability, and data-model dependency are formally defined and illustrated with examples. Afterwards, a broad discussion goes through key applications of ML in workflows of radiation oncology as well as vendors' perspectives for the clinical implementation of ML.
DA  - 2022/06/07/
PY  - 2022
DO  - 10.1088/1361-6560/ac678a
VL  - 67
IS  - 11
SN  - 0031-9155
AN  - WOS:000805130900001
KW  - machine learning
KW  - Interpretability
KW  - Deep learning
KW  - Machine Learning
KW  - uncertainty quantification
KW  - Performance
KW  - Convolutional neural network
KW  - Machine learning models
KW  - Risk assessment
KW  - Complex networks
KW  - Large dataset
KW  - Neural Networks, Computer
KW  - Uncertainty quantifications
KW  - Quality assurance
KW  - Work-flows
KW  - clinical implementation
KW  - Clinical implementation
KW  - Institute of Physics
KW  - interpretability and explainability
KW  - Interpretability and explainability
KW  - Model dependencies
KW  - Oncology
KW  - radiation oncology
KW  - Radiation Oncology
KW  - Radiotherapy
ER  - 

TY  - JOUR
TI  - Safe Deep Reinforcement Learning for Microgrid Energy Management in Distribution Networks With Leveraged SpatialTemporal Perception
AU  - Ye, YJ
AU  - Wang, HR
AU  - Chen, PL
AU  - Tang, Y
AU  - Strbac, GR
T2  - IEEE TRANSACTIONS ON SMART GRID
AB  - Microgrids (MG) have recently attracted great interest as an effective solution to the challenging problem of distributed energy resources ’ management in distribution networks. In this context, despite deep reinforcement learning (DRL) constitutes a well-suited model-free and data-driven methodological framework, its application to MG energy management is still challenging, driven by their limitations on environment status perception and constraint satisfaction. In this paper, the MG energy management problem is formalized as a Constrained Markov Decision Process, and is solved with the state-of-the-art interior-point policy optimization (IPO) method. In contrast to conventional DRL approaches, IPO facilitates efficient learning in multi-dimensional, continuous state and action spaces, while promising satisfaction of complex network constraints of the distribution network. The generalization capability of IPO is further enhanced through the extraction of spatial-temporal correlation features from original MG operating status, combining the strength of edge conditioned convolutional network and long short-term memory network. Case studies based on an IEEE 15-bus and 123-bus test feeders with real-world data demonstrate the superior performance of the proposed method in improving MG cost effectiveness, safeguarding the secure operation of the network and uncertainty adaptability, through performance benchmarking against model-based and DRL-based baseline methods. Finally, case studies also analyze the computational and scalability performance of proposed and baseline methods.
DA  - 2023/09//undefined
PY  - 2023
DO  - 10.1109/TSG.2023.3243170
VL  - 14
IS  - 5
SP  - 3759
EP  - 3775
SN  - 1949-3053
AN  - WOS:001068126800033
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Bayesian networks
KW  - Uncertainty analysis
KW  - Benchmarking
KW  - Complex networks
KW  - Markov processes
KW  - Cost effectiveness
KW  - Constrained optimization
KW  - Energy management
KW  - Microgrid
KW  - Power
KW  - Safe deep reinforcement learning
KW  - Electric power distribution
KW  - safe deep reinforcement learning
KW  - Energy resources
KW  - Interior point
KW  - microgrids
KW  - network constraints
KW  - Network constraints
KW  - Point policy
KW  - power system spatial-temporal perception
KW  - Power system spatial-temporal perception
KW  - Spatial temporals
KW  - Temporal perception
ER  - 

TY  - JOUR
TI  - Adaptive Safety Shields for Reinforcement Learning-Based Cell Shaping
AU  - Dey, S
AU  - Mujumdar, A
AU  - Dasgupta, P
AU  - Dey, S
T2  - IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT
AB  - Adjusting the remote electrical tilt (RET) of antennas is one of the important actions targeting run-time optimization of key performance indicators (KPIs) related to service quality in wireless self-organizing networks (SONs). Reinforcement learning (RL) is one of the preferred Machine Learning methods for automating the choice of RET for all the antennas managed by a company in a region. The automated system should ensure that the system will operate within a safe region to maintain a minimum defined service quality. The safe region of operation is typically customizable based on the targeted service quality at any point in time. This customizable nature of the safe region necessitates automated learning of adaptive safety shields for steering the RL agent away from unsafe regions. This paper presents an adaptive safety shield framework that is capable of learning such shields during the training phase of the RL agent. Our adaptive safety shield framework has been evaluated in different RET scenarios, and we have shown the benefits of our proposed framework over the Baseline method currently in use and a vanilla RL-based method in terms of both safety and performance metrics.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1109/TNSM.2022.3194566
VL  - 19
IS  - 4
SP  - 5034
EP  - 5043
SN  - 1932-4537
AN  - WOS:000966900300001
ER  - 

TY  - JOUR
TI  - FVRD: Fishing Vessels Relationships Discovery System Through Vessel Trajectory
AU  - Huang, HG
AU  - Cui, XJ
AU  - Bi, XM
AU  - Liu, C
AU  - Hong, F
AU  - Guo, S
T2  - IEEE ACCESS
AB  - Vessel monitoring system (VMS) is an effective tool for the quantified study of fishing. As the fishing vessels equipped with VMS clients, a large amount of trajectory data has been collected, which brings a new opportunity for fishing research. According to fishery safety production regulations, fishing vessels should perform grouping operations based on actual conditions, but the group information cannot be collected by the VMS. In this paper, we propose the Fishing Vessels Relationships Discovery system (FVRD) by calculating the interaction time among fishing vessels and then using it as a weight to generate a relationship network. The experiment of the proposed FVRD on the vessel dataset of Zhejiang Province reveals that the generated fishing community is consistent with the type of operation of the fishing vessels, which means the proposed method is effective. The experiment also indicates that the fishing vessel relationship network has the characteristics of small-world and scale-free that is similar to the human social network, Moreover, FVRD shows that 86.78% of vessels share the collaboration relationships over one week, 10.72% of vessels are in the long-term cooperation, confirming the regulation that most fishing vessels are sailing together for fishing.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3002173
VL  - 8
SP  - 112530
EP  - 112538
SN  - 2169-3536
AN  - WOS:000546414500019
ER  - 

TY  - CONF
TI  - A Qualitative Approach to Signal Mining in Pharmacovigilance using Formal Concept Analysis
AU  - Lillo-Le Louët, A
AU  - Toussaint, Y
AU  - Villerd, J
T2  - MEDINFO 2010, PTS I AND II
A2  - Safran, C
A2  - Reti, S
A2  - Marin, HF
AB  - "Pharmacovigilance is the process and science of monitoring the safety of medicines, consisting in (i) collecting and managing data on the safety of medicines (ii) looking at the data to detect 'signals' (any new or changing safety issue)" [1]. Pharmacovigilance is mainly based on spontaneous reports: when suspecting an adverse drug reaction, health care practitioners send a report to a spontaneous reporting system (SRS). This produces huge databases containing numerous reports and their manual exploration is both cost and time prohibitive. Existing techniques that automatically extract relevant signals rely on statistics or Bayesian models but do not provide information to the experts about possible biases lying in the data, nor about the specificity of a signal to a particular patient profile. Our extraction method combines numerical methods from the state of the art with a qualitative approach that helps interpretation. We build a synthetic representation of the database that is used to (i) identify unexpected patterns and biases (ii) extract potentially relevant signals w.r.t. patient profiles (iii) provide traceability facilities between extracted signals and raw data.
DA  - 2010///
PY  - 2010
DO  - 10.3233/978-1-60750-588-4-969
VL  - 160
SP  - 969
EP  - 973
SN  - 0926-9630
AN  - WOS:000392215900190
ER  - 

TY  - JOUR
TI  - Governance of Clinical AI applications to facilitate safe and equitable deployment in a large health system: Key elements and early successes
AU  - Liao, F
AU  - Adelaine, S
AU  - Afshar, M
AU  - Patterson, BW
T2  - FRONTIERS IN DIGITAL HEALTH
AB  - One of the key challenges in successful deployment and meaningful adoption of AI in healthcare is health system-level governance of AI applications. Such governance is critical not only for patient safety and accountability by a health system, but to foster clinician trust to improve adoption and facilitate meaningful health outcomes. In this case study, we describe the development of such a governance structure at University of Wisconsin Health (UWH) that provides oversight of AI applications from assessment of validity and user acceptability through safe deployment with continuous monitoring for effectiveness. Our structure leverages a multi-disciplinary steering committee along with project specific sub-committees. Members of the committee formulate a multi-stakeholder perspective spanning informatics, data science, clinical operations, ethics, and equity. Our structure includes guiding principles that provide tangible parameters for endorsement of both initial deployment and ongoing usage of AI applications. The committee is tasked with ensuring principles of interpretability, accuracy, and fairness across all applications. To operationalize these principles, we provide a value stream to apply the principles of AI governance at different stages of clinical implementation. This structure has enabled effective clinical adoption of AI applications. Effective governance has provided several outcomes: (1) a clear and institutional structure for oversight and endorsement; (2) a path towards successful deployment that encompasses technologic, clinical, and operational, considerations; (3) a process for ongoing monitoring to ensure the solution remains acceptable as clinical practice and disease prevalence evolve; (4) incorporation of guidelines for the ethical and equitable use of AI applications.
DA  - 2022/08/24/
PY  - 2022
DO  - 10.3389/fdgth.2022.931439
VL  - 4
SN  - 2673-253X
AN  - WOS:001034020100001
ER  - 

TY  - JOUR
TI  - Run-Time Monitoring of Machine Learning for Robotic Perception: A Survey of Emerging Trends
AU  - Rahman, QM
AU  - Corke, P
AU  - Dayoub, F
T2  - IEEE ACCESS
AB  - As deep learning continues to dominate all state-of-the-art computer vision tasks, it is increasingly becoming an essential building block for robotic perception. This raises important questions concerning the safety and reliability of learning-based perception systems. There is an established field that studies safety certification and convergence guarantees of complex software systems at design-time. However, the unknown future deployment environments of an autonomous system and the complexity of learning-based perception make the generalization of design-time verification to run-time problematic. In the face of this challenge, more attention is starting to focus on run-time monitoring of performance and reliability of perception systems with several trends emerging in the literature in the face of this challenge. This paper attempts to identify these trends and summarize the various approaches to the topic.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3055015
VL  - 9
SP  - 20067
EP  - 20075
SN  - 2169-3536
AN  - WOS:000615041000001
ER  - 

TY  - JOUR
TI  - Machine learning-based methods for analyzing grade crossing safety
AU  - Yang, CS
AU  - Trudel, E
AU  - Liu, Y
T2  - CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS
AB  - A grade crossing is defined as an intersection between a roadway and a railway at the same elevation or grade. Multiple new prevention measures have been implemented to reduce the number of train-vehicle collisions; however, crossing safety remains a major issue as accidents still frequently occur. The push for machine learning-based model to analyze risks at grade crossings has also increased to keep up with new technologies. There are many different protection types (gates with bells, cross-buck, stop-sign, mirrors and etc.) that serve to warn or stop oncoming traffic. Many attributes have an inherent impact on accident frequency, including the protection type, train speed, traffic volume and etc. To find out which factors are most important, we propose a machine learning-based method to effectively analyze the impact of multiple factors that affect crossing safety and subsequently provide scientific insight for key factors for enhancing crossing safety. In this work, the Canadian crossing accident database from 2004 to 2013 was used with additional generated features to enhance the performance of models. These include features that were computed using geographical information systems (GIS) and sightline measurements. Based on the performance, the machine learning algorithm, RandomForest is used to rank and analyze 21 attributes for each protection type. From the analysis results it is possible to identify which key factors have the highest influence on improving safety and collision prediction at grade crossings.
DA  - 2017/06//undefined
PY  - 2017
DO  - 10.1007/s10586-016-0714-2
VL  - 20
IS  - 2
SP  - 1625
EP  - 1635
SN  - 1386-7857
AN  - WOS:000403457100058
KW  - Artificial intelligence
KW  - Accidents
KW  - Learning systems
KW  - Learning algorithms
KW  - Crashworthiness
KW  - Data-driven model
KW  - Machine learning algorithm
KW  - Data-driven modeling
KW  - Railroad accidents
KW  - Geographic information systems
KW  - Grade crossing
KW  - Railroad crossings
KW  - GIS
KW  - Collision prediction
KW  - Feature generation
KW  - Grade-crossing safety
KW  - Prevention measures
KW  - RandomForest regression
KW  - Accident frequency
KW  - Crossing safety
ER  - 

TY  - CONF
TI  - Data-Driven Modeling Method for Analyzing Grade Crossing Safety
AU  - Trudel, E
AU  - Liu, Y
AU  - Yang, CS
T2  - 2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD)
A2  - Shen, W
A2  - Liu, X
A2  - Yang, C
A2  - Barthes, JP
A2  - Luo, J
A2  - Chen, L
A2  - Yong, J
AB  - A grade crossing is defined as an intersection between a roadway and a railway at the same elevation or grade. Multiple new prevention measures have been implemented to reduce the number of train-vehicle collisions; however, crossing safety is still a major issue as accidents still frequently occur. The push for data-driven models to evaluate risks at grade crossings has also increased to keep up with the changing technologies. There are many different protection types (gates with bells, cross-buck, stop-sign, mirrors and etc.) that serve to warn or stop oncoming traffic. Many attributes have an inherent impact on accident frequency; including the protection type, train speed, traffic volume and e.t.c. To address which factors are most important, we propose a data-driven modeling method to effectively analyze the impact of multiple factors that affect crossing safety and subsequently provide scientific insight for key factors for enhancing crossing safety. In this work, the Canadian crossing accident database for the years of 2004 - 2013 was used with additional generated features to enhance the scope of the study. These include features that were computed using GIS and sightline measurements. Data-driven modeling using RandomForests were used to rank and analyze 21 attributes for each protection type. From the analysis results it is possible to identify which key factors have the highest influence on improving safety and collision prediction at grade crossings.
DA  - 2016///
PY  - 2016
SP  - 145
EP  - 151
SN  - 978-1-5090-1915-1
AN  - WOS:000389305700030
KW  - Artificial intelligence
KW  - Accidents
KW  - Learning systems
KW  - Learning algorithms
KW  - Interactive computer systems
KW  - Crashworthiness
KW  - machine learning algorithm
KW  - Data-driven model
KW  - Railroad accidents
KW  - Geographic information systems
KW  - Grade crossing
KW  - Railroad crossings
KW  - GIS
KW  - data-driven modeling
KW  - Collision prediction
KW  - crossing safety
KW  - Data driven modeling methods
KW  - feature generation
KW  - Feature generation
KW  - Grade-crossing safety
KW  - Prevention measures
KW  - RandomForest regression
ER  - 

TY  - JOUR
TI  - Generalization Capability of Mixture Estimation Model for Peristaltic Continuous Mixing Conveyor
AU  - Oshino, S
AU  - Nishihama, R
AU  - Wakamatsu, K
AU  - Inoue, K
AU  - Matsui, D
AU  - Okui, M
AU  - Nakajima, K
AU  - Kuniyoshi, Y
AU  - Nakamura, T
T2  - IEEE ACCESS
AB  - We propose herein a method for estimating the mixing state of the contents of a peristaltic continuous mixing conveyor simulating the intestine, developed for mixing and conveying powders and liquids. This study serves to improve a previously proposed method for estimating the mixing state using a logistic regression model with the pressure and flow rate sensors installed in the device as inputs. Moreover, the estimation accuracy of the proposed method is better than that of the previous method. The generalizability of the proposed method is evaluated for four conditions in which the feeding order of the contents, powder, and liquid are changed. The feeding order is as follows: powder first, liquid first, and powder and liquid alternately. As a result, a highly accurate estimation of mixing is achieved under the condition wherein the powder component is in the unit adjacent to the lid, but not under the condition wherein the liquid component is fed first. It is speculated that this is because the movement of the powder component inside the device is more easily reflected by the pressure and flow rate sensors installed in the device than in the liquid component.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3112614
VL  - 9
SP  - 138866
EP  - 138875
SN  - 2169-3536
AN  - WOS:000707433500001
KW  - machine learning
KW  - transportation
KW  - Logistic Regression modeling
KW  - predictive models
KW  - Logistic regression
KW  - Mixing
KW  - Highly accurate
KW  - Continuous mixing
KW  - Conveyors
KW  - data acquisition
KW  - Flow rate sensors
KW  - Generalization capability
KW  - Liquid components
KW  - Liquids
KW  - Mixing state
KW  - Mixture estimation
KW  - product safety
KW  - robot sensing systems
KW  - Soft robotics
ER  - 

TY  - JOUR
TI  - Smart Train Operation Algorithms Based on Expert Knowledge and Reinforcement Learning
AU  - Zhou, KC
AU  - Song, SJ
AU  - Xue, AK
AU  - You, KY
AU  - Wu, H
T2  - IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS
AB  - During decades, the automatic train operation (ATO) system has been gradually adopted in many subway systems for its low-cost and intelligence. This article proposes two smart train operation (STO) algorithms by integrating the expert knowledge with reinforcement learning algorithms. Compared with previous works, the proposed algorithms can realize the control of continuous action for the subway system and optimize multiple critical objectives without using an offline speed profile. First, through learning historical data of experienced subway drivers, we extract the expert knowledge rules and build inference methods to guarantee the riding comfort, the punctuality, and the safety of the subway system. Then we develop two algorithms for optimizing the energy efficiency of train operation. One is the STO algorithm based on deep deterministic policy gradient named (STOD) and the other is the STO algorithm based on normalized advantage function (STON). Finally, we verify the performance of proposed algorithms via some numerical simulations with the real field data from the Yizhuang Line of the Beijing Subway and illustrate that the developed STO algorithm are better than expert manual driving and existing ATO algorithms in terms of energy efficiency. Moreover, STOD and STON can adapt to different trip times and different resistance conditions.
DA  - 2022/02//undefined
PY  - 2022
DO  - 10.1109/TSMC.2020.3000073
VL  - 52
IS  - 2
SP  - 716
EP  - 727
SN  - 2168-2216
AN  - WOS:000742732900011
ER  - 

TY  - JOUR
TI  - Full-Spectrum Out-of-Distribution Detection
AU  - Yang, JK
AU  - Zhou, KY
AU  - Liu, ZW
T2  - INTERNATIONAL JOURNAL OF COMPUTER VISION
AB  - Existing out-of-distribution (OOD) detection literature clearly defines semantic shift as a sign of OOD but does not have a consensus over covariate shift. Samples experiencing covariate shift but not semantic shift from the in-distribution (ID) are either excluded from the test set or treated as OOD, which contradicts the primary goal in machine learning-being able to generalize beyond the training distribution. In this paper, we take into account both shift types and introduce full-spectrum OOD (F-OOD) detection, a more realistic problem setting that considers both detecting semantic shift and being tolerant to covariate shift; and design three benchmarks. These new benchmarks have a more fine-grained categorization of distributions (i.elet@tokeneonedot, training ID, covariate-shifted ID, near-OOD, and far-OOD) for the purpose of more comprehensively evaluating the pros and cons of algorithms. To address the F-OOD detection problem, we propose SEM, a simple featurebased semantics score function. SEM is mainly composed of two probability measures: one is based on high-level features containing both semantic and non-semantic information, while the other is based on low-level feature statistics only capturing non-semantic image styles. With a simple combination, the non-semantic part is canceled out, which leaves only semantic information in SEM that can better handle F-OOD detection. Extensive experiments on the three new benchmarks show that SEM significantly outperforms current state-of-the-art methods. Our code and benchmarks are released in https://github.com/ Jingkang50/OpenOOD.
DA  - 2023/10//undefined
PY  - 2023
DO  - 10.1007/s11263-023-01811-z
VL  - 131
IS  - 10
SP  - 2607
EP  - 2622
SN  - 0920-5691
AN  - WOS:001008683200001
ER  - 

TY  - JOUR
TI  - Ranking Risk Factors in Financial Losses From Railroad Incidents: A Machine Learning Approach
AU  - Dhingra, N
AU  - Bridgelall, R
AU  - Lu, P
AU  - Szmerekovsky, J
AU  - Bhardwaj, B
T2  - TRANSPORTATION RESEARCH RECORD
AB  - The reported financial losses from railroad accidents since 2009 have been more than US$4.11 billion dollars. This considerable loss is a major concern for the industry, society, and the government. Therefore, identifying and ranking the factors that contribute to financial losses from railroad accidents would inform strategies to minimize them. To achieve that goal, this paper evaluates and compares the results of applying different non-parametric statistical and regression methods to 15 years of railroad Class I freight train accident data. The models compared are random forest, k-nearest neighbors, support vector machines, stochastic gradient boosting, extreme gradient boosting, and stepwise linear regression. The results indicate that these methods are all suitable for analyzing non-linear and heterogeneous railroad incident data. However, the extreme gradient boosting method provided the best performance. Therefore, the analysis used that model to identify and rank factors that contribute to financial losses, based on the gain percentage of the prediction accuracy. The number of derailed freight cars and the absence of territory signalization dominated as contributing factors in more than 57% and 20% of the accidents, respectively. Partial-dependence plots further explore the complex non-linear dependencies of each factor to better visualize and interpret the results.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1177/03611981221133085
VL  - 2677
IS  - 2
SP  - 299
EP  - 309
SN  - 0361-1981
AN  - WOS:000886510500001
ER  - 

TY  - JOUR
TI  - Joint Domain Adaptation Based on Adversarial Dynamic Parameter Learning
AU  - Yuan, YM
AU  - Li, YH
AU  - Zhu, ZL
AU  - Li, RX
AU  - Gu, XW
T2  - IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
AB  - Domain adaptation aims to improve the performance of the classifier in the target domain by reducing the difference between the two domains. Domain shifts usually exist in both marginal distribution and conditional distribution, and their relative importance varies with datasets. Moreover, there is an influence between marginal distribution distance and conditional distribution distance. However, joint domain adaptation approaches rarely consider those. Existing dynamic distribution alignment methods require a feature discriminator, and they need to train a subdomain discriminator for each class. Besides, they don't think about the interaction between the two distribution distances. In this article, we propose a dynamic joint domain adaptation approach, namely Joint Domain Adaptation Based on Adversarial Dynamic Parameter Learning (ADPL), to deal with the above problems. Both marginal distribution alignment and conditional distribution alignment can be implemented by adversarial learning. The dynamic algorithm can keep a balance between marginal and conditional distribution alignment with only two domain discriminators. In addition, the dynamic algorithm takes the influence between the two distribution distances into consideration. Compared with several advanced domain adaptation methods on both text and image datasets, all classification experiments and extensive comparison experiments demonstrate that ADPL has higher learning performance of classification and less running time. This reveals that ADPL outperforms the state-of-the-art domain adaptation approaches.
DA  - 2021/08//undefined
PY  - 2021
DO  - 10.1109/TETCI.2021.3055873
VL  - 5
IS  - 4
SP  - 714
EP  - 723
SN  - 2471-285X
AN  - WOS:000677536500017
ER  - 

TY  - CONF
TI  - A Deployment Model to Extend Ethically Aligned AI Implementation Method ECCOLA
AU  - Antikainen, J
AU  - Agbese, M
AU  - Alanen, HK
AU  - Halme, E
AU  - Isomäki, H
AU  - Jantunen, M
AU  - Kemell, KK
AU  - Rousi, R
AU  - Vainio-Pekka, H
AU  - Vakkuri, V
T2  - 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021)
A2  - Yue, T
A2  - Mirakhorli, M
AB  - There is a struggle in Artificial intelligence (AI) ethics to gain ground in actionable methods and models to be utilized by practitioners while developing and implementing ethically sound AI systems. AI ethics is a vague concept without a consensus of definition or theoretical grounding and bearing little connection to practice. Practice involving primarily technical tasks like software development is not aptly equipped to process and decide upon ethical considerations. Efforts to create tools and guidelines to help people working with AI development have been concentrating almost solely on the technical aspects of AI. A few exceptions do apply, such as the ECCOIA method for creating ethically aligned AI -systems. ECCOIA has proven results in terms of increased ethical considerations in AI systems development. Yet, it is a novel innovation, and room for development still exists. This study aims to extend ECCOIA with a deployment model to drive the adoption of ECCOIA, as any method - no matter how good -is of no value without adoption and use. The model includes simple metrics to facilitate the communication of ethical gaps or outcomes of ethical AI development. It offers the opportunity to assess any AI system at any given life-cycle phase, e.g., opening possibilities like analyzing the ethicality of an AI system under acquisition
DA  - 2021///
PY  - 2021
DO  - 10.1109/REW53955.2021.00043
SP  - 230
EP  - 235
SN  - 978-1-6654-1898-0
AN  - WOS:000788547300034
ER  - 

TY  - JOUR
TI  - Fuzzy Granule Manifold Alignment Preserving Local Topology
AU  - Li, W
AU  - Xue, JW
AU  - Chen, YM
AU  - Zhang, XB
AU  - Tang, C
AU  - Zhang, Q
AU  - Gao, YF
T2  - IEEE ACCESS
AB  - Granular computing has the advantage of discovering complex data knowledge, and manifold alignment has proven of great value in a lot of areas of machine learning. We propose a novel algorithm of fuzzy granule manifold alignment (FGMA), where we define some new operations, measurements, and local topology of fuzzy granular vectors in fuzzy granular space. Furthermore, the algorithm is very different from Semi-supervised and Procrustes algorithm because predetermining correspondence is not necessary. A projection is learned that can map instances described by two types of features to a low-dimensional space. Meanwhile, the local topology of the fuzzy granular vector induced by the instance is also preserved and matched within each set in lower dimensional space. This approach makes it possible to directly compare between data instances in different spaces. We convert an alignment problem of data in feature space into fuzzy granular manifold alignment problem of granular space. Specifically, we first define fuzzy granule, fuzzy granular vector, operations, and measurements in fuzzy granular space and gave proofs of theorems and deductions. Next, the local topology around the fuzzy granular vector is introduced and the optimal local topology matching can be achieved by minimizing their Frobenius norm. Finally, two manifolds are connected and the optimal mapping can be calculated to obtain dimensionality reduction of the joint structure. Thus, the corresponding relationship between two data instances can be got. We verified this algorithm in Oxford image and Alzheimer's disease voice dataset. Theoretical analysis and experiments demonstrate the algorithm proposed is robust and effective.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3027311
VL  - 8
SP  - 178695
EP  - 178705
SN  - 2169-3536
AN  - WOS:000577836600001
ER  - 

TY  - JOUR
TI  - A Dynamic Deep Reinforcement Learning-Bayesian Framework for Anomaly Detection
AU  - Watts, J
AU  - van Wyk, F
AU  - Rezaei, S
AU  - Wang, YY
AU  - Masoud, N
AU  - Khojandi, A
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - To assure the successful operation of connected and automated vehicles, it is critical to detect and isolate anomalous and/or faulty information in a timely manner. To do so, anomaly detection techniques should be implemented in real-time where if the probability of anomalous information exceeds a certain threshold, the information is dealt with accordingly. Traditionally, the threshold for judging whether the data is anomalous is fixed and determined a priori. However, not only does this approach fail to account for the feedback obtained during a trip on the performance of the algorithms, but it also fails to respond to potential changes in rates of anomalies. Hence, it is important to develop an approach that can dynamically alter this threshold in response to exogenous factors to assure reliable and robust system operation. We develop a mathematical framework which utilizes a dynamic threshold for an anomaly classification algorithm in order to maximize the safety of a trip. Specifically, we develop and pair an anomaly classification algorithm based on convolutional neural networks (CNN), with a partially observable Markov decision process (POMDP) model. We solve the resulting POMDP model using the asynchronous advantage actor critic (A3C) deep reinforcement learning algorithm. The prescribed policy determines the anomaly classification threshold in real-time that maximizes the performance. Our numerical experiments show that the POMDP model outperforms state-of-the-art benchmarks, especially under more difficult to detect anomaly profiles.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1109/TITS.2022.3200906
VL  - 23
IS  - 12
SP  - 22884
EP  - 22894
SN  - 1524-9050
AN  - WOS:000849244700001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Vehicle safety
KW  - Neural networks
KW  - Automated vehicles
KW  - Cyber-physical systems
KW  - Anomaly detection
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - anomaly detection
KW  - Convolution
KW  - Convolutional neural network
KW  - Markov processes
KW  - Data structures
KW  - Embedded systems
KW  - Heuristic algorithms
KW  - Cybe-physical systems
KW  - Cyber Physical System
KW  - deep reinforcement learning
KW  - Vehicle's dynamics
KW  - Heuristics algorithm
KW  - Bayes method
KW  - vehicle safety
KW  - Connected and automated vehicle
KW  - Dynamics models
KW  - connected and automated vehicles
KW  - dynamic model
KW  - partial information
KW  - Partial information
ER  - 

TY  - CONF
TI  - Contributions from the community IT programme
AU  - Corsi, P
T2  - ON-LINE FAULT DETECTION AND SUPERVISION IN THE CHEMICAL PROCESS INDUSTRIES 1998
A2  - Dhurjati, PS
A2  - Cauvin, S
AB  - Being industrially oriented, the Information Technologies (ESPRIT) Programme is nowadays found operating at the intersection of advanced technologies and existing and new markets. The development, trialing, facilitation of the adoption and diffusion of innovative technologies by industrial and academic Esprit consortia has become the core tenet of contractual projects in all domains of ESPRIT.
This paper introduces a number of salient projects and activities which have recently been or are currently funded by the Commission of the European Communities within ESPRIT (DGIII - Industry) in relationship to advanced, intelligent techniques for industrial and business control, at the levels of systems, methods, tools, techniques, and applications with the accompanying actions to support them. A number of issues of special resonance to the Fifth framework Programme are discussed. Copyright (C) 1998 IFAC.
DA  - 1998///
PY  - 1998
SP  - 1
EP  - 8
SN  - 0-08-043233-6
AN  - WOS:000078239800001
ER  - 

TY  - CONF
TI  - Deep Learning-driven Explainable AI using Generative Adversarial Network (GAN)
AU  - Maan, J
AU  - IEEE
T2  - 2022 IEEE 19TH INDIA COUNCIL INTERNATIONAL CONFERENCE, INDICON
AB  - In today's digital world, human decisions are influenced by machine driven AI systems and it is essential to trust the outcome of such systems to justify the decisions whereas, ethical issues in fairness and interpretability of such systems are some of the major risks associated with machine learning models which are developed and trained with biased datasets along with sensitive attributes like race, caste, geographical location, sex etc. Biasness in AI Systems erode trust between humans & machines that learn together, and such biases may compound over time. There is hardly any AI System and machine learning models are completely unbiased or universally fair. Transparency and fairness in the predictions of such models is of a major concern across various business domains. Sensing a big void due to lack of innovative solution to address such problem, proposed solution evaluated various approaches and finally proposed an adversarial Neural Network based machine learning method which not only evaluate the fairness of the model against sensitive attributes (i.e. age, race, gender, sex and so on) to help mitigate the biases without losing much accuracy but improve transparency through interpretability of the model which clearly explain how a particular model arrive to a certain decision.
DA  - 2022///
PY  - 2022
DO  - 10.1109/INDICON56171.2022.10039793
SN  - 2325-940X
AN  - WOS:000978286100085
ER  - 

TY  - JOUR
TI  - Three-Stage Inverter-Based Peak Shaving and Volt-VAR Control in Active Distribution Networks Using Online Safe Deep Reinforcement Learning
AU  - Nguyen, HT
AU  - Choi, DH
T2  - IEEE TRANSACTIONS ON SMART GRID
AB  - This paper presents a three-stage inverter-based peak shaving and Volt-VAR control (VVC) framework in active distribution systems using the online safe deep reinforcement learning (DRL) method. The proposed framework aims to reduce the peak load, voltage violations, and real power loss by coordinating three stages with different control timescales. In the first stage, a day-ahead charging/discharging scheduling of energy storage systems (ESSs) with a 30 min resolution is performed via their inverters for peak shaving. In the second stage, the discharging power of ESSs is adjusted through measurements with a 1 min resolution to completely shave peak loads. A model-free DRL algorithm integrated with a safety module is also implemented in the second stage. Using this algorithm, the reactive powers of photovoltaic (PV) systems and ESSs are controlled by the DRL agent to reduce the voltage violation and real power loss, whereas no voltage violation occurs during the online training process. In the third stage, a proportional-integral controller with real-power compensation is integrated into inverters of PV systems and ESSs to rapidly mitigate local voltage violations with a 0.1 s resolution. The high efficiency and safety of the proposed method were validated on the IEEE 33-bus and IEEE 123-bus systems.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.1109/TSG.2022.3166192
VL  - 13
IS  - 4
SP  - 3266
EP  - 3277
SN  - 1949-3053
AN  - WOS:000814692300066
KW  - Deep learning
KW  - Reinforcement learning
KW  - Interactive computer systems
KW  - Online systems
KW  - Real - Time system
KW  - Real time systems
KW  - Controllers
KW  - Safe deep reinforcement learning
KW  - Electric inverters
KW  - Voltage control
KW  - safe deep reinforcement learning
KW  - Two term control systems
KW  - Reactive power
KW  - Value engineering
KW  - Storage systems
KW  - Inverter
KW  - Load modeling
KW  - VAR control
KW  - Volt-VAR control
KW  - local voltage control
KW  - Local voltage control.
KW  - peak shaving
KW  - Peak-shaving
KW  - Voltage violation
ER  - 

TY  - JOUR
TI  - CoTV: Cooperative Control for Traffic Light Signals and Connected Autonomous Vehicles Using Deep Reinforcement Learning
AU  - Guo, JY
AU  - Cheng, L
AU  - Wang, S
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - The target of reducing travel time only is insufficient to support the development of future smart transportation systems. To align with the United Nations Sustainable Development Goals (UN-SDG), a further reduction of fuel and emissions, improvements of traffic safety, and the ease of infrastructure deployment and maintenance should also be considered. Different from existing work focusing on optimizing the control in either traffic light signal (to improve the intersection throughput), or vehicle speed (to stabilize the traffic), this paper presents a multi-agent Deep Reinforcement Learning (DRL) system called CoTV, which Cooperatively controls both Traffic light signals and Connected Autonomous Vehicles (CAV). Therefore, our CoTV can well balance the reduction of travel time, fuel, and emissions. CoTV is also scalable to complex urban scenarios by cooperating with only one CAV that is nearest to the traffic light controller on each incoming road. This avoids costly coordination between traffic light controllers and all possible CAVs, thus leading to the stable convergence of training CoTV under the large-scale multi-agent scenario. We describe the system design of CoTV and demonstrate its effectiveness in a simulation study using SUMO under various grid maps and realistic urban scenarios with mixed-autonomy traffic.
DA  - 2023/06/05/
PY  - 2023
DO  - 10.1109/TITS.2023.3276416
SN  - 1524-9050
AN  - WOS:001006668400001
ER  - 

TY  - JOUR
TI  - Unsupervised Adversarial Network Alignment with Reinforcement Learning
AU  - Zhou, Y
AU  - Ren, JX
AU  - Jin, RM
AU  - Zhang, ZJ
AU  - Zheng, JY
AU  - Jiang, Z
AU  - Yan, D
AU  - Dou, DJ
T2  - ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA
AB  - Network alignment, which aims at learning amatching between the same entities across multiple information networks, often suffers challenges from feature inconsistency, high-dimensional features, to unstable alignment results. This article presents a novel network alignment framework, Unsupervised Adversarial learning based Network Alignment (UANA), that combines generative adversarial network (GAN) and reinforcement learning (RL) techniques to tackle the above critical challenges. First, we propose a bidirectional adversarial network distribution matching model to perform the bidirectional cross-network alignment translations between two networks, such that the distributions of real and translated networks completely overlap together. In addition, two cross-network alignment translation cycles are constructed for training the unsupervised alignment without the need of prior alignment knowledge. Second, in order to address the feature inconsistency issue, we integrate a dual adversarial autoencoder module with an adversarial binary classification model together to project two copies of the same vertices with high-dimensional inconsistent features into the same low-dimensional embedding space. This facilitates the translations of the distributions of two networks in the adversarial network distribution matching model. Finally, we develop an RL based optimization approach to solve the vertex matching problem in the discrete space of the GAN model, i.e., directly select the vertices in target networks most relevant to the vertices in source networks, without unstable similarity computation that is sensitive to discriminative features and similarity metrics. Extensive evaluation on realworld graph datasets demonstrates the outstanding capability of UANA to address the unsupervised network alignment problem, in terms of both effectiveness and scalability.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1145/3477050
VL  - 16
IS  - 3
SN  - 1556-4681
AN  - WOS:000804983600010
KW  - Reinforcement learning
KW  - reinforcement learning
KW  - Reinforcement learnings
KW  - Classification (of information)
KW  - Information services
KW  - Alignment
KW  - Generative adversarial networks
KW  - Network alignments
KW  - Adversarial networks
KW  - adversarial classification
KW  - Adversarial classifications
KW  - adversarial network distribution matching
KW  - Adversarial network distribution matching
KW  - Distribution matching
KW  - feature inconsistency
KW  - Feature inconsistency
KW  - high-dimensional features
KW  - Higher dimensional features
KW  - Network distributions
KW  - Unsupervised network
KW  - Unsupervised network alignment
ER  - 

TY  - JOUR
TI  - MetaMining: Mining in the Metaverse
AU  - Liu, KH
AU  - Chen, L
AU  - Li, LX
AU  - Ren, HW
AU  - Wang, FY
T2  - IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS
AB  - Mines are one of the important energy sources in the world. Due to mining areas are often affected by adverse weather and environmental conditions (sand, dust, extreme cold, heavy snow, etc.), the efficiency and security of mining are low. As a new, efficient, prospective mode, Metaverse has been studied and successfully applied in various industries. However, there is still no research about its usage in mines. In this article, we apply Metaverse to mining and propose MetaMining. We present its definition and analyze the functions it could perform. Furthermore, we propose its development phases and architecture. Specifically, MetaMining is a mode, which aims to achieve high-efficiency, high-security mining in the physical world through the interaction between the physical world and the virtual world. Its development phases involve three steps: 1) digital twins; 2) digital natives; and 3) surreality. Its architecture consists of three components: 1) human world; 2) virtual mining system; and 3) physical mining system. In addition, we analyze key technologies and possible challenges in the construction of MetaMining.
DA  - 2023/06//undefined
PY  - 2023
DO  - 10.1109/TSMC.2022.3233588
VL  - 53
IS  - 6
SP  - 3858
EP  - 3867
SN  - 2168-2216
AN  - WOS:000920490000001
ER  - 

TY  - JOUR
TI  - Disclosure control of machine learning models from trusted research environments (TRE): New challenges and opportunities
AU  - Mansouri-Benssassi, E
AU  - Rogers, S
AU  - Reel, S
AU  - Malone, M
AU  - Smith, J
AU  - Ritchie, F
AU  - Jefferson, E
T2  - HELIYON
AB  - Introduction: Artificial intelligence (AI) applications in healthcare and medicine have increased in recent years. To enable access to personal data, Trusted Research Environments (TREs) (other-wise known as Safe Havens) provide safe and secure environments in which researchers can access sensitive personal data and develop AI (in particular machine learning (ML)) models. However, currently few TREs support the training of ML models in part due to a gap in the practical decision-making guidance for TREs in handling model disclosure. Specifically, the training of ML models creates a need to disclose new types of outputs from TREs. Although TREs have clear policies for the disclosure of statistical outputs, the extent to which trained models can leak personal training data once released is not well understood. Background: We review, for a general audience, different types of ML models and their applica-bility within healthcare. We explain the outputs from training a ML model and how trained ML models can be vulnerable to external attacks to discover personal data encoded within the model. Risks: We present the challenges for disclosure control of trained ML models in the context of training and exporting models from TREs. We provide insights and analyse methods that could be introduced within TREs to mitigate the risk of privacy breaches when disclosing trained models. Discussion: Although specific guidelines and policies exist for statistical disclosure controls in TREs, they do not satisfactorily address these new types of output requests; i.e., trained ML models. There is significant potential for new interdisciplinary research opportunities in devel-oping and adapting policies and tools for safely disclosing ML outputs from TREs.
DA  - 2023/04//undefined
PY  - 2023
DO  - 10.1016/j.heliyon.2023.e15143
VL  - 9
IS  - 4
SN  - 2405-8440
AN  - WOS:000999090800001
KW  - Machine learning
KW  - AI
KW  - Data privacy
KW  - Disclosure control
KW  - Safe haven
KW  - Trusted research environment
ER  - 

TY  - JOUR
TI  - Shortest Path Problems with a Crash Risk Objective
AU  - Hu, Q
AU  - Mehdizadeh, A
AU  - Vinel, A
AU  - Cai, M
AU  - Rigdon, SE
AU  - Zhang, WB
AU  - Megahed, FM
T2  - TRANSPORTATION RESEARCH RECORD
AB  - With more and more data related to driving, traffic, and road conditions becoming available, there has been renewed interest in predictive modeling of traffic incident risk and corresponding risk factors. New machine learning approaches in particular have recently been proposed, with the goal of forecasting the occurrence of either actual incidents or their surrogates, or estimating driving risk over specific time intervals, road segments, or both. At the same time, as evidenced by our review, prescriptive modeling literature (e.g., routing or truck scheduling) has yet to capitalize on these advancements. Indeed, research into risk-aware modeling for driving is almost entirely focused on hazardous materials transportation (with a very distinct risk profile) and frequently assumes a fixed incident risk per mile driven. We propose a framework for developing data-driven prescriptive optimization models with risk criteria for traditional trucking applications. This approach is combined with a recently developed machine learning model to predict driving risk over a medium-term time horizon (the next 20 min to an hour of driving), resulting in a biobjective shortest path problem. We further propose a solution approach based on the k-shortest path algorithm and illustrate how this can be employed.
DA  - 2023/09/16/
PY  - 2023
DO  - 10.1177/03611981231195053
SN  - 0361-1981
AN  - WOS:001067032100001
KW  - Machine learning
KW  - data and data science
KW  - Machine-learning
KW  - safety
KW  - Risk perception
KW  - Roads and streets
KW  - Risk assessment
KW  - Driving conditions
KW  - Optimisations
KW  - optimization
KW  - Safety performance
KW  - Graph theory
KW  - Safety analysis
KW  - Data and data science
KW  - Machine learning (artificial intelligence)
KW  - Planning and analyse
KW  - Trucks
KW  - Crash risk
KW  - machine learning (artificial intelligence)
KW  - safety performance and analysis
KW  - Materials handling
KW  - planning and analysis
KW  - Shortest path problem
ER  - 

TY  - CONF
TI  - Identifying Insuficient Data Coverage for Ordinal Continuous-Valued Atributes
AU  - Asudeh, A
AU  - Shahbazi, N
AU  - Jin, ZJ
AU  - Jagadish, HV
AU  - ASSOC COMP MACHINERY
T2  - SIGMOD '21: PROCEEDINGS OF THE 2021 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA
AB  - Appropriate training data is a requirement for building good machine-learned models. In this paper, we study the notion of coverage for ordinal and continuous-valued attributes, by formalizing the intuition that the learned model can accurately predict only at data points for which there are "enough" similar data points in the training data set.
We develop an efficient algorithm to identify uncovered regions in low-dimensional attribute feature space, by making a connection to Voronoi diagrams. We also develop a randomized approximation algorithm for use in high-dimensional attribute space. We evaluate our algorithms through extensive experiments on real datasets.
DA  - 2021///
PY  - 2021
DO  - 10.1145/3448016.3457315
SP  - 129
EP  - 141
SN  - 0730-8078
AN  - WOS:000747673800016
KW  - trustworthy AI
KW  - Database systems
KW  - Approximation algorithms
KW  - Information management
KW  - fairness in machine learning
KW  - High-dimensional
KW  - responsible data science
KW  - Training data sets
KW  - Real data sets
KW  - bias detection
KW  - Continuous-valued attribute
KW  - Data coverage
KW  - Low dimensional
KW  - Randomized approximation
KW  - Voronoi diagrams
ER  - 

TY  - JOUR
TI  - From the Editors of the Special Issue on Current Applications and Innovations of Artificial Intelligence and Machine Learning in Aerospace
AU  - Mohammed, S
AU  - Chang, RS
AU  - Ramos, C
AU  - Kim, TH
T2  - IEEE AEROSPACE AND ELECTRONIC SYSTEMS MAGAZINE
AB  - The articles in this special section focus on current applications and innovations of artificial intelligence and machine learning in aerospace. Artificial intelligence (AI) and machine learning (ML) play an increasingly important role in aerospace applications and serve various military, commercial aviation, and space exploration sectors to ensure safety, dependability, and customer loyalty. AI/ML contributes to provide various automated systems used in aviation, such as fuel efficiency, smart maintenance, smart air traffic management, pilot training, passenger identification, threat identification, remote sensing, and fully autonomous aerial vehicles among other systems. AI/ML is concerned with algorithms and techniques that allow systems to "learn" and "reason" based on algorithms and techniques employing computational and statistical methods. It can significantly enhance speed, efficiency, workload, and safety to enable the integrating of more complex technologies, such as autonomous visionbased navigation and data ecosystems. Recently advanced data analytics provided the aviation industry a way to respond to COVID and advise airlines on when to swap aircraft for bigger or smaller planes and how the global health restrictions may change flight schedules. While there are many other innovative use cases of AI/ML in aviation and aerospace, the overarching conclusion is that the implementation must be driven by safety.
DA  - 2022/06/01/
PY  - 2022
DO  - 10.1109/MAES.2022.3170740
VL  - 37
IS  - 6
SP  - 4
EP  - 5
SN  - 0885-8985
AN  - WOS:000808063500008
ER  - 

TY  - CONF
TI  - Find me if you can: aligning users in different social networks
AU  - Kasbekar, P
AU  - Potika, K
AU  - Pollett, C
AU  - IEEE
T2  - 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2020)
AB  - Online Social Networks allow users to share experiences with friends and relatives, make announcements, find news and jobs, and more. Several have user bases that number in the hundred of millions and even billions. Very often many users belong to multiple social networks at the same time under possibly different user names. Identifying a user from one social network on another social network gives information about a user's behavior on each platform, which in turn can help companies perform graph mining tasks, such as community detection and link prediction. The process of identifying or aligning users in multiple networks is called network alignment. These similar (or same) users on different networks are called anchor nodes and the edges between them are called anchor links. The network alignment problem aims at finding these anchor links. In this work we propose two supervised algorithms and one unsupervised algorithm using thresholds. All these algorithms use local structural graph features of users and some of them use additional information about the users. We present the performance of our models in various settings using experiments based on Foursquare-Twitter and Facebook-Twitter data [1]. We show that our approaches perform well even when we use the neighborhood of the users only, and the accuracy improves even more given additional information about a user, such as the username and the profile image. We further show that our best approaches perform better at the HR@1 task than unsupervised and semi-supervised factoid embedding approaches considered earlier for these datasets.
DA  - 2020///
PY  - 2020
DO  - 10.1109/BigDataService49289.2020.00015
SP  - 46
EP  - 53
SN  - 978-1-7281-7022-0
AN  - WOS:000621584100007
KW  - Data mining
KW  - User experience
KW  - Online Social Networks
KW  - Supervised learning
KW  - Behavioral research
KW  - Big Data
KW  - Information use
KW  - Big data
KW  - Social networking (online)
KW  - Image enhancement
KW  - Link prediction
KW  - Unsupervised learning
KW  - Alignment
KW  - Embeddings
KW  - Network alignments
KW  - Structural graph
KW  - Multiple networks
KW  - Supervised algorithm
KW  - Anchor links
KW  - Community detection
KW  - Graph algorithms
KW  - Graph structure
KW  - Network Alignment
KW  - On-line social networks
KW  - Unsupervised algorithms
ER  - 

TY  - CONF
TI  - Aircraft FDI and human factors analysis of a take-off maneuvre using SIVOR flight simulator
AU  - Kraemer, AD
AU  - Villani, E
AU  - Arjoni, DH
T2  - IFAC PAPERSONLINE
AB  - This paper presents a human factors analysis in aviation within the context of failure detection and identification (FDI) using statistical data analysis and clustering. We used data from experiments in a motion-based flight simulator (SIVOR) with 4 experienced pilots performing a take-off maneuvre under three conditions: normal, under engine failure and under flap failure. We propose two metrics based on statistical data analysis to evaluate and compare human behavior during flight. We also use k-means clustering in order to classify flights according to maneuvre conditions and misclassified flights are further analyzed according to which pilot has performed it. Results show that for the statistical data analysis the behavior of one specific pilot has higher dissimilarity with all other pilots. Moreover, for the k-means clustering, most of the misclassified flights were performed by this same pilot. (C) 2019, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.
DA  - 2019///
PY  - 2019
DO  - 10.1016/j.ifacol.2019.01.063
VL  - 51
SP  - 184
EP  - 189
SN  - 2405-8963
AN  - WOS:000458143400029
KW  - Behavioral research
KW  - Human behaviors
KW  - Human engineering
KW  - Factor analysis
KW  - Statistics
KW  - cluster analysis
KW  - Information analysis
KW  - Data reduction
KW  - Unsupervised machine learning
KW  - Flight simulators
KW  - unsupervised machine learning
KW  - human factors
KW  - data analysis
KW  - Cluster analysis
KW  - K-means clustering
KW  - Failure detection
KW  - Engine failures
KW  - Factors analysis
KW  - Flight safety
KW  - Statistical data analysis
KW  - Takeoff
ER  - 

TY  - JOUR
TI  - Application of Bayesian network and artificial intelligence to reduce accident/incident rates in oil & gas companies
AU  - Sattari, F
AU  - Macciotta, R
AU  - Kurian, D
AU  - Lefsrud, L
T2  - SAFETY SCIENCE
AB  - Process safety management (PSM) is a framework that demonstrates a company's commitment to process safety, a better understanding of hazards and risks, a comprehensive assessment and management of risks, and enhanced learning from experience to improve overall safety and operational performance. Companies often use an incident data reporting system to execute PSM. While companies keep incident data in thousands of reports, rarely do they glean full value in learning from these to prevent and reduce future incidents. To overcome this challenge, this research applied machine learning and keyword analysis to label and classify 8199 incident reports from an oil and gas company into nine groups identified in the latest version of PSM guidelines published by the Center for Chemical Process Safety (CCPS). To converge on an optimal solution, two different Bayesian network techniques (Tabu and hill climbing) were applied. Both methods resulted in the same map, showing that the Total Number of Incidents has the maximum dependency (50%) on Asset Integrity & Reliability; this means focusing resources on this aspect could reduce the total number of incidents by half. Cross correlation analysis (CCA) was also applied, which validated and confirmed this result. This analysis identifies which measures enhance the company's safety management strategy to reduce these latent causes, but also supports critical thinking, enhanced communication, and learning culture to improve organizational safety.
DA  - 2021/01//undefined
PY  - 2021
DO  - 10.1016/j.ssci.2020.104981
VL  - 133
SN  - 0925-7535
AN  - WOS:000590202600003
KW  - machine learning
KW  - artificial intelligence
KW  - Artificial intelligence
KW  - Machine learning
KW  - Bayesian network
KW  - reliability
KW  - Gas industry
KW  - article
KW  - Bayesian networks
KW  - Risk assessment
KW  - correlation analysis
KW  - practice guideline
KW  - Petroleum industry
KW  - Applied machine learning
KW  - cross correlation
KW  - Comprehensive assessment
KW  - accident
KW  - Process safety management
KW  - Chemical analysis
KW  - Operational performance
KW  - critical thinking
KW  - Incident data
KW  - Keyword analysis
KW  - Application of Bayesian networks
KW  - Center for chemical process safeties
KW  - chemical reaction
KW  - climbing
KW  - Cross-correlation analysis
KW  - incident report
KW  - Latent causes
KW  - Organizational safety
KW  - Public utilities
ER  - 

TY  - JOUR
TI  - Centroid Estimation With Guaranteed Efficiency: A General Framework for Weakly Supervised Learning
AU  - Gong, C
AU  - Yang, J
AU  - You, JN
AU  - Sugiyama, M
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - In this paper, we propose a general framework termed centroid estimation with guaranteed efficiency (CEGE) for weakly supervised learning (WSL) with incomplete, inexact, and inaccurate supervision. The core of our framework is to devise an unbiased and statistically efficient risk estimator that is applicable to various weak supervision. Specifically, by decomposing the loss function (e.g., the squared loss and hinge loss) into a label-independent term and a label-dependent term, we discover that only the latter is influenced by the weak supervision and is related to the centroid of the entire dataset. Therefore, by constructing two auxiliary pseudo-labeled datasets with synthesized labels, we derive unbiased estimates of centroid based on the two auxiliary datasets, respectively. These two estimates are further linearly combined with a properly decided coefficient which makes the final combined estimate not only unbiased but also statistically efficient. This is better than some existing methods that only care about the unbiasedness of estimation but ignore the statistical efficiency. The good statistical efficiency of the derived estimator is guaranteed as we theoretically prove that it acquires the minimum variance when estimating the centroid. As a result, intensive experimental results on a large number of benchmark datasets demonstrate that our CEGE generally obtains better performance than the existing approaches related to typical WSL problems including semi-supervised learning, positive-unlabeled learning, multiple instance learning, and label noise learning.
DA  - 2022/06/01/
PY  - 2022
DO  - 10.1109/TPAMI.2020.3044997
VL  - 44
IS  - 6
SP  - 2841
EP  - 2855
SN  - 0162-8828
AN  - WOS:000803117500007
ER  - 

TY  - JOUR
TI  - Artificial intelligence in the water domain: Opportunities for responsible use
AU  - Doorn, N
T2  - SCIENCE OF THE TOTAL ENVIRONMENT
AB  - Recent years have seen a rise of techniques based on artificial intelligence (AI). With that have also come initiatives for guidance on how to develop "responsible AI" aligned with human and ethical values. Compared to sectors like energy, healthcare, or transportation, the use of AI-based techniques in the water domain is relatively modest. This paper presents a review of current AI applications in the water domain and develops some tentative insights as to what "responsible AI" could mean there. Building on the reviewed literature, four categories of application are identified: modeling, prediction and forecasting, decision support and operational management, and optimization. We also identify three insights pertaining to the water sector in particular: the use of AI techniques in general, and many-objective optimization in particular, that allow for a pluralism of values and changing values; the use of theory-guided data science, which can avoid some of the pitfalls of strictly data-driven models; and the ability to build on experiences with participatory decision-making in the water sector. These insights suggest that the development and application of responsible AI techniques for the water sector should not be left to data scientists alone, but requires concerted effort by water professionals and data scientists working together, complemented with expertise from the social sciences and humanities. (C) 2020 The Author(s). Published by Elsevier B.V.
DA  - 2021/02/10/
PY  - 2021
DO  - 10.1016/j.scitotenv.2020.142561
VL  - 755
SN  - 0048-9697
AN  - WOS:000600537400004
ER  - 

TY  - JOUR
TI  - Toward Responsible AI: An Overview of Federated Learning for User-centered Privacy-preserving Computing
AU  - Yang, Q
T2  - ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS
AB  - With the rapid advances of Artificial Intelligence (AI) technologies and applications, an increasing concern is on the development and application of responsible AI technologies. Building AI technologies or machine-learning models often requires massive amounts of data, which may include sensitive, user private information to be collected from different sites or countries. Privacy, security, and data governance constraints rule out a brute force process in the acquisition and integration of these data. It is thus a serious challenge to protect user privacy while achieving high-performance models. This article reviews recent progress of federated learning in addressing this challenge in the context of privacy-preserving computing. Federated learning allows global AI models to be trained and used among multiple decentralized data sources with high security and privacy guarantees, as well as sound incentive mechanisms. This article presents the background, motivations, definitions, architectures, and applications of federated learning as a new paradigm for building privacy-preserving, responsible AI ecosystems.
DA  - 2021/08//undefined
PY  - 2021
DO  - 10.1145/3485875
VL  - 11
IS  - 3-4
SN  - 2160-6455
AN  - WOS:000754674100016
KW  - machine learning
KW  - Machine learning
KW  - Blockchain
KW  - Learning systems
KW  - blockchain
KW  - responsible AI
KW  - Machine-learning
KW  - Privacy preserving
KW  - Artificial intelligence technologies
KW  - Federated learning
KW  - Engineering education
KW  - Responsible artificial intelligence
KW  - Privacy-preserving techniques
KW  - Block-chain
KW  - Decentralised
KW  - User privacy
KW  - Sensitive data
KW  - data security
KW  - decentralized AI
KW  - Decentralized artificial intelligence
KW  - Historic preservation
KW  - privacy-preserving computing
KW  - Privacy-preserving computing
KW  - user privacy
ER  - 

TY  - JOUR
TI  - Responsible AI for Digital Health: a Synthesis and a Research Agenda
AU  - Trocin, C
AU  - Mikalef, P
AU  - Papamitsiou, Z
AU  - Conboy, K
T2  - INFORMATION SYSTEMS FRONTIERS
AB  - Responsible AI is concerned with the design, implementation and use of ethical, transparent, and accountable AI technology in order to reduce biases, promote fairness, equality, and to help facilitate interpretability and explainability of outcomes, which are particularly pertinent in a healthcare context. However, the extant literature on health AI reveals significant issues regarding each of the areas of responsible AI, posing moral and ethical consequences. This is particularly concerning in a health context where lives are at stake and where there are significant sensitivities that are not as pertinent in other domains outside of health. This calls for a comprehensive analysis of health AI using responsible AI concepts as a structural lens. A systematic literature review supported our data collection and sampling procedure, the corresponding analysis, and extraction of research themes helped us provide an evidence-based foundation. We contribute with a systematic description and explanation of the intellectual structure of Responsible AI in digital health and develop an agenda for future research.
DA  - 2021/06/26/
PY  - 2021
DO  - 10.1007/s10796-021-10146-4
SN  - 1387-3326
AN  - WOS:000666843900001
ER  - 

TY  - JOUR
TI  - Adversarial Evaluation of Autonomous Vehicles in Lane-Change Scenarios
AU  - Chen, BM
AU  - Chen, X
AU  - Wu, Q
AU  - Li, L
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Autonomous vehicles must be comprehensively evaluated before deployed in cities and highways. However, most existing evaluation approaches for autonomous vehicles are static and lack adaptability, so they are usually inefficient in generating challenging scenarios for tested vehicles. In this paper, we propose an adaptive evaluation framework to efficiently evaluate autonomous vehicles in adversarial environments generated by deep reinforcement learning. Considering the multimodal nature of dangerous scenarios, we use ensemble models to represent different local optimums for diversity. We then utilize a nonparametric Bayesian method to cluster the adversarial policies. The proposed method is validated in a typical lane-change scenario that involves frequent interactions between the ego vehicle and the surrounding vehicles. Results show that the adversarial scenarios generated by our method significantly degrade the performance of the tested vehicles. We also illustrate different patterns of generated adversarial environments, which can be used to infer the weaknesses of the tested vehicles.
DA  - 2022/08//undefined
PY  - 2022
DO  - 10.1109/TITS.2021.3091477
VL  - 23
IS  - 8
SP  - 10333
EP  - 10342
SN  - 1524-9050
AN  - WOS:000732424900001
ER  - 

TY  - CONF
TI  - Risk-averse Distributional Reinforcement Learning: A CVaR Optimization Approach
AU  - Stanko, S
AU  - Macek, K
T2  - IJCCI: PROCEEDINGS OF THE 11TH INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL INTELLIGENCE
A2  - Merelo, JJ
A2  - Garibaldi, J
A2  - Barranco, AL
A2  - Madani, K
A2  - Warwick, K
AB  - Conditional Value-at-Risk (CVaR) is a well-known measure of risk that has been directly equated to robustness, an important component of Artificial Intelligence (AI) safety. In this paper we focus on optimizing CVaR in the context of Reinforcement Learning (RL), as opposed to the usual risk-neutral expectation. As a first original contribution, we improve the CVaR Value Iteration algorithm (Chow et al., 2015) in a way that reduces computational complexity of the original algorithm from polynomial to linear time. Secondly, we propose a sampling version of CVaR Value Iteration we call CVaR Q-learning. We also derive a distributional policy improvement algorithm, and later use it as a heuristic for extracting the optimal policy from the converged CVaR Q-learning algorithm. Finally, to show the scalability of our method, we propose an approximate Q-learning algorithm by reformulating the CVaR Temporal Difference update rule as a loss function which we later use in a deep learning context. All proposed methods are experimentally analyzed, including the Deep CVaR Q-learning agent which learns how to avoid risk from raw pixels.
DA  - 2019///
PY  - 2019
DO  - 10.5220/0008175604120423
SP  - 412
EP  - 423
SN  - 978-989-758-384-1
AN  - WOS:000571773900044
KW  - Deep learning
KW  - Reinforcement learning
KW  - Machine learning
KW  - Learning algorithms
KW  - Risk assessment
KW  - Safety engineering
KW  - Risk
KW  - Optimization
KW  - Iterative methods
KW  - Value iteration
KW  - Q-learning algorithms
KW  - AI safety
KW  - Conditional Value-at-Risk
KW  - Value engineering
KW  - Q-learning
KW  - Deep Q-learning
KW  - Optimization approach
KW  - Temporal differences
KW  - Risks
KW  - Distributional reinforcement learning
KW  - Value iteration algorithm
KW  - Conditional value-at-risk
KW  - CVaR
ER  - 

TY  - JOUR
TI  - Learning-Based Stochastic Driving Model for Autonomous Vehicle Testing
AU  - Liu, L
AU  - Feng, S
AU  - Feng, YH
AU  - Zhu, XC
AU  - Liu, HX
T2  - TRANSPORTATION RESEARCH RECORD
AB  - In the simulation-based testing and evaluation of autonomous vehicles (AVs), how background vehicles (BVs) drive directly influences the AV's driving behavior and further affects the test results. Most existing simulation platforms use either predetermined trajectories or deterministic driving models to model BV behaviors. However, predetermined BV trajectories cannot react to AV maneuvers, and deterministic models are different from real human drivers because of the lack of stochastic components and errors. Both methods lead to unrealistic traffic scenarios. This paper presents a learning-based stochastic driving model that meets the unique needs of AV testing (i.e., interactive and human-like stochasticity). The model is built based on the long short-term memory architecture. By incorporating the concept of quantile regression into the loss function of the model, the stochastic behaviors are reproduced without prior assumption of human drivers. The model is trained with the large-scale naturalistic driving data (NDD) from the Safety Pilot Model Deployment project and compared with a stochastic intelligent driving model (IDM). Analysis of individual trajectories shows that the proposed model can reproduce more similar trajectories of human drivers than IDM. To validate the ability of the proposed model in generating a naturalistic driving environment, traffic simulation experiments are implemented. The results show that traffic flow parameters such as speed, range, and time headway distribution match closely with the NDD, which is of significant importance for AV testing and evaluation.
DA  - 2022/01//undefined
PY  - 2022
DO  - 10.1177/03611981211035756
VL  - 2676
IS  - 1
SP  - 54
EP  - 64
SN  - 0361-1981
AN  - WOS:000685634400001
ER  - 

TY  - JOUR
TI  - Exploring Factors Associated With Crossing Assertiveness of Pedestrians at Unsignalized Intersections
AU  - Li, ZH
AU  - Kong, XQ
AU  - Zhang, YL
T2  - TRANSPORTATION RESEARCH RECORD
AB  - A pedestrian's assertiveness when crossing an intersection measures his or her willingness to cross under given conditions, and this level of assertiveness affects pedestrian crossing behavior and safety. Crossing assertiveness at an unsignalized intersection is a complex psychological decision affected by many features, such as the speeds and trajectories of oncoming vehicles, eye contact, facial expression, and hand gesture communications between pedestrians and drivers. To provide a comprehensive understanding of crossing assertiveness of pedestrians at unsignalized intersections, this study applied a pattern recognition method-association rules mining to uncover the patterns for different levels of crossing assertiveness, including assertive, neutral, and passive, using a unique naturalistic driving dataset. An elaborated feature engineering with the decision tree, gradient-boosting decision tree, and XGBoost with SHAP were utilized to select a distinct feature set as input of the Apriori algorithm to recognize the patterns. The results revealed that the driver's facial expression, the driver's initiative and passive yield, and the presence of the "yield-to-pedestrian" traffic sign were highly associated with assertive crossing. Features such as the absence of pedestrians on the crosswalk, the presence of incoming speeding vehicles, and the absence of traffic control signs were strongly related to passive crossing. Meanwhile, the number and position of pedestrians at the crosswalk or near the curbside, the communication between pedestrians and drivers, and who actively seeks eye contact were the three major features to convert crossing from neutral to assertive or passive. The results provided a unique and meaningful understanding of pedestrian crossing assertiveness at unsignalized intersections.
DA  - 2023/06//undefined
PY  - 2023
DO  - 10.1177/03611981221145140
VL  - 2677
IS  - 6
SP  - 182
EP  - 198
SN  - 0361-1981
AN  - WOS:000925917900001
KW  - Decision trees
KW  - Machine learning
KW  - Pattern recognition
KW  - artificial intelligence and advanced computing applications
KW  - data and data science
KW  - Machine-learning
KW  - safety
KW  - Crosswalks
KW  - Pedestrian safety
KW  - Traffic signals
KW  - Traffic signs
KW  - Condition
KW  - Unsignalized intersections
KW  - Artificial intelligence and advanced computing application
KW  - Computing applications
KW  - Facial Expressions
KW  - Data and data science
KW  - Machine learning (artificial intelligence)
KW  - pattern recognition
KW  - machine learning (artificial intelligence)
KW  - Eye-contact
KW  - pedestrian and bicyclist safety
KW  - Pedestrian and bicyclist safety
ER  - 

TY  - JOUR
TI  - The Ethics of AI for Information Professionals: Eight Scenarios
AU  - Cox, A
T2  - JOURNAL OF THE AUSTRALIAN LIBRARY AND INFORMATION ASSOCIATION
AB  - Artificial Intelligence (AI) is central to transformative changes happening in many industries, perhaps potentially to a fourth industrial revolution, but it has also raised a storm of ethical concerns. Information professionals need to navigate these ethical issues effectively because they are likely to use AI in delivering services as well as contributing to the process of adoption of AI more widely in their organisations. Professional ethical codes are too high level to offer precise or complete guidance. In this context, the purpose of this paper is to review the relevant literature and describe eight ethics scenarios of AI which have been developed specifically for information professionals to understand the issues in a concrete form. The paper considers how AI might be defined and presents some of the applications relevant to the information profession. It then summarises the key ethical issues raised by AI in general both those inherent to the technology and those arising from the nature of the AI industry. It considers existing studies that have discussed aspects of the ethical issues specifically for information professionals. It then describes a set of eight ethics scenarios that have been developed and shared in an open form to promote their reuse.
DA  - 2022/07/03/
PY  - 2022
DO  - 10.1080/24750158.2022.2084885
VL  - 71
IS  - 3
SP  - 201
EP  - 214
SN  - 2475-0158
AN  - WOS:000811119900001
ER  - 

TY  - JOUR
TI  - Analysis of Motorcycle Accident Injury Severity and Performance Comparison of Machine Learning Algorithms
AU  - Santos, K
AU  - Firme, B
AU  - Dias, JP
AU  - Amado, C
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Motorcycle road traffic accidents represent a big concern, as vulnerable road users account for more than half of all road deaths worldwide. The estimation of the influential factors associated with the increase of injury severity of motorcyclists involved in a road accident is of extreme importance as it provides a necessary basis for the development of an appropriate and targeted sustainable prevention plan for improving road safety. This study adopted the decision tree, ordered logistic regression (LR), random forest (RF), gradient boosting, extreme gradient boosting, k-nearest neighbor, and support vector machine methods to predict the injury severity outcome of motorcycle accidents. All the developed models were compared with six different performance metrics. A 10-year (2010-2019) dataset with motorcycle accidents that occurred in Portugal was used for analysis. As usual in traffic accidents datasets, this dataset is class unbalanced which was dealt with by under-sampling. The developed models made it possible to determine the factors associated with the increase of injury severity of motorcyclists involved in road accidents. The interpretation of each factor is based on the Shapley additive explanations values. The RF and LR models (developed with the balanced dataset) outperformed the other models. Risk factors associated with alcohol consumption, road type, road conditions, location, motorcycle age, rider's gender, and when the accident occurs were estimated. This study provides a suitable framework analysis to build a proper predictive model, allowing researchers and practitioners to evaluate more accurately the risk factors of motorcycle injury severity.
DA  - 2023/06/05/
PY  - 2023
DO  - 10.1177/03611981231172507
SN  - 0361-1981
AN  - WOS:001008334000001
KW  - Decision trees
KW  - Learning systems
KW  - safety evaluation
KW  - artificial intelligence and advanced computing applications
KW  - data and data science
KW  - Learning algorithms
KW  - Machine-learning
KW  - safety
KW  - Risk perception
KW  - Road vehicles
KW  - Roads and streets
KW  - Motor transportation
KW  - Risk assessment
KW  - Highway accidents
KW  - Nearest neighbor search
KW  - Random forests
KW  - Artificial intelligence and advanced computing application
KW  - Computing applications
KW  - Support vector regression
KW  - Logistic regression
KW  - Health risks
KW  - Injury severity
KW  - Data and data science
KW  - Machine learning (artificial intelligence)
KW  - Safety evaluations
KW  - machine learning (artificial intelligence)
KW  - Motorcycles
KW  - Motorcycle and moped
KW  - motorcycles and mopeds
KW  - Motorcycle accident
ER  - 

TY  - JOUR
TI  - Prediction of the Future State of Pedestrians While Jaywalking Under Non-Lane-Based Heterogeneous Traffic Conditions
AU  - Muduli, K
AU  - Ghosh, I
T2  - TRANSPORTATION RESEARCH RECORD
AB  - This study proposes a novel framework to predict jaywalkers' future state in non-lane-based heterogeneous traffic conditions by combining the effects of the surrounding dynamics with jaywalkers' poses. Different variables, such as the pedestrian pose, walking speed, location in the road environment, count and direction of approaching traffic, speed and type of closest approaching vehicle, and so forth, are used as input variables. The dataset for this study consists of 47,588 samples gathered by analyzing 1753 jaywalkers under non-lane-based heterogeneous traffic situations. Keypoint detection on the pedestrian body is made using MediaPipe. YOLOv4 and DeepSORT are used to detect and track road users to get trajectory data. Training and testing datasets are prepared for different prediction horizons to test the proposed models' applicability for roads of varying design speeds. Four machine learning models based on ensemble techniques, namely random forest (RF), adaptive boosting (AdaBoost), gradient boosting, and extreme gradient boosting, are trained and tested for different prediction horizons from 0.5 to 4 s. Up to the prediction horizon of 1 s, all models performed equally well with Area under the ROC curve (AUC) values above 0.95. At higher prediction horizons, the RF is found to outperform the other models. All models, except AdaBoost, maintained an AUC value of greater than 0.9 when predicting future states up to a maximum of 2.5 s. The proposed model performs well for both short-term and long-term predictions by combining the effect of surrounding dynamics with pedestrian stance and speed. The outcomes can be utilized to assist infrastructure-to-vehicle connectivity in empowering vehicles to navigate through jaywalkers safely, enhancing pedestrian safety.
DA  - 2023/04/27/
PY  - 2023
DO  - 10.1177/03611981231161619
SN  - 0361-1981
AN  - WOS:000977227700001
KW  - Machine learning
KW  - Vehicles
KW  - artificial intelligence and advanced computing applications
KW  - data and data science
KW  - pedestrians
KW  - Machine-learning
KW  - safety
KW  - Roads and streets
KW  - Forecasting
KW  - Pedestrian safety
KW  - Adaptive boosting
KW  - Pedestrian
KW  - Artificial intelligence and advanced computing application
KW  - Computing applications
KW  - Forestry
KW  - human factors
KW  - Data and data science
KW  - Machine learning (artificial intelligence)
KW  - Traffic conditions
KW  - machine learning (artificial intelligence)
KW  - bicycles
KW  - Heterogeneous traffic
KW  - Prediction horizon
ER  - 

TY  - JOUR
TI  - AI Ethics-A Bird's Eye View
AU  - Christoforaki, M
AU  - Beyan, O
T2  - APPLIED SCIENCES-BASEL
AB  - The explosion of data-driven applications using Artificial Intelligence (AI) in recent years has given rise to a variety of ethical issues regarding data collection, annotation, and processing using mostly opaque algorithms, as well as the interpretation and employment of the results of the AI pipeline. The ubiquity of AI applications negatively impacts a variety of sensitive areas, ranging from discrimination against vulnerable populations to privacy invasion and the environmental cost that these algorithms entail, and puts into focus on the ever present domain of AI ethics. In this review article we present a bird's eye view approach of the AI ethics landscape, starting from a historical point of view, examining the moral issues that were introduced by big datasets and the application of non-symbolic AI algorithms, the normative approaches (principles and guidelines) to these issues and the ensuing criticism, as well as the actualization of these principles within the proposed frameworks. Subsequently, we focus on the concept of responsibility, both as personal responsibility of the AI practitioners and sustainability, meaning the promotion of beneficence for both the society and the domain, and the role of professional certification and education in averting unethical choices. Finally, we conclude with indicating the multidisciplinary nature of AI ethics and suggesting future challenges.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.3390/app12094130
VL  - 12
IS  - 9
SN  - 2076-3417
AN  - WOS:000794686500001
ER  - 

TY  - JOUR
TI  - An Assessment of the Barriers Impacting Responsible Artificial Intelligence
AU  - Merhi, MI
T2  - INFORMATION SYSTEMS FRONTIERS
AB  - Responsible Artificial Intelligence (AI) has recently gained a lot of attention, especially in the last few years. Scholars have conducted systematic literature reviews to gain more knowledge about responsible AI. However, no study has collected and evaluated the most significant barriers to responsible AI. We filled this gap in the literature by identifying eleven barriers and categorized them, using the Technology-Organization-Environment framework, into three categories. We collected data from seven experts and used the analytical hierarchy process to evaluate the importance of the barriers. The results indicated that technology, as a category, is the most important. The findings also recommended that data quality is the most vital among all eleven barriers. We offered eleven propositions as a theoretical contribution for future researchers in terms of conceptual development. We discussed the implications of the findings for research and practice.
DA  - 2023/06//undefined
PY  - 2023
DO  - 10.1007/s10796-022-10276-3
VL  - 25
IS  - 3
SP  - 1147
EP  - 1160
SN  - 1387-3326
AN  - WOS:000784822400003
ER  - 

TY  - CONF
TI  - Representation in AI Evaluations
AU  - Bergman, AS
AU  - Hendricks, LA
AU  - Rauh, M
AU  - Wu, BX
AU  - Agnew, W
AU  - Kunesch, M
AU  - Duan, I
AU  - Gabriel, I
AU  - Isaac, W
AU  - ASSOC COMPUTING MACHINERY
T2  - PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023
AB  - Calls for representation in artificial intelligence (AI) and machine learning (ML) are widespread, with "representation" or "representativeness" generally understood to be both an instrumentally and intrinsically beneficial quality of an AI system, and central to fairness concerns. But what does it mean for an AI system to be "representative"? Each element of the AI lifecycle is geared towards its own goals and effect on the system, therefore requiring its own analyses with regard to what kind of representation is best. In this work we untangle the benefits of representation in AI evaluations to develop a framework to guide an AI practitioner or auditor towards the creation of representative ML evaluations. Representation, however, is not a panacea. We further lay out the limitations and tensions of instrumentally representative datasets, such as the necessity of data existence and access, surveillance vs expectations of privacy, implications for foundation models and power. This work sets the stage for a research agenda on representation in AI, which extends beyond instrumentally valuable representation in evaluations towards refocusing on, and empowering, impacted communities.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3593013.3594019
SP  - 519
EP  - 533
SN  - 978-1-4503-7252-7
AN  - WOS:001062819300049
KW  - Machine learning
KW  - responsible AI
KW  - Machine-learning
KW  - Life cycle
KW  - Artificial intelligence learning
KW  - Responsible artificial intelligence
KW  - Artificial intelligence systems
KW  - Dataset
KW  - datasets
KW  - Fairness concerns
KW  - Foundation models
KW  - Lay-out
KW  - Learning evaluations
KW  - machine learning evaluation
KW  - Machine learning evaluation
ER  - 

TY  - JOUR
TI  - In-Depth Understanding of Near-Crash Events Through Pattern Recognition
AU  - Kong, XQ
AU  - Das, S
AU  - Zhang, YL
AU  - Wu, LT
AU  - Wallis, J
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Studying near-crashes can help safety researchers understand the nature of crashes from different perspectives. Conventional crash data sets lack information about what occurred directly before the crash event. This study used a near-crash data set extracted from a naturalistic driving study that includes features describing the vehicles, drivers, and information on other vehicles involved before and during the near-crash incidents. This data set provides us with a unique perspective to understand the patterns of near-crashes. This study applied the cluster correspondence analysis (cluster CA) algorithm to explore the patterns and the magnitude of each feature's dominance within and between the clusters through dimension reduction. The analysis identifies six clusters with four types of near-crashes: near-crash with adjacent vehicles; near-crash with the following or leading vehicles; near-crash with turning vehicles; and near-crash with objects on the roadway. The results also show that the first two types of near-crash are the most common. The patterns for these two most common types of near-crash are different with or without the engagement of secondary tasks. The findings of this study provide a fresh perspective to understand different types of crash and associated patterns. Furthermore, these findings could help transportation agencies or vehicle designers develop a more effective countermeasure to mitigate the risk of collision.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1177/03611981221097395
VL  - 2676
IS  - 12
SP  - 775
EP  - 785
SN  - 0361-1981
AN  - WOS:000810315100001
ER  - 

TY  - JOUR
TI  - Impact and prospect of the fourth industrial revolution in food safety: Mini-review
AU  - Kim, SS
AU  - Kim, S
T2  - FOOD SCIENCE AND BIOTECHNOLOGY
AB  - The fourth industrial revolution represented by big data and artificial intelligence (AI), already had a significant impact on the food industry. In this review, the impacts and prospects of the 4th industrial revolution in food safety were discussed. First, the general process and characteristics of AI application from data collection to visualization are covered. Additionally, various data collection and analysis methods are discussed, with emphasis on the collection of high variety, volume, and velocity data and visualization. Available literature presents examples of machine learning applications in food samples that are mostly associated with the classification of agricultural food items through convolutional neural networks. Based on these examples, the prospects of the 4th industrial revolution in food safety are categorized as follows: prediction of food safety risk, detection of foodborne pathogens, and food safety management. This mini-review will help understand the relationship between the 4th industrial revolution and food safety.
DA  - 2022/04//undefined
PY  - 2022
DO  - 10.1007/s10068-022-01047-6
VL  - 31
IS  - 4
SP  - 399
EP  - 406
SN  - 1226-7708
AN  - WOS:000758291100001
KW  - Artificial intelligence
KW  - Machine learning
KW  - Visualization
KW  - Convolutional neural networks
KW  - Accident prevention
KW  - Data visualization
KW  - Big data
KW  - Machine learning applications
KW  - Data acquisition
KW  - Data collection
KW  - Food safety
KW  - Food-safety
KW  - Industry 4.0
KW  - Agricultural foods
KW  - Data analysis-methods
KW  - Data collection method
KW  - Food industries
KW  - Food industry
KW  - Food samples
KW  - Velocities data
KW  - Volume data
ER  - 

TY  - CONF
TI  - Assuring autonomous operations in aviation: is use of AI a good idea?
AU  - Bharadwaj, R
T2  - ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR MULTI-DOMAIN OPERATIONS APPLICATIONS IV
A2  - Pham, T
A2  - Solomon, L
AB  - Autonomous systems, including self-driving cars and unmanned underwater/surface/ground/air/space vehicles, have caught the imagination of the press, the public, and personnel of the U.S. Department of Defense (DoD). Moreover, these systems increasingly harness the power of Artificial Intelligence and Machine Learning (AI/ML), more specifically Deep Learning (DL), for their operation. The stunning performance of deep learning algorithms in comparison to extant methods, including pattern matching, computational linguistics, statistical inferencing, and legacy machine-learning, has taken the world by storm. However, adoption of such systems in safety-critical applications has been the subject of intense debate and scrutiny, because of the propensity of these algorithms for erroneous operation, such as misdirection with seemingly innocuous signage, and their vulnerability to data poisoning and data sparsity attacks, leading to incorrect operation which can be both embarrassing and damaging. This has naturally led the DoD community to ask, "How do we harness this technology being unleashed upon the world, and yet keep our nation and warfighters safe?" Before we answer this question, however, it is important to note that trust is integral to DoD systems, including autonomous systems, and ensuring reliable system operations is paramount. Therefore, we need strategies to equip the DoD to design, build, deploy, and sustain autonomous systems that are trustworthy, secure, reliable, and dependable. In this paper, we investigate issues leading to poor performance and lack of robustness of autonomous systems based on machine learning, and discuss the state of the art for their mitigation.
DA  - 2022///
PY  - 2022
DO  - 10.1117/12.2631786
VL  - 12113
SN  - 0277-786X
AN  - WOS:000844508600041
KW  - Deep learning
KW  - Artificial Intelligence
KW  - Machine Learning
KW  - Learning systems
KW  - Assured autonomy
KW  - Learning algorithms
KW  - Machine-learning
KW  - Safety engineering
KW  - Adversarial training
KW  - Adversarial Training
KW  - Aviation safety
KW  - Pattern matching
KW  - Department of Defence
KW  - Air space
KW  - Assured Autonomy
KW  - Autonomous operations
KW  - Aviation Safety
KW  - Space vehicles
KW  - Surface ground
KW  - US Department of Defence
ER  - 

TY  - JOUR
TI  - The robustness of popular multiclass machine learning models against poisoning attacks: Lessons and insights
AU  - Maabreh, M
AU  - Maabreh, A
AU  - Qolomany, B
AU  - Al-Fuqaha, A
T2  - INTERNATIONAL JOURNAL OF DISTRIBUTED SENSOR NETWORKS
AB  - Despite the encouraging outcomes of machine learning and artificial intelligence applications, the safety of artificial intelligence-based systems is one of the most severe challenges that need further exploration. Data set poisoning is a severe problem that may lead to the corruption of machine learning models. The attacker injects data into the data set that are faulty or mislabeled by flipping the actual labels into the incorrect ones. The word "robustness" refers to a machine learning algorithm's ability to cope with hostile situations. Here, instead of flipping the labels randomly, we use the clustering approach to choose the training samples for label changes to influence the classifiers' performance and the distance-based anomaly detection capacity in quarantining the poisoned samples. According to our experiments on a benchmark data set, random label flipping may have a short-term negative impact on the classifier's accuracy. Yet, an anomaly filter would discover on average 63% of them. On the contrary, the proposed clustering-based flipping might inject dormant poisoned samples until the number of poisoned samples is enough to influence the classifiers' performance severely; on average, the same anomaly filter would discover 25% of them. We also highlight important lessons and observations during this experiment about the performance and robustness of popular multiclass learners against training data set-poisoning attacks that include: trade-offs, complexity, categories, poisoning resistance, and hyperparameter optimization.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.1177/15501329221105159
VL  - 18
IS  - 7
SN  - 1550-1329
AN  - WOS:000827449300001
KW  - machine learning
KW  - Deep learning
KW  - deep learning
KW  - Machine learning algorithms
KW  - Learning systems
KW  - Anomaly detection
KW  - Learning algorithms
KW  - Machine-learning
KW  - Classification (of information)
KW  - Economic and social effects
KW  - Machine learning models
KW  - Big Data
KW  - Big data
KW  - Clustering algorithms
KW  - Data set
KW  - clustering
KW  - Clusterings
KW  - Poisoning attack
KW  - Poisoning attacks
KW  - artificial intelligence safety
KW  - Artificial intelligence safety
KW  - Classifier performance
KW  - multiclass
KW  - Multiclass
ER  - 

TY  - JOUR
TI  - Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI
AU  - Arrieta, AB
AU  - Díaz-Rodríguez, N
AU  - Del Ser, J
AU  - Bennetot, A
AU  - Tabik, S
AU  - Barbado, A
AU  - García, S
AU  - Gil-López, S
AU  - Molina, D
AU  - Benjamins, R
AU  - Chatila, R
AU  - Herrera, F
T2  - INFORMATION FUSION
AB  - In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.
DA  - 2020/06//undefined
PY  - 2020
DO  - 10.1016/j.inffus.2019.12.012
VL  - 58
SP  - 82
EP  - 115
SN  - 1566-2535
AN  - WOS:000516799200007
KW  - Accountability
KW  - Interpretability
KW  - Transparency
KW  - Deep learning
KW  - Deep neural networks
KW  - Fairness
KW  - Explainable Artificial Intelligence
KW  - Privacy
KW  - Comprehensibility
KW  - Data Fusion
KW  - Deep Learning
KW  - Machine Learning
KW  - Responsible Artificial Intelligence
KW  - Learning systems
KW  - Machine learning models
KW  - Expert systems
KW  - Data privacy
KW  - Data fusion
KW  - Taxonomies
KW  - Literature analysis
KW  - Reference material
KW  - Rule-based models
ER  - 

TY  - JOUR
TI  - Incident Duration Time Prediction Using Supervised Topic Modeling Method
AU  - Park, J
AU  - Lee, J
AU  - Dimitrijevic, B
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Accurate prediction of the duration of traffic incidents is one of the most prominent prerequisites for effective implementation of proactive traffic incident management strategies. This paper presents a novel method for immediate prediction of traffic incident duration using an emerging supervised topic modeling. The proposed method employs natural language processing techniques for semantic text analysis of the text-based incident traffic incident dataset. The model applies the labeled latent Dirichlet allocation approach, and it is trained using 1,466 incident records collected by the Korea Expressway Corporation from 2016 to 2019. For training purposes, the proposed method divides the incidents into two groups based on the incident duration: incidents shorter than 2 h and incidents lasting 2 h or longer, following the incident management guidelines of the Federal Highway Administration Manual on Uniform Traffic Control Devices for Streets and Highways (2009). The model is tested with randomly selected incident records that were not used for the model training. The results demonstrate overall prediction accuracies of approximately 74% for incidents lasting up to 2 h, and 82% for incidents lasting 2 h or longer.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1177/03611981221106786
VL  - 2677
IS  - 2
SP  - 418
EP  - 430
SN  - 0361-1981
AN  - WOS:000825092000001
ER  - 

TY  - JOUR
TI  - Application of machine learning in safety evaluation of athletes training based on physiological index monitoring
AU  - Wang, XQ
AU  - Yin, J
T2  - SAFETY SCIENCE
AB  - In order to realize the monitoring and adaptive evaluation of athletes' training safety, the physiological index monitoring and training safety evaluation method of athletes based on machine learning is put forward. Taking the physiological index parameters such as heart rate HR, maximum oxygen uptake VO(2)max, oxygen pulse O2P, respiratory entropy RQ, maximum ventilation (VEmax) as constraint indexes, the physiological index monitoring big data analysis model of athlete training safety evaluation is constructed. The multivariate index joint analysis modeling method is used to reconstruct the characteristics of athletes' physiological index monitoring, the related characteristic quantities of athletes' physiological index monitoring data are extracted, the correlation of athletes' physiological indexes is analyzed by using association rule reconstruction method, and the adaptive training of athletes' physiological index monitoring and safety evaluation is carried out combined with machine learning method. The statistical analysis and optimization control model of athletes' training safety evaluation is constructed, and the physiological index monitoring and training safety evaluation of athletes are realized under machine learning. The simulation results show that the confidence level of this method is high and the convergence of the evaluation process is good, so it has a good application value in athletes training and physiological monitoring.
DA  - 2019/12//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2019.08.025
VL  - 120
SP  - 833
EP  - 837
SN  - 0925-7535
AN  - WOS:000496335100081
KW  - machine learning
KW  - simulation
KW  - Machine learning
KW  - risk assessment
KW  - Training
KW  - Learning systems
KW  - article
KW  - human
KW  - Personnel training
KW  - Machine learning methods
KW  - Safety assessment
KW  - Safety assessments
KW  - Physiology
KW  - Physiological models
KW  - monitoring
KW  - statistical analysis
KW  - training
KW  - Oxygen
KW  - Patient monitoring
KW  - joint
KW  - Athletes
KW  - Data analysis models
KW  - Physiological index monitoring
KW  - Physiological indices
KW  - Physiological monitoring
KW  - Reconstruction method
KW  - Safety evaluation methods
ER  - 

TY  - JOUR
TI  - Study on safety mode of dragon boat sports physical fitness training based on machine learning
AU  - Yin, J
AU  - Wang, XQ
T2  - SAFETY SCIENCE
AB  - In order to improve the safety control ability of dragon boat sports physical fitness training, this paper uses the advantages of machine learning in data analysis and feature mining in the training of dragon boat sports. A machine learning-based safety mode control model for dragon boat sports physical fitness training was proposed. Big data statistical analysis method was used to analyze the constraint parameters of the safety mode of dragon boat sports physical fitness training, and combined with the joint association rule mining method, the dragon boat sports physical fitness training safety mode training was carried out. The correlation feature quantity which constrains the safety of dragon boat physical ability training is extracted. The fuzzy clustering technique is used to classify and study the safety management data of dragon boat sport physical ability training. The method of spectral density analysis and fuzzy fusion clustering analysis is used to realize automatic mining of safety association feature data of dragon boat physical fitness training, and machine learning algorithm is combined to realize the optimization of safety pattern of dragon boat sports physical fitness training. The simulation results show that the feature extraction of the safety model of dragon boat sports physical fitness training is better and the ability of feature resolution is stronger, which improves the safety management ability of dragon boat sports physical fitness training.
DA  - 2019/12//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2019.06.028
VL  - 120
SP  - 1
EP  - 5
SN  - 0925-7535
AN  - WOS:000496335100001
KW  - simulation
KW  - Machine learning
KW  - big data
KW  - Data mining
KW  - Learning systems
KW  - Learning algorithms
KW  - article
KW  - controlled study
KW  - spectroscopy
KW  - Health
KW  - feature extraction
KW  - data analysis
KW  - Fuzzy clustering
KW  - Mining
KW  - statistical analysis
KW  - training
KW  - mining
KW  - Clustering analysis
KW  - Sports
KW  - Association rule mining methods
KW  - Boats
KW  - Correlation features
KW  - Data statistical analysis
KW  - Dragon boat sports
KW  - Feature resolution
KW  - fitness
KW  - Fuzzy clustering techniques
KW  - joint
KW  - physical capacity
KW  - Physical training
KW  - Safety mode
KW  - Spectral density
KW  - Spectral density analysis
ER  - 

TY  - JOUR
TI  - Deep reinforcement learning based direct torque control strategy for distributed drive electric vehicles considering active safety and energy saving performance
AU  - Wei, HQ
AU  - Zhang, N
AU  - Liang, J
AU  - Ai, Q
AU  - Zhao, WQ
AU  - Huang, TY
AU  - Zhang, YT
T2  - ENERGY
AB  - Distributed drive electric vehicles are regarded as a broadly promising transportation tool owing to their convenience and maneuverability. However, reasonable and efficient allocation of torque demand to four wheels is a challenging task. In this paper, a deep reinforcement learning-based torque distribution strategy is proposed to guarantee the active safety and energy conservation. The torque distribution task is explicitly formulated as a Markov decision process, in which the vehicle dynamic characteristics can be approximated. The actor-critic networks are utilized to approximate the action value and policy functions for a better control effect. To guarantee continuous torque output and further stabilize the learning process, a twin delayed deep deterministic policy gradient algorithm is deployed. The motor efficiency is incorporated into the cumulative reward to reduce the energy consumption. The results of double lane change demonstrate that the proposed strategy results in better handling stability performance. In addition, it can improve the vehicle transient response and eliminate the static deviation in the step steering maneuver test. For typical steering maneuvers, the proposed direct torque distribution strategy significantly improves the average motor efficiency and reduces the energy loss by 5.25%-10.51%. Finally, a hardware-in-loop experiment was implemented to validate the real-time executability of the proposed torque distribution strategy. This study provides a foundation for the practical application of intelligent safety control algorithms in future vehicles. (c) 2021 Elsevier Ltd. All rights reserved.
DA  - 2022/01/01/
PY  - 2022
DO  - 10.1016/j.energy.2021.121725
VL  - 238
SN  - 0360-5442
AN  - WOS:000709462500004
KW  - Deep learning
KW  - Reinforcement learning
KW  - Vehicle safety
KW  - electric vehicle
KW  - Behavioral research
KW  - Maneuverability
KW  - Reinforcement learnings
KW  - algorithm
KW  - Automobile steering equipment
KW  - Steering
KW  - Energy efficiency
KW  - learning
KW  - Electric vehicles
KW  - Energy utilization
KW  - deep reinforcement learning
KW  - Energy dissipation
KW  - reinforcement
KW  - Torque
KW  - vehicle safety
KW  - energy efficiency
KW  - torque
KW  - Energy
KW  - Transient analysis
KW  - Active safety
KW  - Active energy
KW  - Direct torque control strategies
KW  - direct torque distribution
KW  - Direct torque distribution
KW  - Distribution strategies
KW  - Motor efficiencies
KW  - Torque distribution
KW  - Traction motors
KW  - Vehicle wheels
ER  - 

TY  - JOUR
TI  - Self-Supervised Learning of Audio Representations From Audio-Visual Data Using Spatial Alignment
AU  - Wang, SS
AU  - Politis, A
AU  - Mesaros, A
AU  - Virtanen, T
T2  - IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING
AB  - Learning fromaudio-visual data offers many possibilities to express correspondence between the audio and visual content, similar to the human perception that relates aural and visual information. In this work, we present a method for self-supervised representation learning based on audio-visual spatial alignment (AVSA), a more sophisticated alignment task than the audio-visual correspondence (AVC). In addition to the correspondence, AVSA also learns from the spatial location of acoustic and visual content. Based on 360. video and Ambisonics audio, we propose selection of visual objects using object detection, and beamforming of the audio signal towards the detected objects, attempting to learn the spatial alignment between objects and the sound they produce. We investigate the use of spatial audio features to represent the audio input, and different audio formats: Ambisonics, mono, and stereo. Experimental results show a 10% improvement on AVSA for the first order ambisonics intensity vector (FOA-IV) in comparison with log-mel spectrogram features; the addition of object-oriented crops also brings significant performance increases for the human action recognition downstreamtask. Anumber of audio-only downstream tasks are devised for testing the effectiveness of the learnt audio feature representation, obtaining performance comparable to state-of-the-art methods on acoustic scene classification from ambisonic and binaural audio.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1109/JSTSP.2022.3180592
VL  - 16
IS  - 6
SP  - 1467
EP  - 1479
SN  - 1932-4553
AN  - WOS:000870301500028
KW  - Task analysis
KW  - Supervised learning
KW  - Job analysis
KW  - Classification (of information)
KW  - Object detection
KW  - Data visualization
KW  - Stereo image processing
KW  - feature learning
KW  - Object recognition
KW  - self-supervised learning
KW  - Self-supervised learning
KW  - Alignment
KW  - Audio acoustics
KW  - Crops
KW  - Feature learning
KW  - Flow visualization
KW  - Audio classification
KW  - Audio-visual
KW  - audio-visual corres-pondence
KW  - Audio-visual correspondence
KW  - audio-visual data
KW  - Audio-visual data
KW  - audio-visual spatial alignment
KW  - Audio-visual spatial alignment
KW  - Spatial alignment
KW  - Spatial audio
KW  - Visual-spatial
ER  - 

TY  - JOUR
TI  - Security Constrained Dispatch for Renewable Proliferated Distribution Network Based on Safe Reinforcement Learning
AU  - Cui, H
AU  - Ye, YJ
AU  - Tian, QD
AU  - Tang, Y
T2  - FRONTIERS IN ENERGY RESEARCH
AB  - As the terminal of electricity consumption, the distribution network is a vital field to lower the carbon emission of the power system. With the integration of distributed energy resources, the flexibility of the distribution network has been promoted significantly where dispatch actions can be employed to lower carbon emissions without compromising the accessibility of reliable electricity. This study proposes a security constrained dispatch policy based on safe reinforcement learning for the distribution network. The researched problem is set up as a constrained Markov decision process, where continuous-discrete mixed action space and high-dimensional state space are in place. In addition, security-related rules are embedded into the problem formulation. To guarantee the generalization of the reinforcement learning agent, various scenarios are generated in the offline training stage, including randomness of renewables, scheduled maintenance, and different load profiles. A case study is performed on a modified version of the IEEE 33-bus system, and the numerical results verify the effectiveness of the proposed method in decarbonization.
DA  - 2022/07/04/
PY  - 2022
DO  - 10.3389/fenrg.2022.933011
VL  - 10
SN  - 2296-598X
AN  - WOS:000828224200001
KW  - Reinforcement learning
KW  - Reinforcement learnings
KW  - Carbon
KW  - Network security
KW  - Markov processes
KW  - Safe reinforcement learning
KW  - Numerical methods
KW  - safe reinforcement learning
KW  - Energy resources
KW  - Electric load dispatching
KW  - Network-based
KW  - Electric energy storage
KW  - Active distribution network
KW  - Active distributions
KW  - active distribution networks
KW  - Decarbonisation
KW  - Decarbonization
KW  - decarbonization dispatch
KW  - Decarbonization dispatch
KW  - electricity storage
KW  - Electricity storages
KW  - renewable generation
KW  - Renewable generation
KW  - Security constrained dispatch
ER  - 

TY  - CONF
TI  - Application of DM in Data Safety of Machine Learning Based on Combined Grey Neural Network
AU  - Wang, YD
AU  - Qu, ZM
T2  - 2009 ISECS INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT, VOL II
A2  - Luo, Q
A2  - Yi, J
A2  - Bin, C
AB  - Using the theory of grey system, DM technology and radial basis function (RBF) neural network method, a new model, the combined model of grey system and RBF neural network is setup, which aims at solving the user's received data safety of machine learning. The results show that, in short-term prediction of data safety of machine learning, GM is an effective way and RBF has perfect ability to study and map. The combined model of grey system and neural network, to a large extent, has the dual properties of trend and fluctuation under the condition of combining with the time-dependent sequence data. It is concluded that great improvement comparing with any method of trend prediction and simple factor in combined grey neural network (CGNN) comparing with the any model of grey system and RBF neural network in data safety of machine learning of machine learning.
DA  - 2009///
PY  - 2009
SP  - 439
EP  - 442
SN  - 978-1-4244-4246-1
AN  - WOS:000274016200109
KW  - Machine learning
KW  - Neural networks
KW  - Computer science
KW  - DM
KW  - Machine-learning
KW  - Safety factor
KW  - Education
KW  - Radial basis function networks
KW  - System theory
KW  - Robot learning
KW  - CGNN
KW  - Combined model
KW  - Data safety of machine learning
KW  - Grey neural networks
KW  - Grey systems
KW  - New model
KW  - Radial basis function neural networks
KW  - RBF Neural Network
KW  - Sequence data
KW  - Short term prediction
KW  - Time-dependent
KW  - Trend prediction
ER  - 

TY  - CONF
TI  - Toward Physics-Guided Safe Deep Reinforcement Learning for Green Data Center Cooling Control
AU  - Wang, RH
AU  - Zhang, XY
AU  - Zhou, X
AU  - Wen, YG
AU  - Tan, R
AU  - IEEE COMP SOC
T2  - 2022 13TH ACM/IEEE INTERNATIONAL CONFERENCE ON CYBER-PHYSICAL SYSTEMS (ICCPS 2022)
AB  - Deep reinforcement learning (DRL) has shown good performance in tackling Markov decision process (MDP) problems. As DRL optimizes a long-term reward, it is a promising approach to improving the energy efficiency of data center cooling. However, enforcement of thermal safety constraint during DRL's state exploration is a main challenge. The widely adopted reward shaping approach adds negative reward when the exploratory action results in unsafety. Thus, it needs to experience sufficient unsafe states before it learns how to prevent unsafety. In this paper, we propose a safety-aware DRL framework for single-hall data center cooling control. It applies offline imitation learning and online post-hoc rectification to holistically prevent thermal unsafety during online DRL. In particular, the post-hoc rectification searches for the minimum modification to the DRL-recommended action such that the rectified action will not result in unsafety. The rectification is designed based on a thermal state transition model that is fitted using historical safe operation traces and able to extrapolate the transitions to unsafe states explored by DRL. Extensive evaluation for chilled water and direct expansion cooled data centers in two climate conditions shows that our approach saves 22.7% to 26.6% total data center power compared with conventional control, reduces safety violations by 94.5% to 99% compared with reward shaping.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICCPS54341.2022.00021
SP  - 159
EP  - 169
SN  - 2375-8317
AN  - WOS:000851578700015
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Performance
KW  - Reinforcement learnings
KW  - Energy efficiency
KW  - Markov Decision Processes
KW  - Markov processes
KW  - Safe reinforcement learning
KW  - safe reinforcement learning
KW  - Datacenter
KW  - Green computing
KW  - Safety constraint
KW  - Cooling control
KW  - Data center
KW  - Data center cooling
KW  - energy efficiency
KW  - Green data centers
KW  - thermal safety
KW  - Thermal safety
ER  - 

TY  - JOUR
TI  - Deep-Learning-Based Fault Occurrence Prediction of Public Trains in South Korea
AU  - Caliwag, A
AU  - Han, SY
AU  - Park, KJ
AU  - Lim, W
T2  - TRANSPORTATION RESEARCH RECORD
AB  - The reliability and safety of the train system is a critical issue, as it transports many passengers in its daily operation. Most studies focus on fault diagnosis methods to determine the cause of faults in the train system. Aside from fault diagnosis, it is also vital to perceive a fault even before it occurs. In this study, a fault occurrence prediction based on a machine learning model is developed. The fault occurrence prediction method aims to predict the remaining useful life (RUL) of a train subsystem. RUL refers to the remaining amount of time before a fault occurs on a train subsystem. The prediction method developed in this study can be used to clear a fault even before it occurs. In case of inevitable faults, the output from the prediction method can be used to alert the personnel in charge by imposing an alarm. Therefore, the fault occurrence prediction method is expected to increase the reliability of the train system. The deep neural-network-based model is tested on an actual device. Deep neural network is used because of its feature extraction capability, especially in handling big amount of data. The testing results in 90.08% accuracy. In addition, a graphical user interface is developed as an interface between a user and the actual device containing the fault occurrence prediction model.
DA  - 2022/04//undefined
PY  - 2022
DO  - 10.1177/03611981211064893
VL  - 2676
IS  - 4
SP  - 710
EP  - 718
SN  - 0361-1981
AN  - WOS:000766055100001
ER  - 

TY  - JOUR
TI  - Artificial intelligence as ally in hazard analysis
AU  - Garvin, T
AU  - Kimbleton, S
T2  - PROCESS SAFETY PROGRESS
AB  - Hazard analysis techniques have been around for many years, and have proven effective in the prevention of incidents and no doubt the saving of lives. Process hazard analysis (PHA) is now fairly robust and regulated, focused on overarching risks associated with the safe handling of hazardous materials and approaches to engineer-out such risks. Occupational hazard analysis (OHA) is keenly focused on human activity, and personal protection in hazardous working conditions. Both approaches are critical - but are often carried out separately, by different parts of an organization, which could result in an incomplete picture of the full set of operational risks in the field. Developing a holistic picture of both past and present dangers calls for a deep exploration of evidence. HAZOPs, PHA's, incident records and investigations provide expert analysis of hazards and mitigating strategies. Near-miss reports and safety observations add a large amount of information as well; the reporting frequency of these "leading indicators" can be both a blessing and a curse, as time and available resources constrain the ability to analyze and detect hazard signals within. As important as analyzing the historical record is for lessons learned, the more recent observations could indicate new hazards or highlight concerning trends. These could feed valuable "real time" information back to operations and maintenance teams to improve risk assessments and task planning. Enter artificial intelligence (AI) as a means to analyze the large amount of written hazard analyses, reports and observations to quickly extract insights around hazardous conditions, activities, incident causes and risk mitigation measures. Trained to understand concepts and contexts in both process and personal safety, AI can provide a natural-language information exploration environment for scanning thousands of documents in seconds and present common themes and related records. Not unlike us humans, AI learns from the past, informs the present and can help reduce risks in the future.
DA  - 2021/09//undefined
PY  - 2021
DO  - 10.1002/prs.12243
VL  - 40
IS  - 3
SP  - 43
EP  - 49
SN  - 1066-8527
AN  - WOS:000618546700001
KW  - Artificial intelligence
KW  - safety
KW  - Risk assessment
KW  - Hazards
KW  - Natural languages
KW  - Leading indicators
KW  - Safe handling
KW  - ai
KW  - artificial_intelligence
KW  - Historical records
KW  - hse
KW  - machine_learning
KW  - Occupational hazards
KW  - Operational risks
KW  - Operations and maintenance
KW  - Personal protection
KW  - Process hazard analysis
KW  - text_analytics
KW  - unstructured_data
ER  - 

TY  - CONF
TI  - A TOPOLOGICAL DATA ANALYSIS GUIDED FUSION ALGORITHM: MAPPER-REGULARIZED MANIFOLD ALIGNMENT
AU  - Hu, JL
AU  - Hong, DF
AU  - Wan, YY
AU  - Zhu, XX
T2  - 2019 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (IGARSS 2019)
AB  - Hyperspectral images and polarimetric synthetic aperture radar (PolSAR) data are two important data sources, yet they barely appear under the same scope, even though multi-modal data fusion is attracting more and more attention. To our best knowledge, this paper investigates for the first time semi-supervised manifold alignment (SSMA) for the fusion of the hyperspectral image and PolSAR data. The SSMA searches a latent space where different data sources are aligned, which is accomplished by using the label information and the topological structure of the data. This paper is the first attempt to apply topological data analysis (TDA), a recent mathematic sub-field of data analysis, in remote sensing. It aims to reveal relevant information from the shape of a data in its feature space, and has been proven powerful in medicine. The paper also proposes a novel algorithm, MAPPER-regularized manifold alignment, which embeds the TDA into a semi-supervised manifold alignment for the fusion of the hyperspectral image and PolSAR data. The proposed algorithm exhibits superior performance in fusing a simulated EnMAP data set and a Sentinel-1 data set for an image of Berlin.
DA  - 2019///
PY  - 2019
DO  - 10.1109/igarss.2019.8898471
SP  - 2822
EP  - 2825
SN  - 2153-6996
AN  - WOS:000519270602224
KW  - semi-supervised learning
KW  - Data handling
KW  - Classification (of information)
KW  - data fusion
KW  - Semi-supervised learning
KW  - Synthetic aperture radar
KW  - Information analysis
KW  - Classification
KW  - Remote sensing
KW  - Space optics
KW  - Alignment
KW  - Topology
KW  - Data fusion
KW  - land use
KW  - Land use
KW  - Geology
KW  - Modal analysis
KW  - Spectroscopy
KW  - Image fusion
KW  - land cover
KW  - Manifold alignments
KW  - manifold alignment
KW  - Space-based radar
KW  - Topological data analysis
KW  - EnMAP
KW  - hyperspectral image
KW  - Hyperspectral imaging
KW  - Land cover
KW  - MAPPER
KW  - PolSAR
KW  - Sentinel-1
KW  - topological data analysis (TDA)
ER  - 

TY  - JOUR
TI  - Artificial intelligence, big data, and blockchain in food safety
AU  - Zhou, QQ
AU  - Zhang, H
AU  - Wang, SY
T2  - INTERNATIONAL JOURNAL OF FOOD ENGINEERING
AB  - Food safety plays an essential role in our daily lives, and it becomes serious with the development of worldwide trade. To tackle the food safety issues, many advanced technologies have been developed to monitor the process of the food industry (FI) to ensure food safety, including the process of food production, processing, transporting, storage, and retailing. These technologies are often referred to as artificial intelligence (AI), big data, and blockchain, which have been widely applied in many research areas. In this review, we introduce these technologies and their applications in the food safety domain. Firstly, basic concepts of these technologies are presented. Then, applications for food safety from a data perspective based on these technologies are analyzed. Finally, future challenges of the applications of AI, big data, and blockchain are discussed.
DA  - 2022/01//undefined
PY  - 2022
DO  - 10.1515/ijfe-2021-0299
VL  - 18
IS  - 1
SP  - 1
EP  - 14
SN  - 2194-5764
AN  - WOS:000738161000001
ER  - 

TY  - JOUR
TI  - SmarTxT: A Natural Language Processing Approach for Efficient Vehicle Defect Investigation
AU  - Francis, J
AU  - Cates, K
AU  - Caldiera, G
T2  - TRANSPORTATION RESEARCH RECORD
AB  - The investigation of vehicle defects, which is generally led by the National Highway Traffic Safety Administration (NHTSA) in the U.S., is critical to the continued trust of the general public in the safety of vehicles. NHTSA routinely receives millions of reports of potential defects, complaints, recalls, and manufacturer communications, which may provide evidence of a new vehicle defect. However, the large quantity and text-based communication make efficiently identifying defect trends difficult for analysts. To accelerate the investigation of defect reports, we introduce a natural language processing (NLP) application that identifies key topics and similar defect reports to assist analysts and investigators. Further, our application is built to provide users with a web interface for interacting with the NLP models. The integration of NLP with current NHTSA datasets provides a method for quickly identifying defect trends in large text-based datasets. To demonstrate the effectiveness of our method, we apply our approach to two publicly available NHTSA datasets, namely the Technical Service Bulletins and Recalls Dataset.
DA  - 2023/03//undefined
PY  - 2023
DO  - 10.1177/03611981221125744
VL  - 2677
IS  - 3
SP  - 1579
EP  - 1592
SN  - 0361-1981
AN  - WOS:000871126600001
ER  - 

TY  - JOUR
TI  - A DEFENSE OF THE PRINCIPLE OF DISTRIBUTED RESPONSIBILITY IN ARTIFICIAL INTELLIGENCE
AU  - Gouveia, SS
T2  - REVUE ROUMAINE DE PHILOSOPHIE
AB  - One of the biggest challenges posed by Artificial Intelligence is the status of the normative concept of responsibility. With the emergence of increasingly developed technologies and artificial agents impacting the day by day, several problems arise but, at this stage, we don't seem to have the conceptual tools to engage with its solutions. The main caveat for that is the traditional or conventional thesis (CT) that it is held regarding Artificial Agents (AA). This view argues for the following negative thesis: no (AA) is responsible for its actions or motivations. On the basis of (CT) we can find a fundamental ontological assumption: the thesis that no (AA) posses, ontologically, the x property that is relevant to give moral status to an entity. In this paper we will argue that (CT) creates what it is known as the "responsibility gap" (RG). We will show that (CT) is implausible to deal with the rapid development of current technologies and, at the shoulders of Luciano Floridi (2013, 2016), we will propose the concept of Distributed Responsibility (DR) to close the current normative gap.
DA  - 2019/07//undefined
PY  - 2019
VL  - 63
IS  - 2
SP  - 235
EP  - 248
SN  - 1220-5400
AN  - WOS:000503010600002
ER  - 

TY  - JOUR
TI  - Domain fuzzy generalization networks for semi-supervised intelligent fault diagnosis under unseen working conditions
AU  - Ren, H
AU  - Wang, J
AU  - Zhu, ZK
AU  - Shi, JJ
AU  - Huang, WG
T2  - MECHANICAL SYSTEMS AND SIGNAL PROCESSING
AB  - In recent years, domain adaptation methods have made remarkable achievements in fault diagnosis under variable working conditions. However, the methods usually fail when target data are unavailable for model training. Confronting with the problem of intelligent fault diagnosis for unseen working conditions, domain generalization methods have been gradually explored. Most existing domain generalization fault diagnosis methods are supervised learning models that require multiple fully labeled source domains. Few studies have been done on semi-supervised domain generalization when only partial source domains have class labels, which is generally a practical industrial scenario because labeling industrial data is a laborious work and requires scarce domain experts. Consequently, this paper proposes a novel semi-supervised domain generalization framework, named domain fuzzy generalization networks (DFGN), for intelligent fault diagnosis under unseen working conditions. The main idea of the DFGN is to enhance the capabilities of learning domain-invariant and discriminative features by proposing domain fuzzy and metric learning strategies. First, the traditional domain discriminator outputting onedimensional domain probability is innovatively substituted by a domain classifier that predicts the domain probabilities belonging to all the source domains. Then, the domain fuzzy strategy is established in domain-adversarial training to extract the domain-invariant features with finegrained distribution alignment. Finally, the metric learning is embedded in feature extractor to extract the discriminative features from a class-level optimization perspective. Benefited from the extracted domain-invariant and discriminative features, the proposed DFGN model exhibits strong generalization ability that can be effectively applied to intelligent fault diagnosis under unseen working conditions. The advantages and superiority of the proposed method over state-ofthe-art semi-supervised domain generalization methods are confirmed by extensive generalization experiments on two bearing datasets.
DA  - 2023/10/01/
PY  - 2023
DO  - 10.1016/j.ymssp.2023.110579
VL  - 200
SN  - 0888-3270
AN  - WOS:001037016700001
KW  - Fuzzy neural networks
KW  - Learning systems
KW  - Condition
KW  - Fuzzy logic
KW  - Failure analysis
KW  - Fault detection
KW  - Semi-supervised
KW  - Domain adaptation
KW  - Adversarial learning
KW  - Generalisation
KW  - Faults diagnosis
KW  - Fault diagnosis
KW  - Fine grained
KW  - Fine-grained distribution alignment
KW  - Semi-supervised domain generalization
KW  - Unseen working condition
KW  - Unseen working conditions
ER  - 

TY  - JOUR
TI  - Safe semi-supervised learning using a bayesian neural network
AU  - Bae, J
AU  - Lee, MJ
AU  - Kim, SB
T2  - INFORMATION SCIENCES
AB  - Semi-supervised learning attempts to use a large set of unlabeled data to increase the pre-diction accuracy of machine learning models when the amount of labeled data is limited. However, in realistic cases, unlabeled data may worsen performance because they contain out-of-distribution (OOD) data that differ from the labeled data. To address this issue, safe semi-supervised deep learning has recently been presented. This study suggests a new safe semi-supervised algorithm that uses an uncertainty-aware Bayesian neural network. Our proposed method, safe uncertainty-based consistency training (SafeUC), uses Bayesian uncertainty to minimize the harmful effects caused by unlabeled OOD examples. The pro-posed method improves the model's generalization performance by regularizing the net-work for consistency against uncertain noise. Moreover, to avoid uncertain prediction results, the proposed method includes a practical inference tip based on a well -calibrated uncertainty. The effectiveness of the proposed method is demonstrated in the experimental results on CIFAR-10 and SVHN by showing that it achieved state-of-the-art performance for all semi-supervised learning tasks with OOD data presence rates.(c) 2022 Elsevier Inc. All rights reserved.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1016/j.ins.2022.08.094
VL  - 612
SP  - 453
EP  - 464
SN  - 0020-0255
AN  - WOS:000863219500003
KW  - Deep learning
KW  - Convolutional neural networks
KW  - Learning algorithms
KW  - Uncertainty
KW  - Semi-supervised learning
KW  - Semi-supervised
KW  - Unlabeled data
KW  - Regularisation
KW  - Bayesian neural network
KW  - Bayesian neural networks
KW  - Out-of-distribution
KW  - Consistency regularization
KW  - Safe semi-supervised deep learning
KW  - Uncertain noise
ER  - 

TY  - CONF
TI  - Not All Parameters Should Be Treated Equally: Deep Safe Semi-supervised Learning under Class Distribution Mismatch
AU  - He, RD
AU  - Han, ZY
AU  - Yang, Y
AU  - Yin, YL
AU  - Assoc Advancement Artificial Intelligence
T2  - THIRTY-SIXTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FOURTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE / THE TWELVETH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
AB  - Deep semi-supervised learning (SSL) aims to utilize a sizeable unlabeled set to train deep networks, thereby reducing the dependence on labeled instances. However, the unlabeled set often carries unseen classes that cause the deep SSL algorithm to lose generalization. Previous works focus on the data level that they attempt to remove unseen class data or assign lower weight to them but could not eliminate their adverse effects on the SSL algorithm. Rather than focusing on the data level, this paper turns attention to the model parameter level. We find that only partial parameters are essential for seen-class classification, termed safe parameters. In contrast, the other parameters tend to fit irrelevant data, termed harmful parameters. Driven by this insight, we propose Safe Parameter Learning (SPL) to discover safe parameters and make the harmful parameters inactive, such that we can mitigate the adverse effects caused by unseen-class data. Specifically, we firstly design an effective strategy to divide all parameters in the pre-trained SSL model into safe and harmful ones. Then, we introduce a bi-level optimization strategy to update the safe parameters and kill the harmful parameters. Extensive experiments show that SPL outperforms the state-of-the-art SSL methods on all the benchmarks by a large margin. Moreover, experiments demonstrate that SPL can be integrated into the most popular deep SSL networks and be easily extended to handle other cases of class distribution mismatch.
DA  - 2022///
PY  - 2022
SP  - 6874
EP  - 6883
SN  - 2159-5399
AN  - WOS:000893636206110
KW  - Deep learning
KW  - Learning models
KW  - Semi-supervised learning
KW  - Parameter learning
KW  - Generalisation
KW  - Bi-level optimization
KW  - Modeling parameters
KW  - Class distributions
KW  - Adverse effect
KW  - Data level
KW  - Parameter levels
ER  - 

TY  - CONF
TI  - Open-Set Fault Diagnosis Method for Industrial Process Based on Semi-supervised Learning
AU  - Liu, JR
AU  - Song, H
AU  - Wang, JG
T2  - INTELLIGENT ROBOTICS AND APPLICATIONS (ICIRA 2022), PT IV
A2  - Liu, H
A2  - Yin, Z
A2  - Liu, L
A2  - Jiang, L
A2  - Gu, G
A2  - Wu, X
A2  - Ren, W
AB  - Aiming at the inconsistent distribution of labeled and unlabeled data categories in the actual industrial production process, this paper proposes an openset semi-supervised process fault diagnosis method based on uncertainty distribution alignment. Firstly, the proposed method forces the matching of the distribution of labeled data and unlabeled data. Then it combines a semi-supervised fault diagnosis model with the anomaly detection of one-vs-all classifier. The interior point (unlabeled samples in known class) is correctly classified while rejecting outliers to realize the fault diagnosis of open-set industrial process data. Finally, fault diagnosis experiments are carried out through numerical simulation and Tennessee-Eastman chemical process to verify the effectiveness and feasibility of the proposed method. Compared with temporal ensembling-dual student (TE-DS) and other semi-supervised fault diagnosis methods, it is proved that the proposed method is suitable for open-set fault diagnosis.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-13841-6_10
VL  - 13458
SP  - 103
EP  - 112
SN  - 0302-9743
AN  - WOS:000870518600009
KW  - Machine learning
KW  - Anomaly detection
KW  - Semi-supervised learning
KW  - Failure analysis
KW  - Fault detection
KW  - Numerical methods
KW  - Semi-supervised
KW  - Faults diagnosis
KW  - Industrial processs
KW  - Fault diagnosis
KW  - Labeled and unlabeled data
KW  - Fault diagnosis method
KW  - Industrial process
KW  - Open-set
KW  - Process-based
KW  - Uncertainty distribution alignment
KW  - Uncertainty distributions
ER  - 

TY  - JOUR
TI  - Semi-Supervised Medical Image Segmentation with Co-Distribution Alignment
AU  - Wang, T
AU  - Huang, ZZ
AU  - Wu, JW
AU  - Cai, YZ
AU  - Li, ZY
T2  - BIOENGINEERING-BASEL
AB  - Medical image segmentation has made significant progress when a large amount of labeled data are available. However, annotating medical image segmentation datasets is expensive due to the requirement of professional skills. Additionally, classes are often unevenly distributed in medical images, which severely affects the classification performance on minority classes. To address these problems, this paper proposes Co-Distribution Alignment (Co-DA) for semi-supervised medical image segmentation. Specifically, Co-DA aligns marginal predictions on unlabeled data to marginal predictions on labeled data in a class-wise manner with two differently initialized models before using the pseudo-labels generated by one model to supervise the other. Besides, we design an over-expectation cross-entropy loss for filtering the unlabeled pixels to reduce noise in their pseudo-labels. Quantitative and qualitative experiments on three public datasets demonstrate that the proposed approach outperforms existing state-of-the-art semi-supervised medical image segmentation methods on both the 2D CaDIS dataset and the 3D LGE-MRI and ACDC datasets, achieving an mIoU of 0.8515 with only 24% labeled data on CaDIS, and a Dice score of 0.8824 and 0.8773 with only 20% data on LGE-MRI and ACDC, respectively.
DA  - 2023/07//undefined
PY  - 2023
DO  - 10.3390/bioengineering10070869
VL  - 10
IS  - 7
SN  - 2306-5354
AN  - WOS:001037932400001
KW  - semi-supervised learning
KW  - distribution alignment
KW  - co-training
KW  - medical image segmentation
ER  - 

TY  - CONF
TI  - Self-paced Safe Co-training for Regression
AU  - Min, F
AU  - Li, Y
AU  - Liu, LY
T2  - ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PAKDD 2022, PT II
A2  - Gama, J
A2  - Li, T
A2  - Yu, Y
A2  - Chen, E
A2  - Zheng, Y
A2  - Teng, F
AB  - In semi-supervised learning, co-training is successfully in augmenting the training data with predicted pseudo-labels. With two independently trained regressors, a co-trainer iteratively exchanges their selected instances coupled with pseudo-labels. However, some low-quality pseudo-labels may significantly decrease the prediction accuracy. In this paper, we propose a self-paced safe co-training for regression (SPOR) algorithm to enrich the training data with unlabeled instances and their pseudo-labels. First, a safe mechanism is designed to enhance the quality of pseudo-labels without side effects. Second, a self-paced learning technique is designed to select "easy" instances in the current situation. Third, a "qualifier-based" treatment is designed to remove "weak" instances selected in previous rounds. Experiments were undertaken on nine benchmark datasets. The results show that SPOR is superior to both popular co-training regression methods and state-of-the-art semi-supervised regressors.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-05936-0_6
VL  - 13281
SP  - 71
EP  - 82
SN  - 0302-9743
AN  - WOS:000870701000006
KW  - Training data
KW  - Supervised learning
KW  - Regression analysis
KW  - Iterative methods
KW  - Safe learning
KW  - Semi-supervised
KW  - Self-paced learning
KW  - Prediction accuracy
KW  - Safe mechanisms
KW  - Co-training
KW  - Low qualities
KW  - Semi-supervised regression
KW  - Side effect
ER  - 

TY  - JOUR
TI  - Towards Making Unlabeled Data Never Hurt
AU  - Li, YF
AU  - Zhou, ZH
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - It is usually expected that learning performance can be improved by exploiting unlabeled data, particularly when the number of labeled data is limited. However, it has been reported that, in some cases existing semi-supervised learning approaches perform even worse than supervised ones which only use labeled data. For this reason, it is desirable to develop safe semi-supervised learning approaches that will not significantly reduce learning performance when unlabeled data are used. This paper focuses on improving the safeness of semi-supervised support vector machines (S3VMs). First, the S3VM-us approach is proposed. It employs a conservative strategy and uses only the unlabeled instances that are very likely to be helpful, while avoiding the use of highly risky ones. This approach improves safeness but its performance improvement using unlabeled data is often much smaller than S3VMs. In order to develop a safe and well-performing approach, we examine the fundamental assumption of S3VMs, i.e., low-density separation. Based on the observation that multiple good candidate low-density separators may be identified from training data, safe semi-supervised support vector machines (S4VMs) are here proposed. This approach uses multiple low-density separators to approximate the ground-truth decision boundary and maximizes the improvement in performance of inductive SVMs for any candidate separator. Under the assumption employed by S3VMs, it is here shown that S4VMs are provably safe and that the performance improvement using unlabeled data can be maximized. An out-of-sample extension of S4VMs is also presented. This extension allows S4VMs to make predictions on unseen instances. Our empirical study on a broad range of data shows that the overall performance of S4VMs is highly competitive with S3VMs, whereas in contrast to S3VMs which hurt performance significantly in many cases, S4VMs rarely perform worse than inductive SVMs.
DA  - 2015/01//undefined
PY  - 2015
DO  - 10.1109/TPAMI.2014.2299812
VL  - 37
IS  - 1
SP  - 175
EP  - 188
SN  - 0162-8828
AN  - WOS:000346970600015
KW  - Support vector machines
KW  - Learning systems
KW  - Supervised learning
KW  - Semi- supervised learning
KW  - Semi-supervised learning
KW  - Unlabeled data
KW  - Safe
KW  - S3VMs
KW  - S4VMs
KW  - Separators
ER  - 

TY  - JOUR
TI  - Safe co-training for semi-supervised regression
AU  - Liu, LY
AU  - Huang, P
AU  - Yu, H
AU  - Min, F
T2  - INTELLIGENT DATA ANALYSIS
AB  - Co-training is a popular semi-supervised learning method. The learners exchange pseudo-labels obtained from different views to reduce the accumulation of errors. One of the key issues is how to ensure the quality of pseudo-labels. However, the pseudo-labels obtained during the co-training process may be inaccurate. In this paper, we propose a safe co-training (SaCo) algorithm for regression with two new characteristics. First, the safe labeling technique obtains pseudo-labels that are certified by both views to ensure their reliability. It differs from popular techniques of using two views to assign pseudo-labels to each other. Second, the label dynamic adjustment strategy updates the previous pseudo-labels to keep them up-to-date. These pseudo-labels are predicted using the augmented training data. Experiments are conducted on twelve datasets commonly used for regression testing. Results show that SaCo is superior to other co-training style regression algorithms and state-of-the-art semi-supervised regression algorithms.
DA  - 2023///
PY  - 2023
DO  - 10.3233/IDA-226718
VL  - 27
IS  - 4
SP  - 959
EP  - 975
SN  - 1088-467X
AN  - WOS:001035834100005
KW  - semi-supervised learning
KW  - Learning systems
KW  - Statistical tests
KW  - Semi-supervised learning
KW  - safe learning
KW  - Safe learning
KW  - Semi-supervised
KW  - Software testing
KW  - Training process
KW  - Regression
KW  - Semi-supervised learning methods
KW  - regression
KW  - Regression algorithms
KW  - Co-training
KW  - Co-training algorithm
KW  - Key Issues
ER  - 

TY  - CONF
TI  - SCAF: Skip-Connections in Auto-encoder for Face Alignment with Few Annotated Data
AU  - Dornier, M
AU  - Gosselin, PH
AU  - Raymond, C
AU  - Ricquebourg, Y
AU  - Coüasnon, B
T2  - IMAGE ANALYSIS AND PROCESSING, ICIAP 2022, PT I
A2  - Sclaroff, S
A2  - Distante, C
A2  - Leo, M
A2  - Farinella, GM
A2  - Tombari, F
AB  - Supervised face alignment methods need large amounts of training data to achieve good performance in terms of accuracy and generalization. However face alignment datasets rarely exceed a few thousand samples making these methods prone to overfitting on the specific training dataset. Semi-supervised methods like TS3 or 3FabRec have emerged to alleviate this issue by using labeled and unlabeled data during the training. In this paper we propose Skip-Connections in Auto-encoder for Face alignment (SCAF), we build on 3FabRec by adding skip-connections between the encoder and the decoder. These skip-connections lead to better landmark predictions, especially on challenging examples. We also apply for the first time active learning to the face alignment task and introduce a new acquisition function, the Negative Neighborhood Magnitude, specially designed to assess the quality of heatmaps. These two proposals show their effectiveness on several face alignment datasets when training with limited data.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06427-2_36
VL  - 13231
SP  - 425
EP  - 437
SN  - 0302-9743
AN  - WOS:000870304100036
KW  - Training data
KW  - Supervised learning
KW  - Performance
KW  - Active Learning
KW  - Signal encoding
KW  - Alignment
KW  - Generalisation
KW  - Auto encoders
KW  - Face alignment
KW  - Overfitting
KW  - Active learning
KW  - Large amounts
KW  - Alignment methods
KW  - Semi-supervised training
KW  - Semi-supervised trainings
ER  - 

TY  - CONF
TI  - Safe Multi-view Co-training for Semi-supervised Regression
AU  - Liu, LY
AU  - Huang, P
AU  - Min, F
T2  - 2022 IEEE 9TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (DSAA)
A2  - Huang, JZ
A2  - Pan, Y
A2  - Hammer, B
A2  - Khan, MK
A2  - Xie, X
A2  - Cui, L
A2  - He, Y
AB  - Co-training is a popular disagreement-based semisupervised learning method. Learners of different views mutually select reliable unlabeled instances to augment the labeled dataset. Existing co-training style algorithms have cumbersome procedures for selecting confident instances. Furthermore, the pseudolabels assigned to selected unlabeled instances are not always reliable. In this paper, we propose a safe co-training regression algorithm for multi-view scenarios with two characteristics. An instance selection strategy based on the consistency assumption aims to improve the efficiency of selecting confident unlabeled instances. This strategy makes full use of the information provided by a committee to measure the confidence of unlabeled instances. A safe labeling technique in an ensemble manner is introduced to improve the quality of pseudo-labels. The safe pseudo-labels not only integrate information provided by the committee, but also take into account the part of the receiver. The results over twenty datasets prove the superiority of the proposed algorithm against other state-of-the-art semi-supervised regression algorithms.
DA  - 2022///
PY  - 2022
DO  - 10.1109/DSAA54385.2022.10032437
SP  - 56
EP  - 65
SN  - 2472-1573
AN  - WOS:000967751000007
KW  - Learning systems
KW  - Regression analysis
KW  - Computer vision
KW  - safe learning
KW  - Safe learning
KW  - Semi-supervised
KW  - Multi-views
KW  - Semi-supervised learning methods
KW  - Regression algorithms
KW  - Labeled dataset
KW  - co-training
KW  - Co-training
KW  - Semi-supervised regression
KW  - Disagreement-based method
KW  - disagreement-based methods
KW  - multi-view learning
KW  - Multi-view learning
KW  - semi-supervised regression
ER  - 

TY  - CONF
TI  - RDA: Reciprocal Distribution Alignment for Robust Semi-supervised Learning
AU  - Duan, Y
AU  - Qi, L
AU  - Wang, L
AU  - Zhou, LP
AU  - Shi, YH
T2  - COMPUTER VISION - ECCV 2022, PT XXX
A2  - Avidan, S
A2  - Brostow, G
A2  - Cisse, M
A2  - Farinella, GM
A2  - Hassner, T
AB  - In this work, we propose Reciprocal Distribution Alignment (RDA) to address semi-supervised learning (SSL), which is a hyperparameter-free framework that is independent of confidence threshold and works with both the matched (conventionally) and the mismatched class distributions. Distribution mismatch is an often overlooked but more general SSL scenario where the labeled and the unlabeled data do not fall into the identical class distribution. This may lead to the model not exploiting the labeled data reliably and drastically degrade the performance of SSL methods, which could not be rescued by the traditional distribution alignment. In RDA, we enforce a reciprocal alignment on the distributions of the predictions from two classifiers predicting pseudo-labels and complementary labels on the unlabeled data. These two distributions, carrying complementary information, could be utilized to regularize each other without any prior of class distribution. Moreover, we theoretically show that RDA maximizes the input-output mutual information. Our approach achieves promising performance in SSL under a variety of scenarios of mismatched distributions, as well as the conventional matched SSL setting. Our code is available at: https://github.com/NJUyued/RDA4RobustSSL.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20056-4_31
VL  - 13690
SP  - 533
EP  - 549
SN  - 0302-9743
AN  - WOS:000903586400031
KW  - Supervised learning
KW  - Performance
KW  - Semi-supervised learning
KW  - Labeled data
KW  - Alignment
KW  - Hyper-parameter
KW  - Unlabeled data
KW  - Confidence threshold
KW  - Distribution alignment
KW  - Class distributions
KW  - Learning scenarios
KW  - Mismatched distribution
KW  - Mismatched distributions
ER  - 

TY  - JOUR
TI  - Spectroscopy Approaches for Food Safety Applications: Improving Data Efficiency Using Active Learning and Semi-supervised Learning
AU  - Zhang, HL
AU  - Wisuthiphaet, N
AU  - Cui, HM
AU  - Nitin, N
AU  - Liu, X
AU  - Zhao, Q
T2  - FRONTIERS IN ARTIFICIAL INTELLIGENCE
AB  - The past decade witnessed rapid development in the measurement and monitoring technologies for food science. Among these technologies, spectroscopy has been widely used for the analysis of food quality, safety, and nutritional properties. Due to the complexity of food systems and the lack of comprehensive predictive models, rapid and simple measurements to predict complex properties in food systems are largely missing. Machine Learning (ML) has shown great potential to improve the classification and prediction of these properties. However, the barriers to collecting large datasets for ML applications still persists. In this paper, we explore different approaches of data annotation and model training to improve data efficiency for ML applications. Specifically, we leverage Active Learning (AL) and Semi-Supervised Learning (SSL) and investigate four approaches: baseline passive learning, AL, SSL, and a hybrid of AL and SSL. To evaluate these approaches, we collect two spectroscopy datasets: predicting plasma dosage and detecting foodborne pathogen. Our experimental results show that, compared to the de facto passive learning approach, advanced approaches (AL, SSL, and the hybrid) can greatly reduce the number of labeled samples, with some cases decreasing the number of labeled samples by more than half.
DA  - 2022/06/22/
PY  - 2022
DO  - 10.3389/frai.2022.863261
VL  - 5
SN  - 2624-8212
AN  - WOS:000915761300001
KW  - machine learning
KW  - semi-supervised learning
KW  - active learning
KW  - data efficiency
KW  - food science
KW  - spectroscopy analysis
ER  - 

TY  - JOUR
TI  - Adversarial feature distribution alignment for semi-supervised learning
AU  - Mayer, C
AU  - Paul, M
AU  - Timofte, R
T2  - COMPUTER VISION AND IMAGE UNDERSTANDING
AB  - Training deep neural networks with only a few labeled samples can lead to overfitting. This is problematic in semi-supervised learning where only a few labeled samples are available. In this paper, we show that a consequence of overfitting in SSL is feature distribution misalignment between labeled and unlabeled samples. Hence, we propose a new feature distribution alignment method. Our method is particularly effective when using only a small amount of labeled samples. We test our method on CIFAR-10, SVHN and LSUN. On SVHN we achieve a test error of 3.88% (250 labeled samples) and 3.39% (1000 labeled samples), which is close to the fully supervised model 2.89% (73k labeled samples). In comparison, the current SOTA achieves only 4.29% and 3.74%. On LSUN we achieve superior results than a state-of-the- art method even when using 100x less unlabeled samples (500 labeled samples). Finally, we provide a theoretical insight why feature distribution misalignment occurs and show that our method reduces it.
DA  - 2021/01//undefined
PY  - 2021
DO  - 10.1016/j.cviu.2020.103109
VL  - 202
SN  - 1077-3142
AN  - WOS:000616091100012
KW  - Deep learning
KW  - Deep neural networks
KW  - Semi-supervised learning
KW  - Unlabeled samples
KW  - State-of-the-art methods
KW  - Alignment
KW  - Overfitting
KW  - Alignment methods
KW  - Feature distribution
KW  - Test errors
ER  - 

TY  - CONF
TI  - Semi-Supervised Learning by Augmented Distribution Alignment
AU  - Wang, Q
AU  - Li, W
AU  - Van Gool, L
AU  - IEEE
T2  - 2019 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2019)
AB  - In this work, we propose a simple yet effective semi-supervised learning approach called Augmented Distribution Alignment. We reveal that an essential sampling bias exists in semi-supervised learning due to the limited number of labeled samples, which often leads to a considerable empirical distribution mismatch between labeled data and unlabeled data. To this end, we propose to align the empirical distributions of labeled and unlabeled data to alleviate the bias. On one hand, we adopt an adversarial training strategy to minimize the distribution distance between labeled and unlabeled data as inspired by domain adaptation works. On the other hand, to deal with the small sample size issue of labeled data, we also propose a simple interpolation strategy to generate pseudo training samples. Those two strategies can be easily implemented into existing deep neural networks. We demonstrate the effectiveness of our proposed approach on the benchmark SVHN and CIFAR10 datasets.
DA  - 2019///
PY  - 2019
DO  - 10.1109/ICCV.2019.00155
SP  - 1466
EP  - 1475
SN  - 1550-5499
AN  - WOS:000531438101058
KW  - Deep learning
KW  - Deep neural networks
KW  - Computer vision
KW  - Semi-supervised learning
KW  - Sampling
KW  - Labeled data
KW  - Domain adaptation
KW  - Unlabeled data
KW  - Training strategy
KW  - Training sample
KW  - Labeled and unlabeled data
KW  - Empirical distributions
KW  - Sampling bias
KW  - Small Sample Size
ER  - 

TY  - CONF
TI  - Safe-Student for Safe Deep Semi-Supervised Learning with Unseen-Class Unlabeled Data
AU  - He, RD
AU  - Han, ZY
AU  - Lu, XK
AU  - Yin, YL
AU  - IEEE COMP SOC
T2  - 2022 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR 2022)
AB  - Deep semi-supervised learning (SSL) methods aim to take advantage of abundant unlabeled data to improve the algorithm performance. In this paper, we consider the problem of safe SSL scenario where unseen-class instances appear in the unlabeled data. This setting is essential and commonly appears in a variety of real applications. One intuitive solution is removing these unseen-class instances after detecting them during the SSL process. Nevertheless, the performance of unseen-class identification is limited by the small number of labeled data and ignoring the availability of unlabeled data. To take advantage of these unseen-class data and ensure performance, we propose a safe SSL method called SAFE-STUDENT from the teacher-student view. Firstly, a new scoring function called energy-discrepancy (ED) is proposed to help the teacher model improve the security of instances selection. Then, a novel unseen-class label distribution learning mechanism mitigates the unseen-class perturbation by calibrating the unseen-class label distribution. Finally, we propose an iterative optimization strategy to facilitate teacher-student network learning. Extensive studies on several representative datasets show that SAFE-STUDENT remarkably outperforms the state-of-the-art, verifying the feasibility and robustness of our method in the under-explored problem.
DA  - 2022///
PY  - 2022
DO  - 10.1109/CVPR52688.2022.01418
SP  - 14565
EP  - 14574
SN  - 1063-6919
AN  - WOS:000870783000016
KW  - Deep learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Performance
KW  - Categorization
KW  - Representation learning
KW  - Retrieval
KW  - Semi-supervised learning
KW  - Iterative methods
KW  - Students
KW  - Unlabeled data
KW  - Semi-supervised learning methods
KW  - retrieval
KW  - categorization
KW  - Class labels
KW  - Self- & semi- & meta- recognition: detection
KW  - Self- & semi- & meta- Recognition: detection
KW  - Teachers'
ER  - 

TY  - JOUR
TI  - Semi-supervised generative adversarial network with guaranteed safeness for industrial quality prediction
AU  - Zhang, X
AU  - Zou, YY
AU  - Li, SY
T2  - COMPUTERS & CHEMICAL ENGINEERING
AB  - In process industries, due to the low sampling rate of the quality variables, there are abundant unlabeled data but limited labeled data. Most data-driven quality prediction models only use the labeled data but ignore the unlabeled data, resulting in overfitting and low generalization performance. Hence, it is necessary to extract useful information from the unlabeled process data. Due to the noise in the signal transmission process and sensors, there are unlabeled data with low confidence that will mislead the training process. To tackle this problem, we propose a semi-supervised Generative adversarial network with Co trained Generators (GCG) that utilizes the unlabeled data safely through the co-training of generators. The optimal parameters and weight coefficients of co-trained generators guarantee the "safeness", i.e., the performance of GCG is not worse than generators with only labeled data. The proposed method is validated by a benchmarked industrial case and the real absorption-stabilization system in Fluid Catalytic Cracking Unit (FCCU). The results suggest that the GCG method improves the generalization performance of the quality prediction model. (c) 2021 Elsevier Ltd. All rights reserved.
DA  - 2021/10//undefined
PY  - 2021
DO  - 10.1016/j.compchemeng.2021.107418
VL  - 153
SN  - 0098-1354
AN  - WOS:000683569900002
KW  - Forecasting
KW  - Semi-supervised learning
KW  - Labeled data
KW  - Semi-supervised
KW  - Unlabeled data
KW  - Generalization performance
KW  - Adversarial networks
KW  - Co-training
KW  - Generative adversarial network
KW  - Fluid catalytic cracking
KW  - Quality prediction models
KW  - Safeness
ER  - 

TY  - CONF
TI  - MINING DRIVING SAFETY PATTERN USING SEMI-SUPERVISED LEARNING ON TIME SERIES DATA
AU  - Gong, YH
AU  - IEEE
T2  - ICME: 2009 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-3
AB  - This paper introduces a driving danger-level warning system that uses statistical modeling to predict driving risks. The major challenge of the research is how to model the safe/dangerous driving patterns from a sparsely labeled training data set. This paper utilizes both the labeled and the unlabeled data as well as their interdependency to build a proper danger-level function. In addition, the learned function adopts a continuous parametric form, which is more suitable in modeling the continuous safe/dangerous driving state transitions in practical dangerous driving warning system. Our comprehensive experimental evaluations reveal that, in comparison with sequential classification based methods, the proposed method requires less training time and achieved higher prediction accuracy.
DA  - 2009///
PY  - 2009
SP  - 1520
EP  - 1523
SN  - 1945-7871
AN  - WOS:000277357000373
KW  - Supervised learning
KW  - Alarm systems
KW  - Semi-supervised learning
KW  - Time series
KW  - Driving safety
KW  - Unlabeled data
KW  - Multimedia systems
KW  - Labeled training data
KW  - Training time
KW  - Prediction accuracy
KW  - Experimental evaluation
KW  - Statistical modeling
KW  - Driving state
KW  - Classification based methods
KW  - Driving pattern
KW  - ON time
KW  - Parametric forms
KW  - Warning systems
ER  - 

TY  - CONF
TI  - Unifying Distribution Alignment as a Loss for Imbalanced Semi-supervised Learning
AU  - Lazarow, J
AU  - Sohn, K
AU  - Lee, CY
AU  - Li, CL
AU  - Zhang, ZZ
AU  - Pfister, T
T2  - 2023 IEEE/CVF WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV)
AB  - While remarkable progress has been made in imbalanced supervised learning, less attention has been given to the setting of imbalanced semi-supervised learning (SSL) where not only are few labeled data provided, but the underlying data distribution can be severely imbalanced. Recent work requires both complicated sampling strategies of pseudo-labeled unlabeled data and distribution alignment of the pseudo-label distribution to accommodate this imbalance. We present a novel approach that relies only on a form of a distribution alignment but no sampling strategy where rather than aligning the pseudo-labels during inference, we move the distribution alignment component into the respective cross entropy loss computations for both the supervised and unsupervised losses. This alignment compensates for both imbalance in the data and the eventual distributional shift present during evaluation. Altogether, this provides a unified strategy that offers both significantly reduced training requirements and improved performance across both low and richly labeled regimes and over varying degrees of imbalance. In experiments, we validate the efficacy of our method on SSL variants of CIFAR10LT, CIFAR100-LT, and ImageNet-127. On ImageNet-127, our method shows 1.6% accuracy improvement over CReST with an 80% training time reduction and is competitive with other SOTA methods. Code is available at https: //github.com/google-research/crest
DA  - 2023///
PY  - 2023
DO  - 10.1109/WACV56688.2023.00560
SP  - 5633
EP  - 5642
SN  - 2472-6737
AN  - WOS:000971500205073
KW  - Deep learning
KW  - Image recognition
KW  - Learning algorithms
KW  - Machine-learning
KW  - Object detection
KW  - Learning architectures
KW  - Image enhancement
KW  - Image segmentation
KW  - Semi-supervised learning
KW  - Object recognition
KW  - Objects detection
KW  - Alignment
KW  - Algorithm: machine learning architecture
KW  - Algorithms: Machine learning architectures
KW  - And algorithm (including transfer)
KW  - and algorithms (including transfer)
KW  - Formulation
KW  - formulations
KW  - Image recognition and understanding (object detection, categorization, segmentation, scene modeling, visual reasoning)
KW  - Scene model
KW  - Visual reasoning
ER  - 

TY  - CONF
TI  - Safe Deep Semi-Supervised Learning for Unseen-Class Unlabeled Data
AU  - Guo, LZ
AU  - Zhang, ZY
AU  - Jiang, Y
AU  - Li, YF
AU  - Zhou, ZH
T2  - INTERNATIONAL CONFERENCE ON MACHINE LEARNING, VOL 119
A2  - Daume, H
A2  - Singh, A
AB  - Deep semi-supervised learning (SSL) has been recently shown very effectively. However, its performance is seriously decreased when the class distribution is mismatched, among which a common situation is that unlabeled data contains some classes not seen in the labeled data. Efforts on this issue remain to be limited. This paper proposes a simple and effective safe deep SSL method to alleviate the harm caused by it. In theory, the result learned from the new method is never worse than learning from merely labeled data, and it is theoretically guaranteed that its generalization approaches the optimal in the order O(root dln(n)/n), even faster than the convergence rate in supervised learning associated with massive parameters. In the experiment of benchmark data, unlike the existing deep SSL methods which are no longer as good as supervised learning in 40% of unseen-class unlabeled data, the new method can still achieve performance gain in more than 60% of unseen-class unlabeled data. Moreover, the proposal is suitable for many deep SSL algorithms and can be easily extended to handle other cases of class distribution mismatch.
DA  - 2020///
PY  - 2020
VL  - 119
SN  - 2640-3498
AN  - WOS:000683178504002
KW  - Deep learning
KW  - Learning systems
KW  - Benchmarking
KW  - Semi-supervised learning
KW  - Labeled data
KW  - Convergence rates
KW  - Unlabeled data
KW  - Performance Gain
KW  - Semi-supervised learning (SSL)
KW  - Benchmark data
KW  - Class distributions
ER  - 

TY  - JOUR
TI  - Long-Distance Pipeline Safety Early Warning: A Distributed Optical Fiber Sensing Semi-Supervised Learning Method
AU  - Yang, YY
AU  - Zhang, HF
AU  - Li, Y
T2  - IEEE SENSORS JOURNAL
AB  - Pipeline safety early warning (PSEW) systems based on distributed optical fiber sensors are used to recognize and locate third-party events that may damage long-distance energy transportation pipelines and are essential to ensure pipeline safety and energy supply. However, the deployment of PSEW systems in real sites is hindered by the high experimental cost of collecting large real-site data sets for model building and the small percentage of labeled data (typically less than 0.5%). Besides, the optical fiber sensors are sensitive to hardware and the environment, ensuring challenges to directly migrate the old PSEW system for a new deployment. In this study, a novel semi-supervised learning model is proposed to monitor the safety of pipelines in real-time. Concretely, the sparse stacked autoencoder trained with unlabeled data is used to extract more robust features, and the fully-connected networktrained with a small amount of labeled data is used for location and identification. Encouraging empirical results on the real-world long-distance energy pipelines of the PipeChina confirm that our method achieves better recognition and localization performance in comparison to the baseline with less labeled data. Further, the model size and recognition latency are reduced by 18.9x and 7.9x of the baseline, respectively. Also, the decoded features have better visualization than the input. This work reduces the cost of PSEW system deployments, improves its performance and portability, and will contribute to the widespread use of PSEW systems in the industry.
DA  - 2021/09/01/
PY  - 2021
DO  - 10.1109/JSEN.2021.3087537
VL  - 21
IS  - 17
SP  - 19453
EP  - 19461
SN  - 1530-437X
AN  - WOS:000692613100120
KW  - semi-supervised learning
KW  - Pipelines
KW  - Learning systems
KW  - Semi-supervised learning
KW  - Labeled data
KW  - pattern recognition
KW  - Semi-supervised learning methods
KW  - Optical fibers
KW  - Long distance pipelines
KW  - Distributed optical fiber sensing
KW  - distributed optical fiber sensor
KW  - Distributed optical fiber sensors
KW  - Energy transportation
KW  - Fiber optic sensors
KW  - Fully connected networks
KW  - Localization performance
KW  - Pipeline safety early warning
KW  - Safety of pipelines
KW  - sparse stacked autoencoder
ER  - 

TY  - JOUR
TI  - Semi-Supervised Learning for Indoor Hybrid Fingerprint Database Calibration With Low Effort
AU  - Zhou, M
AU  - Tang, YX
AU  - Tian, ZS
AU  - Geng, XL
T2  - IEEE ACCESS
AB  - The interest of indoor localization based on the IEEE 802.11 wireless local area network signal increases remarkably to support pervasive computing applications, but the process of fingerprints calibration, which is point-by-point conducted manually, is time consuming and labor intensive. To address this problem, we propose to use a novel improved semi-supervised manifold alignment approach by integrating the execution characteristic function to reduce both the number of reference points (RPs) and sampling time involved in the radio map construction. Specifically, the radio map is constructed from a small number of calibrated fingerprints and a batch of user traces, which are sporadically collected in the target environment. The user traces enable to compensate for the effort of reducing the calibration cost as well as improving the effectiveness of radio map. In addition, the cubic spline interpolation approach is applied to enrich the radio map with the limited number of RPs. Extensive experiments show that the proposed approach is capable of not only reducing the effort of fingerprints calibration remarkably, but also guaranteeing the high localization accuracy.
DA  - 2017///
PY  - 2017
DO  - 10.1109/ACCESS.2017.267860
VL  - 5
SP  - 4388
EP  - 4400
SN  - 2169-3536
AN  - WOS:000402940400057
ER  - 

TY  - JOUR
TI  - Safe Artificial General Intelligence via Distributed Ledger Technology
AU  - Carlson, KW
T2  - BIG DATA AND COGNITIVE COMPUTING
AB  - Artificial general intelligence (AGI) progression metrics indicate AGI will occur within decades. No proof exists that AGI will benefit humans and not harm or eliminate humans. A set of logically distinct conceptual components is proposed that are necessary and sufficient to (1) ensure various AGI scenarios will not harm humanity, and (2) robustly align AGI and human values and goals. By systematically addressing pathways to malevolent AI we can induce the methods/axioms required to redress them. Distributed ledger technology (DLT, "blockchain") is integral to this proposal, e.g., "smart contracts" are necessary to address the evolution of AI that will be too fast for human monitoring and intervention. The proposed axioms: (1) Access to technology by market license. (2) Transparent ethics embodied in DLT. (3) Morality encrypted via DLT. (4) Behavior control structure with values at roots. (5) Individual bar-code identification of critical components. (6) Configuration Item (from business continuity/disaster recovery planning). (7) Identity verification secured via DLT. (8) "Smart" automated contracts based on DLT. (9) Decentralized applications-AI software modules encrypted via DLT. (10) Audit trail of component usage stored via DLT. (11) Social ostracism (denial of resources) augmented by DLT petitions. (12) Game theory and mechanism design.
DA  - 2019/09//undefined
PY  - 2019
DO  - 10.3390/bdcc3030040
VL  - 3
IS  - 3
SN  - 2504-2289
AN  - WOS:000697671000006
ER  - 

TY  - JOUR
TI  - A Survey of Technologies for Unmanned Merchant Ships
AU  - Wang, J
AU  - Xiao, Y
AU  - Li, TS
AU  - Chen, CLP
T2  - IEEE ACCESS
AB  - Unmanned merchant ships are ships that carry goods and engage in commercial activities without manual operations on board. In contrast to traditional merchant ships, unmanned merchant ships have great advantages in economy, society, and safety. However, we observe that commercial applications of unmanned ships are still at an exploratory stage. We believe that unmanned merchant ships will be widely adopted and popular in the near future. There is a need to have a good survey of current technologies, foundation, and obstacles of implementation of future unmanned merchant ships. Such a survey is beneficial to ship builders, researchers, owners, and students. Therefore, in this paper, we present a comprehensive survey of ship structure and technology, navigation, automation, algorithms, communication, Internet of Things (IOT), etc. We introduce traditional ships and analyze the role of crew and navigation operations on board. We summarize classifications, benefits, and core technologies of unmanned merchant ships. We review architecture, communication standards, security, essential technologies of IOT for unmanned merchant ships. Moreover, we introduce intelligent awareness, data fusion, applications, and E-navigation for unmanned merchant ships. We also present several future research directions at the end.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3044040
VL  - 8
SP  - 224461
EP  - 224486
SN  - 2169-3536
AN  - WOS:000604020900001
ER  - 

TY  - CONF
TI  - A WEB-BASED UNCERTAINTY PLUG-IN (WUPI) FOR FATIGUE LIFE PREDICTION BASED ON NDE DATA AND FRACTURE MECHANICS ANALYSIS
AU  - Fong, JT
AU  - Marcel, PV
AU  - Hedden, OF
AU  - Chao, YJB
AU  - Lam, PS
T2  - PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE, VOL 6, PTS A AND B
A2  - Rudland, DL
AB  - Over the last thirty years, much research has been done on the development and application of failure event databases, NDE databases, and material property databases for pressure vessels and piping, as reported in two recent symposia: (1) ASME 2007 PVP Symposium (in honor of the late Dr. Spencer Bush), San Antonio, Texas, on "Engineering Safety, Applied Mechanics, and Nondestructive Evaluation (NDE)." (2) ASME 2008 PVP Symposium, Chicago, Illinois, on "Failure Prevention via Robust Design and Continuous NDE Monitoring." The two symposia concluded that those three types of databases, if properly documented and maintained on a worldwide basis, could hold the key to the continued safe and reliable operation of numerous aging nuclear power or petrochemical processing plants. During the 2008 symposium, four uncertainty categories associated with causing uncertainty in fatigue life estimates were identified, namely, (1) Uncertainty-1 in failure event databases, (2) Uncertainty-2 in NDE databases, (3) Uncertainty-3 in material property databases, and (4) Uncertainty-M in crack-growth and damage modeling. In this paper, which is one of a series of four to address all those four uncertainty categories, we address Uncertainty-2 in NDE databases by developing a Web-based Uncertainty Plug-In (WUPI), which automates the uncertainty estimation algorithms of flaw sizing, fracture toughness, and crack growth vs. AK data such that NDE data from the field can be acted on by office engineers with a reduced feedback time for maintenance decision making.
DA  - 2010///
PY  - 2010
SP  - 1331
EP  - 1374
SN  - 978-0-7918-4369-7
AN  - WOS:000280407700145
ER  - 

TY  - JOUR
TI  - Residual Physics and Post-Posed Shielding for Safe Deep Reinforcement Learning Method
AU  - Zhang, QG
AU  - Bin Mahbod, MH
AU  - Chng, CB
AU  - Lee, PS
AU  - Chui, CK
T2  - IEEE TRANSACTIONS ON CYBERNETICS
AB  - Deep reinforcement learning (DRL) has been researched for computer room air conditioning unit control problems in data centers (DCs). However, two main issues limit the deployment of DRL in actual systems. First, a large amount of data is needed. Next, as a mission-critical system, safe control needs to be guaranteed, and temperatures in DCs should be kept within a certain operating range. To mitigate these issues, this article proposes a novel control method RP-SDRL. First, Residual Physics, built using the first law of thermodynamics, is integrated with the DRL algorithm and a Prediction Model. Subsequently, a Correction Model adapted from gradient descent is combined with the Prediction Model as Post-Posed Shielding to enforce safe actions. The RP-SDRL method was validated using simulation. Noise is added to the states of the model to further test its performance under state uncertainty. Experimental results show that the combination of Residual Physics and DRL can significantly improve the initial policy, sample efficiency, and robustness. Residual Physics can also improve the sample efficiency and the accuracy of the prediction model. While DRL alone cannot avoid constraint violations, RP-SDRL can detect unsafe actions and significantly reduce violations. Compared to the baseline controller, about 13% of electricity usage can be saved.
DA  - 2022/06/14/
PY  - 2022
DO  - 10.1109/TCYB.2022.3178084
SN  - 2168-2267
AN  - WOS:000826396900001
KW  - Safety
KW  - Predictive models
KW  - Atmospheric modeling
KW  - Cooling
KW  - Temperature distribution
KW  - Physics
KW  - Data center (DC) cooling
KW  - residual physics
KW  - safe deep reinforcement learning (DRL)
KW  - shielding
KW  - Thermodynamics
ER  - 

TY  - JOUR
TI  - Using Slightly Imbalanced Binary Classification to Predict the Efficiency of Winter Road Maintenance
AU  - Hatamzad, M
AU  - Pinerez, GP
AU  - Casselgren, J
T2  - IEEE ACCESS
AB  - The prediction of efficiency scores for winter road maintenance (WRM) is a challenging and serious issue in countries with cold climates. While effective and efficient WRM is a key contributor to maximizing road transportation safety and minimizing costs and environmental impacts, it has not yet been included in intelligent prediction methods. Therefore, this study aims to design a WRM efficiency classification prediction model that combines data envelopment analysis and machine learning techniques to improve decision support systems for decision-making units. The proposed methodology consists of six stages and starts with road selection. Real data are obtained by observing road conditions in equal time intervals via road weather information systems, optical sensors, and road-mounted sensors. Then, data preprocessing is performed, and efficiency scores are calculated with the data envelopment analysis method to classify the decision-making units into efficient and inefficient classes. Next, the WRM efficiency classes are considered targets for machine learning classification algorithms, and the dataset is split into training and test datasets. A slightly imbalanced binary classification case is encountered since the distributions of inefficient and efficient classes in the training dataset are unequal, with a low ratio between classes. The proposed methodology includes a comparison of different machine learning classification techniques. The graphical and numerical results indicate that the combination of a support vector machine and genetic algorithm yields the best generalization performance. The results include analyzing the variables that affect the WRM and using efficiency classes to drive future insights to improve the process of decision-making.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3131702
VL  - 9
SP  - 160048
EP  - 160063
SN  - 2169-3536
AN  - WOS:000728917600001
KW  - machine learning
KW  - Prediction algorithms
KW  - Decision making
KW  - Support vector machines
KW  - Learning algorithms
KW  - Real time systems
KW  - Classification (of information)
KW  - Roads and streets
KW  - Forecasting
KW  - Prediction methods
KW  - Decision support systems
KW  - Efficiency
KW  - Safety engineering
KW  - Statistical tests
KW  - Digital storage
KW  - Classification
KW  - Classification algorithm
KW  - Environmental impact
KW  - Support vectors machine
KW  - Genetic algorithms
KW  - Maintenance
KW  - Winter road maintenance
KW  - Machine learning classification
KW  - Binary classification
KW  - data envelopment analysis
KW  - Data envelopment analysis
KW  - Decision making unit
KW  - Maintenance efficiency
KW  - prediction methods
KW  - Road transportation safeties
KW  - road transportation safety
KW  - winter road maintenance
ER  - 

TY  - JOUR
TI  - Assessing occupational risk of heat stress at construction: A worker-centric wearable sensor-based approach
AU  - Shakerian, S
AU  - Habibnezhad, M
AU  - Ojha, A
AU  - Lee, G
AU  - Liu, YZ
AU  - Jebelli, H
AU  - Lee, S
T2  - SAFETY SCIENCE
AB  - Construction workers are at a high risk of exposure to excessive heat generated by several factors such as intensive physical activities, personal protective clothing, and frequent heat events at construction sites. Previous studies attempted to evaluate the occupational risk of heat stress by concentrating on environmental variables or the self-assessment measures of perceived heat. Despite their potentials, most of these approaches were intrusive, inaccurate, and intermittent. More importantly, they mainly overlooked the disparities in workers' physical and physiological characteristics. To address these limitations, this study proposes a heat-stress risk-assessment process to evaluate workers' bodily responses to heat - heat strain - based on the continuous measurement of their physiological signals. To this end, workers' physiological signals were captured using a wristband-type biosensor. Subsequently, their physiological signals were decontaminated from noises, resampled into an array of informative features, and finally interpreted into distinct states of individuals' heat strain by employing several supervised learning algorithms. To examine the performance of the proposed process, physiological signals were collected from 18 subjects while performing specific construction tasks under three predetermined environmental conditions with a different probability of exposure to heat stress. The analysis results revealed the proposed process could predict the risk of heat strain with more than 92% accuracy, illuminating the potentials of wearable biosensors to continuously assess workers' heat strain. The long-term implications of this study can be capitalized as guidelines to improve systematic evaluation of heat strain and promote workers' occupational safety and well-being through early detection of heat strain at construction sites.
DA  - 2021/10//undefined
PY  - 2021
DO  - 10.1016/j.ssci.2021.105395
VL  - 142
SN  - 0925-7535
AN  - WOS:000675899400034
KW  - risk assessment
KW  - Signal processing
KW  - signal processing
KW  - prediction
KW  - Supervised learning
KW  - Learning algorithms
KW  - adult
KW  - controlled study
KW  - female
KW  - human
KW  - human experiment
KW  - Risk assessment
KW  - Article
KW  - scoring system
KW  - Electrodermal activity
KW  - artificial neural network
KW  - probability
KW  - random forest
KW  - support vector machine
KW  - practice guideline
KW  - learning algorithm
KW  - Wearable sensors
KW  - classifier
KW  - Occupational risks
KW  - Workers'
KW  - Physiology
KW  - k nearest neighbor
KW  - Physiological models
KW  - Health risks
KW  - construction worker
KW  - occupational safety
KW  - noise
KW  - Petroleum reservoir evaluation
KW  - measurement accuracy
KW  - normal human
KW  - task performance
KW  - Signal-processing
KW  - occupational hazard
KW  - wellbeing
KW  - Biosensors
KW  - construction work
KW  - Construction worker' safety
KW  - Construction Workers' safety
KW  - Data-driven health monitoring
KW  - decontamination
KW  - Electrodermal activity (EDA)
KW  - Heat strains
KW  - heat stress
KW  - Occupational heat strain risk
KW  - Occupational Heat strain risk
KW  - Protective clothing
KW  - Skin temperature
KW  - Skin temperature (ST)
KW  - Supervised learning algorithm
KW  - Supervised learning algorithms
KW  - Thermal stress
KW  - Wearable biosensor
KW  - Wearable biosensors
KW  - work experience
ER  - 

TY  - CONF
TI  - What's fair is ... fair? Presenting JustEFAB, an ethical framework for operationalizing medical ethics and social justice in the integration of clinical machine learning
AU  - Mccradden, MD
AU  - Odusi, O
AU  - Joshi, S
AU  - Akrout, I
AU  - Ndlovu, K
AU  - Ben Glocker
AU  - Maicas, G
AU  - Liu, X
AU  - Mazwi, M
AU  - Garnett, T
AU  - Oakden-Rayner, L
AU  - Alfred, M
AU  - Sihlahla, I
AU  - Shafei, O
AU  - Goldenberg, A
AU  - ASSOC COMPUTING MACHINERY
T2  - PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023
AB  - The problem of algorithmic bias represents an ethical threat to the fair treatment of patients when their care involves machine learning (ML) models informing clinical decision-making. The design, development, testing, and integration of ML models therefore require a lifecycle approach to bias identification and mitigation efforts. Presently, most work focuses on the ML tool alone, neglecting the larger sociotechnical context in which these models operate. Moreover, the narrow focus on technical definitions of fairness must be integrated within the larger context of medical ethics in order to facilitate equitable care with ML. Drawing from principles of medical ethics, research ethics, feminist philosophy of science, and justice-based theories, we describe the Justice, Equity, Fairness, and Anti-Bias (JustEFAB) guideline intended to support the design, testing, validation, and clinical evaluation of ML models with respect to algorithmic fairness. This paper describes JustEFAB's development and vetting through multiple advisory groups and the lifecycle approach to addressing fairness in clinical ML tools. We present an ethical decision-making framework to support design and development, adjudication between ethical values as design choices, silent trial evaluation, and prospective clinical evaluation guided by medical ethics and social justice principles. We provide some preliminary considerations for oversight and safety to support ongoing attention to fairness issues. We envision this guideline as useful to many stakeholders, including ML developers, healthcare decision-makers, research ethics committees, regulators, and other parties who have interest in the fair and judicious use of clinical ML tools.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3593013.3594096
SP  - 1505
EP  - 1519
SN  - 978-1-4503-7252-7
AN  - WOS:001062819300124
KW  - Accountability
KW  - Machine learning
KW  - Decision making
KW  - Fairness
KW  - accountability
KW  - fairness
KW  - ethics
KW  - Machine-learning
KW  - Philosophical aspects
KW  - Patient treatment
KW  - Life cycle
KW  - Algorithmics
KW  - algorithmic bias
KW  - Algorithmic bias
KW  - clinical machine learning
KW  - Clinical machine learning
KW  - Clinical research
KW  - health policy
KW  - Health policy
KW  - healthcare
KW  - Healthcare
KW  - Integration testing
KW  - justice
KW  - Justice
KW  - Organisational
KW  - Organizational ethic
KW  - organizational ethics
KW  - safe deployment
KW  - Safe deployment
ER  - 

TY  - JOUR
TI  - Safe Reinforcement Learning Using Robust MPC
AU  - Zanon, M
AU  - Gros, S
T2  - IEEE TRANSACTIONS ON AUTOMATIC CONTROL
AB  - Reinforcement learning (RL) has recently impressed the world with stunning results in various applications. While the potential of RL is now well established, many critical aspects still need to be tackled, including safety and stability issues. These issues, while secondary for the RL community, are central to the control community that has been widely investigating them. Model predictive control (MPC) is one of the most successful control techniques because, among others, of its ability to provide such guarantees even for uncertain constrained systems. Since MPC is an optimization-based technique, optimality has also often been claimed. Unfortunately, the performance of MPC is highly dependent on the accuracy of the model used for predictions. In this article, we propose to combine RL and MPC in order to exploit the advantages of both, and therefore, obtain a controller that is optimal and safe. We illustrate the results with two numerical examples in simulations.
DA  - 2021/08//undefined
PY  - 2021
DO  - 10.1109/TAC.2020.3024161
VL  - 66
IS  - 8
SP  - 3638
EP  - 3652
SN  - 0018-9286
AN  - WOS:000678334500018
KW  - Reinforcement learning
KW  - Model predictive control
KW  - Predictive control systems
KW  - Optimality
KW  - Reinforcement learning (RL)
KW  - Control techniques
KW  - Constrained systems
KW  - Control community
KW  - Optimization-based techniques
KW  - robust model predictive control (MPC)
KW  - Robust mpc
KW  - safe policies
KW  - Safety and stabilities
ER  - 

TY  - JOUR
TI  - Deep Learning Methods for Vessel Trajectory Prediction Based on Recurrent Neural Networks
AU  - Capobianco, S
AU  - Millefiori, LM
AU  - Forti, N
AU  - Braca, P
AU  - Willett, P
T2  - IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS
AB  - Data-driven methods open up unprecedented possibilities for maritime surveillance using automatic identification system (AIS) data. In this work, we explore deep learning strategies using historical AIS observations to address the problem of predicting future vessel trajectories with a prediction horizon of several hours. We propose novel sequence-to-sequence vessel trajectory prediction models based on encoder-decoder recurrent neural networks (RNNs) that are trained on historical trajectory data to predict future trajectory samples given previous observations. The proposed architecture combines long short-term memory RNNs for sequence modeling to encode the observed data and generate future predictions with different intermediate aggregation layers to capture space-time dependencies in sequential data. Experimental results on vessel trajectories from an AIS dataset made freely available by the Danish Maritime Authority (DMA) show the effectiveness of deep learning methods for trajectory prediction based on sequence-to-sequence neural networks, which achieve better performance than baseline approaches based on linear regression or on the multilayer perceptron architecture. The comparative evaluation of results shows: first, the superiority of attention pooling over static pooling for the specific application, and second, the remarkable performance improvement that can be obtained with labeled trajectories, i.e., when predictions are conditioned on a low-level context representation encoded from the sequence of past observations, as well as on additional inputs (e.g., port of departure or arrival) about the vessel's high-level intention, which may be available from AIS.
DA  - 2021/12//undefined
PY  - 2021
DO  - 10.1109/TAES.2021.3096873
VL  - 57
IS  - 6
SP  - 4329
EP  - 4346
SN  - 0018-9251
AN  - WOS:000725819700062
ER  - 

TY  - JOUR
TI  - Distributed iterative learning coordination control for leader-follower uncertain non-linear multi-agent systems with input saturation
AU  - Yang, NN
AU  - Li, JM
T2  - IET CONTROL THEORY AND APPLICATIONS
AB  - In this study, the fully distributed adaptive iterative learning coordination control of the uncertain non-linear leader-follower multi-agent systems with input saturation is studied. Under the alignment initial condition and Lyapunov theory, a novel adaptive distributed control protocol with a fully saturated parameter learning law is designed. Despite the existence of input saturation, the global perfect consensus tracking can be realised over a finite time interval. Besides, the consensus tracking problem is extended to the formation control problem as well. Ultimately, the validity of theoretical analysis of this study is shown by two examples.
DA  - 2019/09/24/
PY  - 2019
DO  - 10.1049/iet-cta.2018.6268
VL  - 13
IS  - 14
SP  - 2252
EP  - 2260
SN  - 1751-8644
AN  - WOS:000484962100011
ER  - 

TY  - JOUR
TI  - Application of XGBoost for Hazardous Material Road Transport Accident Severity Analysis
AU  - Shen, XY
AU  - Wei, SS
T2  - IEEE ACCESS
AB  - Hazardous material road transport accidents pose a serious threat to public life, property and the environment. Therefore, studying the factors influencing road transport accidents involving hazardous materials can help identify the main causes behind them and contribute to the adoption of specific and targeted measures to reduce casualty rates and improve traffic safety. However, most existing research either adopted methods based on statistical analysis or neglected to further evaluate the spatial relationships. This study aims to use the eXtreme Gradient Boosting (XGBoost) algorithm to analyze hazardous material road transport accident data from seven regions of China. Considering the rarity of these events, the classification performance of different methods is compared based on precision, recall, F-score and Area Under Curve (AUC). The results indicate that the proposed XGBoost method has the best modeling performance. There is some variation between regions in the features that have a significant impact on accident severity. The influence of the same feature on the severity of an accident even varies from region to region. The aforementioned results provide a theoretical basis for exploring the issues, sustainability, challenges, and tasks of safe transportation activities for hazardous materials in the future. These results can help regions develop targeted prevention and response policies to efficiently reduce the incidence and severity of accidents.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3037922
VL  - 8
SP  - 206806
EP  - 206819
SN  - 2169-3536
AN  - WOS:000594419300001
ER  - 

TY  - JOUR
TI  - Choosing between prediction and explanation in geological engineering: lessons from psychology
AU  - Mitelman, A
AU  - Yang, B
AU  - Elmo, D
AU  - Giat, Y
T2  - INTERDISCIPLINARY SCIENCE REVIEWS
AB  - In their highly influential paper, Yarkoni, Tal, and Jacob Westfall. 2017. "Choosing Prediction over Explanation in Psychology: Lessons from Machine Learning." Perspectives on Psychological Science 12 (6):1100-1122. the authors highlight difficulties in traditional explanatory research in the field of psychology and argue in favour of novel data-driven science. By applying machine-learning methods to large data sets, predictive power has been shown to increase significantly. Geological engineers are responsible for a wide range of applications, including the design of tunnels, dams, foundations, and mines. While the field of geological engineering stands on solid mechanistic grounds, we argue that its predictive aspect aligns more closely with psychology than other mechanistic sciences. We therefore propose a paradigm shift in geological engineering research towards a prediction-centric approach. Potentially, this could enhance cost-effectiveness in structural design and lead to substantial societal savings.
DA  - 2023/10/02/
PY  - 2023
DO  - 10.1080/03080188.2023.2234216
SN  - 0308-0188
AN  - WOS:001041757900001
KW  - Machine learning
KW  - Psychology
KW  - Prediction
KW  - Machine-learning
KW  - Forecasting
KW  - Machine learning methods
KW  - Safety factor
KW  - Cost effectiveness
KW  - Structural design
KW  - Data driven
KW  - Large datasets
KW  - Data science
KW  - Explanatory model
KW  - Explanatory models
KW  - Factor of safety
KW  - Factors of safeties
KW  - Geological engineering
KW  - Geology
KW  - Mechanistics
KW  - Mining
KW  - Predictive power
KW  - Rock mechanics
ER  - 

TY  - CONF
TI  - Data-Driven Methods for Aviation Safety: From Data to Knowledge
AU  - Buselli, I
AU  - Oneto, L
AU  - Dambra, C
AU  - Gallego, CV
AU  - Martinez, MG
T2  - ADVANCES IN SYSTEM-INTEGRATED INTELLIGENCE, SYSINT 2022
A2  - Valle, M
A2  - Lehmhus, D
A2  - Gianoglio, C
A2  - Ragusa, E
A2  - Seminara, L
A2  - Bosse, S
A2  - Ibrahim, A
A2  - Thoben, KD
AB  - Demand upon the future Air Traffic Management (ATM) systems is expected to grow to possibly exceed available system capacity, pushing forward the need for automation and digitisation to maintain safety while increasing efficiency. This work focuses on a manifestation of ATM safety, the Loss of Separation (LoS), exploiting safety reports and ATM-system data (e.g., flights information, radar tracks, and Air Traffic Control events).
Current research on Data-Driven Models (DDMs) is rarely able to support safety practitioners in the process of investigation of an incident after it happened. Furthermore, integration between different sources of data (i.e., free-text reports and structured ATM data) is almost never exploited.
To fill these gaps, the authors propose (i) to automatically extract information from Safety Reports and (ii) to develop a DDM able to automatically assess if the Pilots or the Air Traffic Controller (ATCo) or both contributed to the incident, as soon as the LoS happens.
The LoSs' reported in the public database of the Comision de Estudio y Analisis de Notificaciones de Incidentes de Transito Aereo (CEANITA) support the authors' proposal.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-16281-7_13
VL  - 546
SP  - 126
EP  - 136
SN  - 2367-3370
AN  - WOS:000871881800013
KW  - Safety
KW  - Machine Learning
KW  - Safety reports
KW  - ATM
KW  - Data-Driven Models
KW  - Digitisation
KW  - Loss of Separation
KW  - Random Forests
ER  - 

TY  - JOUR
TI  - Adaptive Douglas-Peucker Algorithm With Automatic Thresholding for AIS-Based Vessel Trajectory Compression
AU  - Liu, JX
AU  - Li, HH
AU  - Yang, ZL
AU  - Wu, KF
AU  - Liu, Y
AU  - Liu, RW
T2  - IEEE ACCESS
AB  - Automatic identification system (AIS) is an important part of perfecting terrestrial networks, radar systems and satellite constellations. It has been widely used in vessel traffic service system to improve navigational safety. Following the explosion in vessel AIS data, the issues of data storing, processing, and analysis arise as emerging research topics in recent years. Vessel trajectory compression is used to eliminate the redundant information, preserve the key features, and simplify information for further data mining, thus correspondingly improving data quality and guaranteeing accurate measurement for ensuring navigational safety. It is well known that trajectory compression quality significantly depends on the threshold selection. We propose an Adaptive Douglas-Peucker (ADP) algorithm with automatic thresholding for AIS-based vessel trajectory compression. In particular, the optimal threshold is adaptively calculated using a novel automatic threshold selection method for each trajectory, as an improvement and complement of original Douglas-Peucker (DP) algorithm. It is developed based on the channel and trajectory characteristics, segmentation framework, and mean distance. The proposed method is able to simplify vessel trajectory data and extract useful information effectively. The time series trajectory classification and clustering are discussed and analysed based on ADP algorithm in this paper. To verify the reasonability and effectiveness of the proposed method, experiments are conducted on two different trajectory data sets in inland waterway of Yangtze River for trajectory classification based on the nearest neighbor classifier, and for trajectory clustering based on the spectral clustering. Comprehensive results demonstrate that the proposed algorithm can reduce the computational cost while ensuring the clustering and classification accuracy.
DA  - 2019///
PY  - 2019
DO  - 10.1109/ACCESS.2019.2947111
VL  - 7
SP  - 150677
EP  - 150692
SN  - 2169-3536
AN  - WOS:000497163000026
ER  - 

TY  - JOUR
TI  - Failure analysis and control of natural gas pipelines under excavation impact based on machine learning scheme
AU  - Xu, D
AU  - Chen, LQ
AU  - Yu, C
AU  - Zhang, S
AU  - Zhao, X
AU  - Lai, X
T2  - INTERNATIONAL JOURNAL OF PRESSURE VESSELS AND PIPING
AB  - Third-party excavation operations pose a serious threat to the safe operation of natural gas pipelines, and quantifying the failure conditions of pipelines can effectively identify the hazards of excavation operations. Considering the current lack of test data on the full-size critical conditions of pipelines under different failure modes, to make the research results have better field application, this study aims to develop a failure prediction model, which is adopted for predicting the failure modes of the pipeline under different excavation conditions in order to propose control strategies. In this work, finite element analysis is combined with machine learning algorithms. The finite element analysis process derives the critical loads for different failure modes of the pipe and establishes the failure condition data set. Correlation analysis and sensitivity analysis were employed to investigate the influence pattern of the features. The prediction performance of different machine learning combination algorithms was tested, and a hybrid data-driven prediction model was established and combined with the excavation equipment parameters to determine the risk level of the excavation equipment and the risk area of the operation. The results demonstrate that the critical load value for failure grows when the strength of the pipe increases. The four features of yield strength, strength limit, pipe diameter, and wall thickness exhibit the highest importance scores. The bucket tooth wedge angle only influences the magnitude of the puncture critical load, with correlation and sensitivity coefficients being 0.315 and 0.116, respectively. In the test of the combined algorithm, the RFECV-CSVR-NSGAIII algorithm built in this study has the highest generalization performance, the mean absolute error percentage (MAPE) is lower than 0.0476, the coefficient of determination R2 reaches over 0.9960, and the prediction model has excellent accuracy. The prediction model was subjected to case studies to obtain rapid identification of risk levels and operational risk areas of excavation equipment.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1016/j.ijpvp.2022.104870
VL  - 201
SN  - 0308-0161
AN  - WOS:000966323700001
KW  - Machine learning
KW  - Predictive models
KW  - Learning algorithms
KW  - Machine-learning
KW  - Forecasting
KW  - Risk assessment
KW  - Data driven
KW  - Sensitivity analysis
KW  - Finite element method
KW  - Risk analysis
KW  - Combinatorial algorithm
KW  - Data-driven predictive model
KW  - Excavation
KW  - Failure modes
KW  - Failure risk
KW  - Impact load
KW  - Impact loads
KW  - Machine learning combinatorial algorithm
KW  - Machine learning combinatorial algorithms
KW  - Natural gas
KW  - Natural gas pipelines
KW  - Quantifying failure risk analyse
KW  - Quantifying failure risk analysis
KW  - Safety of natural gas pipeline
KW  - Safety of natural gas pipelines
ER  - 

TY  - JOUR
TI  - AIS-Based Intelligent Vessel Trajectory Prediction Using Bi-LSTM
AU  - Yang, CH
AU  - Wu, CH
AU  - Shao, JC
AU  - Wang, YC
AU  - Hsieh, CM
T2  - IEEE ACCESS
AB  - Accurate vessel trajectory prediction is essential for maritime traffic control and management. In addition to collision avoidance, accurate vessel trajectory prediction can help in planning navigation routes, shortening the sailing distance, and increasing navigation efficiency. Vessel trajectory prediction with automatic identification system (AIS) data has thus attracted considerable attention in the maritime industry. Original AIS data may contain noise, which limits their application in real-world maritime traffic management. To overcome this problem, this study proposes a vessel trajectory prediction method that combines data denoising and a deep learning prediction model. In this method, data denoising is realized in three steps: trajectory separation, data denoising, and standardization. First, outliers from the original AIS data samples are removed, after which the moving average model is employed to further clean up the data; finally the denoised data are standardized into uniformly distributed time-series data. Bidirectional long short-term memory (Bi-LSTM) is then applied for vessel trajectory prediction. The performance of the proposed prediction model was verified using data on the trajectories of ten vessels and comparing the results obtained with those obtained using other prediction models (exponential smoothing, autoregressive integrated moving average, support vector regression, recurrent neural network, and LSTM models); the trajectory data were downloaded from a public AIS database. The experimental results revealed that model prediction accuracy increased after the data denoising process. Specifically, the Bi-LSTM model had the lowest mean absolute error, mean absolute percentage error, and root-mean-square error, demonstrating that the proposed method is highly efficient for trajectory prediction and can help vessel traffic controllers predict accurate vessel tracks; this would enable them to take early preventive measures to avoid collisions and thus improve the efficiency and safety of maritime traffic.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3154812
VL  - 10
SP  - 24302
EP  - 24315
SN  - 2169-3536
AN  - WOS:000766544100001
ER  - 

TY  - JOUR
TI  - Bayesian Global Optimization Gated Recurrent Unit Model for Human-Driven Vehicle Lane-Change Trajectory Prediction Considering Hyperparameter Optimization
AU  - Hu, XH
AU  - Chen, SZ
AU  - Zhao, JH
AU  - Cao, YS
AU  - Wang, R
AU  - Zhang, TT
AU  - Long, B
AU  - Xu, YM
AU  - Chen, XH
AU  - Zheng, MTY
AU  - Guo, JP
T2  - TRANSPORTATION RESEARCH RECORD
AB  - To address the low accuracy and inefficiency of current lane-change trajectory prediction methods for human-driven vehicles, this study develops a neural network lane-change trajectory prediction model with hyperparametric optimization capability using Bayesian optimization and gated recurrent units to consider the effect of lane-change intention on vehicle lane-change behavior and to predict it. The proposed model was instantiated using trajectory data of 8,721 vehicles. The results show that the overall recognition accuracy of intention recognition under the optimal input is 93.54%, and the recognition accuracy of keeping straight, left lane-change and right lane-change is 95.59%, 91.72%, and 93.30%, respectively. The root mean square errors of the predicted and actual trajectories to the left and to the right under the optimal input are 0.2582 and 0.2957, respectively. This paper demonstrates that, for the intention recognition module, the low-dimensional input enables the model to obtain high prediction accuracy, while for the trajectory prediction module, the high-latitude input enables the model to obtain a low prediction error. The developed trajectory prediction model can be used to assist in driving decision-making, path planning, and so forth.
DA  - 2023/07/10/
PY  - 2023
DO  - 10.1177/03611981231182390
SN  - 0361-1981
AN  - WOS:001025324800001
ER  - 

TY  - JOUR
TI  - Technological Sustainability and Artificial Intelligence Algor-ethics
AU  - Mantini, A
T2  - SUSTAINABILITY
AB  - Since 2018, a new terminology has been developed, called Algor-ethics, indicating the necessity for a dedicated study concerning the evaluation of an ethics applied to technology, to Algorithms and to Artificial Intelligence (AI). At the same time, since 1987, when the concept of sustainability was introduced, the discussion on this issue has become increasingly lively and has now spread to every area of life. In this paper, we would like to propose an application of the concept of sustainability to technological processes and in particular to the elaboration of AI systems. To reach this goal we will first try to build an ethical framework, here called Dynamical Techno-Algor-Ethical Composition, to define the interaction between the most important ethical ingredients involving the human person in relation to technology, taking a person-centered approach. Out of this will emerge a possible structure and definition of Technological Sustainability. The second step will consist of evaluating the process for the elaboration of an AI algorithm as a concrete application of the previously analyzed framework, to set ethical contents composing what we might call a good and sustainable algorithm.
DA  - 2022/03//undefined
PY  - 2022
DO  - 10.3390/su14063215
VL  - 14
IS  - 6
SN  - 2071-1050
AN  - WOS:000774435200001
ER  - 

TY  - JOUR
TI  - Modeling of Safe Distance Between Ship Routes and Offshore Wind Farm Based on Tolerable Collision Probability
AU  - Gao, HT
AU  - Xie, C
AU  - Liu, KZ
AU  - Chen, SZ
AU  - Zhou, L
AU  - Liu, Z
AU  - Wang, R
T2  - IEEE ACCESS
AB  - With the continuous increase of offshore wind farms and other offshore regional buildings, the contradiction between them and the navigation safety in the densely distributed areas of offshore ship tracks is increasingly obvious. It is urgent to build a safe distance model based on the actual sea condition to reduce the mutual influence. Based on the drift distance of ships in the boundary water areas of the wind farm under the actual meteorological and hydrological conditions, as well as the tolerable collision probability, reliability model and the normal distribution trend of ships in the ship routes, and the probability model of safe distance between ship routes and wind farm is built in the end. Based on the example and the tolerable collision probability of ships, the safe distance is analyzed, the analysis results show that the calculation model can determine the safe distance according to the control requirements of the collision probability between the ship and the offshore wind farm. In addition, the collision probability and the safe distance obtained are basically consistent with the safe distance published by the local maritime authority in combination with the changes of the output results caused by the velocity difference of the ship. The model lays a theoretical foundation on offshore wind farm site selection optimization, route boundary demarcation, ship safety and maritime supervision.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3187117
VL  - 10
SP  - 71777
EP  - 71790
SN  - 2169-3536
AN  - WOS:000838371500001
ER  - 

TY  - JOUR
TI  - Analysis of Failure Features of High-Speed Automatic Train Protection System
AU  - Kang, RW
AU  - Wang, JF
AU  - Chen, JQ
AU  - Zhou, JJ
AU  - Pang, YZ
AU  - Cheng, JF
T2  - IEEE ACCESS
AB  - An automatic train protection (ATP) system is the core to ensure operation safety of high-speed railway. At present, failure rate change rules of the system are not well understood and the maintenance strategy is not refined. In order to improve the protection capability and maintenance level of high-speed trains, this paper proposes a decision tree machine learning model for failure feature extraction of ATP systems. First, system type, mean operation mileage, mean service time, etc. are selected as ATP failure feature parameters, and cumulative failure rate is selected as a model output label. Second, support vector machine, AdaBoost, artificial neural networks and decision tree model are adopted to train and test practical failure data. Performance analysis shows that decision tree learning model has better generalization ability. The accuracy of 0.9761 is significantly greater than the other machine learning models. Therefore, it is most suitable for failure features analysis. Third, interpretability analysis reveals the quantitative relationship between system failure and features. Finally, an intelligent maintenance system for ATP systems is built, which realize the refined maintenance throughout life cycle.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3113381
VL  - 9
SP  - 128734
EP  - 128746
SN  - 2169-3536
AN  - WOS:000698841700001
ER  - 

TY  - JOUR
TI  - An innovative approach of determining the sample data size for machine learning models: a case study on health and safety management for infrastructure workers
AU  - Wang, HQ
AU  - Yi, W
AU  - Liu, YN
T2  - ELECTRONIC RESEARCH ARCHIVE
AB  - Numerical experiment is an essential part of academic studies in the field of transportation management. Using the appropriate sample size to conduct experiments can save both the data collecting cost and computing time. However, few studies have paid attention to determining the sample size. In this research, we use four typical regression models in machine learning and a dataset from transport infrastructure workers to explore the appropriate sample size. By observing 12 learning curves, we conclude that a sample size of 250 can balance model performance with the cost of data collection. Our study can provide a reference when deciding on the sample size to collect in advance.
DA  - 2022///
PY  - 2022
DO  - 10.3934/era.2022176
VL  - 30
IS  - 9
SP  - 3452
EP  - 3462
SN  - 2688-1594
AN  - WOS:000831864400001
KW  - Machine learning
KW  - Health and safety management
KW  - Learning curve
KW  - Sample size
KW  - Transportation infrastructure
ER  - 

TY  - JOUR
TI  - Automated Vehicle Identification Based on Car-Following Data With Machine Learning
AU  - Li, QW
AU  - Li, XP
AU  - Yao, HD
AU  - Liang, ZH
AU  - Xie, WJ
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Vehicles with adaptive cruise control, i.e., SAE Levels 1 and 2 automated vehicles (AVs), have been operating on roads with a significant and rapidly growing penetration rate. Identifying these AVs is critical to understanding near-future mixed traffic characteristics and managing highway mobility and safety. This study identifies adaptive cruise control-equipped vehicles from human-driven vehicles (HVs) by constructing a set of learning-based models using car-following trajectories in a short time window. It is extendible to Level 3 and $+$ AV identification when data is available. To compare model performance and draw physical insights, two physics-based models are proposed based on the premise that, in general, the car-following behavior of an AV is less volatile than an HV. Four car-following datasets, including AV makes from different manufacturers, are mixed to build a comprehensive identification model. Results show that physics-based approaches identify more than 80% AVs and 70% HVs. The identification accuracy of learning-based models is even higher. For example, the cluster-aware long short-term memory network identifies 98.79% of AVs and 95.45% of HVs. Learning-based identification models developed by this study can be integrated with the existing infrastructure (e.g., surveillance cameras), which have been used to extract car-following trajectories, to detect AVs in mixed traffic streams. This opens unparalleled data-driven opportunities to analyze and control mixed traffic to enhance safety (e.g., notifying surrounding traffic of the presence of AVs) and mobility (e.g., opening AV dedicated lanes when the percentage is great enough).
DA  - 2023/09/11/
PY  - 2023
DO  - 10.1109/TITS.2023.3304607
SN  - 1524-9050
AN  - WOS:001068964800001
KW  - Roads
KW  - Safety
KW  - Machine learning
KW  - Automation
KW  - Accidents
KW  - Vehicles
KW  - Trajectory
KW  - Data models
KW  - Behavioral science
KW  - Behavioral sciences
KW  - Learning systems
KW  - Automated vehicles
KW  - Behavioral research
KW  - Accident prevention
KW  - Machine learning models
KW  - Adaptive control systems
KW  - Adaptive cruise control
KW  - Highway accidents
KW  - adaptive cruise control
KW  - Trajectories
KW  - Road
KW  - Security systems
KW  - Car following
KW  - Automated vehicle identification
KW  - Automated vehicle identifications
KW  - car following
KW  - Global Positioning System
KW  - Identification modeling
KW  - Learning Based Models
KW  - machine learning model
KW  - Mixed traffic
KW  - physics-based model
KW  - Physics-based models
ER  - 

TY  - JOUR
TI  - A Data-Driven Indirect Approach for Predicting the Response of Existing Structures Induced by Adjacent Excavation
AU  - Li, LY
AU  - Sun, QX
AU  - Wang, YC
AU  - Gao, YH
T2  - APPLIED SCIENCES-BASEL
AB  - A data-driven indirect approach for predicting the response of existing structures induced by excavation is hereby proposed based on making full use of monitoring data during excavation, which can predict the deformation history of the research object during excavation. In this article, a machine-learning-based model framework for implementing the proposed approach is constructed and the treatment of key issues in the design and implementation of the proposed method is described in detail including the theoretical framework, the implementation mode of the method, the dimensionality reduction of the model parameters, and the normalization of data for model. On this basis, three models are provided to predict the settlement of buildings induced by adjacent excavation, namely the SVM model, BP model, and BP-SVM model. Relying on an excavation project for a subway in Xuzhou, Jiangsu Province, China, the proposed method is verified, and some conclusions are obtained.
DA  - 2023/03//undefined
PY  - 2023
DO  - 10.3390/app13063826
VL  - 13
IS  - 6
SN  - 2076-3417
AN  - WOS:000955127700001
KW  - machine learning
KW  - construction safety
KW  - data-driven indirect approach
KW  - excavation
KW  - prediction model of response
ER  - 

TY  - JOUR
TI  - Biosensors in Occupational Safety and Health Management: A Narrative Review
AU  - Baldassarre, A
AU  - Mucci, N
AU  - Lecca, LI
AU  - Tomasini, E
AU  - Parcias-do-Rosario, MJ
AU  - Pereira, CT
AU  - Arcangeli, G
AU  - Oliveira, PAB
T2  - INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
AB  - A sensor is a device used to gather information registered by some biological, physical or chemical change, and then convert the information into a measurable signal. The first biosensor prototype was conceived more than a century ago, in 1906, but a properly defined biosensor was only developed later in 1956. Some of them have reached the commercial stage and are routinely used in environmental and agricultural applications, and especially, in clinical laboratory and industrial analysis, mostly because it is an economical, simple and efficient instrument for the in situ detection of the bioavailability of a broad range of environmental pollutants. We propose a narrative review, that found 32 papers and aims to discuss the possible uses of biosensors, focusing on their use in the area of occupational safety and health (OSH).
DA  - 2020/04//undefined
PY  - 2020
DO  - 10.3390/ijerph17072461
VL  - 17
IS  - 7
SN  - 1660-4601
AN  - WOS:000530763300293
ER  - 

TY  - JOUR
TI  - ParaUDA: Invariant Feature Learning With Auxiliary Synthetic Samples for Unsupervised Domain Adaptation
AU  - Zhang, WW
AU  - Wang, JG
AU  - Wang, YT
AU  - Wang, FY
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Recognizing and locating objects by algorithms are essential and challenging issues for Intelligent Transportation Systems. However, the increasing demand for much labeled data hinders the further application of deep learning-based object detection. One of the optimal solutions is to train the target model with an existing dataset and then adapt it to new scenes, namely Unsupervised Domain Adaptation (UDA). However, most of existing methods at the pixel level mainly focus on adapting the model from source domain to target domain and ignore the essence of UDA to learn domain-invariant feature learning. Meanwhile, almost all methods at the feature level ignore to make conditional distributions matched for UDA while conducting feature alignment between source and target domain. Considering these problems, this paper proposes the ParaUDA, a novel framework of learning invariant representations for UDA in two aspects: pixel level and feature level. At the pixel level, we adopt CycleGAN to conduct domain transfer and convert the problem of original unsupervised domain adaptation to supervised domain adaptation. At the feature level, we adopt an adversarial adaption model to learn domain-invariant representation by aligning the distributions of domains between different image pairs with same mixture distributions. We evaluate our proposed framework in different scenes, from synthetic scenes to real scenes, from normal weather to challenging weather, and from scenes across cameras. The results of all the above experiments show that ParaUDA is effective and robust for adapting object detection models from source scenes to target scenes.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.1109/TITS.2022.3176397
VL  - 23
IS  - 11
SP  - 20217
EP  - 20229
SN  - 1524-9050
AN  - WOS:000880752900025
ER  - 

TY  - JOUR
TI  - HackGAN: Harmonious Cross-Network Mapping Using CycleGAN With Wasserstein-Procrustes Learning for Unsupervised Network Alignment
AU  - Yang, LY
AU  - Wang, X
AU  - Zhang, J
AU  - Yang, J
AU  - Xu, YC
AU  - Hou, JC
AU  - Xin, KJ
AU  - Wang, FY
T2  - IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
AB  - Network alignment (NA) that identifies equivalent nodes across networks is an effective tool for integrating knowledge from multiple networks. The state-of-the-art NA methods learn inter-network node similarities based on labeled anchor links, which are costly, time-consuming, and difficult to acquire. Therefore, a few unsupervised network alignment (UNA) methods propose solving NA problems without anchor links. However, most existing UNA methods rely on discriminative attributes to capture nodes' similarities and are hard to obtain optimal one-to-one alignments. Toward these issues, this article proposes a novel method named HackGAN to solve the UNA problem solely based on the structural information. Specifically, HackGAN represents nodes with embeddings based on an unsupervised graph neural network (GNN) to capture their global and local structural features. After that, it initializes mapping functions to transform the embedding spaces of different networks into the same vector space by iteratively solving the Wasserstein-Procrustes problem. The mapping functions are then refined by an adversarial model with cycle-consistency and Sinkhorn distance losses to obtain optimized one-to-one mappings. Based on the distances between mapped embeddings, accurate and robust results are obtained with a collective alignment algorithm. Experimental comparisons on both synthetic and real-world datasets demonstrate the superiority of HackGAN.
DA  - 2023/04//undefined
PY  - 2023
DO  - 10.1109/TCSS.2022.3144350
VL  - 10
IS  - 2
SP  - 746
EP  - 759
SN  - 2329-924X
AN  - WOS:000751481300001
ER  - 

TY  - CONF
TI  - Tensor-based Relational Learning for Ontology Matching
AU  - Szwabe, A
AU  - Misiorek, P
AU  - Walkowiak, P
T2  - ADVANCES IN KNOWLEDGE-BASED AND INTELLIGENT INFORMATION AND ENGINEERING SYSTEMS
A2  - Grana, M
A2  - Toro, C
A2  - Posada, J
A2  - Howlett, RJ
A2  - Jain, LC
AB  - In this paper we propose the Tensor-based Reflective Relational Learning System (TRRLS) as a first tensor-based approach to decision support in the area of ontology alignment. The system may be seen as realizing a probabilistic inference with regard to the relation representing the 'semantic equivalence' of ontology classes or their properties. Despite the fact that TRRLS is based on the new idea of algebraic modeling of multi-relational data, it provides similar results to the best approaches of the Ontology Alignment Evaluation Initiative (OAEI) competitors to the task of matching concepts of Adult Mouse Anatomy ontology and NCI Thesaurus ontology on the basis of partially known expert matches.
DA  - 2012///
PY  - 2012
DO  - 10.3233/978-1-61499-105-2-509
VL  - 243
SP  - 509
EP  - 518
SN  - 0922-6389
AN  - WOS:000332936700052
ER  - 

TY  - JOUR
TI  - Misbehavior Detection for Position Falsification Attacks in VANETs Using Machine Learning
AU  - Ercan, S
AU  - Ayaida, M
AU  - Messai, N
T2  - IEEE ACCESS
AB  - Cooperative Intelligent Transport Systems (C-ITS) is an advanced technology for road safety and traffic efficiency over Vehicular Ad Hoc Networks (VANETs) allowing vehicles to communicate with other vehicles or infrastructures. The security of VANETs is one of the main concerns in C-ITS because there may be some attacks in such type of network that may endanger the safety of the passengers. Intrusion Detection Systems (IDS) play an important role to protect the vehicular network by detecting misbehaving vehicles. In general, the works in the literature use the same well-known features in a centralized IDS. In this paper, we propose a Machine Learning (ML) mechanism that takes advantage of three new features, which are mainly related to the sender position, allowing to enhance the performances of IDS for position falsification attacks. Besides, it presents a comparison of two different ML methods for classification, i.e. k-Nearest Neighbor (kNN) and Random Forest (RF) that are used to detect malicious vehicles using these features. Finally, Ensemble Learning (EL) which combines different ML methods, in our case kNN and RF, is also carried out to improve the detection performance. An IDS is constructed allowing vehicles to detect misbehavior in a distributed way, while the detection mechanism is trained centrally. The results demonstrate that the proposed mechanism gives better results, in terms of classification performance indicators and computational time, than the best previous approaches on average.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2021.3136706
VL  - 10
SP  - 1893
EP  - 1904
SN  - 2169-3536
AN  - WOS:000739982900001
ER  - 

TY  - JOUR
TI  - ON THE POSSIBILITY OF DOCTRINAL PERCEPTION OF ARTIFICIAL INTELLIGENCE AS THE SUBJECT OF CRIME IN THE SYSTEM OF COMMON LAW: USING THE EXAMPLE OF THE U.S. CRIMINAL LEGISLATION
AU  - Shestak, VA
AU  - Volevodz, AG
AU  - Alizade, VA
T2  - RUSSIAN JOURNAL OF CRIMINOLOGY
AB  - The authors examine the possibility of holding artificial intelligence (AI) criminally liable under the current U.S. criminal legislation and study the opinions of Western lawyers who believe that this possibility for a machine controlled by AI may become reality in the near future. They analyze the requirements for criminal liability as determined by American legislators: a willful unlawful act or omission of an act (actus reus), criminal intent (mens rea), i.e. the person knowingly commits a criminal act or is negligent, as well as three basic models of AI's criminal liability. In the first model, a crime is committed through the actions of another person, i.e. the cases when the subject of crime does not have sufficient cognitive abilities to understand the criminal intent and, moreover, to be guided by it. This category of persons includes minors, persons with limited legal capacity and modern cybernetic systems, who cannot be viewed as capable of cognition that equals human cognition. The latter are considered to be innocent of a criminal act because their actions are controlled by an algorithm or a person who has indirect program control. In the second model, a crime is committed by a being who is objectively guilty of it. A segment of the program code in intellectual systems allows for some illegal act by default, for example, includes a command to unconditionally destroy all objects that the system recognizes as dangerous for the purpose that such AI is working to fulfill. According to this model, the person who gives the unlawful command should be held liable. If such a "collaborator" is not hidden, criminal liability should be imposed on the person who gives an unlawful command to the system, not on the performer, because the algorithmic system that determines the actions of the performer is itself unlawful. Thus, criminal liability in this case should be imposed on the persons who write or use the program, on the condition that they were aware of the unlawfulness of orders that guide the actions of the performer. Such crimes include acts that are criminal but cannot be prevented by the performer - the AI system. In the third model, AI is directly liable for the acts that contain both a willful action and the unlawful intent of the machine. Such liability is possible if AI is recognized as a subject of criminal law, and also if it independently works out an algorithm to commit an act leading to publically dangerous consequences, or if such consequences are the result of the system's omission to act according to the initial algorithm, i.e. if its actions are willful and guilty.
DA  - 2019///
PY  - 2019
DO  - 10.17150/2500-4255.2019.13(4).547-554
VL  - 13
IS  - 4
SP  - 547
EP  - 554
SN  - 2500-4255
AN  - WOS:000483323500002
ER  - 

TY  - JOUR
TI  - Deep Multiadversarial Conditional Domain Adaptation Networks for Fault Diagnostics of Industrial Equipment
AU  - Wang, BS
AU  - Baraldi, P
AU  - Zio, E
T2  - IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB  - Deep learning methods of fault diagnostics require the availability of a large amount of labeled data for training, i.e., signal values corresponding to known degradation and fault states. Furthermore, the distribution of the training data should be similar to that of the (test) data collected in the field. Since these conditions are typically not satisfied in most industrial applications, this article develops a deep multiadversarial conditional domain adaptation network. The main original contribution lies in a novel method to align, class by class, the weighted marginal data distributions using multiple domain discriminators. The network allows overtaking the classification underperformance caused by the problem of negative transfer, which is typically encountered when only few training data of some of the classes are available. The proposed method is shown to outperform other state-of-the-art methods on two cross-domain fault diagnostic case studies, verified by applying Friedman and Holm post-hoc tests.
DA  - 2023/08//undefined
PY  - 2023
DO  - 10.1109/TII.2022.3222400
VL  - 19
IS  - 8
SP  - 8841
EP  - 8851
SN  - 1551-3203
AN  - WOS:001030673600027
KW  - Deep learning
KW  - Task analysis
KW  - Data mining
KW  - Transfer learning
KW  - Features extraction
KW  - Job analysis
KW  - Fleet operations
KW  - Classification (of information)
KW  - Information management
KW  - Railroad transportation
KW  - Prognostic and health management
KW  - Domain adaptation
KW  - Automatic doors
KW  - Bearing
KW  - bearings
KW  - conditional domain adaptation
KW  - Conditional domain adaptation
KW  - deep transfer learning
KW  - Deep transfer learning
KW  - distribution alignment
KW  - Distribution alignment
KW  - fault diagnostics
KW  - Faults diagnostics
KW  - Fleet of machine
KW  - fleet of machines
KW  - Multi-adversarial domain adaptation
KW  - multiadversarial domain adaptation
KW  - negative transfer
KW  - Negative transfer
KW  - railway industry
KW  - Railway industry
ER  - 

TY  - JOUR
TI  - Deep learning-based helmet wear analysis of a motorcycle rider for intelligent surveillance system
AU  - Yogameena, B
AU  - Menaka, K
AU  - Perumaal, SS
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - Automatic helmet wear analysis of a motorcycle rider is a promising video surveillance application, as the helmets are indispensable for saving the lives of humans from head injuries during road accidents. This article presents an intelligent video surveillance system for automatically detecting the motorcyclists with and without safety helmets. If the motorcyclists are found without the helmet, his/her license plate (LP) number is recognised to initiate further actions such as deduction of penalty amount from one's account linked with the vehicle license and Aadhar Number (Applicable to Indian Scenario) by the traffic police and the legal authority. First, the foreground objects are segmented, using Gaussian mixture model (GMM) and then labelled. Afterwards, the proposed system adapts faster region-based convolutional neural network (faster R-CNN) for the detection of motorcycles in the labelled foreground objects to ensure the presence of motorcyclists. Subsequently, faster R-CNN is also used for the detection of the motorcyclists with and without helmet. Finally, the LP number of the motorcyclists without the helmet is recognised, using character-sequence encoding CNN model and spatial transformer (ST). The proposed framework is evaluated, using the performance metric and mean average precision (mAP) on the surveillance dataset and it outperforms the state-of-the-art algorithms.
DA  - 2019/07//undefined
PY  - 2019
DO  - 10.1049/iet-its.2018.5241
VL  - 13
IS  - 7
SP  - 1190
EP  - 1198
SN  - 1751-956X
AN  - WOS:000473239700015
ER  - 

TY  - JOUR
TI  - Quantifying the Vulnerability of Attributes for Effective Privacy Preservation Using Machine Learning
AU  - Majeed, A
AU  - Hwang, SO
T2  - IEEE ACCESS
AB  - Personal data have been increasingly used in data-driven applications to improve quality of life. However, privacy preservation of personal data while sharing it with analysts/ researchers has become an essential requirement to be met by data owners (hospitals, banks, insurance companies, etc.). The existing literature on privacy preservation does not precisely quantify the vulnerability of each item among user attributes, thereby leading to explicit privacy disclosures and poor data utility during published data analytics. In this work, we propose and implement an automated way of quantifying the vulnerability of each item among the attributes by using a machine learning (ML) technique to significantly preserve the privacy of users without degrading data utility. Our work can solve four technical problems in the privacy preservation field: optimization of the privacy-utility trade-off, privacy guarantees (i.e., safeguard against identity and sensitive information disclosures) in imbalanced data (or clusters), over-anonymization issues, and rectifying or enabling the applicability of prior privacy models when data have skewed distributions. The experiments were performed on two real-world benchmark datasets to prove the feasibility of the concept in practical scenarios. Compared with state-of-the-art (SOTA) methods, the proposed method effectively preserves the equilibrium between utility and privacy in the anonymized data. Furthermore, our method can significantly contribute towards responsible data science (extracting enclosed knowledge from data without violating subjects' privacy) by controlling higher changes in data during its anonymization.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ACCESS.2023.3235016
VL  - 11
SP  - 4400
EP  - 4411
SN  - 2169-3536
AN  - WOS:000917220900001
KW  - machine learning
KW  - privacy
KW  - Artificial intelligence
KW  - Privacy
KW  - Learning systems
KW  - Machine-learning
KW  - Economic and social effects
KW  - Insurance
KW  - Trade off
KW  - Vulnerability
KW  - Responsible data science
KW  - vulnerability
KW  - Information filtering
KW  - Utility
KW  - anonymization
KW  - Anonymization
KW  - Code
KW  - Data owner
KW  - data owners
KW  - imbalanced data
KW  - Imbalanced data
KW  - Information integrity
KW  - Personal data
KW  - privacy models
KW  - Privacy models
KW  - privacy-utility trade-off
KW  - Privacy-utility trade-off
KW  - responsible data science
KW  - Sensitive data
KW  - utility
ER  - 

TY  - JOUR
TI  - Machine Learning Approaches for Radio Propagation Modeling in Urban Vehicular Channels
AU  - Ahmad, K
AU  - Hussain, S
T2  - IEEE ACCESS
AB  - The use of vehicular communications is anticipated to improve safety in road traffic. The traditional radio channel models that describe the effects of radio wave propagation in dynamic vehicular environments have their own limitations. In this paper, machine learning (ML) techniques are applied for radio channel modeling in urban vehicular environments. A large data set of path loss (PL) and root-mean-square Delay spread (RMS-DS) is computed using ray-tracing for a Line-of-Sight (LOS) straight road and a Non-Line-of-Sight (NLOS) intersection road scenario. Fourteen input features are used to train three ML models for vehicular channel prediction. The models considered in this work include Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN), and Random Forest (RF). The results show that RF gives better performance than MLP and CNN models in the prediction of PL and RMS-DS in urban vehicular channels.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3218622
VL  - 10
SP  - 113690
EP  - 113698
SN  - 2169-3536
AN  - WOS:000880601700001
ER  - 

TY  - JOUR
TI  - INNOVATIVE TECHNOLOGIES FOR DRILLING MUD LOSS PREVENTION IN WELL CONSTRUCTION
AU  - Chernikov, AD
AU  - Eremin, NA
AU  - Zamriy, AV
AU  - Chernykh, SP
T2  - PROCEEDINGS OF THE TULA STATES UNIVERSITY-SCIENCES OF EARTH
AB  - The article discusses the issues of preventing complications associated with the absorption of drilling mud during the construction of oil and gas wells, poses and provides solutions to the problem of ensuring the safety of the construction of oil and gas wells on land and at sea using intelligent systems for early warning of complications in the form of losses of drilling mud according to results of processing large volumes of data from stations of geological and technological measurements. The advantage of using machine learning methods for solving the problems of identifying and predicting complications in the form of drilling mud losses during the construction of oil and gas wells is that in the course of their creation and training, explicit and hidden patterns are revealed with a given accuracy between geological and geophysical, technical and technological parameters. Efficient formation, integration and clustering of ever-increasing multidimensional data volumes from various types of sensors used to measure parameters in the process of drilling wells are carried out using machine learning technologies. Loss prevention is one of the promising areas for smart microcontainer technology. The use of smart microcontainers technology will significantly increase the efficiency of the lost circulation elimination process, which will lead to a significant reduction in well drilling costs.
DA  - 2022///
PY  - 2022
DO  - 10.46689/2218-5194-2022-2-1-399-414
VL  - 2
SP  - 399
EP  - 414
SN  - 2218-5194
AN  - WOS:000883155200034
ER  - 

TY  - JOUR
TI  - Pre-deployment assessment of an AI model to assist radiologists in chest X-ray detection and identification of lead-less implanted electronic devices for pre-MRI safety screening: realized implementation needs and proposed operational solutions
AU  - White, RD
AU  - Demirer, M
AU  - Gupta, V
AU  - Sebro, RA
AU  - Kusumoto, FM
AU  - Erdal, BS
T2  - JOURNAL OF MEDICAL IMAGING
AB  - Purpose: Chest X-ray (CXR) use in pre-MRI safety screening, such as for lead-less implanted electronic device (LLIED) recognition, is common. To assist CXR interpretation, we "pre-deployed" an artificial intelligence (AI) model to assess (1) accuracies in LLIED-type (and consequently safety-level) identification, (2) safety implications of LLIED nondetections or misidentifications, (3) infrastructural or workflow requirements, and (4) demands related to model adaptation to real-world conditions.
Approach: A two-tier cascading methodology for LLIED detection/localization and identification on a frontal CXR was applied to evaluate the performance of the original nine-class AI model. With the unexpected early appearance of LLIED types during simulated real-world trialing, retraining of a newer 12-class version preceded retrialing. A zero footprint (ZF) graphical user interface (GUI)/viewer with DICOM-based output was developed for inference-result display and adjudication, supporting end-user engagement and model continuous learning and/or modernization.
Results: During model testing or trialing using both the nine-class and 12-class models, robust detection/localization was consistently 100%, with mAP 0.99 from fivefold cross-validation. Safety-level categorization was high during both testing (AUC >= 0.98 and >= 0.99, respectively) and trialing (accuracy 98% and 97%, respectively). LLIED-type identifications by the two models during testing (1) were 98.9% and 99.5% overall correct and (2) consistently showed AUC >= 0.92 (1.00 for 8/9 and 9/12 LLIED-types, respectively). Pre-deployment trialing of both models demonstrated overall type-identification accuracies of 94.5% and 95%, respectively. Of the small number of misidentifications, none involved MRI-stringently conditional or MRI-unsafe types of LLIEDs. Optimized ZF GUI/viewer operations led to greater user-friendliness for radiologist engagement.
Conclusions: Our LLIED-related AI methodology supports (1) 100% detection sensitivity, (2) high identification (including MRI-safety) accuracy, and (3) future model deployment with facilitated inference-result display and adjudication for ongoing model adaptation to future real-world experiences. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 International License.
DA  - 2022/09/01/
PY  - 2022
DO  - 10.1117/1.JMI.9.5.054504
VL  - 9
IS  - 5
SN  - 2329-4302
AN  - WOS:000877016000013
ER  - 

TY  - JOUR
TI  - Fullest COLREGs Evaluation Using Fuzzy Logic for Collaborative Decision-Making Analysis of Autonomous Ships in Complex Situations
AU  - Bakdi, A
AU  - Vanem, E
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Maritime Autonomous Surface Ships (MASSs) will reshape the fast-evolving ecosystem for their attractive socio-economic benefits and potential to improve safety. However, their new systems and technology need thorough verifications to identify unintended components of risk. The interaction between MASS cyber-physical systems and the existing regulatory framework is currently unpredictable; AI-powered intelligent situation awareness and autonomous navigation algorithms must safely and efficiently adhere to the regulations which are only designed for human interpretation without MASSs consideration. This paper contributes to algorithmic regulations and particularly algorithmic COLREGs in real-world MASS applications. It focuses on codifying COLREGs into a machine-executable system applicable to MASSs. This fullest COLREGs evaluation is modelled in form of a fuzzy expert system based on ordinary seamanship practice. The full input space spans 21 features derived from maneuverability-dependent risk, AIS traffic data, vessel information, maps and nautical charts, water-depth, visibility, and sea conditions. The model assesses pairwise vessel encounters over the full time-window of a situation from entrance to exit. 42 fuzzy rules are designed in 6 criteria that represent COLREGs Rules 2-19 and model their logical connections, priorities, and relationships. This algorithmic COLREGs form satisfies the crucial needs in simulation, collision-avoidance, complexity monitoring, and compliance quantification in MASS applications. The fullest COLREGs evaluation model is verified on a large database of historical encounters using real data from multiple sources.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1109/TITS.2022.3151826
VL  - 23
IS  - 10
SP  - 18433
EP  - 18445
SN  - 1524-9050
AN  - WOS:000767810000001
ER  - 

TY  - CONF
TI  - ARTIFICIAL INTELLIGENCE (Al) TOOLS FOR DATA ACQUISITION AND PROBABILITY RISK ANALYSIS OF NUCLEAR PIPING FAILURE DATABASES (*)
AU  - Marcel, PV
AU  - Fong, JT
AU  - Yamagata, N
T2  - PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE, VOL 6, PTS A AND B
A2  - Rudland, DL
AB  - Over the last thirty years, much research has been done on the development and application of in-service inspection (ISI) and failure event databases for pressure vessels and piping, as reported in two recent symposia: (1) ASME 2007 PVP Symposium (in honor of the late Dr. Spencer Bush), San Antonio, Texas, on "Engineering Safety, Applied Mechanics, and Nondestructive Evaluation (NDE)." (2) ASME 2008 PVP Symposium, Chicago, Illinois, on "Failure Prevention via Robust Design and Continuous NDE Monitoring." The two symposia concluded that those databases, if properly documented and maintained on a worldwide basis, could hold the key to the continued safe and profitable operation of numerous aging nuclear power or petro-chemical processing plants. During the 2008 symposium, four uncertainty categories associated with causing uncertainty in fatigue life estimates were identified, namely, (1) Uncertainty-1 in failure event databases, (2) Uncertainty-2 in NDE databases, (3) Uncertainty-3 in material property databases, and (4) Uncertainty-M in crack-growth and damage modeling. In this paper, which is one of a series of four to address all those four uncertainty categories, we introduce an automatic natural language abstracting and processing (ANLAP) tool to address Uncertainty-1. Three examples are presented and discussed.
DA  - 2010///
PY  - 2010
SP  - 1613
EP  - 1649
SN  - 978-0-7918-4369-7
AN  - WOS:000280407700170
ER  - 

TY  - JOUR
TI  - Improving Robot Proficiency Self-Assessment via Meta-Assessment
AU  - Cao, X
AU  - Crandall, JW
AU  - Goodrich, MA
T2  - IEEE ROBOTICS AND AUTOMATION LETTERS
AB  - Proficiency self-assessment (PSA), which is the ability to estimate how likely one can complete a task, is a beneficial property for autonomous robots. Prior work developed the assumption-alignment tracking (AAT) method for PSA, which estimates the probability that a robot will successfully complete a task. This letter refers to the prediction made by AAT as the first-level assessment (FLA), and further proposes a second-level assessment (SLA) that determines whether the FLA prediction is correct. The probability that the FLA prediction is correct is conditioned on four features: 1) the mean distance from a test sample to its nearest neighbors in the training set; 2) the predicted probability of success made by the FLA; 3) the ratio between the robot's current performance and its performance standard; and 4) the percentage of the task the robot has already completed. The SLA model is trained on the four features using a Random Forest algorithm. It is evaluated by two metrics: discriminability, measured by the area under the ROC curve, and calibration, measured using expected calibration error. On a simulated navigation task and a manipulation task by a Sawyer robot, results demonstrate that the SLA model not only calibrates the FLA model as well as existing calibration methods (Platt calibration and isotonic regression), but also produces very high discriminability even if the FLA model's original discriminability is much lower. Results also indicate the usefulness of each of the four features used by the SLA model.
DA  - 2023/11//undefined
PY  - 2023
DO  - 10.1109/LRA.2023.3316896
VL  - 8
IS  - 11
SP  - 7297
EP  - 7303
SN  - 2377-3766
AN  - WOS:001078079600007
ER  - 

TY  - JOUR
TI  - Past, present, and future of sustainable finance: insights from big data analytics through machine learning of scholarly research
AU  - Kumar, S
AU  - Sharma, D
AU  - Rao, SD
AU  - Lim, WM
AU  - Mangla, SK
T2  - ANNALS OF OPERATIONS RESEARCH
AB  - Sustainable finance is a rich field of research. Yet, existing reviews remain limited due to the piecemeal insights offered through a sub-set rather than the entire corpus of sustainable finance. To address this gap, this study aims to conduct a large-scale review that would provide a state-of-the-art overview of the performance and intellectual structure of sustainable finance. To do so, this study engages in a review of sustainable finance research using big data analytics through machine learning of scholarly research. In doing so, this study unpacks the most influential articles and top contributing journals, authors, institutions, and countries, as well as the methodological choices and research contexts for sustainable finance research. In addition, this study reveals insights into seven major themes of sustainable finance research, namely socially responsible investing, climate financing, green financing, impact investing, carbon financing, energy financing, and governance of sustainable financing and investing. To drive the field forward, this study proposes several suggestions for future sustainable finance research, which include developing and diffusing innovative sustainable financing instruments, magnifying and managing the profitability and returns of sustainable financing, making sustainable finance more sustainable, devising and unifying policies and frameworks for sustainable finance, tackling greenwashing of corporate sustainability reporting in sustainable finance, shining behavioral finance on sustainable finance, and leveraging the power of new-age technologies such as artificial intelligence, blockchain, internet of things, and machine learning for sustainable finance.
DA  - 2022/01/04/
PY  - 2022
DO  - 10.1007/s10479-021-04410-8
SN  - 0254-5330
AN  - WOS:000737710700001
KW  - Machine learning
KW  - Governance
KW  - Big data analytics
KW  - Bibliometric analysis
KW  - Systematic literature review
KW  - Carbon financing
KW  - Climate financing
KW  - Energy financing
KW  - Green financing
KW  - Impact investing
KW  - Socially responsible investing
KW  - Sustainable development goals
KW  - Sustainable finance
ER  - 

TY  - JOUR
TI  - Automated decision-making in the EU Member States: The right to explanation and other "suitable safeguards" in the national legislations
AU  - Malgieri, G
T2  - COMPUTER LAW & SECURITY REVIEW
AB  - The aim of this paper is to analyse the very recently approved national Member States' laws that have implemented the GDPR in the field of automated decision-making (prohibition, exceptions, safeguards): all national legislations have been analysed and in particular 9 Member States Law address the case of automated decision making providing specific exemptions and relevant safeguards, as requested by Article 22(2)(b) of the GDPR (Belgium, The Netherlands, France, Germany, Hungary, Slovenia, Austria, the United Kingdom, Ireland).
The approaches are very diverse: the scope of the provision can be narrow (just automated decisions producing legal or similarly detrimental effects) or wide (any decision with a significant impact) and even specific safeguards proposed are very diverse.
After this overview, this article will also address the following questions: are Member States free to broaden the scope of automated decision-making regulation? Are 'positive decisions' allowed under Article 22, GDPR, as some Member States seem to affirm? Which safeguards can better guarantee rights and freedoms of the data subject?
In particular, while most Member States refers just to the three safeguards mentioned at Article 22(3) (i.e. subject's right to express one's point of view; right to obtain human intervention; right to contest the decision), three approaches seem very innovative: a) some States guarantee a right to legibility/explanation about the algorithmic decisions (France and Hungary); b) other States (Ireland and United Kingdom) regulate human intervention on algorithmic decisions through an effective accountability mechanism (e.g. notification, explanation of why such contestation has not been accepted, etc.); c) another State (Slovenia) require an innovative form of human rights impact assessments on automated decision-making. (C) 2019 The Authors. Published by Elsevier Ltd.
DA  - 2019/10//undefined
PY  - 2019
DO  - 10.1016/j.clsr.2019.05.002
VL  - 35
IS  - 5
SN  - 0267-3649
AN  - WOS:000491685200002
ER  - 

TY  - CONF
TI  - DESIGN OF A PYTHON-BASED PLUG-IN FOR BENCHMARKING PROBABILISTIC FRACTURE MECHANICS COMPUTER CODES WITH FAILURE EVENT DATA (*)
AU  - Fong, JT
AU  - Marcal, PV
AU  - Heckert, NA
AU  - Dewit, R
AU  - Filliben, JJ
AU  - Gosselin, SR
T2  - PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE, VOL 6, PTS A AND B
A2  - Rudland, DL
AB  - In a 2007 paper entitled "Application of Failure Event Data to Benchmark Probabilistic Fracture Mechanics (PFM) Computer Codes" (Simonen, F. A., Gosselin, S. R., Lydell, B. O. Y, Rudland, D. L., & Wikowski, G. M. Proc. ASME PVP Conf., San Antonio, TX, Paper PVP2007-26373), it was reported that the two benchmarked PFM models, PRO-LOCA and PRAISE, predicted significantly higher failure probabilities of cracking than those derived from field data in three PWR and one BWR cases by a factor ranging from 30 to 10,000. To explain the reasons for having such a large discrepancy, the authors listed ten sources of uncertainties: (1) Welding Residual Stresses. (2) Crack Initiation Predictions. (3) Crack Growth Rates. (4) Circumferential Stress Variation. (5) Operating temperatures different from design temperatures. (6) Temperature factor in actual activation energy vs. assumed. (7) Under reporting of field data due to NDE limitations. (8) Uncertainty in modeling initiation, growth, and linking of multiple cracks around the circumference of a weld. (9) Correlation of crack initiation times and growth rates. (10) Insights from NUREG/CR-6674 (2000) fatigue crack growth models using conservative inputs for cyclic strain rates and environmental parameters such as oxygen content. In this paper we design a Python-based plug-in that allows a user to address those ten sources of uncertainties. This approach is based on the statistical theory of design of experiments with a 2-level factorial design, where a small number of runs is enough to estimate the uncertainties in the predictions of PFM models due to some combination of the source uncertainties listed by Simonen et al (PVP2007-26373).
DA  - 2010///
PY  - 2010
SP  - 1651
EP  - 1693
SN  - 978-0-7918-4369-7
AN  - WOS:000280407700171
ER  - 

TY  - JOUR
TI  - Physical Fitness Assessment for Cancer Patients Using Multi-Model Decision Fusion Based on Multi-Source Data
AU  - Li, JX
AU  - Wang, ZL
AU  - Zhao, HY
AU  - Qiu, S
AU  - Zhang, K
AU  - Shi, X
AU  - Qu, H
AU  - Jiang, GC
T2  - IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE
AB  - Objective and quantitative physical fitness assessment is the basis of pre-rehabilitation treatment for cancer patients, which can speed up the treatment process and reduce the adverse effects after treatment. In this study, in order to make up for the shortcomings of the traditional assessment by oncologists according to the scale, a method using multi-model decision fusion based on multi-source data is proposed. After fully considering the physical weakness of the cancer patients, a novel experimental paradigm is designed. The multi-source physiological data of 201 patients suffer from cancers have been collected and a series of features which can be used to assess the physical fitness are extracted. An improved data oversampling method based on the Mahalanobis distance and boundary constraints (MDBC) is proposed to overcome the problem of class imbalance. Moreover, a multi-model decision fusion (MMDF) method is proposed for classification, which combines multiple individual machine learning classifiers with a meta learner, to improve the accuracy of the physical fitness assessment. The recognition accuracy of our proposed method reaches 95.1%. The overall experimental results demonstrate that our proposed method is effective in physical fitness assessment of cancer patients.
DA  - 2023/08//undefined
PY  - 2023
DO  - 10.1109/TETCI.2022.3221129
VL  - 7
IS  - 4
SP  - 1290
EP  - 1300
SN  - 2471-285X
AN  - WOS:000912731700001
ER  - 

TY  - JOUR
TI  - Characterizing Urban Vehicle-to-Vehicle Communications for Reliable Safety Applications
AU  - Lyu, F
AU  - Zhu, HZ
AU  - Cheng, N
AU  - Zhou, HB
AU  - Xu, WC
AU  - Li, ML
AU  - Shen, XM
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - The IEEE 802.11p-based dedicated short range communication (DSRC) is essential to enhance driving safety and improve road efficiency by enabling rapid cooperative message exchanging. However, there is a lack of good understanding on the DSRC performance in urban environments for vehicle-to-vehicle (V2V) communications, which impedes its reliable and efficient application. In this paper, we first conduct intensive data analytics on V2V performance, based on a large amount of real-world DSRC communications trace collected in Shanghai city, and obtain several key insights as follows. First, among many context factors, the non-line-of-sight (NLoS) link condition is the major factor degrading V2V performance. Second, the durations of line-of-sight (LoS) and NLoS transmission conditions follow power law distributions, which indicate that the probability of experiencing long LoS/NLoS conditions both could be high. Third, the packet inter-reception (PIR) time distribution follows an exponential distribution in the LoS conditions but a power law in the NLoS conditions, which means that the consecutive packet reception failures rarely appear in the LoS conditions but can constantly appear in the NLoS conditions. Based on these findings, we propose a context-aware reliable beaconing scheme, called CoBe, to enhance the broadcast reliability for safety applications. The CoBe is a fully distributed scheme, in which a vehicle first detects the link condition with each of its neighbors by machine learning algorithms, then exchanges such link condition information with its neighbors, and finally selects the minimal number of helper vehicles to rebroadcast its beacons to those neighbors in bad link condition. To analyze and evaluate the CoBe performance, a two-state Markov chain is devised to model beaconing behaviors. The extensive trace-driven simulations are conducted to demonstrate the efficacy of CoBe.
DA  - 2020/06//undefined
PY  - 2020
DO  - 10.1109/TITS.2019.2920813
VL  - 21
IS  - 6
SP  - 2586
EP  - 2602
SN  - 1524-9050
AN  - WOS:000545427200030
ER  - 

TY  - JOUR
TI  - Data-Driven Long-Landing Event Detection and Interpretability Analysis in Civil Aviation
AU  - Yang, X
AU  - Ren, J
AU  - Li, JC
AU  - Zhang, HG
AU  - Yang, JF
T2  - IEEE ACCESS
AB  - Long-landing Events (LLEs) can occur as a result of pilot's improper operation, resulting in shorter available runways and higher operating costs. The LLE can be effectively pinpointed by analyzing data from the Quick Access Recorder (QAR), which records all of the pilot's operations during takeoff and landing. Traditionally, domain experts inspect LLEs by manually setting thresholds on uni-dimensional data. However, they cannot detect effectively the defects caused by the pilot's maneuvering technique because the potential mutual information between different features in the large amount of data is not considered. This paper proposes a data-driven LLE detection and causation analysis workflow, which can automatically mine and analyze the mutual information, to overcome the existing problems. Firstly, a dataset is established based on the extracted QAR data from 2002 flights, considering the landing phase of the aircraft. Subsequently, this paper proposes a Hybrid Feature Selection (HFS) method for selecting features that are highly correlated with LLEs in both supervised and unsupervised ways. A categorical Light Gradient Boosting Machine (LGBM) with a Bayesian optimization (LGBMBO) model is used to determine the performance improvement. Furthermore, the model is visualized to analyze the marginal effect of key parameters for the LLEs by using SHapley Additive exPlanations (SHAP). The experimental results demonstrate that our model reduces computational cost and achieves better performance. Additionally, this paper demonstrates that LLEs can be avoided during the landing phase by maintaining the appropriate descent speed, aircraft altitude, and descent angle.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3182796
VL  - 10
SP  - 64257
EP  - 64269
SN  - 2169-3536
AN  - WOS:000814550400001
ER  - 

TY  - JOUR
TI  - Assessment of aircraft damage due to bird strikes: a machine learning approach
AU  - Misra, S
AU  - Toppo, I
AU  - Mendonca, FAC
T2  - INTERNATIONAL JOURNAL OF SUSTAINABLE AVIATION
AB  - The objectives of this study were to identify the factors that are statistically associated with the probability of aircraft damage in the event of a bird strike and to develop classification models to predict aircraft damage in an event of a bird strike. The FAA National Wildlife Strike Database was used for the study to develop random forest, artificial neural network, logistic regression, support vector machine, extra gradient boost (XGBoost), and K-nearest neighbours classifier models. The random forest classifier, logistic regression, and XGBoost classifier exhibited the most robust predictive powers with accuracies of 78.81%, 78.51% and 78.35%, respectively. Based on the variable assessment scores for the random forest classifier, the size of the bird, height of impact, aircraft speed, and aircraft mass had the highest contributions towards predicting aircraft damage for the model.
DA  - 2022///
PY  - 2022
VL  - 8
IS  - 2
SP  - 136
EP  - 151
SN  - 2050-0467
AN  - WOS:000783923500003
ER  - 

TY  - CONF
TI  - Monitoring of Road Transport Infrastructure for the Intelligent Environment "Smart Road"
AU  - Finogeev, A
AU  - Finogeev, A
AU  - Shevchenko, S
T2  - CREATIVITY IN INTELLIGENT TECHNOLOGIES AND DATA SCIENCE, (CIT&DS)
A2  - Kravets, A
A2  - Shcherbakov, M
A2  - Kultsova, M
A2  - Groumpos, P
AB  - In the article, the issues of monitoring the road transport infrastructure based on a distributed network of photoradar complexes for fixing traffic accidents have been considered. This paper discusses tools for collection of road accident's photo and video data fixation, data mining and forecasting of transport incidents, depending on various factors (meteorological, social, operational, etc.). The connection between the complexes and the data processing center is established to ensure secure data transmission using a heterogeneous transport network. In the process of monitoring, tasks of spatial and intellectual analysis, evaluation, and forecasting of traffic accidents and transport situations for preventive response, notification and warning road users are solved. The monitoring system is an integral part of Smart Road intellectual environment within the framework of the Smart & Safe City concept. A multi-agent model of convergent data processing is implemented for big sensor data, which integrates cloud, fog, and mobile computing technologies.
DA  - 2017///
PY  - 2017
DO  - 10.1007/978-3-319-65551-2_47
VL  - 754
SP  - 655
EP  - 668
SN  - 1865-0929
AN  - WOS:000455217000047
KW  - Accidents
KW  - Data mining
KW  - Intelligent systems
KW  - Intelligent transportation systems
KW  - Learning systems
KW  - Data handling
KW  - Smart city
KW  - Intelligent transportation system
KW  - Roads and streets
KW  - Motor transportation
KW  - Sensor data
KW  - Decision support systems
KW  - Transportation
KW  - Highway accidents
KW  - Complex networks
KW  - Multi agent systems
KW  - Monitoring
KW  - Decision supports
KW  - Wireless sensor networks
KW  - Atmospheric movements
KW  - Big sensor data
KW  - Convergent data processing
KW  - Decision support
KW  - Deep machine learning
KW  - Multi-agent approach
KW  - Multiagent approach
KW  - Smart and safe city
KW  - Smart road
KW  - Streaming data processing
ER  - 

TY  - JOUR
TI  - A Reinforcement Learning Empowered Cooperative Control Approach for IIoT-Based Virtually Coupled Train Sets
AU  - Wang, HW
AU  - Zhao, QQ
AU  - Lin, SY
AU  - Cui, DL
AU  - Luo, CC
AU  - Zhu, L
AU  - Wang, X
AU  - Tang, T
T2  - IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB  - Virtually coupled train sets (VCTS) have been proposed to increase the transportation capacity and the flexibility of railway organization. Due to the lack of reliable wireless communications and accurate perceptual information, the promotion of VCTS was challenged. With the development of industrial Internet of Things (IIoT), an IIoT-based VCTS is built in the article based on the popular communication-based train control architecture. Considering the dynamic and complex operation environment, it is difficult to achieve the efficient cooperative control of VCTS. The reason is that the traditional method is frequently trapped into a local optimization. To resolve the problem, we apply reinforcement learning (RL) to obtain an optimal policy for the IIoT-based VCTS, where the traditional artificial potential field (APF) is taken to develop the reward function. RL can thus search the global optimal policy, whereas APF can help RL to reduce the computation complexity. This can substantially increase the efficiency of the proposed approach. Simulation results confirmed that the proposed RL-based cooperative control approach would bring excellent performance in the IIoT-based VCTS.
DA  - 2021/07//undefined
PY  - 2021
DO  - 10.1109/TII.2020.3024946
VL  - 17
IS  - 7
SP  - 4935
EP  - 4945
SN  - 1551-3203
AN  - WOS:000638402700050
ER  - 

TY  - JOUR
TI  - A Data-Driven Method for Battery Charging Capacity Abnormality Diagnosis in Electric Vehicle Applications
AU  - Wang, ZP
AU  - Song, CB
AU  - Zhang, L
AU  - Zhao, Y
AU  - Liu, P
AU  - Dorrell, DG
T2  - IEEE TRANSACTIONS ON TRANSPORTATION ELECTRIFICATION
AB  - Enabling charging capacity abnormality diagnosis is essential for ensuring battery operation safety in electric vehicle (EV) applications. In this article, a data-driven method is proposed for battery charging capacity diagnosis based on massive real-world EV operating data. Using the charging rate, temperature, state of charge, and accumulated driving mileage as the inputs, a tree-based prediction model is developed with a polynomial feature combination used for model training. A statistics-based method is then used to diagnose battery charging capacity abnormity by analyzing the error distribution of large sets of data. The proposed tree-based prediction model is compared with other state-of-the-art methods and is shown to have the highest prediction accuracy. The holistic diagnosis scheme is verified using unseen data.
DA  - 2022/03//undefined
PY  - 2022
DO  - 10.1109/TTE.2021.3117841
VL  - 8
IS  - 1
SP  - 990
EP  - 999
SN  - 2332-7782
AN  - WOS:000792985000079
ER  - 

TY  - JOUR
TI  - Machine Learning Approaches for Road Condition Monitoring Using Synthetic Aperture Radar
AU  - Rischioni, LG
AU  - Babu, A
AU  - Baumgartner, SV
AU  - Krieger, G
T2  - IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
AB  - Airborne synthetic aperture radar (SAR) has the potential to monitor remotely the road traffic infrastructure on a large scale. Of particular interest is the road surface roughness, which is an important road safety parameter. For this task, novel algorithms need to be developed. Machine learning approaches, such as artificial neural networks and random forest regression, which can perform nonlinear regression, can achieve this goal. This work considers fully polarimetric airborne radar datasets captured with German Aerospace Center's (DLR)'s airborne F-SAR radar system. Several machine learning-based approaches were tested on the datasets to estimate road surface roughness. The resulting models were then compared with ground truth surface roughness values and also with the semiempirical surface roughness model studied in the previous work.
DA  - 2023///
PY  - 2023
DO  - 10.1109/JSTARS.2023.3258059
VL  - 16
SP  - 3070
EP  - 3082
SN  - 1939-1404
AN  - WOS:000964706600002
ER  - 

TY  - JOUR
TI  - A Deployment-Efficient Energy Management Strategy for Connected Hybrid Electric Vehicle Based on Offline Reinforcement Learning
AU  - Hu, B
AU  - Li, JX
T2  - IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
AB  - With the development of recent artificial intelligence technology, especially after the great success of AlphaGo, there has been a growing interest in applying reinforcement learning (RL) to solve energy management strategy (EMS) problems for hybrid electric vehicles. However, the issues of current RL algorithms including deployment inefficiency, safety constraint, and simulation-to-real gap make it inapplicable to many industrial EMS tasks. With these in mind and considering the fact that there exists many suboptimal EMS controllers which can generate plentiful amounts of interactive data containing informative behaviors, an offline RL training framework that tries to extract policies with the maximum possible utility out of the available offline data is proposed. Furthermore, with connected vehicle technology standard in many new cars, rather than bringing all the data to the storage and analytics, a scheduled training framework is put forward. This cloud-based approach not only alleviates the computational burden of edge devices, but also more importantly provides a deployment-efficient solution to EMS tasks that have to adapt to changes of driving cycle. To evaluate the effectiveness of the proposed algorithm on real controllers, a hardware-in-the-loop (HIL) test is performed and the superiority of the proposed algorithm in contrast to dynamic programming, behavior cloning, rule-based, and vanilla off-policy RL algorithms is given.
DA  - 2022/09//undefined
PY  - 2022
DO  - 10.1109/TIE.2021.3116581
VL  - 69
IS  - 9
SP  - 9644
EP  - 9654
SN  - 0278-0046
AN  - WOS:000778988400100
ER  - 

TY  - JOUR
TI  - Review of Classification Methods on Unbalanced Data Sets
AU  - Wang, L
AU  - Han, M
AU  - Li, XJ
AU  - Zhang, N
AU  - Cheng, HD
T2  - IEEE ACCESS
AB  - This paper studies the classification of unbalanced data sets. First, this kind of data sets is briefly introduced, and then the classification methods of unbalanced data sets are analyzed in detail from different perspectives such as data sampling method, algorithm level, feature level, cost-sensitive function, and deep learning. In addition, the data sampling methods are divided into different technologies for introduction: unbalanced data set classification method based on synthetic minority over-sampling technology (SMOTE), support vector machine (SVM) technology, and k-nearest neighbor (KNN) technology, etc. Then, the advantages and disadvantages of these methods are compared. Finally, the evaluation criteria of the unbalanced data set classifier are summarized, and the future work directions are prospected and summarized.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3074243
VL  - 9
SP  - 64606
EP  - 64628
SN  - 2169-3536
AN  - WOS:000645859200001
ER  - 

TY  - JOUR
TI  - Distributionally Robust Surrogate Optimal Control for High-Dimensional Systems
AU  - Kandel, A
AU  - Park, S
AU  - Moura, SJ
T2  - IEEE TRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY
AB  - This article presents a novel methodology for tractably solving optimal control and offline reinforcement learning (RL) problems for high-dimensional systems. This work is motivated by the ongoing challenges of safety, computation, and optimality in high-dimensional optimal control. We address these key questions with the following approach. First, we identify a sequence-modeling surrogate methodology that takes as input the initial state and a time series of control inputs and outputs an approximation of the objective function and trajectories of constraint functions. Importantly this approach entirely absorbs the individual state transition dynamics. The sole dependence on the initial state means we can apply dimensionality reduction to compress the model input while retaining most of its information. Uncertainty in the surrogate objective will affect the resulting optimality. Critically, however, uncertainty in the surrogate constraint functions will lead to infeasibility, i.e., unsafe actions. When considering offline RL, the most significant modeling errors will be encountered on out-of-distribution (OOD) data. Therefore, we apply Wasserstein ambiguity sets to "robustify" our surrogate modeling approach subject to worst case out-of-sample modeling errors based on the distribution of test data residuals. We demonstrate the efficacy of this combined approach through a case study of safe optimal fast charging of a high-dimensional lithium-ion battery model at low temperatures.
DA  - 2023/05//undefined
PY  - 2023
DO  - 10.1109/TCST.2022.3216988
VL  - 31
IS  - 3
SP  - 1196
EP  - 1207
SN  - 1063-6536
AN  - WOS:000881967600001
ER  - 

TY  - JOUR
TI  - Toward Privacy Preservation Using Clustering Based Anonymization: Recent Advances and Future Research Outlook
AU  - Majeed, A
AU  - Khan, S
AU  - Hwang, SO
T2  - IEEE ACCESS
AB  - With the continuous increase in avenues of personal data generation, privacy protection has become a hot research topic resulting in various proposed mechanisms to address this social issue. The main technical solutions for guaranteeing a user's privacy are encryption, pseudonymization, anonymization, differential privacy (DP), and obfuscation. Despite the success of other solutions, anonymization has been widely used in commercial settings for privacy preservation because of its algorithmic simplicity and low computing overhead. It facilitates unconstrained analysis of published data that DP and the other latest techniques cannot offer, and it is a mainstream solution for responsible data science. In this paper, we present a comprehensive analysis of clustering-based anonymization mechanisms (CAMs) that have been recently proposed to preserve both privacy and utility in data publishing. We systematically categorize the existing CAMs based on heterogeneous types of data (tables, graphs, matrixes, etc.), and we present an up-to-date, extensive review of existing CAMs and the metrics used for their evaluation. We discuss the superiority and effectiveness of CAMs over traditional anonymization mechanisms. We highlight the significance of CAMs in different computing paradigms, such as social networks, the internet of things, cloud computing, AI, and location-based systems with regard to privacy preservation. Furthermore, we present various proposed representative CAMs that compromise individual privacy, rather than safeguarding it. Besides, this article provides an extended knowledge (e.g., key assertion(s), strengths, weaknesses, clustering methods used in the anonymization process, and %age improvements in quantitative results) about each technique that provides a clear view of how much this topic has been investigated thus far, and what are the research gaps that seek pertinent solutions in the near future. Finally, we discuss the technical challenges of applying CAMs, and we suggest promising opportunities for future research. To the best of our knowledge, this is the first work to systematically cover current CAMs involving different data types and computing paradigms.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3175219
VL  - 10
SP  - 53066
EP  - 53097
SN  - 2169-3536
AN  - WOS:000800158400001
ER  - 

TY  - JOUR
TI  - Towards affect-aware vehicles for increasing safety and comfort: recognising driver emotions from audio recordings in a realistic driving study
AU  - Requardt, AF
AU  - Ihme, K
AU  - Wilbrink, M
AU  - Wendemuth, A
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - For vehicle safety, the in-time monitoring of the driver and assessing his/her state is a demanding issue. Frustration can lead to aggressive driving behaviours, which play a decisive role in up to one-third of fatal road accidents. Consequently, the authors present the automatic analysis of the emotional driver states of frustration, anxiety, positive and neutral. Based on experiments with normal drivers within cars in real-world (low expressivity) situations, they use speech data, as speech can be recorded with zero invasiveness and comes naturally in driving situations. A careful selection of speech features, subject data identification, hyper-parameter optimisation, and machine learning algorithms was applied for this difficult 4-emotion-class detection problem, where the literature hardly reports results above chance level. In-car assistance demands real-time computing. A very detailed analysis yields best results with relatively small random forests, and with an optimal feature set containing only 65 features (6.51% of the standardemobasefeature set) which outperformed all other feature sets, producing 35.38% unweighted average recall (53.26% precision) with low computational effort, and also reducing the inevitably high confusion of 'neutral' with low-expressed emotions. This result is comparable to and even outperforming other reported studies of emotion recognition in the wild. Their work, therefore, triggers adaptive automotive safety applications.
DA  - 2020/10//undefined
PY  - 2020
DO  - 10.1049/iet-its.2019.0732
VL  - 14
IS  - 10
SP  - 1265
EP  - 1277
SN  - 1751-956X
AN  - WOS:000573659000012
ER  - 

TY  - JOUR
TI  - Digital Twin System of Bridges Group Based on Machine Vision Fusion Monitoring of Bridge Traffic Load
AU  - Dan, DH
AU  - Ying, YF
AU  - Ge, LF
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Bridges play an important role in transportation infrastructure systems. Intelligent and digital management of bridges group is an essential part of the future intelligent transportation infrastructure system. This paper proposes a digital twin system for bridges group in the regional transportation infrastructure network, which is interconnected by measured traffic loads. In physical space, a full-bridge traffic load monitoring system based on information fusion of weigh-in-motion (WIM) and multi-source heterogeneous machine vision is set up on the target bridge to measure traffic loads, also lightweight sensors are employed on the bridges group for structural response information. Furthermore, by establishing mechanical analysis models in the corresponding digital space and using the measured traffic loads as links, the working condition perception and safety warning of all bridges in the regional transportation network is achieved, forming an important support for further intelligent transportation infrastructure system. The proposed digital twin system has been preliminarily implemented in a bridges group around Shanghai, China, demonstrating the feasibility of the technical framework proposed in this paper and the bright prospects.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.1109/TITS.2021.3130025
VL  - 23
IS  - 11
SP  - 22190
EP  - 22205
SN  - 1524-9050
AN  - WOS:000732355500001
ER  - 

TY  - JOUR
TI  - Unsupervised Outlier Detection Mechanism for Tea Traceability Data
AU  - Yang, HG
AU  - Li, SW
AU  - Tu, LJ
AU  - Ma, RR
AU  - Chen, Y
T2  - IEEE ACCESS
AB  - The presence of outliers in tea traceability data can mislead customers and have a significant impact on the reputation and profits of tea companies. To solve this problem, an unsupervised outlier detection mechanism for tea traceability data is proposed. Firstly, tea traceability data is uploaded to the MySQL database, and then the data is preprocessed to aggregate features based on relevance, which makes it easier to identify abnormal features. Secondly, the LOKI algorithm based on Local Outlier Factor (LOF), Isolation Forest (IForest), and K-Nearest Neighbors (KNN) algorithms is used to achieve unsupervised outlier detection of tea traceability data. In addition, a Density-Based Spatial Clustering of Applications with Noise (DBSCAN-based) tuning method for unsupervised outlier detection algorithms is also provided. Finally, the types of anomalies among the identified outliers are identified to investigate the causes of the anomalies in order to develop remedial procedures to eliminate the anomalies, and the analysis results are fed back to the tea companies. Experiments on real datasets show that the DBSCAN-based tuning method can effectively help the unsupervised outlier detection algorithm optimize the parameters, and that the LOF-KNN-IForest (LOKI) algorithm can effectively identify the outliers in tea traceability data. This proves that the unsupervised outlier detection mechanism for tea traceability data can effectively guarantee the quality of tea traceability data.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3204760
VL  - 10
SP  - 94818
EP  - 94831
SN  - 2169-3536
AN  - WOS:000854619400001
ER  - 

TY  - JOUR
TI  - Development of Eye Blink Rate Level Classification System Utilizing Sitting Postural Behavior Data
AU  - Lee, H
AU  - Yoo, T
AU  - Hyun, S
AU  - Beck, D
AU  - Park, W
T2  - IEEE ACCESS
AB  - The prevalence of dry eye syndrome (DES) has rapidly increased in recent years, negatively affecting the eye health of many office workers worldwide. Although low eye blink rate (EBR) has been pointed out as one of the main risk factors for DES, it is difficult for office workers to continuously monitor and increase their own involuntary blinking, especially when they are focused on the primary work task. Thus, as an effort to help office workers correct their low EBR, the current study developed a real-time EBR level classification system utilizing sitting postural behavior data. A total of twenty participants performed typical computer tasks on a sensor-embedded chair. The participants' eye blinking and postural behavior data were collected to develop the EBR level classification system with a random forest algorithm. After evaluating the system performance, the relationships between EBR and postural behaviors were empirically examined to help understand how the system worked for EBR level classification. As a result, the developed system showed high classification performance overall; and compared with high EBR condition, low EBR condition was related to less overall postural variability and greater extent of forward bending posture. The real-time EBR level classification system is expected to contribute to preventing/relieving DES and thereby enhancing the eye health of office workers.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3121288
VL  - 9
SP  - 143677
EP  - 143689
SN  - 2169-3536
AN  - WOS:000711701800001
ER  - 

TY  - JOUR
TI  - Evolving robotic surgery training and improving patient safety, with the integration of novel technologies
AU  - Chen, IHA
AU  - Ghazi, A
AU  - Sridhar, A
AU  - Stoyanov, D
AU  - Slack, M
AU  - Kelly, JD
AU  - Collins, JW
T2  - WORLD JOURNAL OF UROLOGY
AB  - Introduction Robot-assisted surgery is becoming increasingly adopted by multiple surgical specialties. There is evidence of inherent risks of utilising new technologies that are unfamiliar early in the learning curve. The development of standardised and validated training programmes is crucial to deliver safe introduction. In this review, we aim to evaluate the current evidence and opportunities to integrate novel technologies into modern digitalised robotic training curricula. Methods A systematic literature review of the current evidence for novel technologies in surgical training was conducted online and relevant publications and information were identified. Evaluation was made on how these technologies could further enable digitalisation of training. Results Overall, the quality of available studies was found to be low with current available evidence consisting largely of expert opinion, consensus statements and small qualitative studies. The review identified that there are several novel technologies already being utilised in robotic surgery training. There is also a trend towards standardised validated robotic training curricula. Currently, the majority of the validated curricula do not incorporate novel technologies and training is delivered with more traditional methods that includes centralisation of training services with wet laboratories that have access to cadavers and dedicated training robots. Conclusions Improvements to training standards and understanding performance data have good potential to significantly lower complications in patients. Digitalisation automates data collection and brings data together for analysis. Machine learning has potential to develop automated performance feedback for trainees. Digitalised training aims to build on the current gold standards and to further improve the 'continuum of training' by integrating PBP training, 3D-printed models, telementoring, telemetry and machine learning.
DA  - 2021/08//undefined
PY  - 2021
DO  - 10.1007/s00345-020-03467-7
VL  - 39
IS  - 8
SP  - 2883
EP  - 2893
SN  - 0724-4983
AN  - WOS:000587072800001
KW  - Machine learning
KW  - Training
KW  - human
KW  - Humans
KW  - procedures
KW  - general surgery
KW  - patient safety
KW  - Education
KW  - Patient safety
KW  - Mentoring
KW  - Eye tracking
KW  - education
KW  - Education, Distance
KW  - Patient Safety
KW  - 3D printed models
KW  - anatomic model
KW  - General Surgery
KW  - invention
KW  - Inventions
KW  - mentoring
KW  - Models, Anatomic
KW  - organization and management
KW  - Proficiency-based progression
KW  - robot assisted surgery
KW  - Robotic Surgical Procedures
KW  - Robotic-assisted surgery
KW  - Surgical education
KW  - Telementoring
KW  - urology
KW  - Urology
ER  - 

TY  - JOUR
TI  - Indoor Semantic Location Privacy Protection With Safe Reinforcement Learning
AU  - Min, MH
AU  - Yang, S
AU  - Zhang, HL
AU  - Ding, JC
AU  - Peng, GJ
AU  - Pan, M
AU  - Han, Z
T2  - IEEE TRANSACTIONS ON COGNITIVE COMMUNICATIONS AND NETWORKING
AB  - The rapid growth and evolution of indoor location-based services (LBS) increase the risk of location privacy breaches. Additionally, the semantic tag of locations can easily expose users' sensitive private information. This paper studies the safe reinforcement learning (RL)-based semantic location privacy protection mechanism (LPPM) in three-dimensional (3D) spaces, such as multi-story buildings. This provides a unique opportunity to derive the optimal location privacy protection (LPP) policy with safe exploration in dynamic 3D environments without knowing the accurate attack model. Safe exploration avoids selecting high-risk perturbation policies by evaluating each state-action pair's risk level. We propose a safe Dueling Double DQN (D3QN)-based 3D LPPM (SDLPPM) to adaptively explore the perturbation policy, avoiding the overestimation of Q-values and reducing the redundant exploration in similar 3D states. 3D geo-indistinguishability is used to randomly perturb users' locations. Besides, we further develop a safe A3C-based LPPM (SALPPM) to continuously select the perturbation policies to avoid discretization errors of perturbation angles and privacy budgets. This mechanism uses multi-thread technology to interact with the environment independently to accelerate the policy selection in complex 3D LPP scenarios. Simulation results demonstrate that the proposed mechanisms increase privacy and reduce QoS loss compared to the benchmark mechanisms.
DA  - 2023/10//undefined
PY  - 2023
DO  - 10.1109/TCCN.2023.3291364
VL  - 9
IS  - 5
SP  - 1385
EP  - 1398
SN  - 2332-7731
AN  - WOS:001082261500019
ER  - 

TY  - JOUR
TI  - An Intelligent Train Operation Method Based on Event-Driven Deep Reinforcement Learning
AU  - Zhang, LQ
AU  - U, LH
AU  - Zhou, ML
AU  - Li, ZN
T2  - IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB  - Train operation control in urban railways is challenging due to its high dynamics, complex environment, and level of comfort and safety. To address these challenges, in this article, the authors propose a new deep reinforcement-based train operation (DRTO) method which includes: 1) A deterministic deep reinforcement learning algorithm, 2) a dynamic incentive system, which is used to ensure safe operation in a multitrain environment, and 3) an event-driven method, which is used to improve the DRTO performance based on an event-driven strategy. To evaluate the performance, we thoroughly compare the proposed method with other operation control solutions on both synthetic and real datasets. Our results demonstrate that DRTO is effective in: 1) Decreasing the energy consumption of train operation, 2) increasing passenger comfort, and 3) achieving a good tradeoff between efficiency and safety. In addition, the effectiveness of the event-driven strategy and the dynamic incentive system is demonstrated in the experiments.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1109/TII.2021.3138098
VL  - 18
IS  - 10
SP  - 6973
EP  - 6980
SN  - 1551-3203
AN  - WOS:000838389400049
ER  - 

TY  - JOUR
TI  - Cross-Scene Hyperspectral Image Classification With Discriminative Cooperative Alignment
AU  - Zhang, YX
AU  - Li, W
AU  - Tao, R
AU  - Peng, JT
AU  - Du, Q
AU  - Cai, ZQ
T2  - IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
AB  - Cross-scene classification is one of the major challenges for hyperspectral image (HSI) classification, especially for target scenes without label samples. Most traditional domain adaptive methods learn a domain invariant subspace to reduce statistical shift while ignoring the fact that there may not exist a shared subspace when marginal distributions of source and target domains are very different. In addition, it is important for HSI classification to preserve discriminant information in the original space. To solve this issue, discriminative cooperative alignment (DCA) of subspace and distribution is proposed to cooperatively reduce the geometric and statistical shift. In the proposed framework, both geometrical and statistical alignments are considered to learn subspaces of the two domains with preserving discrimination information. Furthermore, a reconstruction constraint is imposed to enhance the robustness of subspace projection. Experimental results on three cross-scene HSI data sets demonstrate that the proposed DCA is significantly better than some state-of-the-art domain-adaptive approaches.
DA  - 2021/11//undefined
PY  - 2021
DO  - 10.1109/TGRS.2020.3046756
VL  - 59
IS  - 11
SP  - 9646
EP  - 9660
SN  - 0196-2892
AN  - WOS:000711850900054
ER  - 

TY  - JOUR
TI  - Transfer Learning for Brain-Computer Interfaces: A Euclidean Space Data Alignment Approach
AU  - He, H
AU  - Wu, DR
T2  - IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING
AB  - Objective: This paper targets a major challenge in developing practical electroencephalogram (EEG)-based brain-computer interfaces (BCIs): how to cope with individual differences so that better learning performance can be obtained for a new subject, with minimum or even no subject-specific data? Methods: We propose a novel approach to align EEG trials from different subjects in the Euclidean space to make them more similar, and hence improve the learning performance for a new subject. Our approach has three desirable properties: first, it aligns the EEG trials directly in the Euclidean space, and any signal processing, feature extraction, and machine learning algorithms can then be applied to the aligned trials; second, its computational cost is very low; and third, it is unsupervised and does not need any label information from the new subject. Results: Both offline and simulated online experiments on motor imagery classification and event-related potential classification verified that our proposed approach outperformed a state-of-the-art Riemannian space data alignment approach, and several approaches without data alignment. Conclusion: The proposed Euclidean space EEG data alignment approach can greatly facilitate transfer learning in BCIs. Significance: Our proposed approach is effective, efficient, and easy to implement. It could be an essential pre-processing step for EEG-based BCIs.
DA  - 2020/02//undefined
PY  - 2020
DO  - 10.1109/TBME.2019.2913914
VL  - 67
IS  - 2
SP  - 399
EP  - 410
SN  - 0018-9294
AN  - WOS:000510903800008
ER  - 

TY  - CONF
TI  - Automatic Analysis of Large Data Sets: A Walk-Through on Methods from Different Perspectives
AU  - Hilbrich, M
AU  - Weber, M
AU  - Tschüter, R
AU  - IEEE
T2  - 2013 INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA (CLOUDCOM-ASIA)
AB  - Analyzing data is one of today's hot topics. A complete list of fields of research and buzzwords associated with automatic analysis would extend beyond this document. The importance of this topic stems from the amount of data currently produced in research, engineering, and other fields. The size of these data sets renders manual analysis infeasible. Automatic analysis methods are required to cope with the data sets produced. The algorithms for filtering, categorization, and analysis have a long tradition and are manifold. This raises the question for the best algorithm. The authors of this paper give an overview about manifold automatic analysis approaches along with a classification of these approaches with regard to three different fields of research.
DA  - 2013///
PY  - 2013
DO  - 10.1109/CLOUDCOM-ASIA.2013.47
SP  - 373
EP  - 380
SN  - 978-1-4799-2829-3
AN  - WOS:000355658800053
KW  - Artificial intelligence
KW  - Machine learning
KW  - Data mining
KW  - Visualization
KW  - Learning systems
KW  - Big data
KW  - Sequence alignment
KW  - Sequence alignments
KW  - Clustering
KW  - Resilience
KW  - Monitoring
KW  - Genetic algorithms
KW  - Cloud computing
KW  - Genetic algorithm
KW  - Analysis
KW  - Correlation methods
KW  - Flow visualization
KW  - Research
KW  - Comparison
KW  - Correlation
KW  - Graph search
ER  - 

TY  - JOUR
TI  - Application of the Apriori Algorithm for Traffic Crash Analysis in Thailand
AU  - Mohamad, I
AU  - Kasemsri, R
AU  - Ratanavaraha, V
AU  - Jomnonkwao, S
T2  - SAFETY
AB  - Accidents pose significant obstacles to economic progress and quality of life, especially in developing countries. Thailand faces such challenges and this research seeks to assess the frequency and most common causes of road accidents that lead to fatalities. This study employed the Apriori algorithm to examine the interrelationships among factors contributing to accidents in order to inform policymaking for reducing accident rates, minimizing economic and human losses, and enhancing the effectiveness of the healthcare system. By analyzing road accident data from 2015 to 2020 in Thailand (167,820 accidents causing THB 1.13 billion in damages), this article specifically focuses on the drivers responsible for fatal highway accidents. The findings reveal several interconnected variables that heighten the likelihood of fatalities, such as male gender, exceeding speed limits, riding a motorbike, traveling on straight roads, encountering dry surface conditions, and clear weather. An association rule analysis underscores the increased risk of injury or death in traffic accidents.
DA  - 2023/09//undefined
PY  - 2023
DO  - 10.3390/safety9030058
VL  - 9
IS  - 3
SN  - 2313-576X
AN  - WOS:001072586100001
KW  - machine learning
KW  - road safety
KW  - data mining
KW  - Apriori algorithm
KW  - associated rule
KW  - BDA
KW  - crash frequency
KW  - crash injury
KW  - predictive analysis
ER  - 

TY  - JOUR
TI  - Fatigue driving detection model based on multi-feature fusion and semi-supervised active learning
AU  - Li, X
AU  - Hong, L
AU  - Wang, JC
AU  - Liu, X
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - Fatigue driving is one of the main factors of traffic accidents and there are many research efforts focusing on fatigue driving detection. With the extensive use of on-board sensors, a huge number of unlabelled driving data can be easily collected, however, it is a costly and laborious work to annotate semantic labels for these data manually, posing some difficulties to detect fatigue driving with these data. In this work, the authors propose a novel fatigue driving detection model based on multi-feature fusion and semi-supervised active learning. In the authors' model, the steering features of the vehicle and the facial features of the driver are fused to improve the accuracy and stability of the model. Semi-supervised active learning algorithm allows us to make semantic labels for only a small number of data that can be propagated to the rest data, and help us establish an efficient fatigue driving detection model with automatic label propagation. Some experiments are conducted to validate their model, the results show that the accuracy is 86.25%, which proves the effectiveness of the fatigue driving detection model.
DA  - 2019/09//undefined
PY  - 2019
DO  - 10.1049/iet-its.2018.5590
VL  - 13
IS  - 9
SP  - 1401
EP  - 1409
SN  - 1751-956X
AN  - WOS:000482448600010
ER  - 

TY  - JOUR
TI  - Curriculum Feature Alignment Domain Adaptation for Epithelium-Stroma Classification in Histopathological Images
AU  - Qi, Q
AU  - Lin, X
AU  - Chen, CQ
AU  - Xie, WP
AU  - Huang, Y
AU  - Ding, XH
AU  - Liu, XQ
AU  - Yu, YZ
T2  - IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS
AB  - In recent years, deep learning methods have received more attention in epithelial-stroma (ES) classification tasks. Traditional deep learning methods assume that the training and test data have the same distribution, an assumption that is seldom satisfied in complex imaging procedures. Unsupervised domain adaptation (UDA) transfers knowledge from a labelled source domain to a completely unlabeled target domain, and is more suitable for ES classification tasks to avoid tedious annotation. However, existing UDA methods for this task ignore the semantic alignment across domains. In this paper, we propose a Curriculum Feature Alignment Network (CFAN) to gradually align discriminative features across domains through selecting effective samples from the target domain and minimizing intra-class differences. Specifically, we developed the Curriculum Transfer Strategy (CTS) and Adaptive Centroid Alignment (ACA) steps to train our model iteratively. We validated the method using three independent public ES datasets, and experimental results demonstrate that our method achieves better performance in ES classification compared with commonly used deep learning methods and existing deep domain adaptation methods.
DA  - 2021/04//undefined
PY  - 2021
DO  - 10.1109/JBHI.2020.3021558
VL  - 25
IS  - 4
SP  - 1163
EP  - 1172
SN  - 2168-2194
AN  - WOS:000638401400026
ER  - 

TY  - CONF
TI  - Approximate Dynamic Programming For Linear Systems with State and Input Constraints
AU  - Chakrabarty, A
AU  - Quirynen, R
AU  - Danielson, C
AU  - Gao, WN
AU  - IEEE
T2  - 2019 18TH EUROPEAN CONTROL CONFERENCE (ECC)
AB  - Enforcing state and input constraints during reinforcement learning (RL) in continuous state spaces is an open but crucial problem which remains a roadblock to using RL in safety-critical applications. This paper leverages invariant sets to update control policies within an approximate dynamic programming (ADP) framework that guarantees constraint satisfaction for all time and converges to the optimal policy (in a linear quadratic regulator sense) asymptotically. An algorithm for implementing the proposed constrained ADP approach in a data-driven manner is provided. The potential of this formalism is demonstrated via a numerical example.
DA  - 2019///
PY  - 2019
DO  - 10.23919/ecc.2019.8795815
SP  - 524
EP  - 529
SN  - 978-3-907144-00-8
AN  - WOS:000490488300084
KW  - Reinforcement learning
KW  - Machine learning
KW  - Safety engineering
KW  - Iterative methods
KW  - Dynamic programming
KW  - Data driven
KW  - Safe learning
KW  - Policy iteration
KW  - Data-driven
KW  - Linear systems
KW  - Invariant set
KW  - Invariant sets
KW  - Linear quadratic regulator
ER  - 

TY  - JOUR
TI  - USING MACHINE LEARNING TO CATEGORISE EMERGENCY DEPARTMENT DATA FOR PRODUCT SAFETY SURVEILLANCE
AU  - Vallmuur, K
AU  - Nanda, G
AU  - Lehto, M
T2  - INJURY PREVENTION
DA  - 2016/09//undefined
PY  - 2016
DO  - 10.1136/injuryprev-2016-042156.347
VL  - 22
SP  - A127
EP  - A127
SN  - 1353-8047
AN  - WOS:000405066801033
ER  - 

TY  - CONF
TI  - Using Big Data and Machine Learning to Improve Aircraft Reliability and Safety
AU  - Salvador, M
AU  - Yacout, S
AU  - AboElHassan, A
AU  - IEEE
T2  - 2022 68TH ANNUAL RELIABILITY AND MAINTAINABILITY SYMPOSIUM (RAMS 2022)
AB  - The evolution of aircraft systems monitoring technology has made it possible to acquire increasing amounts of data. The big volume of available information has helped aerospace companies to increase the reliability and availability of their products and to improve the safety of aircraft, flight crew and passengers. In the event of system failures, the high complexity of the new aircraft systems, combined with the large amount of data provided by them, make the management of risk assessments a more complex activity and make the decision-making process more accurate but challenging. This process may lead to excessive conservatism when evaluating risk levels, which may in turn impact operation costs and production costs; increase the flight crew's workload due to possibility to add more work to their normal tasks to deal with systems failures; or, conversely, lead to an underestimation of the criticality of the risk, thus exposing aircraft occupants to an unacceptable level of risk.
Logical Analysis of Data (LAD) makes it possible for input signals variables or condition indicators of different physical components to be combined and compared in multiple scenarios, in a process known as pattern recognition and interpretation of physical condition. This paper addresses the potential for machine learning and pattern generation and interpretation to support reliability and safety in the aerospace industry. It examines a set of three scenarios from industry practice: in the first two, Machine Learning (ML) is used as a supporting tool for reducing costs, and improving reliability and safety, respectively. In the final scenario, ML is embedded in the system architecture to highlight the challenges of the use of ML in association with the current design assurance levels for software and real-time risk assessment. The paper ultimately aims to lay the groundwork for a better decision-making process, supporting quantitative and qualitative assessment of the level of risk in an aircraft system.
DA  - 2022///
PY  - 2022
DO  - 10.1109/RAMS51457.2022.9894015
SN  - 0149-144X
AN  - WOS:000942487400098
KW  - machine learning
KW  - artificial intelligence
KW  - Machine learning
KW  - risk assessment
KW  - Pattern recognition
KW  - Learning systems
KW  - Accident prevention
KW  - Machine-learning
KW  - Risk perception
KW  - Systems engineering
KW  - Risk assessment
KW  - System failures
KW  - Big data
KW  - Safety assessments
KW  - Costs
KW  - Aircraft
KW  - Information management
KW  - Decision-making process
KW  - Reliability analysis
KW  - Risks assessments
KW  - Reliability and safeties
KW  - Risk analysis
KW  - risk analysis
KW  - Distribution functions
KW  - safety assessment
KW  - aviation
KW  - aerospace
KW  - Aerospace
KW  - Aerospace industry
KW  - Aircraft reliability
KW  - Aircraft systems
KW  - Flight crews
ER  - 

TY  - JOUR
TI  - Safe Data-Driven Lane Change Decision Using Machine Learning in Vehicular Networks
AU  - Naja, R
T2  - JOURNAL OF SENSOR AND ACTUATOR NETWORKS
AB  - This research proposes a unique platform for lane change assistance for generating data-driven lane change (LC) decisions in vehicular networks. The goal is to reduce the frequency of emergency braking, the rate of vehicle collisions, and the amount of time spent in risky lanes. In order to analyze and mine the massive amounts of data, our platform uses effective Machine Learning (ML) techniques to forecast collisions and advise the driver to safely change lanes. From the unprocessed large data generated by the car sensors, kinematic information is retrieved, cleaned, and evaluated. Machine learning algorithms analyze this kinematic data and provide an action: either stay in lane or change lanes to the left or right. The model is trained using the ML techniques K-Nearest Neighbor, Artificial Neural Network, and Deep Reinforcement Learning based on a set of training data and focus on predicting driver actions. The proposed solution is validated via extensive simulations using a microscopic car-following mobility model, coupled with an accurate mathematical modelling. Performance analysis show that KNN yields up to best performance parameters. Finally, we draw conclusions for road safety stakeholders to adopt the safer technique to lane change maneuver.
DA  - 2023/08//undefined
PY  - 2023
DO  - 10.3390/jsan12040059
VL  - 12
IS  - 4
SN  - 2224-2708
AN  - WOS:001055862100001
KW  - machine learning
KW  - lane change
KW  - data analytics
KW  - vehicular networks
ER  - 

TY  - JOUR
TI  - Safe-State Enhancement Method for Autonomous Driving via Direct Hierarchical Reinforcement Learning
AU  - Gu, ZQ
AU  - Gao, LP
AU  - Ma, HT
AU  - Li, SE
AU  - Zheng, SF
AU  - Jing, W
AU  - Chen, JB
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Reinforcement learning (RL) has shown excellent performance in the sequential decision-making problem, where safety in the form of state constraints is of great significance in the design and application of RL. Simple constrained end-to-end RL methods might lead to significant failure in a complex system like autonomous vehicles. In contrast, some hierarchical RL (HRL) methods generate driving goals directly, which could be closely combined with motion planning. With safety requirements, some safe-enhanced RL methods add post-processing modules to avoid unsafe goals or achieve expectation-based safety, which accepts the existence of unsafe states and allows some violations of safe constraints. However, ensuring state safety is vital for autonomous vehicles. Therefore, this paper proposes a state-based safety enhancement method for autonomous driving via direct hierarchical reinforcement learning. Finally, we design a constrained reinforcement learner based on the State-based Constrained Markov Decision Process (SCMDP), where a learnable safety module could adjust the constraint strength adaptively. We integrate a dynamic module in the policy training and generate future goals considering safety, temporal-spatial continuity, and dynamic feasibility, which could eliminate dependence on the prior model. Simulations in the typical highway scenes with uncertainties show that the proposed method has better training performance, higher driving safety in interactive scenes, more decision intelligence in traffic congestions, and better economic driving ability on roads with changing slopes.
DA  - 2023/05/05/
PY  - 2023
DO  - 10.1109/TITS.2023.3271642
SN  - 1524-9050
AN  - WOS:000988371100001
ER  - 

TY  - CONF
TI  - GASTeN: Generative Adversarial Stress Test Networks
AU  - Cunha, L
AU  - Soares, C
AU  - Restivo, A
AU  - Teixeira, LF
T2  - ADVANCES IN INTELLIGENT DATA ANALYSIS XXI, IDA 2023
A2  - Cremilleux, B
A2  - Hess, S
A2  - Nijssen, S
AB  - Concerns with the interpretability of ML models are growing as the technology is used in increasingly sensitive domains (e.g., health and public administration). Synthetic data can be used to understand models better, for instance, if the examples are generated close to the frontier between classes. However, data augmentation techniques, such as Generative Adversarial Networks (GAN), have been mostly used to generate training data that leads to better models. We propose a variation of GANs that, given a model, generates realistic data that is classified with low confidence by a given classifier. The generated examples can be used in order to gain insights on the frontier between classes. We empirically evaluate our approach on two well-known image classification benchmark datasets, MNIST and Fashion MNIST. Results show that the approach is able to generate images that are closer to the frontier when compared to the original ones, but still realistic. Manual inspection confirms that some of those images are confusing even for humans.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-30047-9_8
VL  - 13876
SP  - 91
EP  - 102
SN  - 0302-9743
AN  - WOS:000999877600008
ER  - 

TY  - CONF
TI  - A QUANTITATIVE ANALYSIS OF THE ROBUSTNESS OF NEURAL NETWORKS FOR TABULAR DATA
AU  - Gupta, K
AU  - Pesquet-Popescu, B
AU  - Kaakai, F
AU  - Pesquet, JC
AU  - IEEE
T2  - 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021)
AB  - This paper presents a quantitative approach to demonstrate the robustness of neural networks for tabular data. These data form the backbone of the data structures found in most industrial applications. We analyse the effect of various widely used techniques we encounter in neural network practice, such as regularization of weights, addition of noise to the data, and positivity constraints. This analysis is performed by using three state-of-the-art techniques, which provide mathematical proofs of robustness in terms of Lipschitz constant for feed-forward networks. The experiments are carried out on two prediction tasks and one classification task. Our work brings insights into building robust neural network architectures for safety critical systems that require certification or approval from a competent authority.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICASSP39728.2021.9413858
SP  - 8057
EP  - 8061
SN  - 978-1-7281-7605-5
AN  - WOS:000704288408068
KW  - Safety
KW  - Signal processing
KW  - Neural networks
KW  - Supervised learning
KW  - Safety engineering
KW  - Network architecture
KW  - Robustness
KW  - Feedforward neural networks
KW  - Classification tasks
KW  - Safety critical systems
KW  - Feed-forward network
KW  - Tabular data
KW  - Lipschitz constant
KW  - Competent authorities
KW  - Lipschitz stability
KW  - Mathematical proof
KW  - Quantitative approach
KW  - State-of-the-art techniques
ER  - 

TY  - JOUR
TI  - Data mining on road safety: factor assessment on vehicle accidents using classification models
AU  - Castro, Y
AU  - Kim, YJ
T2  - INTERNATIONAL JOURNAL OF CRASHWORTHINESS
AB  - In this study, we use three data mining classification models to detect factors with the greatest influence on car accidents. Understanding the circumstances in which the drivers and passengers are more likely to be killed or severely injured in an automobile crash is of particular concern in traffic safety. Our experimental objective is exploring the role of different factors on injury risk using a Bayesian network, decision trees and artificial neural networks. To identify relevant patterns and detect the most frequent factors involved in an accident, we conducted an experiment with road accident data, from 2010 to 2012, provided by the Driver and Vehicle Standards Agency (DVSA) of the United Kingdom. Here, we evaluate and discuss our results, which show that the three most frequent factors are light conditions, vehicle manoeuvre and road type. The investigation also found that the age of the vehicle and weather conditions had no significant influence on the degree of injury.
DA  - 2016/03/03/
PY  - 2016
DO  - 10.1080/13588265.2015.1122278
VL  - 21
IS  - 2
SP  - 104
EP  - 111
SN  - 1358-8265
AN  - WOS:000372734400002
ER  - 

TY  - JOUR
TI  - Fully automated deep learning for knee alignment assessment in lower extremity radiographs: a cross-sectional diagnostic study
AU  - Simon, S
AU  - Schwarz, GM
AU  - Aichmair, A
AU  - Frank, BJH
AU  - Hummer, A
AU  - DiFranco, MD
AU  - Dominkus, M
AU  - Hofstaetter, JG
T2  - SKELETAL RADIOLOGY
AB  - Objectives Accurate assessment of knee alignment and leg length discrepancy is currently measured manually from standing long-leg radiographs (LLR), a process that is both time consuming and poorly reproducible. The aim was to assess the performance of a commercial available AI software by comparing its outputs with manually performed measurements. Materials and methods The AI was trained on over 15,000 radiographs to measure various clinical angles and lengths from LLRs. We performed a retrospective single-center analysis on 295 LLRs obtained between 2015 and 2020 from male and female patients over 18 years. AI and expert measurements were performed independently. Kellgren-Lawrence score and reading time were assessed. All measurements were compared and non-inferiority, mean-absolute-deviation (sMAD), and intra-class-correlation (ICC) were calculated. Results A total of 295 LLRs from 284 patients (mean age, 65 years (18; 90); 97 (34.2%) men) were analyzed. The AI model produces outputs on 98.0% of the LLRs. Manually annotations were considered as 100% accurate. For each measurement, its divergence was calculated, resulting in an overall accuracy of 89.2% when comparing the AI outputs to the manually measured. AI vs. mean observer revealed an sMAD between 0.39 and 2.19 degrees for angles and 1.45-5.00 mm for lengths. AI showed good reliability in all lengths and angles (ICC >= 0.87). Non-inferiority comparing AI to the mean observer revealed an equivalence-index (gamma) between 0.54 and 3.03 degrees for angles and - 0.70-1.95 mm for lengths. On average, AI was 130 s faster than clinicians. Conclusion Automated measurements of knee alignment and length measurements produced with an AI tool result in reproducible, accurate measures with a time savings compared to manually acquired measurements.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1007/s00256-021-03948-9
VL  - 51
IS  - 6
SP  - 1249
EP  - 1259
SN  - 0364-2348
AN  - WOS:000718096400001
ER  - 

TY  - JOUR
TI  - Establishing a social licence for Financial Technology: Reflections on the role of the private sector in pursuing ethical data practices
AU  - Aitken, M
AU  - Toreini, E
AU  - Carmichael, P
AU  - Coopamootoo, K
AU  - Elliott, K
AU  - van Moorsel, A
T2  - BIG DATA & SOCIETY
AB  - Current attention directed at ethical dimensions of data and Artificial Intelligence have led to increasing recognition of the need to secure and maintain public support for uses (and reuses) of people's data. This is essential to establish a "Social Licence" for current and future practices. The notion of a "Social Licence" recognises that there can be meaningful differences between what is legally permissible and what is socially acceptable. Establishing a Social Licence entails public engagement to build relationships of trust and ensure that practices align with public values. While the concept of the Social Licence is well-established in other sectors - notably in relation to extractive industries - it has only very recently begun to be discussed in relation to digital innovation and data-intensive industries. This article therefore draws on existing literature relating to the Social Licence in extractive industries to explore the potential approaches needed to establish a Social Licence for emerging data-intensive industries. Additionally, it draws on well-established literature relating to trust (from psychology and organisational science) to examine the relevance of trust, and trustworthiness, for emerging practices in data-intensive industries. In doing so the article considers the extent to which pursuing a Social Licence might complement regulation and inform codes of practice to place ethical and social considerations at the heart of industry practice. We focus on one key industry: Financial Technology. We demonstrate the importance of combining technical and social approaches to address ethical challenges in data-intensive innovation (particularly relating to Artificial Intelligence) and to establish relationships of trust to underpin a Social Licence for Financial Technology. Such approaches are needed across all areas and industries of data-intensive innovation to complement regulation and inform the development of ethical codes of practice. This is important to underpin culture change and to move beyond rhetorical commitments to develop best practice putting ethics at the heart of innovation. Published under license by AIP Publishing.
DA  - 2020/01//undefined
PY  - 2020
DO  - 10.1177/2053951720908892
VL  - 7
IS  - 1
SN  - 2053-9517
AN  - WOS:000524545400001
ER  - 

TY  - JOUR
TI  - Adversarial Robustness Via Fisher-Rao Regularization
AU  - Picot, M
AU  - Messina, F
AU  - Boudiaf, M
AU  - Labeau, F
AU  - Ayed, IB
AU  - Piantanida, P
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - Adversarial robustness has become a topic of growing interest in machine learning since it was observed that neural networks tend to be brittle. We propose an information-geometric formulation of adversarial defense and introduce Fire, a new Fisher-Rao regularization for the categorical cross-entropy loss, which is based on the geodesic distance between the softmax outputs corresponding to natural and perturbed input features. Based on the information-geometric properties of the class of softmax distributions, we derive an explicit characterization of the Fisher-Rao Distance (FRD) for the binary and multiclass cases, and draw some interesting properties as well as connections with standard regularization metrics. Furthermore, we verify on a simple linear and Gaussian model, that all Pareto-optimal points in the accuracy-robustness region can be reached by Fire while other state-of-the-art methods fail. Empirically, we evaluate the performance of various classifiers trained with the proposed loss on standard datasets, showing up to a simultaneous 1% of improvement in terms of clean and robust performances while reducing the training time by 20% over the best-performing methods.
DA  - 2023/03/01/
PY  - 2023
DO  - 10.1109/TPAMI.2022.3174724
VL  - 45
IS  - 3
SP  - 2698
EP  - 2710
SN  - 0162-8828
AN  - WOS:000934990500001
KW  - Deep learning
KW  - deep learning
KW  - Neural networks
KW  - Learning systems
KW  - neural networks
KW  - Machine-learning
KW  - Classification (of information)
KW  - article
KW  - Computer vision
KW  - Robustness
KW  - computer vision
KW  - classifier
KW  - Neural-networks
KW  - Perturbation method
KW  - Perturbation techniques
KW  - Adversarial machine learning
KW  - adversarial training
KW  - Adversarial training
KW  - Regularisation
KW  - Geometry
KW  - Pareto principle
KW  - Adversarial regularization
KW  - fisher-rao distance
KW  - Fisher-rao distance
KW  - information geometry
KW  - Information geometry
KW  - Manifold
KW  - safety AI
KW  - Safety AI
ER  - 

TY  - JOUR
TI  - A Call for Controlled Validation Data Sets: Promoting the Safe Introduction of Artificial Intelligence in Breast Imaging
AU  - Strand, F
AU  - Patel, BK
AU  - Allen, B
T2  - JOURNAL OF THE AMERICAN COLLEGE OF RADIOLOGY
DA  - 2019/11//undefined
PY  - 2019
DO  - 10.1016/j.jacr.2021.06.001
VL  - 18
IS  - 11
SP  - 1564
EP  - 1565
SN  - 1546-1440
AN  - WOS:000715036800001
ER  - 

TY  - CONF
TI  - Iterative machine learning based rotational alignment of brain 3D CT data
AU  - Chmelik, J
AU  - Jakubicek, R
AU  - Vicar, T
AU  - Walek, P
AU  - Ourednicek, P
AU  - Jan, JR
AU  - IEEE
T2  - 2019 41ST ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY (EMBC)
AB  - The optimal rotational alignment of brain Computed Tomography (CT) images to a required standard position has a crucial importance for both automatic and manual diagnostic analysis. In this contribution, we present a novel two-step iterative approach for the automatic 3D rotational alignment of brain CT data. The angles of axial and coronal rotations are determined by an unsupervised by localisation of the Midsagittal Plane (MSP) method. This includes detection and pairing of medially symmetrical feature points. The sagittal rotation angle is subsequently estimated by regression convolutional neural network (CNN). The proposed methodology has been evaluated on a dataset of CT data manually aligned by radiologists. It has been shown that the algorithm achieved the low error of estimated rotations (approximate to 1 degree) and in a significantly shorter time than the experts (approximate to 2 minutes per case).
DA  - 2019///
PY  - 2019
DO  - 10.1109/embc.2019.8857858
SP  - 4404
EP  - 4408
SN  - 1557-170X
AN  - WOS:000557295304193
KW  - machine learning
KW  - Machine learning
KW  - Machine Learning
KW  - Convolutional neural networks
KW  - brain
KW  - Diagnosis
KW  - Algorithms
KW  - human
KW  - Humans
KW  - algorithm
KW  - Iterative methods
KW  - Brain
KW  - Alignment
KW  - diagnostic imaging
KW  - Localisation
KW  - Neural Networks, Computer
KW  - Computerized tomography
KW  - Tomography, X-Ray Computed
KW  - x-ray computed tomography
KW  - Brain CT
KW  - Coronal rotation
KW  - Diagnostic analysis
KW  - Iterative approach
KW  - Mid-sagittal planes
KW  - Rotation angles
KW  - Rotational alignment
ER  - 

TY  - JOUR
TI  - Model-Based Chance-Constrained Reinforcement Learning via Separated Proportional-Integral Lagrangian
AU  - Peng, BY
AU  - Duan, JL
AU  - Chen, JY
AU  - Li, SBE
AU  - Xie, GJ
AU  - Zhang, CS
AU  - Guan, Y
AU  - Mu, Y
AU  - Sun, EX
T2  - IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB  - Safety is essential for reinforcement learning (RL) applied in the real world. Adding chance constraints (or probabilistic constraints) is a suitable way to enhance RL safety under uncertainty. Existing chance-constrained RL methods, such as the penalty methods and the Lagrangian methods, either exhibit periodic oscillations or learn an overconservative or unsafe policy. In this article, we address these shortcomings by proposing a separated proportional-integral Lagrangian (SPIL) algorithm. We first review the constrained policy optimization process from a feedback control perspective, which regards the penalty weight as the control input and the safe probability as the control output. Based on this, the penalty method is formulated as a proportional controller, and the Lagrangian method is formulated as an integral controller. We then unify them and present a proportional-integral Lagrangian method to get both their merits with an integral separation technique to limit the integral value to a reasonable range. To accelerate training, the gradient of safe probability is computed in a model-based manner. The convergence of the overall algorithm is analyzed. We demonstrate that our method can reduce the oscillations and conservatism of RL policy in a car-following simulation. To prove its practicality, we also apply our method to a real-world mobile robot navigation task, where our robot successfully avoids a moving obstacle with highly uncertain or even aggressive behaviors.
DA  - 2022/05/30/
PY  - 2022
DO  - 10.1109/TNNLS.2022.3175595
SN  - 2162-237X
AN  - WOS:000805807500001
KW  - Reinforcement learning
KW  - Safety
KW  - Task analysis
KW  - Training
KW  - neural networks
KW  - Job analysis
KW  - Navigation
KW  - Controllers
KW  - Uncertainty
KW  - Optimisations
KW  - Uncertainty analysis
KW  - Optimization
KW  - Mobile robots
KW  - Lagrange multipliers
KW  - Constrained optimization
KW  - Neural-networks
KW  - Model-based OPC
KW  - Oscillators
KW  - Two term control systems
KW  - Safe reinforcement learning .
KW  - Constrained controls
KW  - Robot navigation
KW  - Separation
KW  - Constrained control
KW  - Lagrangian methods
KW  - Proportional integral
KW  - robot navigation
KW  - safe reinforcement learning (RL).
ER  - 

TY  - JOUR
TI  - Safe Navigation for UAV-Enabled Data Dissemination by Deep Reinforcement Learning in Unknown Environments
AU  - Huang, F
AU  - Li, GX
AU  - Tian, SW
AU  - Chen, J
AU  - Fan, GT
AU  - Chang, JH
T2  - CHINA COMMUNICATIONS
AB  - Unmanned aerial vehicles (UAVs) are increasingly considered in safe autonomous navigation systems to explore unknown environments where UAVs are equipped with multiple sensors to perceive the surroundings. However, how to achieve UAV-enabled data dissemination and also ensure safe navigation synchronously is a new challenge. In this paper, our goal is minimizing the whole weighted sum of the UAV's task completion time while satisfying the data transmission task requirement and the UAV's feasible flight region constraints. However, it is unable to be solved via standard optimization methods mainly on account of lacking a tractable and accurate system model in practice. To overcome this tough issue, we propose a new solution approach by utilizing the most advanced dueling double deep Q network (dueling DDQN) with multi-step learning. Specifically, to improve the algorithm, the extra labels are added to the primitive states. Simulation results indicate the validity and performance superiority of the proposed algorithm under different data thresholds compared with two other benchmarks.
DA  - 2022/01//undefined
PY  - 2022
VL  - 19
IS  - 1
SP  - 202
EP  - 217
SN  - 1673-5447
AN  - WOS:000747460300015
KW  - data dissemination
KW  - dueling double deep Q network (dueling DDQN)
KW  - safe autonomous navigation
KW  - unknown environments
KW  - Unmanned aerial vehicles (UAVs)
ER  - 

TY  - JOUR
TI  - Reinforcement-Learning-Aided Safe Planning for Aerial Robots to Collect Data in Dynamic Environments
AU  - Khamidehi, B
AU  - Sousa, ES
T2  - IEEE INTERNET OF THINGS JOURNAL
AB  - We study the data collection problem in an Internet of Things (IoT) network where an unmanned aerial vehicle (UAV) is utilized to aggregate data from a set of IoT devices. We formulate the scheduling and path planning problems for the UAV. The goal of the scheduling problem is to find the sequence of nodes that the UAV will visit to complete the data collection task in the shortest possible time, ensuring that it does not run out of energy during its mission. We express this problem as a mixed-integer nonlinear problem and propose an efficient algorithm to solve the aforementioned NP-hard problem in polynomial time. Path planning problem aims to find a collision-free path for the UAV. While the state-of-the-art schemes have focused on solving the path planning problem in static environments, we study the problem in a dynamic environment with moving obstacles. We develop an algorithm that works on both static and dynamic environments. Our method combines deep reinforcement learning (RL) with graph-based global path planning algorithms to find a collision-free path for the UAV. One important advantage of our RL-based method over the existing studies is its map independency, which allows us to transform the agent's learning from one environment to another. Via simulation studies, we show that our method is significantly effective in improving the safety of the path planning algorithms in dynamic environments.
DA  - 2022/08/01/
PY  - 2022
DO  - 10.1109/JIOT.2022.3145008
VL  - 9
IS  - 15
SP  - 13901
EP  - 13912
SN  - 2327-4662
AN  - WOS:000831217100081
KW  - Deep learning
KW  - Reinforcement learning
KW  - Motion planning
KW  - path planning
KW  - Internet of things
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Dynamic environments
KW  - Graphic methods
KW  - Unmanned aerial vehicles (UAV)
KW  - Heuristic algorithms
KW  - Antennas
KW  - Heuristics algorithm
KW  - Data acquisition
KW  - Data collection
KW  - Robot programming
KW  - Unmanned aerial vehicle
KW  - Scheduling
KW  - Polynomial approximation
KW  - Computational complexity
KW  - Wireless sensor networks
KW  - Internet of thing
KW  - Internet of Things (IoT)
KW  - Collision-free paths
KW  - Deep reinforcement learning (RL)
KW  - Path planning problems
KW  - Path planning.
KW  - Path-planning algorithm
KW  - unmanned aerial vehicles (UAVs)
ER  - 

TY  - JOUR
TI  - VALIDATION OF ARTIFICIAL INTELLIGENCE FOR PERFORMING SYSTEMATIC LITERATURE REVIEW SEARCHING FOR CLINICAL EFFICACY AND SAFETY DATA
AU  - Lionikaite, V
AU  - Curry, A
AU  - Brown, A
T2  - VALUE IN HEALTH
DA  - 2022/01//undefined
PY  - 2022
VL  - 25
IS  - 1
SP  - S207
EP  - S207
SN  - 1098-3015
AN  - WOS:000746490201256
ER  - 

TY  - JOUR
TI  - Effects of Adversarial Training on the Safety of Classification Models
AU  - Kim, H
AU  - Han, J
T2  - SYMMETRY-BASEL
AB  - Artificial intelligence (AI) is one of the most important topics that implements symmetry in computer science. As like humans, most AI also learns by trial-and-error approach which requires appropriate adversarial examples. In this study, we prove that adversarial training can be useful to verify the safety of classification model in early stage of development. We experimented with various amount of adversarial data and found that the safety can be significantly improved by appropriate ratio of adversarial training.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.3390/sym14071338
VL  - 14
IS  - 7
SN  - 2073-8994
AN  - WOS:000831461100001
ER  - 

TY  - JOUR
TI  - A railway accident prevention method based on reinforcement learning-Active preventive strategy by multi-modal data
AU  - Yan, DY
AU  - Li, KP
AU  - Zhu, QZ
AU  - Liu, YY
T2  - RELIABILITY ENGINEERING & SYSTEM SAFETY
AB  - Railway systems are entering an era of highly intelligent automation where stability and safety are becoming increasingly important. However, there is still a lack of intelligent and effective ways for railway accident prevention, especially active accident prevention strategies. This paper presents a railway accident prevention method based on the reinforcement learning model and multi-modal data to achieve active railway accident prevention strategies. Three metrics are designed to show the performance of active prevention methods. Based on the three metrics and the data from Federal Railroad Administration, the effectiveness of the proposed method is verified in the case study by introducing two methods as baselines. The results also show that nearly 30% of accidents can be effectively prevented through active preventive measures with the proposed method. Finally, this paper analyzes the influence of personal skills on the proposed model and makes relevant suggestions for improving railway safety based on the analysis of the results.
DA  - 2023/06//undefined
PY  - 2023
DO  - 10.1016/j.ress.2023.109136
VL  - 234
SN  - 0951-8320
AN  - WOS:000944286700001
ER  - 

TY  - JOUR
TI  - POTENTIAL AND CHALLENGES OF ARTIFICIAL INTELLIGENCE
AU  - Casonato, C
T2  - BIOLAW JOURNAL-RIVISTA DI BIODIRITTO
AB  - The article, based on the writings collected in the issue, proposes a constitutionally oriented perspective of artificial intelligence (AI). Dealing with the main potentials and threats of AI, it suggests some constitutional principles as the basis for an effective regulation of the phenomenon, calling for a precise and direct human responsibility.
DA  - 2019///
PY  - 2019
IS  - 1
SP  - 177
EP  - 182
SN  - 2284-4503
AN  - WOS:000462097000012
ER  - 

TY  - CONF
TI  - Artificial Intelligence and Data Science Governance: Roles and Responsibilities at the C-Level and the Board
AU  - Thuraisingham, B
AU  - IEEE Comp Soc
T2  - 2020 IEEE 21ST INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION FOR DATA SCIENCE (IRI 2020)
AB  - Corporate governance and the roles and responsibilities of the corporate officers and the board of directors have received an increasing interest since the Enron scandal of the early 2000s. This scandal resulted in enacting policies, laws and regulations such as the Sarbanes-Oxley and others. More recently, with almost every corporation focusing on the applications of Artificial Intelligence (AI) and Data Science (DS) for their businesses in numerous industries including finance and banking, healthcare and medicine, manufacturing and retail and defense and intelligence, it is critical that these corporations take a serious look at the roles and responsibilities of the corporate officers and the board with respect to the governance of the AI and DS operations. This paper discusses the issues and challenges for AI and DS governance with an emphasis on the potential roles and responsibilities of the corporate officers and the board of directors.
DA  - 2020///
PY  - 2020
DO  - 10.1109/IRI49571.2020.00052
SP  - 314
EP  - 318
SN  - 978-1-7281-1054-7
AN  - WOS:000635425100044
ER  - 

TY  - JOUR
TI  - Data governance functions to support responsible data stewardship in pediatric radiology research studies using artificial intelligence
AU  - Monah, SR
AU  - Wagner, MW
AU  - Biswas, A
AU  - Khalvati, F
AU  - Erdman, LE
AU  - Amirabadi, A
AU  - Vidarsson, L
AU  - McCradden, MD
AU  - Ertl-Wagner, BB
T2  - PEDIATRIC RADIOLOGY
AB  - The integration of human and machine intelligence promises to profoundly change the practice of medicine. The rapidly increasing adoption of artificial intelligence (AI) solutions highlights its potential to streamline physician work and optimize clinical decision-making, also in the field of pediatric radiology. Large imaging databases are necessary for training, validating and testing these algorithms. To better promote data accessibility in multi-institutional AI-enabled radiologic research, these databases centralize the large volumes of data required to effect accurate models and outcome predictions. However, such undertakings must consider the sensitivity of patient information and therefore utilize requisite data governance measures to safeguard data privacy and security, to recognize and mitigate the effects of bias and to promote ethical use. In this article we define data stewardship and data governance, review their key considerations and applicability to radiologic research in the pediatric context, and consider the associated best practices along with the ramifications of poorly executed data governance. We summarize several adaptable data governance frameworks and describe strategies for their implementation in the form of distributed and centralized approaches to data management.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1007/s00247-022-05427-2
VL  - 52
IS  - 11
SP  - 2111
EP  - 2119
SN  - 0301-0449
AN  - WOS:000821982300001
ER  - 

TY  - JOUR
TI  - Dynamic Joint Distribution Alignment Network for Bearing Fault Diagnosis Under Variable Working Conditions
AU  - Shen, CQ
AU  - Wang, X
AU  - Wang, D
AU  - Li, YX
AU  - Zhu, J
AU  - Gong, MM
T2  - IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
AB  - An inconsistent distribution between training and testing data caused by complicated and changeable machine working conditions hinders wide applications of traditional deep learning for machine fault diagnosis. In a target domain, in which labeled samples are not available (testing data), transfer learning can adopt a relevant source domain (training data) to identify the similarity between the two domains and subsequently mitigate the negative effects of a domain shift. Previous studies on transfer learning mainly focused on decreasing the marginal distribution distance of two different domains or narrowing the conditional distribution distance even though marginal and conditional distributions provide different contributions to transfer tasks. The relative importance of the two distributions is difficult to dynamically and quantitatively assess. To align the two distributions (joint distribution) of two different domains, in this article, we propose a dynamic joint distribution alignment network (DJDAN) to evaluate the relative importance of marginal and conditional distributions dynamically and quantitatively. Furthermore, compared with common metrics that use pseudo labels to calculate the conditional distribution distance, the proposed DJDAN uses soft pseudo labels to more accurately measure the conditional distribution discrepancy between different domains. Extensive experiments reveal the superiority and generalization of the proposed DJDAN for bearing fault diagnosis under different working conditions.
DA  - 2021///
PY  - 2021
DO  - 10.1109/TIM.2021.3055786
VL  - 70
SN  - 0018-9456
AN  - WOS:000617752900003
KW  - Deep learning
KW  - Transfer learning
KW  - Training and testing
KW  - Failure analysis
KW  - Fault detection
KW  - Machine fault diagnosis
KW  - unsupervised learning
KW  - Alignment
KW  - Conditional distribution
KW  - Joint distributions
KW  - Marginal distribution
KW  - Bearing fault diagnosis
KW  - Different domains
KW  - Bearing
KW  - distribution alignment
KW  - Bearings (machine parts)
KW  - fault diagnosis
KW  - Machine working
KW  - soft pseudo labels
KW  - Underground structures
ER  - 

TY  - JOUR
TI  - Corporate Digital Responsibility in Service Firms and Their Ecosystems
AU  - Wirtz, J
AU  - Kunz, WH
AU  - Hartley, N
AU  - Tarbit, J
T2  - JOURNAL OF SERVICE RESEARCH
AB  - Digitization, artificial intelligence, and service robots carry serious ethical, privacy, and fairness risks. Using the lens of corporate digital responsibility (CDR), we examine these risks and their mitigation in service firms and make five contributions. First, we show that CDR is critical in service contexts because of the vast streams of customer data involved and digital service technology's omnipresence, opacity, and complexity. Second, we synthesize the ethics, privacy, and fairness literature using the CDR data and technology life-cycle perspective to understand better the nature of these risks in a service context. Third, to provide insights on the origins of these risks, we examine the digital service ecosystem and the related flows of money, service, data, insights, and technologies. Fourth, we deduct that the underlying causes of CDR issues are trade-offs between good CDR practices and organizational objectives (e.g., profit opportunities versus CDR risks) and introduce the CDR calculus to capture this. We also conclude that regulation will need to step in when a firm's CDR calculus becomes so negative that good CDR is unlikely. Finally, we advance a set of strategies, tools, and practices service firms can use to manage these trade-offs and build a strong CDR culture.
DA  - 2023/05//undefined
PY  - 2023
DO  - 10.1177/10946705221130467
VL  - 26
IS  - 2
SP  - 173
EP  - 190
SN  - 1094-6705
AN  - WOS:000864424200001
ER  - 

TY  - CONF
TI  - Machine Learning Based Test Data Generation for Safety-Critical Software
AU  - Cegin, J
T2  - PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20)
A2  - Devanbu, P
A2  - Cohen, M
A2  - Zimmermann, T
AB  - Unit testing focused on Modified Condition/Decision Coverage (MC/DC) criterion is essential in development safety-critical systems. However, design of test data that meets the MC/DC criterion currently needs detailed manual analysis of branching conditions in units under test by test engineers. Multiple state-of-art approaches exist with proven usage even in industrial projects. However, these approaches have multiple shortcomings, one of them being the Path explosion problem which has not been fully solved yet. Machine learning methods as meta-heuristic approximations can model behaviour of programs that are hard to test using traditional approaches, where the Path explosion problem does occur and thus could solve the limitations of the current state-of-art approaches. I believe, motivated by an ongoing collaboration with an industrial partner, that the machine learning methods could be combined with existing approaches to produce an approach suitable for testing of safety-critical projects.
DA  - 2020///
PY  - 2020
DO  - 10.1145/3368089.3418538
SP  - 1678
EP  - 1681
SN  - 978-1-4503-7043-1
AN  - WOS:000744432100162
KW  - Machine learning
KW  - Accident prevention
KW  - Traditional approaches
KW  - Machine learning methods
KW  - Safety critical software
KW  - Heuristic methods
KW  - Safety testing
KW  - Safety critical systems
KW  - Explosions
KW  - Software testing
KW  - Unit testing
KW  - Heuristic programming
KW  - Industrial partners
KW  - Industrial projects
KW  - MC/DC criterion
KW  - Modified condition/decision coverages
KW  - Test data generation
ER  - 

TY  - JOUR
TI  - "Those Who Learn Have a Responsibility To Teach": Black Therapists' Experiences Supervising Black Therapist Trainees
AU  - Goode-Cross, DT
T2  - TRAINING AND EDUCATION IN PROFESSIONAL PSYCHOLOGY
AB  - This phenomenological study examined how 12 Black psychotherapists in college counseling centers around the country experienced the supervision of Black therapist trainees. Participants described how their relationships and methods of supervision differed when working in same-race dyads. They reported feeling closer to their Black supervisees in ways that often felt familial. The therapists described serving as mentors for their Black supervisees. They also reported discussing race more frequently in supervision, and they perceived that their Black supervisees felt safer having Black supervisors. The study also suggests implications for the training of ethnic minority therapists and supervisors.
DA  - 2011/05//undefined
PY  - 2011
DO  - 10.1037/a0023187
VL  - 5
IS  - 2
SP  - 73
EP  - 80
SN  - 1931-3918
AN  - WOS:000290778700003
ER  - 

TY  - JOUR
TI  - Transferable Deep Reinforcement Learning Framework for Autonomous Vehicles With Joint Radar-Data Communications
AU  - Hieu, NQ
AU  - Hoang, DT
AU  - Niyato, D
AU  - Wang, P
AU  - Kim, DI
AU  - Yuen, C
T2  - IEEE TRANSACTIONS ON COMMUNICATIONS
AB  - Autonomous Vehicles (AVs) are required to operate safely and efficiently in dynamic environments. For this, the AVs equipped with Joint Radar-Communications (JRC) functions can enhance the driving safety by utilizing both radar detection and data communication functions. However, optimizing the performance of the AV system with two different functions under uncertainty and dynamic of surrounding environments is very challenging. In this work, we first propose an intelligent optimization framework based on the Markov Decision Process (MDP) to help the AV make optimal decisions in selecting JRC operation functions under the dynamic and uncertainty of the surrounding environment. We then develop an effective learning algorithm leveraging recent advances of deep reinforcement learning techniques to find the optimal policy for the AV without requiring any prior information about surrounding environment. Furthermore, to make our proposed framework more scalable, we develop a Transfer Learning (TL) mechanism that enables the AV to leverage valuable experiences for accelerating the training process when it moves to a new environment. Extensive simulations show that the proposed transferable deep reinforcement learning framework reduces the obstacle miss detection probability by the AV up to 67% compared to other conventional deep reinforcement learning approaches. With the deep reinforcement learning and transfer learning approaches, our proposed solution can find its applications in a wide range of autonomous driving scenarios from driver assistance to full automation transportation.
DA  - 2022/08//undefined
PY  - 2022
DO  - 10.1109/TCOMM.2022.3182034
VL  - 70
IS  - 8
SP  - 5164
EP  - 5180
SN  - 0090-6778
AN  - WOS:000846884500018
ER  - 

TY  - JOUR
TI  - Safe deep reinforcement learning-based constrained optimal control scheme for active distribution networks
AU  - Kou, P
AU  - Liang, DL
AU  - Wang, C
AU  - Wu, ZH
AU  - Gao, L
T2  - APPLIED ENERGY
AB  - Reinforcement learning-based schemes are being recently applied for model-free voltage control in active distribution networks. However, existing reinforcement learning methods face challenges when it comes to continuous state and action spaces problems or problems with operation constraints. To address these limitations, this paper proposes an optimal voltage control scheme based on the safe deep reinforcement learning. In this scheme, the optimal voltage control problem is formulated as a constrained Markov decision process, in which both state and action spaces are continuous. To solve this problem efficiently, the deep deterministic policy gradient algorithm is utilized to learn the reactive power control policies, which determine the optimal control actions from the states. In contrast to existing reinforcement learning methods, deep deterministic policy gradient is naturally capable of addressing control problems with continuous state and action spaces. This is due to the utilization of deep neural networks to approximate both value function and policy. In addition, in order to handle the operation constraints in active distribution networks, a safe exploration approach is proposed to form a safety layer, which is composed directly on top the deep deterministic policy gradient actor network. This safety layer predicts the change in the constrained states and prevents the violation of active distribution networks operation constraints. Numerical simulations on modified IEEE test systems demonstrate that the proposed scheme successfully maintains all bus voltage within the allowed range, and reduces the system loss by 15% compared to the no control case.
DA  - 2020/04/15/
PY  - 2020
DO  - 10.1016/j.apenergy.2020.114772
VL  - 264
SN  - 0306-2619
AN  - WOS:000519517700064
KW  - Deep learning
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - Learning systems
KW  - prediction
KW  - safety
KW  - algorithm
KW  - decision making
KW  - Markov chain
KW  - Markov processes
KW  - optimization
KW  - Constrained optimization
KW  - Voltage control
KW  - Power control
KW  - reinforcement
KW  - distribution system
KW  - Reactive power
KW  - Constraint Satisfaction
KW  - Policy gradient
KW  - Deep deterministic policy gradient
KW  - exploration
KW  - Active distribution network
KW  - Active distribution networks
KW  - Constraint satisfaction
KW  - Optimal voltage control
KW  - Optimal voltages
KW  - Smart transformer
ER  - 

TY  - CONF
TI  - Minimizing Safety Interference for Safe and Comfortable Automated Driving with Distributional Reinforcement Learning
AU  - Kamran, D
AU  - Engelgeh, T
AU  - Busch, M
AU  - Fischer, J
AU  - Stiller, C
AU  - IEEE
T2  - 2021 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS)
AB  - Despite recent advances in reinforcement learning (RL), its application in safety critical domains like autonomous vehicles is still challenging. Although penalizing RL agents for risky situations can help to learn safe policies, it may also lead to highly conservative behavior. In this paper, we propose a distributional RL framework in order to learn adaptive policies which allow to tune their level of conservativity at run-time based on the desired comfort and utility. Using a proactive safety verification approach, the proposed framework can guarantee that actions generated from RL are fail-safe according to the worst-case assumptions. Concurrently, the policy is encouraged to minimize safety interference and generate more comfortable behavior. We trained and evaluated the proposed approach and baseline policies using a high level simulator with a variety of randomized scenarios including several corner cases which rarely happen in reality but are very crucial. In light of our experiments, the behavior of policies learned using distributional RL is adaptive at run-time and robust to the environment uncertainty. Quantitatively, the learned distributional RL agent reduces the average driving time more than 50% compared to the normal DQN policy. It also requires 83% less safety interference compared to the rule-based policy while only slightly increasing the average driving time. We also study sensitivity of the learned policy in environments with higher perception noise and show that our algorithm learns policies that can still drive reliable when the perception noise is two times higher than in the training configuration in automated merging and crossing at occluded intersections.
DA  - 2021///
PY  - 2021
DO  - 10.1109/IROS51168.2021.9636847
SP  - 1236
EP  - 1243
SN  - 2153-0858
AN  - WOS:000755125501003
KW  - Reinforcement learning
KW  - Autonomous Vehicles
KW  - Automated driving
KW  - Intelligent vehicle highway systems
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Safety engineering
KW  - Learn+
KW  - Runtimes
KW  - Spurious signal noise
KW  - ITS applications
KW  - Safety-critical domain
KW  - Adaptive policy
KW  - Conservativity
ER  - 

TY  - JOUR
TI  - Enterprise data security storage integrating blockchain and artificial intelligence technology in property and resource risk management
AU  - Wu, JG
AU  - Jiang, HY
AU  - Chen, JX
T2  - SOFT COMPUTING
AB  - Enterprise data security is a critical concern for businesses, especially when it comes to storing sensitive information related to property and resource risk management. Integrating blockchain and artificial intelligence (AI) technology can provide a more secure and efficient solution for storing this type of data. Some multinational enterprises struggle with poor property and resource management, which leads to the loss of materials inventory information during storage. This lack of information prevents managers from accessing timely and accurate financial information, increasing the risk of foreign investment and resulting in financial crises. To address this problem, this paper proposes a secure storage system for Material Inventory Data (MID) that integrates blockchain and artificial intelligence technology. The proposed system consists of three components: transactions, blocks, and chains, which create a hierarchical structural model. The system's constraint function calculates the probability of multiple intruders attacking the system, and the target constraint conditions are divided to establish a safe storage mechanism. Additionally, the system uses an incentive mechanism where multiple nodes agree on the block contents to optimize the model and maximize block income. Simulation results show that the proposed system has a shorter data storage delay time than the conventional approach, and very little data loss, effectively ensuring the integrity of enterprise data security storage.
DA  - 2023/07/12/
PY  - 2023
DO  - 10.1007/s00500-023-08933-z
SN  - 1432-7643
AN  - WOS:001026728200012
ER  - 

TY  - JOUR
TI  - Automatic alignment of contemporary vector data and georeferenced historical maps using reinforcement learning
AU  - Duan, WW
AU  - Chiang, YY
AU  - Leyk, S
AU  - Uhl, JH
AU  - Knoblock, CA
T2  - INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE
AB  - With large amounts of digital map archives becoming available, automatically extracting information from scanned historical maps is needed for many domains that require long-term historical geographic data. Convolutional Neural Networks (CNN) are powerful techniques that can be used for extracting locations of geographic features from scanned maps if sufficient representative training data are available. Existing spatial data can provide the approximate locations of corresponding geographic features in historical maps and thus be useful to annotate training data automatically. However, the feature representations, publication date, production scales, and spatial reference systems of contemporary vector data are typically very different from those of historical maps. Hence, such auxiliary data cannot be directly used for annotation of the precise locations of the features of interest in the scanned historical maps. This research introduces an automatic vector-to-raster alignment algorithm based on reinforcement learning to annotate precise locations of geographic features on scanned maps. This paper models the alignment problem using the reinforcement learning framework, which enables informed, efficient searches for matching features without pre-processing steps, such as extracting specific feature signatures (e.g. road intersections). The experimental results show that our algorithm can be applied to various features (roads, water lines, and railroads) and achieve high accuracy.
DA  - 2020/04/02/
PY  - 2020
DO  - 10.1080/13658816.2019.1698742
VL  - 34
IS  - 4
SP  - 824
EP  - 849
SN  - 1365-8816
AN  - WOS:000501711200001
KW  - machine learning
KW  - reinforcement learning
KW  - algorithm
KW  - digital humanities
KW  - digital map
KW  - digital map processing
KW  - raster
KW  - spatial data
KW  - topographic mapping
KW  - USGS historical topographic maps
KW  - vector
KW  - Vector-to-raster alignment
ER  - 

TY  - CONF
TI  - Safe Offline Reinforcement Learning Through Hierarchical Policies
AU  - Liu, SF
AU  - Sun, SL
T2  - ADVANCES IN KNOWLEDGE DISCOVERY AND DATA MINING, PAKDD 2022, PT II
A2  - Gama, J
A2  - Li, T
A2  - Yu, Y
A2  - Chen, E
A2  - Zheng, Y
A2  - Teng, F
AB  - Recently, offline reinforcement learning has gained increasing attention. However, the safety of offline reinforcement learning has been ignored. It poses a significant challenge to learn a safe and high-performance policy from a fixed dataset that contains unsafe or unexpected state-action pairs without interacting with the environment. Since the unsafe state-action pairs are usually sparse in the behavior data collected by humans, it is difficult to effectively model information about unsafe behaviors. This paper utilized the hierarchical reinforcement learning framework to alleviate the sparsity issue by modeling unsafe behaviors with hierarchical policies. Specifically, a high-level policy determines a prospective state, and a low-level policy takes action to reach the specified goal state. The training objective of the high-level policy is to improve the expected reward that the low-level policy collects when it moves toward the goal state and reduce the number of unsafe actions. We further develop data processing methods to provide training data for the high-level policy and the low-level policy. Evaluation experiments about performance and safety are conducted in simulation environments that return the rewards and unsafe costs obtained by agents during the interaction. Experimental results demonstrate that the proposed algorithm can choose safe actions while maintaining high performance.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-05936-0_30
VL  - 13281
SP  - 380
EP  - 391
SN  - 0302-9743
AN  - WOS:000870701000030
KW  - Reinforcement learning
KW  - Data handling
KW  - Performance
KW  - Reinforcement learnings
KW  - Learn+
KW  - Safe reinforcement learning
KW  - Offline
KW  - Model informations
KW  - Unsafe behaviors
KW  - Hierarchical policies
KW  - Hierarchical policy
KW  - High level policies
KW  - Off-line training
KW  - Offline training
ER  - 

TY  - CONF
TI  - Alignment of Image-Text and Video-Text Datasets
AU  - Özköse, YE
AU  - Gökçe, Z
AU  - Duygulu, P
AU  - IEEE
T2  - 2023 31ST SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, SIU
AB  - In this study, the alignment of video-text and image-text datasets is studied. Firstly, similarities are calculated over the texts in the two data sets. A retrieval setup with visual similarities is then applied to the subset which is created via calculated text similarities. A BERT-based embedding vector method is applied to the raw and pure texts. As a visual feature, object-based and CLIP-based methods are used to define video frames. According to the results, alignment with CLIP features achieves the best results in the subset created by filtering using raw text.
DA  - 2023///
PY  - 2023
DO  - 10.1109/SIU59756.2023.10224043
SN  - 2165-0608
AN  - WOS:001062571000248
KW  - machine learning
KW  - Deep learning
KW  - deep learning
KW  - Learning systems
KW  - Machine-learning
KW  - Computer vision
KW  - Alignment
KW  - Embeddings
KW  - Data set
KW  - dataset alignment
KW  - Dataset alignment
KW  - Image texts
KW  - Text similarity
KW  - Vector method
KW  - Visual feature
KW  - Visual similarity
ER  - 

TY  - CONF
TI  - Regulating for 'Normal Al Accidents': Operational Lessons for the Responsible Governance of Artificial Intelligence Deployment
AU  - Maas, MM
AU  - ACM
T2  - PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18)
AB  - New technologies, particularly those which are deployed rapidly across sectors, or which have to operate in competitive conditions, can disrupt previously stable technology governance regimes. This leads to a precarious need to balance caution against performance while exploring the resulting 'safe operating space'. This paper will argue that Artificial Intelligence is one such critical technology, the responsible deployment of which is likely to prove especially complex, because even narrow AI applications often involve networked (tightly coupled, opaque) systems operating in complex or competitive environments. This ensures such systems are prone to 'normal accident'-type failures which can cascade rapidly, and are hard to contain or even detect in time. Legal and governance approaches to the deployment of AI will have to reckon with the specific causes and features of such `normal accidents'. While this suggests that large-scale, cascading errors in AI systems are inevitable, an examination of the operational features that lead technologies to exhibit 'normal accidents' enables us to derive both tentative principles for precautionary policymaking, and practical recommendations for the safe(r) deployment of AI systems. This may help enhance the safety and security of these systems in the public sphere, both in the short- and in the long term.
DA  - 2018///
PY  - 2018
DO  - 10.1145/3278721.3278766
SP  - 223
EP  - 228
SN  - 978-1-4503-6012-8
AN  - WOS:000510018100038
ER  - 

TY  - JOUR
TI  - The effectiveness of embedded values analysis modules in Computer Science education: An empirical study
AU  - Kopec, M
AU  - Magnani, M
AU  - Ricks, V
AU  - Torosyan, R
AU  - Basl, J
AU  - Miklaucic, N
AU  - Muzny, F
AU  - Sandler, R
AU  - Wilson, C
AU  - Wisniewski-Jensen, A
AU  - Lundgren, C
AU  - Baylon, R
AU  - Mills, K
AU  - Wells, M
T2  - BIG DATA & SOCIETY
AB  - Embedding ethics modules within computer science courses has become a popular response to the growing recognition that computer science programs need to better equip their students to navigate the ethical dimensions of computing technologies such as artificial intelligence, machine learning, and big data analytics. However, the popularity of this approach has outpaced the evidence of its positive outcomes. To help close that gap, this empirical study reports positive results from Northeastern University's program that embeds values analysis modules into computer science courses. The resulting data suggest that such modules have a positive effect on students' moral attitudes and that students leave the modules believing they are more prepared to navigate the ethical dimensions they will likely face in their eventual careers. Importantly, these gains were accomplished at an institution without a philosophy doctoral program, suggesting this strategy can be effectively employed by a wider range of institutions than many have thought.
DA  - 2023/01//undefined
PY  - 2023
DO  - 10.1177/20539517231176230
VL  - 10
IS  - 1
SN  - 2053-9517
AN  - WOS:001009830300001
ER  - 

TY  - JOUR
TI  - Deep reinforcement learning based active safety control for distributed drive electric vehicles
AU  - Wei, HQ
AU  - Zhao, WQ
AU  - Ai, Q
AU  - Zhang, YT
AU  - Huang, TY
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - Distributed drive electric vehicles are regarded as the promising transportation due to the advanced power flow architecture. Optimizing the yaw motion to enhance vehicle safety is a challenging job. Besides, the nonlinear features in vehicles affect the control accuracy of the yaw motion controllers. To this end, a deep reinforcement learning (DRL) based direct yaw moment control (DYC) strategy is put forward here. Vehicle dynamics can be approximated with the DRL algorithm, which reduces the complex nonlinear solving process. Concretely, the DYC problem is formulated as Markov Decision Process in which the observed signals and external yaw moment are incorporated as the state and action sets. Thereupon, actor-critic network is exhibited to approximate action-value function and policy function for better control performance. Furthermore, to guarantee the continuous solution of external yaw moment, the deep deterministic policy gradient algorithm is employed, in which target and online network parameters are simultaneously trained to maintain learning process stability. The proposed DRL based DYC strategy is verified using the Carsim/Simulink platform under the typical lane change manoeuvres. Numerical test results demonstrate that the proposed DYC strategy outperforms the linear approaches on taking full advantage of understeer features and enhancing the lateral stability, especially under the critical steering manoeuvres.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1049/itr2.12176
VL  - 16
IS  - 6
SP  - 813
EP  - 824
SN  - 1751-956X
AN  - WOS:000763774200001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Vehicle safety
KW  - Learning algorithms
KW  - Safety engineering
KW  - Markov processes
KW  - Electric machine control
KW  - Electric vehicles
KW  - Electric load flow
KW  - Safety controls
KW  - Active safety
KW  - Power flows
KW  - Nonlinear features
KW  - Control accuracy
KW  - Direct yaw moment control strategies
KW  - Flow architectures
KW  - Motion controller
KW  - Yaw moment
KW  - Yaw motions
ER  - 

TY  - JOUR
TI  - Analysis of high-rise building safety detection methods based on big data and artificial intelligence
AU  - Xu, JJ
AU  - Yan, CJ
AU  - Su, YY
AU  - Liu, Y
T2  - INTERNATIONAL JOURNAL OF DISTRIBUTED SENSOR NETWORKS
AB  - With rapid industrialization, the construction of high-rise buildings is a good and effective solution to the rational and effective use of land resources and alleviation of existing land resource tensions. Especially in the construction process, if there is a problem with the pile foundation, the building will inevitably be tilted, which will directly affect the personal safety of the construction workers and resident users. The experiments in this article use the concept of big data to divide the system into modules such as data collection, data preprocessing, feature extraction, prediction model building, and model application in order to provide massive data storage and parallel computing services to form a security test system. The experimental data show that wireless sensor technology is applied to the inclination monitoring of buildings, and a monitoring system based on wireless inclination sensors is designed to enable real-time dynamic monitoring of buildings to ensure human safety. When the experimental model frame is stable under normal environmental conditions, a nonstationary vibration is artificially produced for a period of time from the outside world, which is about 60 s higher than the traditional method, and the efficiency is also increased by about 80%, a situation where a building has a reversible tilt change.
DA  - 2020/06//undefined
PY  - 2020
DO  - 10.1177/1550147720935307
VL  - 16
IS  - 6
SN  - 1550-1477
AN  - WOS:000546004200001
ER  - 

TY  - JOUR
TI  - Artificial intelligence and real-world data for drug and food safety-A regulatory science perspective
AU  - Thakkar, S
AU  - Slikker, W
AU  - Yiannas, F
AU  - Silva, P
AU  - Blais, B
AU  - Chng, KR
AU  - Liu, ZC
AU  - Adholeya, A
AU  - Pappalardo, F
AU  - Soares, MDC
AU  - Beeler, PE
AU  - Whelan, M
AU  - Roberts, R
AU  - Borlak, J
AU  - Hugas, M
AU  - Torrecilla-Salinas, C
AU  - Girard, P
AU  - Diamond, MC
AU  - Verloo, D
AU  - Panda, B
AU  - Rose, MC
AU  - Jornet, JB
AU  - Furuhama, A
AU  - Fang, H
AU  - Kwegyir-Afful, E
AU  - Heintz, K
AU  - Arvidson, K
AU  - Burgos, JG
AU  - Horst, A
AU  - Tong, WD
T2  - REGULATORY TOXICOLOGY AND PHARMACOLOGY
AB  - In 2013, the Global Coalition for Regulatory Science Research (GCRSR) was established with members from over ten countries (www.gcrsr.net). One of the main objectives of GCRSR is to facilitate communication among global regulators on the rise of new technologies with regulatory applications through the annual conference Global Summit on Regulatory Science (GSRS). The 11th annual GSRS conference (GSRS21) focused on "Regulatory Sciences for Food/Drug Safety with Real-World Data (RWD) and Artificial Intelligence (AI)." The conference discussed current advancements in both AI and RWD approaches with a specific emphasis on how they impact regulatory sciences and how regulatory agencies across the globe are pursuing the adaptation and oversight of these technologies. There were presentations from Brazil, Canada, India, Italy, Japan, Germany, Switzerland, Singapore, the United Kingdom, and the United States. These presentations highlighted how various agencies are moving forward with these technologies by either improving the agencies' operation and/or preparing regula-tory mechanisms to approve the products containing these innovations. To increase the content and discussion, the GSRS21 hosted two debate sessions on the question of "Is Regulatory Science Ready for AI?" and a workshop to showcase the analytical data tools that global regulatory agencies have been using and/or plan to apply to regulatory science. Several key topics were highlighted and discussed during the conference, such as the capa-bilities of AI and RWD to assist regulatory science policies for drug and food safety, the readiness of AI and data science to provide solutions for regulatory science. Discussions highlighted the need for a constant effort to evaluate emerging technologies for fit-for-purpose regulatory applications. The annual GSRS conferences offer a unique platform to facilitate discussion and collaboration across regulatory agencies, modernizing regulatory approaches, and harmonizing efforts.
DA  - 2023/05//undefined
PY  - 2023
DO  - 10.1016/j.yrtph.2023.105388
VL  - 140
SN  - 0273-2300
AN  - WOS:000986687600001
ER  - 

TY  - CONF
TI  - Scalable and Accurate Self-supervised Multimodal Representation Learning without Aligned Video and Text Data
AU  - Lialin, V
AU  - Rawls, S
AU  - Chan, D
AU  - Ghosh, S
AU  - Rumshisky, A
AU  - Hamza, W
AU  - IEEE
T2  - 2023 IEEE/CVF WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION WORKSHOPS (WACVW)
AB  - Scaling up weakly-supervised datasets has shown to be highly effective in the image-text domain and has contributed to most of the recent state-of-the-art computer vision and multimodal neural networks. However, existing large-scale video-text datasets and mining techniques suffer from several limitations, such as the scarcity of aligned data, the lack of diversity in the data, and the difficulty of collecting aligned data. Currently popular video-text data mining approach via automatic speech recognition (ASR) used in HowTo100M provides low-quality captions that often do not refer to the video content. Other mining approaches do not provide proper language descriptions (video tags) and are biased toward short clips (alt text). In this work, we show how recent advances in image captioning allow us to pre-train high-quality video models without any parallel video-text data. We pre-train several video captioning models that are based on an OPT language model and a TimeSformer visual backbone. We fine-tune these networks on several video captioning datasets. First, we demonstrate that image captioning pseudolabels work better for pre-training than the existing HowTo100M ASR captions. Second, we show that pre-training on both images and videos produces a significantly better network (+4 CIDER on MSR-VTT) than pre-training on a single modality. Our methods are complementary to the existing pre-training or data mining approaches and can be used in a variety of settings. Given the efficacy of the pseudolabeling method, we are planning to publicly release the generated captions.
DA  - 2023///
PY  - 2023
DO  - 10.1109/WACVW58289.2023.00043
SP  - 390
EP  - 400
SN  - 2572-4398
AN  - WOS:000971997900039
KW  - Speech recognition
KW  - Data mining
KW  - State of the art
KW  - Computer vision
KW  - Multi-modal
KW  - Large dataset
KW  - Pre-training
KW  - Character recognition
KW  - Automatic speech recognition
KW  - Video data
KW  - Image texts
KW  - Image captioning
KW  - Recent state
KW  - Scaling-up
KW  - Text data
KW  - Visual languages
ER  - 

TY  - CONF
TI  - Towards Safe Machine Learning for CPS Infer Uncertainty from Training Data
AU  - Gu, XZ
AU  - Easwaran, A
T2  - ICCPS '19: PROCEEDINGS OF THE 2019 10TH ACM/IEEE INTERNATIONAL CONFERENCE ON CYBER-PHYSICAL SYSTEMS
A2  - Ramachandran, GS
A2  - Ortiz, J
AB  - Machine learning (ML) techniques are increasingly applied to decision-making and control problems in Cyber-Physical Systems among which many are safety-critical, e.g., chemical plants, robotics, autonomous vehicles. Despite the significant benefits brought by ML techniques, they also raise additional safety issues because 1) most expressive and powerful ML models are not transparent and behave as a black box and 2) the training data which plays a crucial role in ML safety is usually incomplete. An important technique to achieve safety for ML models is "Safe Fail", i.e., a model selects a reject option and applies the backup solution, a traditional controller or a human operator for example, when it has low confidence in a prediction.
Data-driven models produced by ML algorithms learn from training data, and hence they are only as good as the examples they have learnt. As pointed in [17], ML models work well in the "training space" (i.e., feature space with sufficient training data), but they could not extrapolate beyond the training space. As observed in many previous studies, a feature space that lacks training data generally has a much higher error rate than the one that contains sufficient training samples [31]. Therefore, it is essential to identify the training space and avoid extrapolating beyond the training space. In this paper, we propose an efficient Feature Space Partitioning Tree (FSPT) to address this problem. Using experiments, we also show that, a strong relationship exists between model performance and FSPT score.
DA  - 2019///
PY  - 2019
DO  - 10.1145/3302509.3311038
SP  - 249
EP  - 258
SN  - 2375-8317
AN  - WOS:000473800800024
KW  - Autonomous vehicles
KW  - Machine learning
KW  - Decision making
KW  - Training data
KW  - Human operator
KW  - Safety engineering
KW  - Embedded systems
KW  - Cyber Physical System
KW  - Extrapolation
KW  - Data-driven model
KW  - Control problems
KW  - Ml algorithms
KW  - Training sample
KW  - Chemical plants
KW  - Model performance
KW  - Feature space partitioning
KW  - Machine Learning Safety, Safe Fail
ER  - 

TY  - CONF
TI  - Learning a Domain-Invariant Embedding for Unsupervised Domain Adaptation Using Class-Conditioned Distribution Alignment
AU  - Gabourie, AJ
AU  - Rostami, M
AU  - Pope, PE
AU  - Kolouri, S
AU  - Kim, K
T2  - 2019 57TH ANNUAL ALLERTON CONFERENCE ON COMMUNICATION, CONTROL, AND COMPUTING (ALLERTON)
AB  - We address the problem of unsupervised domain adaptation (UDA) by learning a cross-domain agnostic embedding space, where the distance between the probability distributions of the two source and target visual domains is minimized. We use the output space of a shared cross-domain deep encoder to model the embedding space and use the Sliced-Wasserstein Distance (SWD) to measure and minimize the distance between the embedded distributions of two source and target domains to enforce the embedding to be domain-agnostic. Additionally, we use the source domain labeled data to train a deep classifier from the embedding space to the label space to enforce the embedding space to be discriminative. As a result of this training scheme, we provide an effective solution to train the deep classification network on the source domain such that it will generalize well on the target domain, where only unlabeled training data is accessible. To mitigate the challenge of class matching, we also align corresponding classes in the embedding space by using high confidence pseudo-labels for the target domain, i.e. assigning the class for which the source classifier has a high prediction probability. We provide experimental results on UDA benchmark tasks to demonstrate that our method is effective and leads to state-of-the-art performance.
DA  - 2019///
PY  - 2019
DO  - 10.1109/allerton.2019.8919960
SP  - 352
EP  - 359
SN  - 2474-0195
AN  - WOS:000535355700051
KW  - Classification (of information)
KW  - Benchmarking
KW  - Probability distributions
KW  - Domain adaptation
KW  - Embeddings
KW  - State-of-the-art performance
KW  - Deep classifications
KW  - Domain agnostics
KW  - Effective solution
KW  - Prediction probabilities
KW  - Sliced wasserstein distances
KW  - Training schemes
ER  - 

TY  - CONF
TI  - Providing Certified Paths for Safe Port Operation: The e-Mariner paradigm
AU  - Bakalos, NG
AU  - Bonazountas, M
AU  - Tsiakos, V
AU  - Hadjipanos, V
AU  - Assoc Comp Machinery
T2  - 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017)
AB  - In this paper we describe a system that utilizes supervised machine learning over GNSS PVT data to produce "safe" paths for maritime port operations. By using meta-knowledge describing the behavior of mobile objects based on specific criteria, and also extend this to address sections of trajectories, we aim at certifying
DA  - 2017///
PY  - 2017
DO  - 10.1145/3056540.3076204
SP  - 331
EP  - 334
SN  - 978-1-4503-5227-7
AN  - WOS:000644308800068
KW  - Artificial intelligence
KW  - Learning systems
KW  - Supervised learning
KW  - Classification of EGNSS data
KW  - Education
KW  - Maritime ITS
KW  - Maritime port operations
KW  - Meta-knowledge
KW  - Mobile objects
KW  - Port operations
KW  - PVT data
KW  - Safe paths
KW  - Supervised machine learning
KW  - Supervised machine learning safe port operations
ER  - 

TY  - CONF
TI  - Unsupervised Domain Adaptation with Joint Domain-Adversarial Reconstruction Networks
AU  - Chen, Q
AU  - Du, YT
AU  - Tan, ZW
AU  - Zhang, Y
AU  - Wang, CJ
T2  - MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2020, PT II
A2  - Hutter, F
A2  - Kersting, K
A2  - Lijffijt, J
A2  - Valera, I
AB  - Unsupervised Domain Adaptation (UDA) attempts to transfer knowledge from a labeled source domain to an unlabeled target domain. Recently, domain-adversarial learning has become an increasingly popular method to tackle this task, which bridges source domain and target domain by adversarially learning domain-invariant representations that cannot be discriminated by a domain discriminator. In spite of the great success achieved by domain-adversarial learning, most of existing methods still suffer two major limitations: (1) due to focusing only on learning domain-invariant representations, they ignore the individual characteristics of each domain and fail to extract domainspecific information that is beneficial for final classification; (2) by focusing only on performing domain-level distribution alignment to learn domain-invariant representations, they fail to achieve the invariance of representations at a class level, which may lead to incorrect distribution alignment. To address the above issues, we propose in this paper a novel model called Joint Domain-Adversarial Reconstruction Network (JDARN), which integrates domain-adversarial learning with data reconstruction to learn both domain-invariant and domain-specific representations. Meanwhile, we propose to employ two novel discriminators called joint domain-class discriminators to achieve the joint alignment and adopt a novel joint adversarial loss to train them. With both domain and class information of two domains, the two discriminators can be used to promote domain-invariant representation learning towards the class level, not only the domain level. Extensive experimental results reveal that the proposed JDARN exceeds the state-of-the-art performance on two standard UDA datasets.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-67661-2_38
VL  - 12458
SP  - 640
EP  - 656
SN  - 2945-9133
AN  - WOS:000717542900038
KW  - Machine learning
KW  - Data mining
KW  - Classification (of information)
KW  - Alignment
KW  - Unsupervised domain adaptation
KW  - Adversarial learning
KW  - State-of-the-art performance
KW  - Data reconstruction
KW  - Class information
KW  - Distribution alignment
KW  - Invariant representation
KW  - Domain-adversarial learning
KW  - Domain-specific information
KW  - Individual characteristics
KW  - Reconstruction networks
ER  - 

TY  - JOUR
TI  - Unsupervised Domain Adaptation via Discriminative Manifold Propagation
AU  - Luo, YW
AU  - Ren, CX
AU  - Dai, DQ
AU  - Yan, H
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - Unsupervised domain adaptation is effective in leveraging rich information from a labeled source domain to an unlabeled target domain. Though deep learning and adversarial strategy made a significant breakthrough in the adaptability of features, there are two issues to be further studied. First, hard-assigned pseudo labels on the target domain are arbitrary and error-prone, and direct application of them may destroy the intrinsic data structure. Second, batch-wise training of deep learning limits the characterization of the global structure. In this paper, a Riemannian manifold learning framework is proposed to achieve transferability and discriminability simultaneously. For the first issue, this framework establishes a probabilistic discriminant criterion on the target domain via soft labels. Based on pre-built prototypes, this criterion is extended to a global approximation scheme for the second issue. Manifold metric alignment is adopted to be compatible with the embedding space. The theoretical error bounds of different alignment metrics are derived for constructive guidance. The proposed method can be used to tackle a series of variants of domain adaptation problems, including both vanilla and partial settings. Extensive experiments have been conducted to investigate the method and a comparative study shows the superiority of the discriminative manifold learning framework.
DA  - 2022/03/01/
PY  - 2022
DO  - 10.1109/TPAMI.2020.3014218
VL  - 44
IS  - 3
SP  - 1653
EP  - 1669
SN  - 0162-8828
AN  - WOS:000752018000041
ER  - 

TY  - CONF
TI  - Training photonic extreme learning machines using feedback alignment
AU  - Kilic, V
AU  - Foster, MA
AU  - IEEE
T2  - 2021 CONFERENCE ON LASERS AND ELECTRO-OPTICS (CLEO)
AB  - Photonic extreme learning machines and reservoir computers enhance machine learning by efficiently mapping data to a high dimensional space. We demonstrate training the input mapping of such approaches using feedback alignment improves performance. (C) 2021 The Author(s)
DA  - 2021///
PY  - 2021
SN  - 2160-9020
AN  - WOS:000831479803209
KW  - Machine learning
KW  - Machine-learning
KW  - Knowledge acquisition
KW  - Mapping
KW  - Learning machines
KW  - Improve performance
KW  - High dimensional spaces
KW  - Mapping data
KW  - Optical fiber communication
KW  - Optical fibers
ER  - 

TY  - JOUR
TI  - Integrating safety constraints into adversarial training for robust deep reinforcement learning
AU  - Meng, JL
AU  - Zhu, F
AU  - Ge, YY
AU  - Zhao, PY
T2  - INFORMATION SCIENCES
AB  - The ability to resist interference is the key to the widespread application of reinforcement learning. Although adversarial training is a promising method for robust promotion, stan-dard adversarial training leads to unstable results or performance deterioration due to the presence of perturbation. To address the problem, a robust reinforcement learning method which integrates safety constraints that are modelled by environment termination condi-tions into adversarial training is proposed, where safety constraints are adopted to restrict agent's actions and guide the training process. For better modelling the robust reinforce-ment learning problem, a modified constrained Markov Decision Process (MDP) that con-siders perturbation for robust reinforcement learning, named Constrained Markov Decision Process (CMDP) with Perturbation (CMDPP) is also introduced. The proposed safe robust reinforcement learning method based on CMDPP utilizes the penalty function to solve CMDP and generates perturbation from the gradient of state for adversarial training. Tests on the robustness of the proposed method under several attack methods and evalu-ation of generalization through changing environment dynamics were carried out on the OpenAI gym and Roboschool environments. The results demonstrate that our method not only has a better performance confronting the attack but also has a higher generaliza-tion capability with reference to the changing environment dynamics.(c) 2022 Elsevier Inc. All rights reserved.
DA  - 2023/01//undefined
PY  - 2023
DO  - 10.1016/j.ins.2022.11.051
VL  - 619
SP  - 310
EP  - 323
SN  - 0020-0255
AN  - WOS:000901771900018
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Safety engineering
KW  - Markov processes
KW  - Constrained Markov decision process
KW  - Reinforcement learning method
KW  - Safety constraint
KW  - Deterioration
KW  - Environment dynamics
KW  - Adversarial training
KW  - Changing environment
KW  - Penalty function method
KW  - Penalty function methods
KW  - Robust deep reinforcement learning
ER  - 

TY  - JOUR
TI  - Evaluation of Goaf Stability Based on Transfer Learning Theory of Artificial Intelligence
AU  - Qin, YG
AU  - Luo, ZQ
AU  - Wang, J
AU  - Ma, SW
AU  - Feng, CD
T2  - IEEE ACCESS
AB  - Current artificial intelligence models for evaluating goaf stability in underground metal mines need a large amount of sample data for training, and their accuracy declines with small sample size. With the aim of solving this problem, this paper proposes an improved TrAdaBoost algorithm based on transfer learning theory. The scope of the TrAdaBoost algorithm is extended from the two-level classification to multi-level classification problems, which makes it suitable for evaluating goaf stability. The isolated forest method is used to filter the bad points of the auxiliary training set, thereby eliminating the interference of abnormal data. The dynamic factor concept is introduced to solve the problem that the weight of source domain data decreases too quickly and irreversibly, and this enhances the generalization performance of the algorithm for different goaf samples. To test the accuracy of the proposed model in predicting goaf stability, an evaluation model is constructed and the performance compared with other algorithms in current use. The prediction accuracy and generalization ability of the model are evaluated by mean square error and F1 measurements, which prove that the performance of the model is excellent. The most obvious finding to emerge from this paper is that, with suitable improvements, goaf evaluation models can still maintain a high level of accuracy with small sample size.
DA  - 2019///
PY  - 2019
DO  - 10.1109/ACCESS.2019.2929533
VL  - 7
SP  - 96912
EP  - 96925
SN  - 2169-3536
AN  - WOS:000478961900123
ER  - 

TY  - CONF
TI  - A Safe Training Approach for Deep Reinforcement Learning-based Traffic Engineering
AU  - Wang, LH
AU  - Wang, M
AU  - Zhang, YJ
AU  - IEEE
T2  - IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC 2022)
AB  - Traffic engineering (TE) is fundamental and important in modern communication networks. Deep reinforcement learning (DRL)-based TE solutions can solve TE in a data-driven and model-free way thus have attracted much attention recently. However, most of these solutions ignore that TE is a real-world application and there are challenges applying DRL to real-world TE like: (1) Efficiency. Existing learning-from-scratch DRL agent needs long-time interactions to find solutions better than traditional methods. (2) Safety. Existing DRL-based solutions make TE decisions without considering safety constraints, poor decisions may be made and cause significant performance degradation. In this paper, we propose a safe training approach for DRL-based TE, which tries to address the above two problems. It focuses on making full use of data and ensuring safety so that DRL agent for TE can learn more quickly and possibly poor decisions will not be applied to real environment. We implemented the proposed method in ns-3 and simulation results show that our method performs better with faster convergence rate compared to other DRL-based methods while ensuring the safety of the performed TE decisions.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICC45855.2022.9838944
SP  - 1450
EP  - 1455
SN  - 1550-3607
AN  - WOS:000864709901129
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Real-world
KW  - Safety engineering
KW  - Safe Reinforcement Learning
KW  - Safe reinforcement learning
KW  - Data driven
KW  - Traffic Engineering
KW  - Highway engineering
KW  - Communications networks
KW  - Engineering decisions
KW  - Engineering solutions
KW  - Learning from demonstration
KW  - Learning from Demonstration
ER  - 

TY  - JOUR
TI  - Two-Stage Deep Reinforcement Learning for Inverter-Based Volt-VAR Control in Active Distribution Networks
AU  - Liu, HT
AU  - Wu, WC
T2  - IEEE TRANSACTIONS ON SMART GRID
AB  - Model-based Vol/VAR optimization method is widely used to eliminate voltage violations and reduce network losses. However, the parameters of active distribution networks(ADNs) are not onsite identified, so significant errors may be involved in the model and make the model-based method infeasible. To cope with this critical issue, we propose a novel two-stage deep reinforcement learning (DRL) method to improve the voltage profile by regulating inverter-based energy resources, which consists of offline stage and online stage. In the offline stage, a highly efficient adversarial reinforcement learning algorithm is developed to train an offline agent robust to the model mismatch. In the sequential online stage, we transfer the offline agent safely as the online agent to perform continuous learning and controlling online with significantly improved safety and efficiency. Numerical simulations on IEEE test networks not only demonstrate that the proposed adversarial reinforcement learning algorithm outperforms the state-of-art algorithm, but also show that our proposed two-stage method achieves much better performance than the existing DRL based methods in the online application.
DA  - 2021/05//undefined
PY  - 2021
DO  - 10.1109/TSG.2020.3041620
VL  - 12
IS  - 3
SP  - 2037
EP  - 2047
SN  - 1949-3053
AN  - WOS:000641976000017
ER  - 

TY  - JOUR
TI  - Driver Profile and Driving Pattern Recognition for Road Safety Assessment: Main Challenges and Future Directions
AU  - Tselentis, DI
AU  - Papadimitriou, E
T2  - IEEE OPEN JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS
AB  - This study reviews the Artificial Intelligence and Machine Learning approaches developed thus far for driver profile and driving pattern recognition, representing a set of macroscopic and microscopic behaviors respectively, to enhance the understanding of human factors in road safety, and therefore reduce the number of crashes. It provides a definition of the two scientific fields in terms of safety, and identifies the most efficient approaches used regarding methodology, data collection and driving metrics. Results show that K-means and Neural Networks are the most commonly used methodologies for driver profile identification, and Dynamic Time Warping for driving pattern detection. Most studies discovered driver profiles related to aggressiveness, considering mainly speed and acceleration as driving metrics. Based on the gaps and challenges identified, this paper provides a new framework for combining microscopic and macroscopic driving behavior analysis, instead of examining them separately as is the state-of-the-art. Such combined results can potentially improve the development of traffic risk models, which could be exploited in applications that monitor drivers in real-time and provide feedback. These models will represent human behavior more accurately, which can eventually lead to the recognition of "optimal " human driving patterns that Automated Vehicles (AV) could 'mimic' to become safer.
DA  - 2023///
PY  - 2023
DO  - 10.1109/OJITS.2023.3237177
VL  - 4
SP  - 83
EP  - 100
SN  - 2687-7813
AN  - WOS:000932437200004
ER  - 

TY  - JOUR
TI  - Hierarchical Program-Triggered Reinforcement Learning Agents for Automated Driving
AU  - Gangopadhyay, B
AU  - Soora, H
AU  - Dasgupta, P
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Recent advances in Reinforcement Learning (RL) combined with Deep Learning (DL) have demonstrated impressive performance in complex tasks, including autonomous driving. The use of RL agents in autonomous driving leads to a smooth human-like driving experience, but the limited interpretability of Deep Reinforcement Learning (DRL) creates a verification and certification bottleneck. Instead of relying on RL agents to learn complex tasks, we propose HPRL - Hierarchical Program-triggered Reinforcement Learning, which uses a hierarchy consisting of a structured program along with multiple RL agents, each trained to perform a relatively simple task. The focus of verification shifts to the master program under simple guarantees from the RL agents, leading to a significantly more interpretable and verifiable implementation as compared to a complex RL agent. The evaluation of the framework is demonstrated on different driving tasks, and National Highway Traffic Safety Administration (NHTSA) pre-crash scenarios using CARLA, an open-source dynamic urban simulation environment.
DA  - 2022/08//undefined
PY  - 2022
DO  - 10.1109/TITS.2021.3096998
VL  - 23
IS  - 8
SP  - 10902
EP  - 10911
SN  - 1524-9050
AN  - WOS:000732104700001
ER  - 

TY  - JOUR
TI  - Domain-invariant adversarial learning with conditional distribution alignment for unsupervised domain adaptation
AU  - Wang, XM
AU  - Sun, BX
AU  - Dong, HB
T2  - IET COMPUTER VISION
AB  - Unsupervised domain adaption aims to reduce the divergence between the source domain and the target domain. The final objective is to learn domain-invariant features from both domains that get the minimised expected error on the target domain. The divergence between domains which is also called domain shift is mainly between the distributions of domains' samples. Additionally, the label shift is also a tricky challenge in domain adaptation. In this study, domain-invariant adversarial learning with conditional distribution alignment is proposed to alleviate the effect of domain shift with label shift. To obtain the domain-invariant features, the proposed method modifies adversarial auto-encoder architecture and performs semi-supervised learning to enlarge the inter-class discrepancy. The marginal distribution is aligned in the adversarial learning process of extracting domain-invariant features. Meanwhile, the label information is incorporated in this way to align the conditional distribution. The proposed work also theoretically analyses the generalisation bound of the proposed model. Finally, the proposed method is evaluated based on several domain adaptation tasks, including digit classification and object recognition, and achieves state-of-the-art performance.
DA  - 2020/12//undefined
PY  - 2020
DO  - 10.1049/iet-cvi.2019.0514
VL  - 14
IS  - 8
SP  - 642
EP  - 649
SN  - 1751-9632
AN  - WOS:000598691200010
KW  - Learning systems
KW  - Semi-supervised learning
KW  - Object recognition
KW  - Alignment
KW  - Domain adaptation
KW  - Adversarial learning
KW  - Conditional distribution
KW  - Marginal distribution
KW  - State-of-the-art performance
KW  - Label information
KW  - Digit classification
KW  - Invariant features
ER  - 

TY  - CONF
TI  - Distributed safe reinforcement learning for multi-robot motion planning
AU  - Lu, Y
AU  - Guo, YH
AU  - Zhao, GX
AU  - Zhu, MH
T2  - 2021 29TH MEDITERRANEAN CONFERENCE ON CONTROL AND AUTOMATION (MED)
AB  - This paper studies optimal motion planning of multiple mobile robots with collision avoidance. We develop a distributed reinforcement learning algorithm which ensures suboptimal goal reaching and anytime collision avoidance simultaneously. Theoretical results on the convergence of neural network weights, the uniform and ultimate boundedness of system states of the closed-loop system, and anytime collision avoidance are established. Numerical simulations for single integrator and unicycle robots illustrate the effectiveness of our theoretical results.
DA  - 2021///
PY  - 2021
DO  - 10.1109/MED51440.2021.9480176
SP  - 1209
EP  - 1214
SN  - 2325-369X
AN  - WOS:000811823100182
KW  - Reinforcement learning
KW  - Safety
KW  - Motion planning
KW  - Collision avoidance
KW  - Learning algorithms
KW  - Mobile robots
KW  - Closed loop systems
KW  - Robot programming
KW  - Distributed reinforcement learning
KW  - System state
KW  - Multi-robot motion planning
KW  - Multiple mobile robot
KW  - Network weights
KW  - Optimal motion planning
KW  - Ultimate boundedness
KW  - Unicycle robots
ER  - 

TY  - CONF
TI  - Formal Methods Assisted Training of Safe Reinforcement Learning Agents
AU  - Murugesan, A
AU  - Moghadamfalahi, M
AU  - Chattopadhyay, A
T2  - NASA FORMAL METHODS (NFM 2019)
A2  - Badger, JM
A2  - Rozier, KY
AB  - Reinforcement learning (RL) is emerging as a powerful machine learning paradigm to develop autonomous safety critical systems; RL enables the systems to learn optimal control strategies by interacting with the environment. However, there is also widespread apprehension to deploying such systems in the real world since rigorously ensuring if they had learned safe strategies by interacting with an environment that is representative of the real world remains a challenge. Hence, there is a surge of interest to establish safety-focused RL techniques.
In this paper, we present a safety-assured training approach that augments standard RL with formal analysis and simulation technology. The benefits of coupling these techniques is three-fold: the formal analysis tools (SMT solvers) guide the system to learn strategies that rigorously uphold specified safety properties; the sophisticated simulators provide a wide-range of quantifiable, realistic learning environments; the adequacy of the safety properties can be assessed as agent explores complex environments. We illustrate this approach using a Flappy Bird game.
DA  - 2019///
PY  - 2019
DO  - 10.1007/978-3-030-20652-9_22
VL  - 11460
SP  - 333
EP  - 340
SN  - 0302-9743
AN  - WOS:000657973800022
KW  - Intelligent agents
KW  - Reinforcement learning
KW  - Machine learning
KW  - Reinforcement learning agent
KW  - Safety engineering
KW  - Computer aided instruction
KW  - Formal methods
KW  - NASA
KW  - Assurance
KW  - Safety critical systems
KW  - Complex environments
KW  - Learning environments
KW  - Formal analysis
KW  - Formal analysis tools
KW  - Optimal control strategy
ER  - 

TY  - JOUR
TI  - Classifying travelers' driving style using basic safety messages generated by connected vehicles: Application of unsupervised machine learning
AU  - Mohammadnazar, A
AU  - Arvin, R
AU  - Khattak, AJ
T2  - TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES
AB  - Driving style can substantially impact mobility, safety, energy consumption, and vehicle emissions. While a range of methods has been used in the past for driving style classification, the emergence of connected vehicles equipped with communication devices provides a new opportunity to classify driving style using high-resolution (10 Hz) microscopic real-world data. In this study, location-based big data and machine learning are used to classify driving styles ranging from aggressive to calm. This classification can be used to customize driver assistance systems, assess mobility, crash risk, fuel consumption, and emissions. This study's main objective is to develop a framework that harnesses Basic Safety Messages (BSMs) generated by connected vehicles to quantify instantaneous driving behavior and classify driving styles in different spatial contexts using unsupervised machine learning methods. To this end, a subset of the Safety Pilot Model Deployment (SPMD) with more than 27 million BSM observations generated by more than 1300 individuals making trips on diverse roadways and through several neighborhoods in Ann Arbor, Michigan, were processed and analyzed. To quantify driving style, the concept of temporal driving volatility, as a surrogate safety measure of unsafe driving behavior, was utilized and applied to vehicle kinematics, i.e., observed speeds and longitudinal/lateral accelerations. Specifically, six volatility measures are extracted and used for classifying drivers. K-means and K-medoids methods are applied for grouping drivers in aggressive, normal, and calm clusters. Clustering results indicate that not only does driving style vary among drivers, but the thresholds for aggressive and calm driving vary across different roadway types due to variations in environment and road conditions. The proportion of aggressive driving styles was also higher on commercial streets than on highways and residential streets. Notably, we propose a Driving Score to measure driving performance consistently across drivers.
DA  - 2021/01//undefined
PY  - 2021
DO  - 10.1016/j.trc.2020.102917
VL  - 122
SN  - 0968-090X
AN  - WOS:000605586900004
KW  - machine learning
KW  - Machine learning
KW  - Vehicles
KW  - United States
KW  - travel behavior
KW  - Automobile drivers
KW  - Behavioral research
KW  - Driving behavior
KW  - classification
KW  - Risk assessment
KW  - Driver assistance system
KW  - Driving performance
KW  - Safety engineering
KW  - Big data
KW  - Energy utilization
KW  - cluster analysis
KW  - transportation safety
KW  - Unsupervised machine learning
KW  - K-means clustering
KW  - data set
KW  - Connected vehicles
KW  - Basic safety message
KW  - Aggressive driving
KW  - Ann Arbor
KW  - Clustering results
KW  - Communication device
KW  - Driving style classification
KW  - Location-based services
KW  - Michigan
KW  - neighborhood
KW  - Vehicle emission
ER  - 

TY  - JOUR
TI  - Safety-constrained reinforcement learning with a distributional safety critic
AU  - Yang, QS
AU  - Simao, TD
AU  - Tindemans, SH
AU  - Spaan, MTJ
T2  - MACHINE LEARNING
AB  - Safety is critical to broadening the real-world use of reinforcement learning. Modeling the safety aspects using a safety-cost signal separate from the reward and bounding the expected safety-cost is becoming standard practice, since it avoids the problem of finding a good balance between safety and performance. However, it can be risky to set constraints only on the expectation neglecting the tail of the distribution, which might have prohibitively large values. In this paper, we propose a method called Worst-Case Soft Actor Critic for safe RL that approximates the distribution of accumulated safety-costs to achieve risk control. More specifically, a certain level of conditional Value-at-Risk from the distribution is regarded as a safety constraint, which guides the change of adaptive safety weights to achieve a trade-off between reward and safety. As a result, we can compute policies whose worst-case performance satisfies the constraints. We investigate two ways to estimate the safety-cost distribution, namely a Gaussian approximation and a quantile regression algorithm. On the one hand, the Gaussian approximation is simple and easy to implement, but may underestimate the safety cost, on the other hand, the quantile regression leads to a more conservative behavior. The empirical analysis shows that the quantile regression method achieves excellent results in complex safety-constrained environments, showing good risk control.
DA  - 2023/03//undefined
PY  - 2023
DO  - 10.1007/s10994-022-06187-8
VL  - 112
IS  - 3
SP  - 859
EP  - 887
SN  - 0885-6125
AN  - WOS:000814940000002
KW  - Reinforcement learning
KW  - Risk management
KW  - Performance
KW  - Reinforcement learnings
KW  - Economic and social effects
KW  - Regression analysis
KW  - Risk assessment
KW  - Real-world
KW  - Safety engineering
KW  - Approximation algorithms
KW  - Value engineering
KW  - Cost benefit analysis
KW  - Quantile regression
KW  - Gaussian approximations
KW  - Risks controls
KW  - Safety aspects
KW  - Safety costs
KW  - Set constraints
KW  - Standard practices
ER  - 

TY  - JOUR
TI  - Artificial intelligence-based public safety data resource management in smart cities
AU  - Zhao, H
T2  - OPEN COMPUTER SCIENCE
AB  - With the development of urbanization, urban public safety is becoming more and more important. Urban public safety is not only the foundation of urban development, but also the basic guarantee for the stability of citizens' lives. In the context of today's artificial intelligence (AI), the concept of smart cities is constantly being practiced. Urban public safety has also ushered in some new problems and challenges. To this end, this article aimed to use AI technology to build an efficient public safety data resource management system in a smart city environment. A major goal of AI research was to enable machines to perform complex tasks that normally require human intelligence. In this article, a data resource management system was constructed according to the city security system and risk data sources, and the data processing method of neural network (NN) was adopted. Factors affecting urban public safety were processed as indicator data. In this article, the feedforward back-propagation neural network (BPNN) was used to predict the index data in real time, which has realized the management functions of risk monitoring and early warning of public safety data indicators. The BPNN model was used to test the urban risk early warning capability of the constructed system. BPNN is a multi-layer feed-forward NN trained according to the error back-propagation algorithm, which is one of the most widely used NN models. The results showed that the average prediction accuracy of the BPNN model for indicator prediction was about 89%, which was 16.1% higher than that of the traditional NN model. The average risk warning accuracy rate of the BPNN model was 90.3%, which was 16.5% higher than that of the traditional NN model. This shows that the BPNN model using AI technology in this article can more efficiently and accurately carry out early warning of risk and management of urban public safety.
DA  - 2023/06/02/
PY  - 2023
DO  - 10.1515/comp-2022-0271
VL  - 13
IS  - 1
SN  - 2299-1093
AN  - WOS:001000348700001
ER  - 

TY  - JOUR
TI  - When AI Meets Information Privacy: The Adversarial Role of AI in Data Sharing Scenario
AU  - Majeed, A
AU  - Hwang, SO
T2  - IEEE ACCESS
AB  - Artificial intelligence (AI) is a transformative technology with a substantial number of practical applications in commercial sectors such as healthcare, finance, aviation, and smart cities. AI also has strong synergy with the information privacy (IP) domain from two distinct aspects: as a protection tool (i.e., safeguarding privacy), and as a threat tool (i.e., compromising privacy). In the former case, AI techniques are amalgamated with the traditional anonymization techniques to improve various key components of the anonymity process, and therefore, privacy is safeguarded effectively. In the latter case, some adversarial knowledge is aggregated with the help of AI techniques and subsequently used to compromise the privacy of individuals. To the best of our knowledge, threats posed by AI-generated knowledge such as synthetic data (SD) to information privacy are often underestimated, and most of the existing anonymization methods do not consider/model this SD-based knowledge that can be available to the adversary, leading to privacy breaches in some cases. In this paper, we highlight the role of AI as a threat tool (i.e., AI used to compromise an individual's privacy), with a special focus on SD that can serve as background knowledge leading to various kinds of privacy breaches. For instance, SD can encompass pertinent information (e.g., total # of attributes in data, distributions of sensitive information, category values of each attribute, minor and major values of some attributes, etc.) about real data that can offer a helpful hint to the adversary regarding the composition of anonymized data, that can subsequently lead to uncovering the identity or private information. We perform reasonable experiments on a real-life benchmark dataset to prove the pitfalls of AI in the data publishing scenario (when a database is either fully or partially released to public domains for conducting analytics).
DA  - 2023///
PY  - 2023
DO  - 10.1109/ACCESS.2023.3297646
VL  - 11
SP  - 76177
EP  - 76195
SN  - 2169-3536
AN  - WOS:001040724700001
ER  - 

TY  - JOUR
TI  - Building Trust in Fintech: An Analysis of Ethical and Privacy Considerations in the Intersection of Big Data, AI, and Customer Trust
AU  - Aldboush, HHH
AU  - Ferdous, M
T2  - INTERNATIONAL JOURNAL OF FINANCIAL STUDIES
AB  - This research paper explores the ethical considerations in using financial technology (fintech), focusing on big data, artificial intelligence (AI), and privacy. Using a systematic literature-review methodology, the study identifies ethical and privacy issues related to fintech, including bias, discrimination, privacy, transparency, justice, ownership, and control. The findings emphasize the importance of safeguarding customer data, complying with data protection laws, and promoting corporate digital responsibility. The study provides practical suggestions for companies, including the use of encryption techniques, transparency regarding data collection and usage, the provision of customer opt-out options, and the training of staff on data-protection policies. However, the study is limited by its exclusion of non-English-language studies and the need for additional resources to deepen the findings. To overcome these limitations, future research could expand existing knowledge and collect more comprehensive data to better understand the complex issues examined.
DA  - 2023/09//undefined
PY  - 2023
DO  - 10.3390/ijfs11030090
VL  - 11
IS  - 3
SN  - 2227-7072
AN  - WOS:001073607100001
ER  - 

TY  - CONF
TI  - Learning Barrier Certificates: Towards Safe Reinforcement Learning with Zero Training-time Violations
AU  - Luo, YP
AU  - Ma, TY
T2  - ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 34 (NEURIPS 2021)
A2  - Ranzato, M
A2  - Beygelzimer, A
A2  - Dauphin, Y
A2  - Liang, PS
A2  - Vaughan, JW
AB  - Training-time safety violations have been a major concern when we deploy reinforcement learning algorithms in the real world. This paper explores the possibility of safe RL algorithms with zero training-time safety violations in the challenging setting where we are only given a safe but trivial-reward initial policy without any prior knowledge of the dynamics and additional offline data. We propose an algorithm, Co-trained Barrier Certificate for Safe RL (CRABS),which iteratively learns barrier certificates, dynamics models, and policies. The barrier certificates are learned via adversarial training and ensure the policy's safety assuming calibrated learned dynamics. We also add a regularization term to encourage larger certified regions to enable better exploration. Empirical simulations show that zero safety violations are already challenging for a suite of simple environments with only 2-4 dimensional state space, especially if high-reward policies have to visit regions near the safety boundary. Prior methods require hundreds of violations to achieve decent rewards on these tasks, whereas our proposed algorithms incur zero violations.
DA  - 2021///
PY  - 2021
VL  - 34
SN  - 1049-5258
AN  - WOS:000922928205035
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Real-world
KW  - Iterative methods
KW  - Learn+
KW  - Prior-knowledge
KW  - Reinforcement learning algorithms
KW  - Dynamics
KW  - Safety violations
KW  - Barrier certificates
KW  - Learning barriers
KW  - Training time
KW  - Offline data
ER  - 

TY  - JOUR
TI  - Safe incomplete label distribution learning
AU  - Zhang, J
AU  - Tao, H
AU  - Luo, TJ
AU  - Hou, CP
T2  - PATTERN RECOGNITION
AB  - Label Distribution Learning (LDL) is a popular scenario for solving label ambiguity problems by learning the relative importance of each label to a particular instance. Nevertheless, the label is often incomplete due to the difficulty in annotating label distribution. In this mixing label case with complete and incomplete labels, it is often expected that the learning method can achieve better performance than the baseline method merely utilizing complete labeled data. However, the usage of incomplete labeled data may degrade the performance in real applications. Therefore, it is vital to design a safe incomplete LDL method, which will not deteriorate the performance when exploiting incomplete labeled data. To tackle this important but rarely studied problem, we propose a Safe Incomplete LDL method (SILDL), which learns a classifier that can prevent incomplete labeled instances from worsening the performance. Concretely, we learn predictions from multiple incomplete supervised learners and design an efficient solving algorithm by formulating it as a convex quadratic program. Theoretically, we prove that SILDL can obtain the maximal performance gain against the best one of the multiple baseline methods with mild conditions. Extensive experimental results validate the safeness of the proposed approach and show improvements in performance. (C) 2021 Elsevier Ltd. All rights reserved.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.1016/j.patcog.2021.108518
VL  - 125
SN  - 0031-3203
AN  - WOS:000742689700004
KW  - Learning systems
KW  - Performance
KW  - Quadratic programming
KW  - Learn+
KW  - Learning methods
KW  - Labeled data
KW  - Real applications
KW  - Baseline methods
KW  - Safeness
KW  - Label distribution
KW  - Incomplete supervised learning
KW  - Label distribution learning
ER  - 

TY  - JOUR
TI  - HPC Platform for Railway Safety-Critical Functionalities Based on Artificial Intelligence
AU  - Labayen, M
AU  - Medina, L
AU  - Eizaguirre, F
AU  - Flich, J
AU  - Aginako, N
T2  - APPLIED SCIENCES-BASEL
AB  - The automation of railroad operations is a rapidly growing industry. In 2023, a new European standard for the automated Grade of Automation (GoA) 2 over European Train Control System (ETCS) driving is anticipated. Meanwhile, railway stakeholders are already planning their research initiatives for driverless and unattended autonomous driving systems. As a result, the industry is particularly active in research regarding perception technologies based on Computer Vision (CV) and Artificial Intelligence (AI), with outstanding results at the application level. However, executing high-performance and safety-critical applications on embedded systems and in real-time is a challenge. There are not many commercially available solutions, since High-Performance Computing (HPC) platforms are typically seen as being beyond the business of safety-critical systems. This work proposes a novel safety-critical and high-performance computing platform for CV- and AI-enhanced technology execution used for automatic accurate stopping and safe passenger transfer railway functionalities. The resulting computing platform is compatible with the majority of widely-used AI inference methodologies, AI model architectures, and AI model formats thanks to its design, which enables process separation, redundant execution, and HW acceleration in a transparent manner. The proposed technology increases the portability of railway applications into embedded systems, isolates crucial operations, and effectively and securely maintains system resources.
DA  - 2023/08//undefined
PY  - 2023
DO  - 10.3390/app13159017
VL  - 13
IS  - 15
SN  - 2076-3417
AN  - WOS:001045447300001
ER  - 

TY  - CONF
TI  - Embedding Alignment for Unsupervised Federated Learning via Smart Data Exchange
AU  - Wagle, S
AU  - Hosseinalipour, S
AU  - Khosravan, N
AU  - Chiang, M
AU  - Brinton, CG
AU  - IEEE
T2  - 2022 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM 2022)
AB  - Federated learning (FL) has been recognized as one of the most promising solutions for distributed machine learning (ML). In most of the current literature, FL has been studied for supervised ML tasks, in which edge devices collect labeled data. Nevertheless, in many applications, it is impractical to assume existence of labeled data across devices. To this end, we develop a novel methodology, Cooperative Federated unsupervised Contrastive Learning (CF-CL), for FL across edge devices with unlabeled datasets. CF-CL employs local device cooperation where data are exchanged among devices through device-to-device (D2D) communications to avoid local model bias resulting from non-independent and identically distributed (non-i.i.d.) local datasets. CF-CL introduces a push-pull smart data sharing mechanism tailored to unsupervised FL settings, in which, each device pushes a subset of its local datapoints to its neighbors as reserved datapoints, and pulls a set of datapoints from its neighbors, sampled through a probabilistic importance sampling technique. We demonstrate that CF-CL leads to (i) alignment of unsupervised learned latent spaces across devices, (ii) faster global convergence, allowing for less frequent global model aggregations; and (iii) is effective in extreme non-i.i.d. datasettings across the devices.
DA  - 2022///
PY  - 2022
DO  - 10.1109/GLOBECOM48099.2022.10000962
SP  - 492
EP  - 497
SN  - 2334-0983
AN  - WOS:000922633500082
KW  - Learning systems
KW  - 'current
KW  - Supervised machine learning
KW  - Labeled data
KW  - Importance sampling
KW  - Embeddings
KW  - Learning tasks
KW  - Distributed machine learning
KW  - Novel methodology
KW  - Datapoints
KW  - D2D communications
KW  - Electronic data interchange
KW  - SMART datum
ER  - 

TY  - CONF
TI  - SafeSCHEMA: Multi-domain Orchestration of Slices based on SafeRL for B5G Networks
AU  - Dalgkitsis, A
AU  - Chawla, A
AU  - Bosneag, AM
AU  - Verikoukis, C
AU  - IEEE
T2  - 2022 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM 2022)
AB  - The success of Software-Defined Networking and Network Function Virtualization enabled providers to partially automate the decision-making of various network operating workflows. Network slicing is an innate feature of the Fifth Generation (5G) and Beyond-5G (B5G) networks, bringing many advantages but also increasing the complexity of managing such networks. In this context, automation tools based on Artificial Intelligence (AI) have become a preeminent instrument of automation used by the industry, as it would be impossible to manually provision and manage such a vast and dynamic infrastructure. Safe interaction of the AI agents with the network is one of the predominant challenges, especially when Reinforcement Learning (RL) is used in critical environments. This is particularly important when the RL agent actions have a high or irreversible impact on the network or service. Slice management is one of the major features that operators want to automate, to offer future services at large scales with manageable complexity to the operator. However, during the exploration phase, RL agents can cause significant performance degradation during operation and possibly introduce irreversible damage to the service being offered. To address this major challenge, we propose a multi-agent, modular, SafeRL architecture for distributed slice orchestration. We study the problem of zerotouch slice management and orchestration, in the context of Ultra-Reliable Low Latency Communication services for B5G networks. Our results demonstrate improved performance over competing solutions, while ensuring the safety of the performed actions during real-time slice orchestration.
DA  - 2022///
PY  - 2022
DO  - 10.1109/GLOBECOM48099.2022.10001219
SP  - 3435
EP  - 3440
SN  - 2334-0983
AN  - WOS:000922633503078
KW  - Reinforcement learning
KW  - Decision making
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Network function virtualization
KW  - Complex networks
KW  - Multi agent systems
KW  - Safe Reinforcement Learning
KW  - Safe reinforcement learning
KW  - 5G mobile communication systems
KW  - Multi-domains
KW  - Queueing networks
KW  - Distributed reinforcement learning
KW  - Distributed Reinforcement Learning
KW  - Service function chain
KW  - Service Function Chain
KW  - Service functions
KW  - Slicing
KW  - Software-defined networks
ER  - 

TY  - JOUR
TI  - Identifying driving safety profiles from smartphone data using unsupervised learning
AU  - Mantouka, EG
AU  - Barmpounakis, EN
AU  - Vlahogianni, EI
T2  - SAFETY SCIENCE
AB  - A large number of drivers with different driving characteristics co-exist on the road network. Assessing a person's driving profile and detecting aggressive and unsafe driving behavior is essential to enhance road safety, reduce fuel consumption and at a macroscopic level - tackle congestion. Nowadays, driving data can be massively collected via sensors embedded in mobile phones, avoiding the expensive and inefficient solutions of in-vehicle devices. In this paper, these data are used to detect unsafe driving styles based on two-stage clustering approach and using information on harsh events occurrence, acceleration profile, mobile usage and speeding. First, an initial clustering was performed in order to separate aggressive from non aggressive trips. Subsequently, to distinguish "normal" trips from unsafe trips, a second level clustering was performed. In this way, trips have been categorized into six distinct groups with increasing importance with respect to safety. Findings reveal that about 50% of the trips were characterized as "safe trips", while in 23.5% of the trips drivers were driving above the speed limit and only 7.5% of the trips are characterized by distracted driving. The further analysis of drivers in relation to the grouping of their trips showed that drivers cannot maintain a stable driving profile through time, but exhibit a strong volatile behavior per trip. Finally, a discussion is provided on the implications of the main findings in research and practice.
DA  - 2019/11//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2019.01.025
VL  - 119
SP  - 84
EP  - 90
SN  - 0925-7535
AN  - WOS:000500376400011
KW  - risk assessment
KW  - Learning systems
KW  - Automobile drivers
KW  - Behavioral research
KW  - Driving behavior
KW  - car driving
KW  - controlled study
KW  - high risk behavior
KW  - human
KW  - Roads and streets
KW  - Motor transportation
KW  - attitude
KW  - traffic accident
KW  - Article
KW  - priority journal
KW  - velocity
KW  - Clustering
KW  - Machine learning techniques
KW  - traffic safety
KW  - Smartphones
KW  - distracted driving
KW  - Driving characteristics
KW  - Aggressive driving
KW  - Acceleration profiles
KW  - cell phone use
KW  - mobile application
KW  - Smartphone sensors
KW  - Trip characterization
KW  - Two-stage clustering
KW  - Unsafe driving
ER  - 

TY  - CONF
TI  - Safe Reinforcement Learning Control for Water Distribution Network
AU  - Val, J
AU  - Wisniewski, R
AU  - Kallesoe, CS
AU  - IEEE
T2  - 5TH IEEE CONFERENCE ON CONTROL TECHNOLOGY AND APPLICATIONS (IEEE CCTA 2021)
AB  - Reinforcement Learning (RL) is an optimal control method for regulating the behaviour of a dynamical system when the system model is unknown. This feature is a strong advantage for controlling systems, such as Water Distribution Networks, where it is difficult to have a reliable model. When learning an optimal policy with RL, the exploration phase implies high degree of uncertainty in the system operation. Large scale infrastructures such as WDN require a robust operation since they cannot afford fails during the operation. This paper presents a model-free control method which provides safety in the operation while learning an optimal policy. This method introduces a policy supervisor block in the control loop which assesses the safety of the learned policy in real-time. The safety verification consists of evaluating the trajectory on a standard linear model. In this model only the fundamental linear dynamics are represented and the system's dimensions do not require to be expressed with high accuracy. If the predicted trajectory violates the boundaries, the supervisor provides a safe control action. Simulation and experimental results prove the applicability of the proposed method.
DA  - 2021///
PY  - 2021
DO  - 10.1109/CCTA48906.2021.9659138
SP  - 1148
EP  - 1153
SN  - 978-1-7281-7140-1
AN  - WOS:000808092400160
KW  - Reinforcement learning
KW  - Reinforcement learnings
KW  - Supervisory personnel
KW  - Dynamical systems
KW  - Controlling system
KW  - Water distribution systems
KW  - Optimal policies
KW  - Reinforcement learning control
KW  - System models
KW  - Reliable models
KW  - Degree of uncertainty
KW  - Exploration phasis
KW  - Optimal control methods
KW  - Water distribution networks
ER  - 

TY  - CONF
TI  - Safe Reinforcement Learning using Data-Driven Predictive Control
AU  - Selim, M
AU  - Alanwar, A
AU  - El-Kharashi, MW
AU  - Abbas, HM
AU  - Johansson, KH
T2  - 2022 5TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS, SIGNAL PROCESSING, AND THEIR APPLICATIONS (ICCSPA)
AB  - Reinforcement learning (RL) algorithms can achieve state-of-the-art performance in decision-making and continuous control tasks. However, applying RL algorithms on safety-critical systems still needs to be well justified due to the exploration nature of many RL algorithms, especially when the model of the robot and the environment are unknown. To address this challenge, we propose a data-driven safety layer that acts as a filter for unsafe actions. The safety layer uses a data-driven predictive controller to enforce safety guarantees for RL policies during training and after deployment. The RL agent proposes an action that is verified by computing the data-driven reachability analysis. If there is an intersection between the reachable set of the robot using the proposed action, we call the data-driven predictive controller to find the closest safe action to the proposed unsafe action. The safety layer penalizes the RL agent if the proposed action is unsafe and replaces it with the closest safe one. In the simulation, we show that our method outperforms state-of-the-art safe RL methods on the robotics navigation problem for a Turtlebot 3 in Gazebo and a quadrotor in Unreal Engine 4 (UE4).
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICCSPA55860.2022.10018994
SN  - 2377-682X
AN  - WOS:000972628300008
KW  - Reinforcement learning
KW  - Decision making
KW  - Motion planning
KW  - Learning systems
KW  - Motion-planning
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Controllers
KW  - Safety engineering
KW  - Predictive control
KW  - robot safety
KW  - Reinforcement learning algorithms
KW  - Data driven
KW  - Robot programming
KW  - Robot safety
KW  - State-of-the-art performance
KW  - Predictive controller
KW  - task and motion planning
KW  - Task planning
ER  - 

TY  - JOUR
TI  - Toward safer ophthalmic artificial intelligence via distributed validation on real-world data
AU  - Nath, S
AU  - Rahimy, E
AU  - Kras, A
AU  - Korot, E
T2  - CURRENT OPINION IN OPHTHALMOLOGY
AB  - Purpose of reviewThe current article provides an overview of the present approaches to algorithm validation, which are variable and largely self-determined, as well as solutions to address inadequacies.Recent findingsIn the last decade alone, numerous machine learning applications have been proposed for ophthalmic diagnosis or disease monitoring. Remarkably, of these, less than 15 have received regulatory approval for implementation into clinical practice. Although there exists a vast pool of structured and relatively clean datasets from which to develop and test algorithms in the computational 'laboratory', real-world validation remains key to allow for safe, equitable, and clinically reliable implementation. Bottlenecks in the validation process stem from a striking paucity of regulatory guidance surrounding safety and performance thresholds, lack of oversight on critical postdeployment monitoring and context-specific recalibration, and inherent complexities of heterogeneous disease states and clinical environments. Implementation of secure, third-party, unbiased, pre and postdeployment validation offers the potential to address existing shortfalls in the validation process.Given the criticality of validation to the algorithm pipeline, there is an urgent need for developers, machine learning researchers, and end-user clinicians to devise a consensus approach, allowing for the rapid introduction of safe, equitable, and clinically valid machine learning implementations.
DA  - 2023/09//undefined
PY  - 2023
DO  - 10.1097/ICU.0000000000000986
VL  - 34
IS  - 5
SP  - 459
EP  - 463
SN  - 1040-8738
AN  - WOS:001046748600017
ER  - 

TY  - JOUR
TI  - Variation of Pilots' Mental Workload Under Emergency Flight Conditions Induced by Different Equipment Failures: A Flight Simulator Study
AU  - Zhang, CY
AU  - Yuan, JJ
AU  - Jiao, YB
AU  - Liu, HY
AU  - Fu, LP
AU  - Jiang, CZ
AU  - Wen, C
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Pilots' excessive mental workload could reduce their ability to perform concurrent tasks during emergency flights, which is one of the most critical aviation safety concerns. Several past efforts have attempted to investigate the underlying issues, but all had limited success owing to the challenge of collecting representative data under realistic operating conditions. This study aimed to address this challenge by conducting a flight simulator study involving a comparatively large number of participants, who were pilot cadets with flight experience, and using noninvasive functional near-infrared spectroscopy (fNIRS) to collect the pilots' brain activity data. Pilots' subjective ratings and brain activity records were collected over a total of 75 simulated flights under three subtask scenarios comprising different equipment failures. A statistical analysis was carried out on the subjective ratings and on the changes observed in the saturation of the oxyhemoglobin (& UDelta;OxyHb) of individual fNIRS channels. The mental workload of the pilots was classified using a support vector machine hierarchical combination classifier, focusing on the question of whether it is feasible to classify pilots' mental workload using brain activity signals (i.e., & UDelta;OxyHb). The results suggested that the pilots' mental workload levels were highly associated with the & UDelta;OxyHb measures as well as with the activities of different brain regions, including the prefrontal-, motor-, and occipital cortex. The findings from this study could provide a reference for optimizing pilot training systems and improving pilot performance during emergency flight operations.
DA  - 2023/07/24/
PY  - 2023
DO  - 10.1177/03611981231184188
SN  - 0361-1981
AN  - WOS:001034149000001
KW  - Mental workload
KW  - Risk management
KW  - Support vector machines
KW  - data and data science
KW  - Machine-learning
KW  - Emergency management
KW  - Aircraft accidents
KW  - Training aircraft
KW  - Brain
KW  - Neurophysiology
KW  - Disasters
KW  - aircraft safety
KW  - Infrared devices
KW  - Data and data science
KW  - Machine learning (artificial intelligence)
KW  - machine learning (artificial intelligence)
KW  - Near infrared spectroscopy
KW  - Civil defense
KW  - Aircraft safety
KW  - aviation
KW  - Brain activity
KW  - emergency management
KW  - pilot safety
KW  - Pilot safety
KW  - security and emergency management
KW  - Security management
ER  - 

TY  - JOUR
TI  - Classification of human hand movements based on EMG signals using nonlinear dimensionality reduction and data fusion techniques
AU  - Rabin, N
AU  - Kahlon, M
AU  - Malayev, S
AU  - Ratnovsky, A
T2  - EXPERT SYSTEMS WITH APPLICATIONS
AB  - Surface electromyography (EMG) is non-invasive signal acquisition technique that plays a central role in many application, including clinical diagnostics, control for prosthetic devices and for human-machine interactions. The processing typically begins with a feature extraction step, which may be followed by the application of a dimensionality reduction technique. The obtained reduced features are input for a machine learning classifier. The constructed machine learning model may then classify new recorded movements.
The features extracted for EMG signals usually capture information both from the time and from the frequency domain. Short time Fourier transform (STFT) is commonly used for signal processing and in particular for EMG processing since it captures the temporal and the frequency characteristics of the data. Since the number of calculated STFT features is large, a common approach in signal processing and machine learning applications is to apply a linear or a nonlinear dimensionality reduction technique for simplifying the feature space. Another aspect that arises in medical applications in general and in EMG based hand classification in particular, is the large variability between subjects. Due to this variability, many studies focus on single subject classification. This requires acquiring a large training set for each tested participant which is not practical in real life application.
The objectives of this study were first to compare between the performances of a nonlinear dimensionality technique to a standard linear dimensionality method when applied for single subject EMG based hand movement classification, and to examined their performances in case of limited amount of training data samples. The second objective was to propose an algorithm for multi-subjects classification that utilized a data alignment step for overcoming the large variability between subjects.
The data set included EMG signals from 5 subjects who perform 6 different hand movements. STFT was calculated for feature extraction, principal component analysis (PCA) and diffusion maps (DM) were compared for dimension reductions. An affine transformation for aligning between the reduced feature spaces of two subjects, was investigated. K-nearest neighbors (KNN) was used for single and multi-subject classification.
The results of this study clearly show that the DM outperformed the PCA in case of limited training data. In addition, the multi-subject classification approach, which utilizes dimension reduction methods along with an alignment algorithm enable robust classification of a new subject based on another subjects' data sets. The proposed framework is general and can be adopted for many EMG classification task. (C) 2020 Elsevier Ltd. All rights reserved.
DA  - 2020/07/01/
PY  - 2020
DO  - 10.1016/j.eswa.2020.113281
VL  - 149
SN  - 0957-4174
AN  - WOS:000525819400022
KW  - Machine learning
KW  - Feature extraction
KW  - Learning systems
KW  - Diagnosis
KW  - Classification (of information)
KW  - Human machine interaction
KW  - Extraction
KW  - Biomedical signal processing
KW  - Nearest neighbor search
KW  - Electromyography
KW  - Medical applications
KW  - Machine learning applications
KW  - Principal component analysis
KW  - Dimensionality reduction
KW  - Data reduction
KW  - Data fusion
KW  - Diffusion maps
KW  - Nonlinear analysis
KW  - K nearest neighbor (KNN)
KW  - Dimension reduction method
KW  - Dimensionality reduction techniques
KW  - Frequency domain analysis
KW  - Graph alignment
KW  - Nonlinear dimensionality reduction
KW  - Short time Fourier transforms
ER  - 

TY  - CONF
TI  - Safe Traffic Sign Recognition through Data Augmentation for Autonomous Vehicles Software
AU  - Jöckel, L
AU  - Kläs, M
AU  - Martínez-Fernández, S
AU  - IEEE
T2  - 2019 COMPANION OF THE 19TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS-C 2019)
AB  - Context: Since autonomous vehicles operate in an open context, their software components, including data-driven ones, have to reliably process inputs (e.g., obtained by cameras) in order to make safe decisions. A key challenge when providing reliable data-driven components is insufficient training data, which could lead to wrong interpretation of the environment, thereby causing accidents. Aim: The goal of our research is to extend available training data of data-driven components for safe autonomous vehicles using the example of traffic sign recognition. Method: We developed an approach to create realistic image augmentations of various quality deficits and applied them on the German traffic sign recognition benchmark dataset (GTSRB). Results: The approach results in images augmented with (any combination of) seven different quality deficits affecting traffic sign recognition (rain, dirt on lens, steam on lens, darkness, motion blur, dirt on sign, backlight) and considers dependencies between combined quality deficits and influences from other contextual information. Conclusion: Our approach can be used to obtain more comprehensive datasets, especially also including samples with quality deficits that are difficult to gather. By structuring the augmentation into a set of basic components, the approach can be adapted for other application domains (e.g., person detection).
DA  - 2019///
PY  - 2019
DO  - 10.1109/QRS-C.2019.00114
SP  - 540
EP  - 541
SN  - 978-1-7281-3925-8
AN  - WOS:000587590500097
KW  - machine learning
KW  - Autonomous vehicles
KW  - Pattern recognition
KW  - Neural networks
KW  - Autonomous driving
KW  - Learning systems
KW  - autonomous driving
KW  - convolutional neural networks
KW  - Accident prevention
KW  - safety
KW  - Convolutional neural network
KW  - Traffic signs
KW  - Benchmarking
KW  - Benchmark datasets
KW  - Data quality
KW  - Software reliability
KW  - Traffic sign recognition
KW  - C (programming language)
KW  - Computer software selection and evaluation
KW  - data quality
KW  - Contextual information
KW  - image augmentation
KW  - Software component
ER  - 

TY  - JOUR
TI  - Electric Vehicle Batteries: Status and Perspectives of Data-Driven Diagnosis and Prognosis
AU  - Zhao, JY
AU  - Burke, AF
T2  - BATTERIES-BASEL
AB  - Mass marketing of battery-electric vehicles (EVs) will require that car buyers have high confidence in the performance, reliability and safety of the battery in their vehicles. Over the past decade, steady progress has been made towards the development of advanced battery diagnostic and prognostic technologies using data-driven methods that can be used to inform EV owners of the condition of their battery over its lifetime. The research has shown promise for accurately predicting battery state of health (SOH), state of safety (SOS), cycle life, the remaining useful life (RUL), and indicators of cells with high risk of failure (i.e., weak cells). These methods yield information about the battery that would be of great interest to EV owners, but at present it is not shared with them. This paper is concerned with the present status of the information available on the battery with a focus on data-driven diagnostic and prognostic approaches, and how the information would be generated in the future for the millions of EVs that will be on the road in the next decade. Finally, future trends and key challenges for the prognostics and health management of the batteries in real-world EV applications are presented from four perspectives (cloud-edge interaction, full-scale diagnosis, artificial intelligence and electronic health reports) are discussed.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.3390/batteries8100142
VL  - 8
IS  - 10
SN  - 2313-0105
AN  - WOS:000872328800001
KW  - machine learning
KW  - Machine learning
KW  - prognosis
KW  - Machine-learning
KW  - safety
KW  - Safety engineering
KW  - Battery
KW  - Data driven
KW  - Secondary batteries
KW  - Health risks
KW  - state of health
KW  - State of health
KW  - data-driven
KW  - battery
KW  - Diagnostics and prognostics
KW  - diagnosis
KW  - Battery status
KW  - Diagnosis and prognosis
KW  - Electric vehicle batteries
KW  - EVs
KW  - Mass marketing
KW  - Prognose
ER  - 

TY  - JOUR
TI  - A machine learning method for the evaluation of ship grounding risk in real operational conditions
AU  - Zhang, MY
AU  - Kujala, P
AU  - Hirdaris, S
T2  - RELIABILITY ENGINEERING & SYSTEM SAFETY
AB  - Ship groundings may often lead to damages resulting in oil spills or ship flooding and subsequent capsizing. Risks can be estimated qualitatively through experts' judgment or quantitatively through the analysis of maritime traffic data. Yet, studies using big data remain limited. In this paper, we present a big data analytics method for the evaluation of grounding risk in real environmental conditions. The method makes use of big data streams from the Automatic Identification System (AIS), nowcast data, and the seafloor depth data from the General Bathymetric Chart of the Oceans (GEBCO). The evasive action of Ro-Pax passenger ships operating in shallow waters is idealized under various traffic patterns that link to side - or forward - grounding scenarios. Consequently, an Avoidance Behaviour-based Grounding Detection Model (ABGD-M) is introduced to identify potential grounding scenarios, and the grounding probabilistic risk is quantified at observation points along ship routes in various voyages. The method is applied on a Ro-Pax ship operating over 2.5 years ice-free period in the Gulf of Finland. Results indicate that grounding probabilistic risk estimation may be extremely diverse and depends on voyage mutes, observation points, and operational conditions. It is concluded that the proposed method may assist with (1) better identification of critical grounding scenarios that are underestimated in existing accident databases; (2) improved understanding of grounding avoidance behaviours in real operational conditions; (3) the estimation of grounding probabilistic risk profile over the life cycle of fleet operations and (4) better evaluation of waterway complexity indices and ship operational vulnerability.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1016/j.ress.2022.108697
VL  - 226
SN  - 0951-8320
AN  - WOS:000829043000001
KW  - Machine learning
KW  - Automation
KW  - Data analytics
KW  - Fleet operations
KW  - Machine-learning
KW  - Risk perception
KW  - Risk assessment
KW  - Big data
KW  - Life cycle
KW  - Operational conditions
KW  - Offshore oil well production
KW  - Advanced Analytics
KW  - Big data analytics
KW  - Data Analytics
KW  - Gulf of Finland
KW  - Ship safety
KW  - Ships
KW  - Big data analytic
KW  - Grounding risk
KW  - Ship grounding
KW  - Grounding scenarios
KW  - Oil spills
KW  - Probabilistic risk
ER  - 

TY  - CONF
TI  - Towards Machine Learning-Assisted Output Checking for Statistical Disclosure Control
AU  - Domingo-Ferrer, J
AU  - Blanco-Justicia, A
T2  - MODELING DECISIONS FOR ARTIFICIAL INTELLIGENCE (MDAI 2021)
A2  - Torra, V
A2  - Narukawa, Y
AB  - There is an increasing demand by researchers to access the microdata (data on individual persons or enterprises) collected by national statistical institutes or other data controllers. If microdata are personally identifiable information, the most usual way for data controllers to share them in a way compliant with the privacy legislation (notably the EU General Data Protection Regulation) is to release anonymized microdata. Yet, data analysts often need access to the original microdata in order to avoid the information loss caused by anonymization. To answer that need, safe access centers (on physical premises or on-line) have been set up by several national statistical institutes. In these centers, users can run their analyses on original data using the controller's software, and the controller checks the outputs of the users' analyses before returning those outputs to them, in order to make sure users do not take home any result that might leak the confidential microdata on which it has been computed. Output checking is currently implemented with human checkers, which is expensive and slow, especially because checkers need to have specific statistical expertise. In this work, we explore the use of machine learning to partially automate output checking. We follow the rule-based approach and our empirical results show that our system can generalize the rules it is trained on. In conclusion, output checking assisted by machine learning seems to work well and should be trialed in safe access centers and decentralized data marketplaces.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-85529-1_27
VL  - 12898
SP  - 335
EP  - 345
SN  - 0302-9743
AN  - WOS:000885003500027
KW  - Machine learning
KW  - Privacy
KW  - Machine-learning
KW  - Controllers
KW  - Statistics
KW  - Laws and legislation
KW  - Data privacy
KW  - Data access
KW  - Data controllers
KW  - Microdata
KW  - National Statistical Institutes
KW  - Output checking
KW  - Personally identifiable information
KW  - Safe data access center
KW  - Safe data access centers
KW  - Statistical disclosure control
KW  - Statistical disclosure Control
ER  - 

TY  - JOUR
TI  - Artificial Intelligence for Surgical Safety Automatic Assessment of the Critical View of Safety in Laparoscopic Cholecystectomy Using Deep Learning
AU  - Mascagni, P
AU  - Vardazaryan, A
AU  - Alapatt, D
AU  - Urade, T
AU  - Emre, T
AU  - Fiorillo, C
AU  - Pessaux, P
AU  - Mutter, D
AU  - Marescaux, J
AU  - Costamagna, G
AU  - Dallemagne, B
AU  - Padoy, N
T2  - ANNALS OF SURGERY
AB  - Objective: To develop a deep learning model to automatically segment hepatocystic anatomy and assess the criteria defining the critical view of safety (CVS) in laparoscopic cholecystectomy (LC). Background: Poor implementation and subjective interpretation of CVS contributes to the stable rates of bile duct injuries in LC. As CVS is assessed visually, this task can be automated by using computer vision, an area of artificial intelligence aimed at interpreting images. Methods: Still images from LC videos were annotated with CVS criteria and hepatocystic anatomy segmentation. A deep neural network comprising a segmentation model to highlight hepatocystic anatomy and a classification model to predict CVS criteria achievement was trained and tested using 5-fold cross validation. Intersection over union, average precision, and balanced accuracy were computed to evaluate the model performance versus the annotated ground truth. Results: A total of 2854 images from 201 LC videos were annotated and 402 images were further segmented. Mean intersection over union for segmentation was 66.6%. The model assessed the achievement of CVS criteria with a mean average precision and balanced accuracy of 71.9% and 71.4%, respectively. Conclusions: Deep learning algorithms can be trained to reliably segment hepatocystic anatomy and assess CVS criteria in still laparoscopic images. Surgical-technical partnerships should be encouraged to develop and evaluate deep learning models to improve surgical safety.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.1097/SLA.0000000000004351
VL  - 275
IS  - 5
SP  - 955
EP  - 961
SN  - 0003-4932
AN  - WOS:000793253900035
KW  - Artificial Intelligence
KW  - deep learning
KW  - artificial intelligence
KW  - Deep Learning
KW  - review
KW  - deep neural network
KW  - controlled study
KW  - human
KW  - Humans
KW  - algorithm
KW  - procedures
KW  - cross validation
KW  - computer vision
KW  - videorecording
KW  - data science
KW  - validation process
KW  - achievement
KW  - anatomical segmentation
KW  - bile duct disease
KW  - Bile Duct Diseases
KW  - Cholecystectomy, Laparoscopic
KW  - critical view of safety
KW  - laparoscopic cholecystectomy
KW  - surgical data science
KW  - surgical safety
KW  - Video Recording
ER  - 

TY  - CONF
TI  - A Distributed Crawler for IoVT-based Public Safety Surveillance Exploring the Spatio-Temporal Correlation
AU  - Nagothu, D
AU  - Dimock, D
AU  - Kulesza, A
AU  - Yang, HR
AU  - Chen, Y
T2  - SENSORS AND SYSTEMS FOR SPACE APPLICATIONS XV
A2  - Chen, G
A2  - Pham, KD
AB  - Modern infrastructure development has led to a rise in deployed surveillance cameras to monitor remote locations and widespread infrastructures. In today's networked surveillance environment, however, human operators are often overwhelmed with the huge amount of visual feeds, which causes poor judgment and delayed response to emergencies. This paper proposes a distributed crawler scheme (DiCrawler) for smart surveillance systems deployed on Internet of Video Things (IoVT). The IoVT camera nodes monitor continuous video input, track the object of interest while preserving privacy, and relay correlative information to targeted nodes for constant monitoring. Each IoVT node monitors the space inside its field of view (FoV) and notifies the neighboring nodes about the objects leaving the FoV and heading in their directions. A smart communication algorithm among IoVT nodes is designed to prevent network bandwidth bottlenecks and preserve computational power. The DiCrawler system can corroborate with human operators and assist with decision-making by raising alarms in case of suspicious behavior. The IoVT network is completely decentralized, using only peer-to-peer (P2P) communication. DiCrawler does not rely on a central server for any computations, preventing a potential bottleneck if hundreds of cameras were connected and constantly uploading data to a server. Each module is also in a compact form factor, making it viable to be mounted on traditional security surveillance cameras. Extensive experimental study on a proof-of-concept prototype validated the effectiveness of the DiCrawler design.
DA  - 2022///
PY  - 2022
DO  - 10.1117/12.2618909
VL  - 12121
SN  - 0277-786X
AN  - WOS:000839326600002
KW  - Machine learning
KW  - Decision making
KW  - Machine Learning
KW  - Human operator
KW  - Machine-learning
KW  - Field of views
KW  - Cameras
KW  - Security systems
KW  - Monitoring
KW  - Public safety
KW  - Spatiotemporal correlation
KW  - Peer to peer networks
KW  - Surveillance cameras
KW  - Distributed crawler
KW  - Distributed Crawler
KW  - Internet of video thing
KW  - Internet of Video Things (IoVT)
KW  - Modern infrastructure
KW  - Public safety surveillance
KW  - Public Safety Surveillance
ER  - 

TY  - CONF
TI  - Improving Analog Functional Safety Using Data-Driven Anomaly Detection
AU  - Su, F
AU  - Goteti, P
AU  - IEEE
T2  - 2018 IEEE INTERNATIONAL TEST CONFERENCE (ITC)
AB  - Safety is a critical objective for automotive developments. Functional Safety of automotive analog and mixed-signal circuits faces several challenges; on the other hand, analog behavior provides an opportunity for early anomaly alert, thus improving functional safety. In this paper we propose a machine learning based methodology using data-driven anomaly detection for analog automotive circuits. The contribution of this work is to provide a framework of mining the dynamic in-field time series data in the context of system operation to detect anomalous events from analog functional safety perspective, with minimal hardware overhead. We present a realistic example to illustrate and analyze the proposed method. It presents an approach for improving functional safety of analog circuits in automotive applications.
DA  - 2018///
PY  - 2018
SN  - 1089-3539
AN  - WOS:000465124200013
KW  - Machine learning
KW  - Machine Learning
KW  - Anomaly detection
KW  - Machine-learning
KW  - Functional Safety
KW  - Timing circuits
KW  - Anomaly Detection
KW  - Automotives
KW  - Data-driven methods
KW  - Analog and mixed signal circuits
KW  - Analog automotive circuit
KW  - Analog Automotive Circuits
KW  - Analog behavior
KW  - Automotive development
KW  - Data-driven anomalies
KW  - Data-Driven Method
KW  - Electric signal systems
KW  - Mixed signal integrated circuits
ER  - 

TY  - JOUR
TI  - Perceptions of the Fourth Agricultural Revolution: What's In, What's Out, and What Consequences are Anticipated?
AU  - Barrett, H
AU  - Rose, DC
T2  - SOCIOLOGIA RURALIS
AB  - Technological advancement is seen as one way of sustainably intensifying agriculture. Scholars argue that innovation needs to be responsible, but it is difficult to anticipate the consequences of the 'fourth agricultural revolution' without a clear sense of which technologies are included and excluded. The major aims of this article were to investigate which technologies are being associated with the fourth agricultural revolution, as well as to understand how this revolution is being perceived, whether positive or negative consequences are given equal attention, and what type of impacts are anticipated. To this end, we undertook a content analysis of UK media and policy documents alongside interviews of farmers and advisers. We found that the fourth agricultural revolution is associated with emergent, game-changing technologies, at least in media and policy documents. In these sources, the benefits to productivity and the environment were prioritised with less attention to social consequences, but impacts were overwhelmingly presented positively. Farmers and advisers experienced many benefits of technologies and some predicted higher-tech futures. It was clear, however, that technologies create a number of negative consequences. We reflect on these findings and provide advice to policy-makers about how to interrogate the benefits, opportunities, and risks afforded by agricultural technologies.
DA  - 2022/04//undefined
PY  - 2022
DO  - 10.1111/soru.12324
VL  - 62
IS  - 2
SP  - 162
EP  - 189
SN  - 0038-0199
AN  - WOS:000572413400001
ER  - 

TY  - JOUR
TI  - AI, big data, and the future of consent
AU  - Andreotta, AJ
AU  - Kirkham, N
AU  - Rizzi, M
T2  - AI & SOCIETY
AB  - In this paper, we discuss several problems with current Big data practices which, we claim, seriously erode the role of informed consent as it pertains to the use of personal information. To illustrate these problems, we consider how the notion of informed consent has been understood and operationalised in the ethical regulation of biomedical research (and medical practices, more broadly) and compare this with current Big data practices. We do so by first discussing three types of problems that can impede informed consent with respect to Big data use. First, we discuss the transparency (or explanation) problem. Second, we discuss the re-repurposed data problem. Third, we discuss the meaningful alternatives problem. In the final section of the paper, we suggest some solutions to these problems. In particular, we propose that the use of personal data for commercial and administrative objectives could be subject to a 'soft governance' ethical regulation, akin to the way that all projects involving human participants (e.g., social science projects, human medical data and tissue use) are regulated in Australia through the Human Research Ethics Committees (HRECs). We also consider alternatives to the standard consent forms, and privacy policies, that could make use of some of the latest research focussed on the usability of pictorial legal contracts.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1007/s00146-021-01262-5
VL  - 37
IS  - 4
SP  - 1715
EP  - 1728
SN  - 0951-5666
AN  - WOS:000691153200001
ER  - 

TY  - JOUR
TI  - Language-agnostic pharmacovigilant text mining to elicit side effects from clinical notes and hospital medication records
AU  - Kaas-Hansen, BS
AU  - Placido, D
AU  - Rodríguez, CL
AU  - Thorsen-Meyer, HC
AU  - Gentile, S
AU  - Nielsen, AP
AU  - Brunak, S
AU  - Jürgens, G
AU  - Andersen, SE
T2  - BASIC & CLINICAL PHARMACOLOGY & TOXICOLOGY
AB  - We sought to craft a drug safety signalling pipeline associating latent information in clinical free text with exposures to single drugs and drug pairs. Data arose from 12 secondary and tertiary public hospitals in two Danish regions, comprising approximately half the Danish population. Notes were operationalised with a fastText embedding, based on which we trained 10 270 neural-network models (one for each distinct single-drug/drug-pair exposure) predicting the risk of exposure given an embedding vector. We included 2 905 251 admissions between May 2008 and June 2016, with 13 740 564 distinct drug prescriptions; the median number of prescriptions was 5 (IQR: 3-9) and in 1 184 340 (41%) admissions patients used >= 5 drugs concomitantly. A total of 10 788 259 clinical notes were included, with 179 441 739 tokens retained after pruning. Of 345 single-drug signals reviewed, 28 (8.1%) represented possibly undescribed relationships; 186 (54%) signals were clinically meaningful. Sixteen (14%) of the 115 drug-pair signals were possible interactions, and two (1.7%) were known. In conclusion, we built a language-agnostic pipeline for mining associations between free-text information and medication exposure without manual curation, predicting not the likely outcome of a range of exposures but also the likely exposures for outcomes of interest. Our approach may help overcome limitations of text mining methods relying on curated data in English and can help leverage non-English free text for pharmacovigilance.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1111/bcpt.13773
VL  - 131
IS  - 4
SP  - 282
EP  - 293
SN  - 1742-7835
AN  - WOS:000829910800001
KW  - machine learning
KW  - pharmacovigilance
KW  - data mining
KW  - safety signal detection
KW  - safety signal refinement
ER  - 

TY  - JOUR
TI  - Multimodal integration for data-driven classification of mental fatigue during construction equipment operations: Incorporating electroencephalography, electrodermal activity, and video signals
AU  - Mehmood, I
AU  - Li, H
AU  - Umer, W
AU  - Arsalan, A
AU  - Anwer, S
AU  - Mirza, MA
AU  - Ma, J
AU  - Antwi-Afari, MF
T2  - DEVELOPMENTS IN THE BUILT ENVIRONMENT
AB  - Construction equipment operations that require high levels of attention can cause mental fatigue, which can lead to inefficiencies and accidents. Previous studies classified mental fatigue using single-modal data with acceptable accuracy. However, mental fatigue is a multimodal problem, and no single modality is superior. Moreover, none of the previous studies in construction industry have investigated multimodal data fusion for classifying mental fatigue and whether such an approach would improve mental fatigue detection. This study proposes a novel approach using three machine learning models and multimodal data fusion to classify mental fatigue states. Electroencephalography, electrodermal activity, and video signals were acquired during an excavation operation, and the decision tree model using multimodal sensor data fusion outperformed other models with 96.2% accuracy and 96.175%-98.231% F1 scores. Multimodal sensor data fusion can aid in the development of a realtime system to classify mental fatigue and improve safety management at construction sites.
DA  - 2023/10//undefined
PY  - 2023
DO  - 10.1016/j.dibe.2023.100198
VL  - 15
SN  - 2666-1659
AN  - WOS:001043757700001
KW  - Decision trees
KW  - Machine learning
KW  - Real time systems
KW  - Machine-learning
KW  - Classification (of information)
KW  - Electrodermal activity
KW  - Electrodes
KW  - Electroencephalography
KW  - Information management
KW  - Construction safety
KW  - Electrophysiology
KW  - Construction industry
KW  - Multimodal data fusion
KW  - Multi-modal data
KW  - Construction equipment
KW  - Construction equipment operations
KW  - Construction equipment operator
KW  - Construction equipment operators
KW  - Equipment operators
KW  - Mental fatigue
KW  - Multimodal data
KW  - Video signal
ER  - 

TY  - JOUR
TI  - Big data platform for health and safety accident prediction
AU  - Ajayi, A
AU  - Oyedele, L
AU  - Delgado, JMD
AU  - Akanbi, L
AU  - Bilal, M
AU  - Akinade, O
AU  - Olawale, O
T2  - WORLD JOURNAL OF SCIENCE TECHNOLOGY AND SUSTAINABLE DEVELOPMENT
AB  - Purpose The purpose of this paper is to highlight the use of the big data technologies for health and safety risks analytics in the power infrastructure domain with large data sets of health and safety risks, which are usually sparse and noisy. Design/methodology/approach The study focuses on using the big data frameworks for designing a robust architecture for handling and analysing (exploratory and predictive analytics) accidents in power infrastructure. The designed architecture is based on a well coherent health risk analytics lifecycle. A prototype of the architecture interfaced various technology artefacts was implemented in the Java language to predict the likelihoods of health hazards occurrence. A preliminary evaluation of the proposed architecture was carried out with a subset of an objective data, obtained from a leading UK power infrastructure company offering a broad range of power infrastructure services. Findings The proposed architecture was able to identify relevant variables and improve preliminary prediction accuracies and explanatory capacities. It has also enabled conclusions to be drawn regarding the causes of health risks. The results represent a significant improvement in terms of managing information on construction accidents, particularly in power infrastructure domain. Originality/value This study carries out a comprehensive literature review to advance the health and safety risk management in construction. It also highlights the inability of the conventional technologies in handling unstructured and incomplete data set for real-time analytics processing. The study proposes a technique in big data technology for finding complex patterns and establishing the statistical cohesion of hidden patterns for optimal future decision making.
DA  - 2019/01/07/
PY  - 2019
DO  - 10.1108/WJSTSD-05-2018-0042
VL  - 16
IS  - 1
SP  - 2
EP  - 21
SN  - 2042-5953
AN  - WOS:000453636000001
KW  - Machine learning
KW  - Big data analytics
KW  - Health and safety
KW  - Health hazards analytics
ER  - 

TY  - JOUR
TI  - The Promise of Artificial Intelligence in Digestive Healthcare and the Bioethics Challenges It Presents
AU  - Mascarenhas, M
AU  - Afonso, J
AU  - Ribeiro, T
AU  - Andrade, P
AU  - Cardoso, H
AU  - Macedo, G
T2  - MEDICINA-LITHUANIA
AB  - With modern society well entrenched in the digital area, the use of Artificial Intelligence (AI) to extract useful information from big data has become more commonplace in our daily lives than we perhaps realize. Medical specialties that rely heavily on imaging techniques have become a strong focus for the incorporation of AI tools to aid disease diagnosis and monitoring, yet AI-based tools that can be employed in the clinic are only now beginning to become a reality. However, the potential introduction of these applications raises a number of ethical issues that must be addressed before they can be implemented, among the most important of which are issues related to privacy, data protection, data bias, explainability and responsibility. In this short review, we aim to highlight some of the most important bioethical issues that will have to be addressed if AI solutions are to be successfully incorporated into healthcare protocols, and ideally, before they are put in place. In particular, we contemplate the use of these aids in the field of gastroenterology, focusing particularly on capsule endoscopy and highlighting efforts aimed at resolving the issues associated with their use when available.
DA  - 2023/04//undefined
PY  - 2023
DO  - 10.3390/medicina59040790
VL  - 59
IS  - 4
SN  - 1010-660X
AN  - WOS:000977456700001
ER  - 

TY  - JOUR
TI  - EccBase: A high-quality database for exploration and characterization of extrachromosomal circular DNAs in cancer
AU  - Sun, HY
AU  - Lu, XY
AU  - Zou, LY
T2  - COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL
AB  - Extrachromosomal circular DNAs (eccDNAs) are widely observed in eukaryotes. Previous studies have demonstrated that eccDNAs are essential to cancer progression, and found that they can not only express in normal cells to regulate RNA, but also function differently in different tissues. It is of major interest to conduct computational or experiments assay to elucidate the mechanisms of eccDNA function, uncover key eccDNAs associated with diseases, and even develop related algorithms for liquid biopsy. Naturally, a comprehensive eccDNAs data resource is urgently needed to provide annotation and analysis more in-depth research. In this study, we constructed the eccBase (http://www.eccbase.net) in literature curation and database retrieval, which was the first database mainly collecting eccDNAs from Homo sapiens (n = 754,391) and Mus musculus (n = 481,381). Homo sapiens eccDNAs were taken from 50 kinds of cancer tissue and/or cell line, and 5 kinds of healthy tissues. The Mus musculus eccDNAs were sourced from 13 kinds of healthy tissue and/or cell line. We thoroughly annotated all eccDNA molecules in terms of basic information, genomic composition, regulatory elements, epigenetic modifications, and raw data. EccBase provided users with the ability to browse, search, download for targets of interest, as well as similarity alignment by the integrated BLAST. Further, comparative analysis suggested the cancer eccDNA is composed of nucleosomes and is prominently derived from the gene-dense regions. We also initially revealed that eccDNAs are strongly tissue-specific. In short, we have started a robust database for eccDNA resource utilization, which may facilitate studying the role of eccDNA in cancer development and therapy, cell function maintenance, and tissue differentiation.& COPY; 2023 Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/).
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.csbj.2023.04.012
VL  - 21
SP  - 2591
EP  - 2601
SN  - 2001-0370
AN  - WOS:001042663200001
KW  - machine learning
KW  - Machine learning
KW  - Machine-learning
KW  - human
KW  - Article
KW  - human cell
KW  - nonhuman
KW  - Database systems
KW  - Sequence alignment
KW  - Sequence alignments
KW  - High quality
KW  - sequence alignment
KW  - Cancer
KW  - Cells
KW  - Diseases
KW  - mouse
KW  - Histology
KW  - Tissue
KW  - malignant neoplasm
KW  - DNA sequence
KW  - human tissue
KW  - genomics
KW  - genetic database
KW  - Database
KW  - animal cell
KW  - animal tissue
KW  - Biodiversity
KW  - cancer tissue
KW  - Cell culture
KW  - cell function
KW  - Cell lines
KW  - circular DNA
KW  - DNA determination
KW  - epigenetic modification
KW  - epigenetics
KW  - Extrachromosomal circular DNA
KW  - extrachromosomal DNA
KW  - Healthy tissues
KW  - Homo sapiens
KW  - Mus musculus
KW  - nucleosome
KW  - tissue differentiation
KW  - tissue specificity
KW  - Tissue specificity
ER  - 

TY  - JOUR
TI  - A self-learning method for automatic alignment in wafer processing
AU  - Kim, HT
AU  - Lee, KW
AU  - Yang, HJ
AU  - Kim, SC
T2  - INTERNATIONAL JOURNAL OF PRECISION ENGINEERING AND MANUFACTURING
AB  - We propose a self-learning method for automatic wafer alignment in the semiconductor manufacturing process. A feed forward neural network is trained by and used for wafer alignment. The network determines the movement of kinematic parts from the misalignment inspected by machine vision. However, it is time-consuming and inconvenient to obtain training data in this way. So, we built an automatic learning rule to gather the data and train the network. The network may determine wrong outputs and cause other misalignments at first, but the error can decrease as the training proceeds. The training sets consisted of a variation of misalignment data and the movement of an alignment stage. Five recent sets are used for training and others are dismissed or forgotten. This retrained network tried aligning, measured misalignment, and made new training sets. This sequence makes it possible to acquire alignment skill and automate the process. After learning, automatic alignment accomplished sub-pixel accuracy for several cases of misalignment. The result showed that the proposed method could be applied to the semiconductor manufacturing process. Its performance improved about 6% compared with conventional algorithms.
DA  - 2013/02//undefined
PY  - 2013
DO  - 10.1007/s12541-013-0030-1
VL  - 14
IS  - 2
SP  - 215
EP  - 221
SN  - 2234-7593
AN  - WOS:000313869700006
KW  - Machine intelligence
KW  - Learning systems
KW  - Feedforward neural networks
KW  - Iterative methods
KW  - Iterative learning control
KW  - Alignment
KW  - Semiconductor device manufacture
KW  - Image registration
KW  - Automatic alignment
KW  - Automatic Alignment
KW  - Iterative Learning Control
KW  - Machine Intelligence
KW  - Self training
KW  - Self-Training
KW  - Silicon wafers
KW  - Wafer processing
KW  - Wafer Processing
ER  - 

TY  - JOUR
TI  - Predicting crash occurrence at intersections in Texas: an opportunity for machine learning
AU  - Charm, T
AU  - Wang, HQ
AU  - Zuniga-Garcia, N
AU  - Ahmed, M
AU  - Kockelman, KM
T2  - TRANSPORTATION PLANNING AND TECHNOLOGY
AB  - This paper studies the frequency of traffic crashes at intersections across Texas by employing Zero-inflated Negative Binomial (ZINB) and Negative Binomial-Lindley (NB-L) generalized linear models, as well as various tree-based machine learning (ML) methods, namely Random Forests (RF), Extreme Gradient Boosting (XGBoost), Light Gradient Boosting Machine (LightGBM), and Bayesian Additive Regression Trees (BART) to predict the frequency of crashes at intersections. Official crash reports from 2010 through 2019 were linked to Texas' over 700,000 intersections. RF provided best prediction performance (using R-square and Root Mean Square Error metrics) while serving well for highly imbalanced crash data (with many zero cases). Sensitivity analysis highlights the practical significance of signalized intersection, annual average daily traffic, number of lanes at intersection approach, and other covariates.
DA  - 2023/02/16/
PY  - 2023
DO  - 10.1080/03081060.2023.2177651
SN  - 0308-1060
AN  - WOS:000959760200001
KW  - machine learning
KW  - Machine learning
KW  - Accidents
KW  - Machine-learning
KW  - Forecasting
KW  - Gradient boosting
KW  - Traffic crashes
KW  - Adaptive boosting
KW  - Random forests
KW  - Forestry
KW  - Sensitivity analysis
KW  - Negative binomial
KW  - imbalanced data
KW  - Imbalanced data
KW  - Crash count
KW  - crash counts
KW  - intersection safety
KW  - Intersection safety
KW  - Motor vehicle crashes
KW  - Zero-inflated
ER  - 

TY  - CONF
TI  - MACHINE LEARNING BASED ESTIMATION OF RESIDUAL USEFUL LIFE OF HIGH-SPEED TRAIN WHEELS BASED ON VEHICLE-MOUNTED VIBRATION SENSOR DATA
AU  - Tang, H
AU  - Dai, J
AU  - Amer Soc Mech Engineers
T2  - PROCEEDINGS OF 2022 JOINT RAIL CONFERENCE (JRC2022)
AB  - Safety is always a top priority during the development of high-speed rail systems. Wheel, as one of the most important components of a high-speed train, requires frequent inspections and maintenances in order to prevent operation failure of the train or even catastrophes from happening. The Residual Useful Life (RUL) has been extensively studied in the research field of health management for industrial components or systems. It is critical to understand the RUL of the high-speed train wheel for informed maintenance and replacement. Given an accurate estimation of train wheel RUL, rail companies can optimize maintenance and repair schedules more economically while ensuring safety. In this paper, we develop a machine learning based methodology to estimate the RUL of high-speed train wheels, using actual, in-field vibration data from sensors mounted on bogies. To our best knowledge, few studies have used data from in-field sensors mounted directly on train components to train and test a model for train wheel RUL estimation. A traditional time-domain signal processing method is implemented to extract characteristic features from the vibration data. Various machine learning models are introduced and applied to validate our proposed method. The estimation results conform to the empirical data, and can be used to infer the RUL of the wheel based on vehicle-mounted vibration sensor data for rail safety management.
DA  - 2022///
PY  - 2022
SN  - 978-0-7918-8575-8
AN  - WOS:000949318600036
KW  - Machine learning
KW  - Signal processing
KW  - Machine Learning
KW  - Machine-learning
KW  - Speed
KW  - Railroads
KW  - Wheels
KW  - Railroad cars
KW  - Industrial research
KW  - Railroad transportation
KW  - In-field
KW  - Disaster prevention
KW  - Rail safeties
KW  - Sensors data
KW  - Time domain analysis
KW  - Vibrations (mechanical)
KW  - High speed rail
KW  - High Speed Rail
KW  - High speed trains
KW  - Rail Safety
KW  - Residual useful lives
KW  - Sensor Data
KW  - Train wheel
KW  - Vibration sensors
KW  - Wheel life
KW  - Wheel Life
ER  - 

TY  - JOUR
TI  - Big Data Technology in Construction Safety Management: Application Status, Trend and Challenge
AU  - Meng, QF
AU  - Peng, QY
AU  - Li, Z
AU  - Hu, X
T2  - BUILDINGS
AB  - The construction industry is a high-risk industry with many safety accidents. The popularity of Internet information technology has led to an explosion in the amount of data obtained in various engineering fields, and it is of necessary significance to explore the current situation of the application of big data technology in construction safety management. This paper systematically reviews 66 articles closely related to the research topic and objectives, describes the current status of big data application to various construction safety issues from the perspectives of both big data collection and big data analysis for engineering and construction projects, and categorically lists the breakthrough results of big data analysis technology in improving construction safety. Finally, the trends and challenges of big data in the field of construction safety are discussed in three directions: the application of big data to worker behavior, the prospect of integrating big data technologies, and the integration of big data technologies with construction management. The aim of this paper is to demonstrate the current state of research on big data technology fueling construction safety management, providing valuable insight into improving safety at engineering construction sites and providing guidance for future research in this field.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.3390/buildings12050533
VL  - 12
IS  - 5
SN  - 2075-5309
AN  - WOS:000801417800001
KW  - machine learning
KW  - big data
KW  - construction safety
KW  - big data analysis
KW  - literature review
ER  - 

TY  - JOUR
TI  - Applying Explainable Machine Learning Techniques in Daily Crash Occurrence and Severity Modeling for Rural Interstates
AU  - Wei, ZH
AU  - Zhang, YL
AU  - Das, S
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Conventional traffic crash analysis methods often use highly aggregated data, making it difficult to understand the effects of time-varying factors on crash occurrence. Although studies have used data with small aggregation intervals, they typically analyze the effect of a single factor on crash occurrence. In this study, we investigate the collaborative effect of roadway geometry, speed distribution, and weather conditions on crash occurrence and severity using explainable machine learning methods on daily level crash data. The data were collected on rural Interstate highways in Texas. Four machine learning methods: random forest, AdaBoost, XGBoost, and deep neural network, were tested on the dataset. The results showed that XGBoost performs the best on the imbalanced dataset. The study used the synthetic minority oversampling technique (SMOTE) method to mitigate the data imbalance issue. The XGBoost model was trained separately on all crash occurrences and severe crash occurrences. Finally, the SHAP (SHapley Additive exPlanation) method was applied to investigate the contribution of all variables to the model's output. The results showed that weather condition factors have a significant contribution to all crash occurrences. Speed distribution factors have a stronger impact on severe crash occurrences.
DA  - 2022/11/17/
PY  - 2022
DO  - 10.1177/03611981221134629
SN  - 0361-1981
AN  - WOS:000930760500001
ER  - 

TY  - JOUR
TI  - Machine Learning-Reinforced Noninvasive Biosensors for Healthcare
AU  - Zhang, KY
AU  - Wang, JW
AU  - Liu, TY
AU  - Luo, YF
AU  - Loh, XJ
AU  - Chen, XD
T2  - ADVANCED HEALTHCARE MATERIALS
AB  - The emergence and development of noninvasive biosensors largely facilitate the collection of physiological signals and the processing of health-related data. The utilization of appropriate machine learning algorithms improves the accuracy and efficiency of biosensors. Machine learning-reinforced biosensors are started to use in clinical practice, health monitoring, and food safety, bringing a digital revolution in healthcare. Herein, the recent advances in machine learning-reinforced noninvasive biosensors applied in healthcare are summarized. First, different types of noninvasive biosensors and physiological signals collected are categorized and summarized. Then machine learning algorithms adopted in subsequent data processing are introduced and their practical applications in biosensors are reviewed. Finally, the challenges faced by machine learning-reinforced biosensors are raised, including data privacy and adaptive learning capability, and their prospects in real-time monitoring, out-of-clinic diagnosis, and onsite food safety detection are proposed.
DA  - 2021/09//undefined
PY  - 2021
DO  - 10.1002/adhm.202100734
VL  - 10
IS  - 17
SN  - 2192-2640
AN  - WOS:000664988000001
KW  - machine learning
KW  - Machine learning
KW  - Machine Learning
KW  - convolutional neural network
KW  - signal processing
KW  - Review
KW  - standardization
KW  - Algorithms
KW  - Learning algorithms
KW  - human
KW  - algorithm
KW  - Privacy by design
KW  - nonhuman
KW  - physiology
KW  - data processing
KW  - artificial neural network
KW  - discriminant analysis
KW  - random forest
KW  - support vector machine
KW  - Health care
KW  - principal component analysis
KW  - clinical practice
KW  - Physiology
KW  - Food safety
KW  - decision tree
KW  - Physiological signals
KW  - recurrent neural network
KW  - Delivery of Health Care
KW  - health care delivery
KW  - health care
KW  - Real time monitoring
KW  - food safety
KW  - Health monitoring
KW  - Biosensors
KW  - Clinical practices
KW  - feed forward neural network
KW  - Adaptive learning
KW  - amperometry
KW  - Biosensing Techniques
KW  - coulometry
KW  - cyclic voltammetry
KW  - data compression
KW  - differential pulse voltammetry
KW  - Digital revolution
KW  - genetic procedures
KW  - hierarchical clustering
KW  - impedance spectroscopy
KW  - non invasive procedure
KW  - noninvasive biosensors
KW  - voltammetry
ER  - 

TY  - JOUR
TI  - Real-time prediction of structural fire responses: A finite element-based machine-learning approach
AU  - Ye, ZN
AU  - Hsu, SC
AU  - Wei, HH
T2  - AUTOMATION IN CONSTRUCTION
AB  - Finite Element (FE) methods have been widely adopted in structural design to analyze the mechanical performance quantitatively, while most comprehensive FE models are computationally intensive and time-consuming, thus failing to be applied in a real-time context. To facilitate real-time prediction of structural fire response, this study develops an FE-based machine learning (ML) framework to predict structural displacement based on temperature data, which integrates the advantages of accuracy from FE methods as well as efficiency from ML techniques. FE models of a steel frame structure are developed for fire analysis in the present study. A numerical database of structure responses subject to hundreds of fire scenarios is established by extracting the results from FE models. Four ML models are trained based on the numerical database with temperature data as input and displacement data as output, among which Random Forest (RF) and Gradient Boosting (GB) models are found to outperform other models in terms of predictive accuracy. From the numerical results, the R square of the predictive mid-span displacement from RF and GB models could reach up to 0.99 when 1000 fire scenarios are included in the training dataset. All models are robust against the noise in temperature data when the signal-tonoise ratio is greater than 15. The FE-based ML framework developed in this study is of high potential to be applied to real-time structural response prediction during fire emergencies.
DA  - 2022/04//undefined
PY  - 2022
DO  - 10.1016/j.autcon.2022.104165
VL  - 136
SN  - 0926-5805
AN  - WOS:000792057300006
KW  - Decision trees
KW  - Machine learning
KW  - Signal to noise ratio
KW  - Numerical models
KW  - Forecasting
KW  - Real-time
KW  - Database systems
KW  - Structural design
KW  - Real- time
KW  - Fires
KW  - Finite element method
KW  - Real-time prediction
KW  - Building fire
KW  - Building fires
KW  - Element-based
KW  - Finite element modelling (FEM)
KW  - Fire response
KW  - Numerical database
KW  - Structural fire safeties
KW  - Structural fire safety
KW  - Structural fires
KW  - Structural frames
KW  - Temperature data
ER  - 

TY  - JOUR
TI  - An enhanced intelligent model: To protect marine IoT sensor environment using ensemble machine learning approach
AU  - Tiwari, D
AU  - Bhati, BS
AU  - Nagpal, B
AU  - Sankhwar, S
AU  - Al-Turjman, F
T2  - OCEAN ENGINEERING
AB  - The research in marine sensors and the Internet of Things (IoT) has grown exponentially with the ample warehouse of natural materials in the sea. The growing activities in the marine sensor environment increased the threat of anomalies and cyber-attacks. Many Intrusion Detection Systems (IDS) and classical machine learningbased models have been proposed to secure the sensor-based IoT infrastructure. Still, these mechanisms have failed to achieve significant results for securing the marine sensor environment due to the discriminant requirements of the IoT appliances in deep oceans, such as distribution, information complexity, scalability, higher network bandwidth requirements, and low computational capacity. Hence, we propose a lightweight and robust ensemble model to secure the marine IoT environment from cyber-attacks and malicious activities. This paper established an optimized Light Gradient Boosting Machine (Light-GBM) algorithm for ocean IoT attack detection. The experiments were conducted on Distributed Smart Space Orchestration System (DS2OS) dataset. The proposed methodology includes a label encoding technique for best feature selection, hyper-parameter tuning, ensemble function, and a novel algorithm to develop an ocean IoT attack detection model. As an extension of traditional methods, the optimized Light-GBM model can handle the distributed IoT attacks in the deeper marine environments with low computational cost and with 98.52% detection accuracy. The comparative analysis confirms the effectiveness of the proposed model for marine sensor safety. Conclusively, the proposed model mitigates the threat of cyber-attacks in the marine sensor environment and presenting a promising future in realtime ocean-based IoT applications.
DA  - 2021/12/15/
PY  - 2021
DO  - 10.1016/j.oceaneng.2021.110180
VL  - 242
SN  - 0029-8018
AN  - WOS:000730063400003
KW  - machine learning
KW  - Machine learning
KW  - Intrusion detection
KW  - Internet of things
KW  - algorithm
KW  - Gradient boosting
KW  - comparative study
KW  - Network security
KW  - Computer crime
KW  - learning
KW  - detection method
KW  - complexity
KW  - Attack detection
KW  - Ensemble learning
KW  - Computational complexity
KW  - ensemble forecasting
KW  - real time
KW  - Data safeties
KW  - Marine applications
KW  - Internet of thing
KW  - data quality
KW  - Ensemble-learning
KW  - Internet of things (IoT)
KW  - Light gradient boosting machine
KW  - Light gradients
KW  - Light-GBM
KW  - Marine data safety
KW  - marine environment
KW  - Marine sensors
KW  - marine technology
KW  - Oceanography
KW  - Seawater corrosion
KW  - sensor
KW  - Sensor-based infrastructure
ER  - 

TY  - JOUR
TI  - Deep Reinforcement Learning Based Blind mmWave MIMO Beam Alignment
AU  - Raj, V
AU  - Nayak, N
AU  - Kalyani, S
T2  - IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
AB  - Directional beamforming is a crucial component for realizing robust wireless millimeter wave (mmWave) communication systems. Beam alignment using brute-force search introduces time overhead, and the location aided blind beam alignment adds additional hardware requirements to the system. In this paper, we propose a blind beam alignment method based on the radio frequency (RF) fingerprints of the user equipment obtained from the base stations. The proposed system performs blind beam alignment using deep reinforcement learning on a multiple-base station cellular environment with multiple mobile users. We present a novel neural network architecture that can handle a mix of both continuous and discrete actions and use policy gradient methods to train the model. Our results show that the proposed method can achieve a data rate of up to four times the data rate of the traditional method without any overheads.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1109/TWC.2022.3169900
VL  - 21
IS  - 10
SP  - 8772
EP  - 8785
SN  - 1536-1276
AN  - WOS:000866499900067
ER  - 

TY  - JOUR
TI  - An Actor-Critic Framework for Online Control With Environment Stability Guarantee
AU  - Osinenko, P
AU  - Yaremenko, G
AU  - Malaniya, G
AU  - Bolychev, A
T2  - IEEE ACCESS
AB  - Online actor-critic reinforcement learning is concerned with training an agent on-the-fly via dynamic interaction with the environment. Due to the specifics of the application, it is not generally possible to perform long pre-training, as it is commonly done in off-line, tabular or Monte-Carlo mode. Such applications may be found more frequently in industry, rather than in pure digital fields, such as cloud services, video games, database management, etc., where reinforcement learning has been demonstrating success. Stability of the closed-loop of the agent plus the environment is a major challenge here, and not only in terms of the environment safety and integrity, but also in terms of sparing resources on failed training episodes. In this paper, we tackle the problem of environment stability under an actor-critic reinforcement learning agent by integration of the Lyapunov stability theory tools. Under the presented approach, the closed-loop stability is secured in all episodes without pre-training. It was observed in a case study with a mobile robot that the suggested agent could always successfully achieve the control goal, while significantly reducing the cost. While many approaches may be exploited for mobile robot control, we suggest that the experiments showed the promising potential of actor-critic reinforcement learning agents based on Lyapunov-like constraints. The presented methodology may be utilized in safety-critical, industrial applications where stability is necessary.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ACCESS.2023.3306070
VL  - 11
SP  - 89188
EP  - 89204
SN  - 2169-3536
AN  - WOS:001061771000001
ER  - 

TY  - JOUR
TI  - Implementation of relevant fourth industrial revolution innovations across the supply chain of fruits and vegetables: A short update on Traceability 4.0
AU  - Hassoun, A
AU  - Kamiloglu, S
AU  - Garcia-Garcia, G
AU  - Parra-López, C
AU  - Trollman, H
AU  - Jagtap, S
AU  - Aadil, RM
AU  - Esatbeyoglu, T
T2  - FOOD CHEMISTRY
AB  - Food Traceability 4.0 refers to the application of fourth industrial revolution (or Industry 4.0) technologies to ensure food authenticity, safety, and high food quality. Growing interest in food traceability has led to the development of a wide range of chemical, biomolecular, isotopic, chromatographic, and spectroscopic methods with varied performance and success rates. This review will give an update on the application of Traceability 4.0 in the fruits and vegetables sector, focusing on relevant Industry 4.0 enablers, especially Artificial Intelligence, the Internet of Things, blockchain, and Big Data. The results show that the Traceability 4.0 has significant po-tential to improve quality and safety of many fruits and vegetables, enhance transparency, reduce the costs of food recalls, and decrease waste and loss. However, due to their high implementation costs and lack of adapt-ability to industrial environments, most of these advanced technologies have not yet gone beyond the laboratory scale. Therefore, further research is anticipated to overcome current limitations for large-scale applications.
DA  - 2023/05/30/
PY  - 2023
DO  - 10.1016/j.foodchem.2022.135303
VL  - 409
SN  - 0308-8146
AN  - WOS:000923220700001
ER  - 

TY  - JOUR
TI  - Learning the representation of surrogate safety measures to identify traffic conflict
AU  - Lu, JJ
AU  - Grembek, O
AU  - Hansen, M
T2  - ACCIDENT ANALYSIS AND PREVENTION
AB  - Traffic conflict can be identified by the presence of evasive actions or the amount of temporal (spatial) proximity measures like time-to-collision (TTC). However, it is not enough to use only one kind of measures in some scenarios and it is hard to set a threshold for those measures. This paper proposed a method to identify traffic conflict by learning the representation of TTC and driver maneuver profiles with deep unsupervised learning and clustering the representations into traffic conflict and non-conflict clusters. We first trained a transformer encoder to encode sequences of surrogate safety measures into some latent space with unsupervised pre-training. Second, we identified informative clusters in the latent space by calculating the statistic summaries and visualizing trajectory pairs of each cluster. Some clusters are interpreted as traffic conflict clusters because they have small TTC, large deceleration rate and intertwining trajectories and they can be further interpreted as rear-end or angle conflicts. Moreover, the identified traffic conflicts contain critical conditions from the two vehicles in an interaction and one vehicle perceives them as abnormal and takes evasive action to avoid crashes.
DA  - 2022/09//undefined
PY  - 2022
DO  - 10.1016/j.aap.2022.106755
VL  - 174
SN  - 0001-4575
AN  - WOS:000864686600002
KW  - Deep learning
KW  - Safety
KW  - Accidents
KW  - Learning systems
KW  - safety
KW  - Automobile Driving
KW  - car driving
KW  - human
KW  - Humans
KW  - Accidents, Traffic
KW  - prevention and control
KW  - traffic accident
KW  - Transformer
KW  - methodology
KW  - Research Design
KW  - cluster analysis
KW  - Unsupervised learning
KW  - Clustering
KW  - Time to collision
KW  - Time-series data
KW  - Safety measures
KW  - Surrogate safety measure
KW  - Clusterings
KW  - Traffic conflicts
KW  - Cluster Analysis
KW  - Civil defense
KW  - Deep unsupervised learning
KW  - Evasive action
KW  - Interaction pattern
KW  - Surrogate safety measure (SSM)
KW  - Time series data
KW  - Traffic conflict
ER  - 

TY  - JOUR
TI  - Applying Machine Learning to Workers' Compensation Data to Identify Industry-Specific Ergonomic and Safety Prevention Priorities: Ohio, 2001 to 2011
AU  - Meyers, AR
AU  - Al-Tarawneh, IS
AU  - Wurzelbacher, SJ
AU  - Bushnell, PT
AU  - Lampl, MP
AU  - Bell, JL
AU  - Bertke, SJ
AU  - Robins, DC
AU  - Tseng, CY
AU  - Wei, C
AU  - Raudabaugh, JA
AU  - Schnorr, TM
T2  - JOURNAL OF OCCUPATIONAL AND ENVIRONMENTAL MEDICINE
AB  - Objective:This study leveraged a state workers' compensation claims database and machine learning techniques to target prevention efforts by injury causation and industry.Methods:Injury causation auto-coding methods were developed to code more than 1.2 million Ohio Bureau of Workers' Compensation claims for this study. Industry groups were ranked for soft-tissue musculoskeletal claims that may have been preventable with biomechanical ergonomic (ERGO) or slip/trip/fall (STF) interventions.Results:On the basis of the average of claim count and rate ranks for more than 200 industry groups, Skilled Nursing Facilities (ERGO) and General Freight Trucking (STF) were the highest risk for lost-time claims (>7 days).Conclusion:This study created a third, major causation-specific U.S. occupational injury surveillance system. These findings are being used to focus prevention resources on specific occupational injury types in specific industry groups, especially in Ohio. Other state bureaus or insurers may use similar methods.
DA  - 2018/01//undefined
PY  - 2018
DO  - 10.1097/JOM.0000000000001162
VL  - 60
IS  - 1
SP  - 55
EP  - 73
SN  - 1076-2752
AN  - WOS:000419431400019
KW  - machine learning
KW  - Safety
KW  - Machine Learning
KW  - safety
KW  - human
KW  - Humans
KW  - Ergonomics
KW  - industry
KW  - Industry
KW  - occupational accident
KW  - occupational health
KW  - Occupational Health
KW  - musculoskeletal disease
KW  - compensation
KW  - ergonomics
KW  - Musculoskeletal Diseases
KW  - occupational disease
KW  - Occupational Diseases
KW  - Occupational Injuries
KW  - Ohio
KW  - Workers' Compensation
KW  - workman compensation
ER  - 

TY  - JOUR
TI  - Unsupervised Visual-Textual Correlation Learning With Fine-Grained Semantic Alignment
AU  - Peng, YX
AU  - Ye, ZD
AU  - Qi, JW
AU  - Zhuo, YK
T2  - IEEE TRANSACTIONS ON CYBERNETICS
AB  - With the rapid growth of multimedia data on the Internet, there has been a rapid rise in the demand for visual-textual cross-media retrieval between images and sentences. However, the heterogeneous property of visual and textual data brings huge challenges to measure the cross-media similarity for retrieval. Although existing methods have achieved great progress with the strong learning ability of the deep neural network, they rely heavily on the scale of training data with manual annotation, that is, either pairwise image-sentence annotation or category annotation as supervised information for visual-textual correlation learning, which are extremely labor and time consuming to collect. Without any pairwise or category annotation, it is highly challenging to construct a correlation between images and sentences due to their inconsistent distributions and representations. But people can naturally understand the correlation between visual and textual data in high-level semantic, and those images and sentences containing the same group of semantic concepts can be easily matched in human brain. Inspired by the above human cognitive process, this article proposes an unsupervised visual-textual correlation learning (UVCL) approach to construct correlations without any manual annotation. The contributions are summarized as follows: 1) unsupervised semantic-guided cross-media correlation mining is proposed to bridge the heterogeneous gap between visual and textual data. We measure the semantic matching degree between images and sentences, and generate descriptive sentences according to the concepts extracted from images to further augment the training data in an unsupervised manner. Therefore, the approach can exploit the semantic knowledge within both visual and textual data to reduce the gap between them for further correlation learning and 2) unsupervised visual-textual fine-grained semantic alignment is proposed to learn cross-media correlation by aligning the fine-grained visual local patches and textual keywords with fine-grained soft attention as well as semantic-guided hard attention, and the results can effectively highlight the fine-grained semantic information within both images and sentences to boost visual-textual alignment. Extensive experiments are conducted to perform visual-textual cross-media retrieval in unsupervised setting without any manual annotation on two widely used datasets, namely, Flickr-30K and MS-COCO, which verify the effectiveness of our proposed UVCL approach.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.1109/TCYB.2020.3015084
VL  - 52
IS  - 5
SP  - 3669
EP  - 3683
SN  - 2168-2267
AN  - WOS:000798227800096
ER  - 

TY  - CONF
TI  - Applying Universal Chip Telemetry to Detect Latent Defects and Aging in Advanced Electronics
AU  - Landman, AE
AU  - Burlak, A
AU  - Sever, CN
AU  - Hutner, DM
AU  - IEEE
T2  - 2022 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
AB  - Mission critical applications and zero downtime tolerant systems are dominating semiconductor consumption, with AI at the Datacenter, 5G and Automotive being implemented on leading edge FinFET silicon technologies and advanced 2.5D and 3D packaging, required to perform at increasing functionality and performance profiles, for extended lifetime durations. With these advanced technologies, comes a plethora of new concerns to the product health and reliability. Out of these applications, Automotive deserves special consideration being subject to additional regulatory and safety concerns.
This paper will discuss how deep data analytics based on Universal Chip TelemetryT (UCT) offers a new approach to lifecycle health and performance monitoring in advanced electronics. By combining on-chip monitoring with machine learning inference in the cloud and edge, production quality is improved through advanced latent defect detection, while lifetime reliability is increased through degradation monitoring and predictive fault detection.
DA  - 2022///
PY  - 2022
DO  - 10.1109/IRPS48227.2022.9764449
SN  - 1541-7026
AN  - WOS:000922926400033
KW  - machine learning
KW  - Machine learning
KW  - functional safety
KW  - AI
KW  - predictive maintenance
KW  - Predictive analytics
KW  - Safety engineering
KW  - Life cycle
KW  - Fault detection
KW  - Reliability
KW  - Functional Safety
KW  - Data Analytics
KW  - Safety testing
KW  - aging
KW  - Reliability analysis
KW  - Defects
KW  - outlier detection
KW  - Predictive maintenance
KW  - 5G mobile communication systems
KW  - Automotives
KW  - OTA updates
KW  - continuous monitoring
KW  - Continuous monitoring
KW  - Outlier Detection
KW  - DPPM
KW  - Aging of materials
KW  - advanced analytics
KW  - automotive
KW  - chip telemetry
KW  - Chip telemetry
KW  - deep data
KW  - Deep data
KW  - degradation monitoring
KW  - Degradation monitoring
KW  - FinFET
KW  - latent defects
KW  - Latent defects
KW  - OTA update
KW  - physics of failure
KW  - Physics of failures
KW  - testing
ER  - 

TY  - CONF
TI  - Robust Semantic Video Segmentation through Confidence-based Feature Map Warping
AU  - Sämann, T
AU  - Amende, K
AU  - Milz, S
AU  - Gross, HM
T2  - ACM COMPUTER SCIENCE IN CARS SYMPOSIUM (CSCS 2019)
A2  - Spencer, SN
AB  - One of the limiting factors when using deep learning methods in the field of highly automated driving is their lack of robustness. Objects that suddenly appear or disappear from one image to another due to inaccurate predictions as well as occurring perturbations in the input data can have devastating consequences. A possibility to increase model robustness is the use of temporal consistency in video data. Our approach aims for a confidence-based combination of feature maps that are warped from previous time stages into the current one. This enables us to stabilize the network prediction and increase its robustness against perturbations. In order to demonstrate the effectiveness of our approach, we have created a test data set with image perturbations such as image artifacts and adversarial examples in which we significantly outperform the baseline.
DA  - 2019///
PY  - 2019
DO  - 10.1145/3359999.3360490
SN  - 978-1-4503-7004-2
AN  - WOS:000693940100001
ER  - 

TY  - JOUR
TI  - Sorting Through the Safety Data Haystack: Using Machine Learning to Identify Individual Case Safety Reports in Social-Digital Media
AU  - Comfort, S
AU  - Perera, S
AU  - Hudson, Z
AU  - Dorrell, D
AU  - Meireis, S
AU  - Nagarajan, M
AU  - Ramakrishnan, C
AU  - Fine, J
T2  - DRUG SAFETY
AB  - There is increasing interest in social digital media (SDM) as a data source for pharmacovigilance activities; however, SDM is considered a low information content data source for safety data. Given that pharmacovigilance itself operates in a high-noise, lower-validity environment without objective 'gold standards' beyond process definitions, the introduction of large volumes of SDM into the pharmacovigilance workflow has the potential to exacerbate issues with limited manual resources to perform adverse event identification and processing. Recent advances in medical informatics have resulted in methods for developing programs which can assist human experts in the detection of valid individual case safety reports (ICSRs) within SDM.
In this study, we developed rule-based and machine learning (ML) models for classifying ICSRs from SDM and compared their performance with that of human pharmacovigilance experts.
We used a random sampling from a collection of 311,189 SDM posts that mentioned Roche products and brands in combination with common medical and scientific terms sourced from Twitter, Tumblr, Facebook, and a spectrum of news media blogs to develop and evaluate three iterations of an automated ICSR classifier. The ICSR classifier models consisted of sub-components to annotate the relevant ICSR elements and a component to make the final decision on the validity of the ICSR. Agreement with human pharmacovigilance experts was chosen as the preferred performance metric and was evaluated by calculating the Gwet AC1 statistic (gKappa). The best performing model was tested against the Roche global pharmacovigilance expert using a blind dataset and put through a time test of the full 311,189-post dataset.
During this effort, the initial strict rule-based approach to ICSR classification resulted in a model with an accuracy of 65% and a gKappa of 46%. Adding an ML-based adverse event annotator improved the accuracy to 74% and gKappa to 60%. This was further improved by the addition of an additional ML ICSR detector. On a blind test set of 2500 posts, the final model demonstrated a gKappa of 78% and an accuracy of 83%. In the time test, it took the final model 48 h to complete a task that would have taken an estimated 44,000 h for human experts to perform.
The results of this study indicate that an effective and scalable solution to the challenge of ICSR detection in SDM includes a workflow using an automated ML classifier to identify likely ICSRs for further human SME review.
DA  - 2018/06//undefined
PY  - 2018
DO  - 10.1007/s40264-018-0641-7
VL  - 41
IS  - 6
SP  - 579
EP  - 590
SN  - 0114-5916
AN  - WOS:000433117800004
KW  - machine learning
KW  - Internet
KW  - Machine Learning
KW  - social media
KW  - automation
KW  - human
KW  - Humans
KW  - procedures
KW  - Article
KW  - priority journal
KW  - statistics and numerical data
KW  - mathematical model
KW  - drug safety
KW  - Pharmacovigilance
KW  - Adverse Drug Reaction Reporting Systems
KW  - data mining
KW  - Data Mining
KW  - drug surveillance program
KW  - adverse drug reaction
KW  - classifier
KW  - medical informatics
KW  - Drug-Related Side Effects and Adverse Reactions
KW  - Social Media
KW  - predictive value
KW  - Databases, Factual
KW  - factual database
KW  - blogging
KW  - Blogging
KW  - data collection method
ER  - 

TY  - JOUR
TI  - Safe Havens, Machine Learning, and the Sources of Geopolitical Risk: A Forecasting Analysis Using Over a Century of Data
AU  - Gupta, R
AU  - Karmakar, S
AU  - Pierdzioch, C
T2  - COMPUTATIONAL ECONOMICS
AB  - We use monthly data covering a century-long sample period (1915-2021) to study whether geopolitical risk helps to forecast subsequent gold volatility. We account not only for geopolitical threats and acts, but also for 39 country-specific sources of geopolitical risk. The response of subsequent volatility is heterogeneous across countries and nonlinear. We find that accounting for geopolitical risk at the country level improves forecast accuracy, especially when we use random forests to estimate our forecasting models. As an extension, we report empirical evidence on the predictive value of the country-level sources of geopolitical risk for two other candidate safe-haven assets, oil and silver, over the sample periods 1900-2021 and 1915-2021, respectively. Our results have important implications for the portfolio and risk-management decisions of investors who seek a safe haven in times of heightened geopolitical tensions.
DA  - 2023/08/17/
PY  - 2023
DO  - 10.1007/s10614-023-10452-w
SN  - 0927-7099
AN  - WOS:001050043200002
KW  - Forecasting
KW  - Random forests
KW  - Geopolitical risk
KW  - Gold
KW  - Returns
KW  - Volatility
ER  - 

TY  - JOUR
TI  - A method for machine learning generation of realistic synthetic datasets for validating healthcare applications
AU  - Arvanitis, TN
AU  - White, S
AU  - Harrison, S
AU  - Chaplin, R
AU  - Despotou, G
T2  - HEALTH INFORMATICS JOURNAL
AB  - Digital health applications can improve quality and effectiveness of healthcare, by offering a number of new tools to users, which are often considered a medical device. Assuring their safe operation requires, amongst others, clinical validation, needing large datasets to test them in realistic clinical scenarios. Access to datasets is challenging, due to patient privacy concerns. Development of synthetic datasets is seen as a potential alternative. The objective of the paper is the development of a method for the generation of realistic synthetic datasets, statistically equivalent to real clinical datasets, and demonstrate that the Generative Adversarial Network (GAN) based approach is fit for purpose. A generative adversarial network was implemented and trained, in a series of six experiments, using numerical and categorical variables, including ICD-9 and laboratory codes, from three clinically relevant datasets. A number of contextual steps provided the success criteria for the synthetic dataset. A synthetic dataset that exhibits very similar statistical characteristics with the real dataset was generated. Pairwise association of variables is very similar. A high degree of Jaccard similarity and a successful K-S test further support this. The proof of concept of generating realistic synthetic datasets was successful, with the approach showing promise for further work.
DA  - 2022/01//undefined
PY  - 2022
DO  - 10.1177/14604582221077000
VL  - 28
IS  - 2
SN  - 1460-4582
AN  - WOS:000783448000001
KW  - machine learning
KW  - Machine Learning
KW  - safety
KW  - human
KW  - Humans
KW  - Delivery of Health Care
KW  - health care delivery
KW  - Neural Networks, Computer
KW  - Generative adversarial networks
KW  - certification
KW  - realistic synthetic datasets
ER  - 

TY  - JOUR
TI  - Data analysis and machine learning techniques in the analysis of car safes in Brazil during the Covid-19 pandemic
AU  - Collin, BRR
AU  - Amaral, TM
AU  - Amaral, FM
T2  - NAVUS-REVISTA DE GESTAO E TECNOLOGIA
AB  - This study aims to analyze the impacts of Covid-19 on vehicle safes in Brazil, correlating these factors with semiconductors imports and economic indicators using Machine Learning models. For this, a collection and preparation of data took place before performing the exploratory analysis, and the developing of predictive models. This work is characterized as an applied and exploratory research, with a quantitative approach. The Python language was used to perform exploratory analysis and to create the models. The data used in this study were collected froco multiples sources of private companies, government, associations and research institutes.Three regression algorithms were used: Random Forest, Multi-Layer Perceptron and Multiple Linear Regression. The neural network presented the best results among the applied algorithms, reaching an R-2 of 82.01% in the test data set. After the exploratory analysis, we also noticed the high impact that semiconductors have on vehicle safes and the drastic effects caused by Covid-19 on the variables used in the study. With the model created, it is possible to predict the safes of vehicles in Brazil in a given month based on some economic indicators, semiconductor imports and the monthly deaths of Covid-19.
DA  - 2022/01//undefined
PY  - 2022
DO  - 10.22279/navus.2022.v12.p01-24.1717
VL  - 12
SP  - 1
EP  - 24
SN  - 2237-4558
AN  - WOS:000761003100001
ER  - 

TY  - JOUR
TI  - Using street view data and machine learning to assess how perception of neighborhood safety influences urban residents' mental health
AU  - Wang, RY
AU  - Yuan, Y
AU  - Liu, Y
AU  - Zhang, JB
AU  - Liu, PH
AU  - Lu, Y
AU  - Yao, Y
T2  - HEALTH & PLACE
AB  - Previous studies have shown that perceptions of neighborhood safety are associated with various mental health outcomes. However, scant attention has been paid to the mediating pathways by which perception of neighborhood safety affects mental health. In addition, most previous studies have evaluated perception of neighborhood safety with questionnaires or field audits, both of which are labor-intensive and time-consuming. This study is the first attempt to measure perception of neighborhood safety using street view data and a machine learning approach. Four potential mediating pathways linking perception of neighborhood safety to mental health were explored for 1029 participants from 35 neighborhoods of Guangzhou, China. The results of multilevel regression models confirm that perception of neighborhood safety is positively associated with mental health. More importantly, physical activity, social cohesion, stress and life satisfaction mediate this relationship. The results of a moderation analysis suggest that the beneficial effects of physical activity and social cohesion on mental health are strengthened by a perception of neighborhood safety. Our findings suggest the need to increase residents' perception of neighborhood safety to maintain mental health in urban areas of China.
DA  - 2019/09//undefined
PY  - 2019
DO  - 10.1016/j.healthplace.2019.102186
VL  - 59
SN  - 1353-8292
AN  - WOS:000500932500019
KW  - machine learning
KW  - Deep learning
KW  - deep learning
KW  - Safety
KW  - Machine Learning
KW  - mental health
KW  - perception
KW  - satisfaction
KW  - safety
KW  - adult
KW  - article
KW  - female
KW  - human
KW  - human experiment
KW  - Humans
KW  - male
KW  - Male
KW  - Adult
KW  - Female
KW  - China
KW  - major clinical study
KW  - regression analysis
KW  - drug safety
KW  - urban area
KW  - demography
KW  - epidemiology
KW  - exercise
KW  - physical activity
KW  - Pathways
KW  - digital map
KW  - neighborhood
KW  - etiology
KW  - Exercise
KW  - Guangdong
KW  - Guangzhou
KW  - life satisfaction
KW  - Mental Health
KW  - mental stress
KW  - Mental well-being
KW  - Neighborhood safety
KW  - Personal Satisfaction
KW  - psychological well-being
KW  - Residence Characteristics
KW  - social environment
KW  - Social Environment
KW  - Street view images
KW  - stress
KW  - Stress, Psychological
KW  - urban population
KW  - Urban Population
ER  - 

TY  - CONF
TI  - Disaster impacts analysis using social media data
AU  - Gangadhari, RK
AU  - Khanzode, V
AU  - Murthy, S
AU  - IEEE
T2  - 2021 INTERNATIONAL CONFERENCE ON MAINTENANCE AND INTELLIGENT ASSET MANAGEMENT (ICMIAM)
AB  - Social media platforms become an important source of information in the event of disasters. In the event of any disaster, people try to post the information, raise their concerns such as help required, report property and assets damages, look for any rehabilitation facilities, and report about injuries or fatalities. In this paper, social media data was used to assess public sentiment and the impact of a disaster to extract valuable insights to support rescue operators, government agencies, and voluntary organizations. The two-stage methodology adopted in this paper uses the data collected from Twitter and applies a filtering layer to rule out non-disaster event messages. Further, state-of-the-art machine learning models combined with regular expressions are used to find information about persons, injuries, and entities. A threshold limit is imposed on social media posts to alert the Government of any rapid changes in public behaviour using tweets or posts. We evaluate our model on a recent industrial disaster, "Vizag Gas Leak Incident," and present the findings and evaluate the importance of this methodology.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICMIAM54662.2021.9715186
SN  - 978-1-6654-6671-4
AN  - WOS:000800216700005
KW  - Machine learning
KW  - Social networking (online)
KW  - Disasters
KW  - Property
KW  - Sources of informations
KW  - Government agencies
KW  - Gas leaks
KW  - Impact analysis
KW  - Public sentiments
KW  - Safety analytic
KW  - Safety Analytics
KW  - Social media data
KW  - Social media datum
KW  - Social media platforms
KW  - Vizag gas leak
ER  - 

TY  - CONF
TI  - Predicting Clinical Deterioration in Hospitals
AU  - Jalali, L
AU  - Tang, HK
AU  - Goldstein, RH
AU  - Rodríguez, JA
T2  - 2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
A2  - Wu, XT
A2  - Jermaine, C
A2  - Xiong, L
A2  - Hu, XH
A2  - Kotevska, O
A2  - Lu, SY
A2  - Xu, WJ
A2  - Aluru, S
A2  - Zhai, CX
A2  - Al-Masri, E
A2  - Chen, ZY
A2  - Saltz, J
AB  - Responding rapidly to a patient who is demonstrating signs of imminent clinical deterioration is a basic tenet of patient care. This gave rise to a patient safety intervention philosophy known as a Rapid Response System (RRS), whereby a patient who meets a pre-determined set of criteria for imminent clinical deterioration is immediately assessed and treated, with the goal of mitigating the deterioration and preventing intensive care unit (ICU) transfer, cardiac arrest, or death. While RRSs have been widely adopted, multiple systematic reviews have failed to find evidence of their effectiveness. Typically, RRS criteria are simple, expert (consensus) defined rules that identify significant physiologic abnormalities or are based on clinical observation. If one can find a pattern in the patient's data earlier than the onset of the physiologic derangement manifest in the current criteria, intervention strategies might be more effective. In this paper, we apply machine learning to electronic medical records (EMR) to infer if patients are at risk for clinical deterioration. Our models are more sensitive and offer greater advance prediction time compared with existing rule-based methods that are currently utilized in hospitals. Our results warrant further testing in the field; if successful, hospitals can integrate our approach into their existing IT systems and use the alerts generated by the model to prevent ICU transfer, cardiac arrest, or death, or to reduce the ICU length of stay.
DA  - 2020///
PY  - 2020
DO  - 10.1109/BigData50022.2020.9378117
SP  - 3744
EP  - 3752
SN  - 2639-1589
AN  - WOS:000662554703113
KW  - Machine Learning
KW  - Big data
KW  - Patient safety
KW  - Medical computing
KW  - Patient treatment
KW  - Physiology
KW  - Deterioration
KW  - Systematic Review
KW  - Rule-based method
KW  - Clinical Deterioration
KW  - Intensive care units
KW  - Patient Safety
KW  - Cardiac arrest
KW  - Prediction time
KW  - Electronic medical record
KW  - Healthcare Big Data Analytics
KW  - Intervention strategy
KW  - Rapid response
ER  - 

TY  - JOUR
TI  - A survey of the opportunities and challenges of supervised machine learning in maritime risk analysis
AU  - Rawson, A
AU  - Brito, M
T2  - TRANSPORT REVIEWS
AB  - Identifying and assessing the likelihood and consequences of maritime accidents has been a key focus of research within the maritime industry. However, conventional methods utilised for maritime risk assessment have been dominated by a few methodologies each of which have recognised weaknesses. Given the growing attention that supervised machine learning and big data applications for safety assessments have been receiving in other disciplines, a comprehensive review of the academic literature on this topic in the maritime domain has been conducted. The review encapsulates the prediction of accident occurrence, accident severity, ship detentions and ship collision risk. In particular, the purpose, methods, datasets and features of such studies are compared to better understand how such an approach can be applied in practice and its relative merits. Several key challenges within these themes are also identified, such as the availability and representativeness of the datasets and methodological challenges associated with transparency, model development and results evaluation. Whilst focused within the maritime domain, many of these findings are equally relevant to other transportation topics. This work, therefore, highlights both novel applications for applying these techniques to maritime safety and key challenges that warrant further research in order to strengthen this methodological approach.
DA  - 2023/01/02/
PY  - 2023
DO  - 10.1080/01441647.2022.2036864
VL  - 43
IS  - 1
SP  - 108
EP  - 130
SN  - 0144-1647
AN  - WOS:000752261800001
KW  - machine learning
KW  - Machine learning
KW  - risk assessment
KW  - computer simulation
KW  - navigation
KW  - accidents
KW  - AIS data
KW  - ship handling
KW  - maritime
KW  - maritime transportation
KW  - navigation safety
KW  - ship motion
ER  - 

TY  - JOUR
TI  - Unsupervised Domain Adaptation Based on Pseudo-Label Confidence
AU  - Fu, TT
AU  - Li, Y
T2  - IEEE ACCESS
AB  - Unsupervised domain adaptation aims to align the distributions of data in source and target domains, as well as assign the labels to data in the target domain. In this paper, we propose a new method named Unsupervised Domain Adaptation based on Pseudo-Label Confidence (UDA-PLC). Concretely, UDA-PLC first learns a new feature representation by projecting data of source and target domains into a latent subspace. In this subspace, the distribution of data in two domains are aligned and the discriminability of features in both domains is improved. Then, UDA-PLC applies Structured Prediction (SP) and Nearest Class Prototype (NCP) to predicting pseudo-labels of data in the target domain, and it takes a fraction of samples with high confidence rather than all the pseudo-labeled target samples into next iterative learning. Finally, experimental results validate that the proposed method outperforms several state-of-the-art methods on three benchmark data sets.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3087867
VL  - 9
SP  - 87049
EP  - 87057
SN  - 2169-3536
AN  - WOS:000673306600001
KW  - Feature representation
KW  - Iterative methods
KW  - State-of-the-art methods
KW  - transfer learning
KW  - Domain adaptation
KW  - Benchmark data
KW  - Distribution alignment
KW  - label propagation
KW  - Discriminability
KW  - unsupervised domain adaptation
KW  - High confidence
KW  - Iterative learning
KW  - structured prediction
KW  - Structured prediction
ER  - 

TY  - JOUR
TI  - DMRVisNet: Deep Multihead Regression Network for Pixel-Wise Visibility Estimation Under Foggy Weather
AU  - You, J
AU  - Jia, SC
AU  - Pei, X
AU  - Yao, DY
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Scene perception is essential for driving decision-making and traffic safety. However, fog, as a kind of common weather, frequently appears in the real world, especially in mountain areas, making it difficult to accurately observe the surrounding environments. Therefore, precisely estimating the visibility under foggy weather can significantly benefit traffic management and safety. To address this, most current methods use professional instruments outfitted at fixed locations on the roads to perform the visibility measurement; these methods are expensive and less flexible. In this paper, we propose an innovative end-to-end convolutional neural network framework to estimate the visibility leveraging Koschmieder's law and the image data. The proposed method estimates the visibility by integrating the physical model into the proposed framework, instead of directly predicting the visibility value via the convolutional neural network. Moreover, we estimate the visibility as a pixel-wise visibility map against those of previous visibility measurement methods which solely predict a single value for the entire image. Thus, the estimated result of our method is more informative, particularly in uneven fog scenarios, which can benefit to developing a more precise early warning system for foggy weather, thereby better protecting the intelligent transportation infrastructure systems and promoting their development. To validate the proposed framework, a virtual dataset, FACI, containing 3,000 foggy images in different concentrations, is collected using the AirSim platform, which is available at https://github.com/coutyou/FoggyAirsimCityImages. Detailed experiments show that the proposed method achieves performance competitive to those of state-of-the-art methods.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.1109/TITS.2022.3180229
VL  - 23
IS  - 11
SP  - 22354
EP  - 22366
SN  - 1524-9050
AN  - WOS:000826389200001
ER  - 

TY  - JOUR
TI  - MetaDrive: Composing Diverse Driving Scenarios for Generalizable Reinforcement Learning
AU  - Li, QY
AU  - Peng, ZH
AU  - Feng, L
AU  - Zhang, QH
AU  - Xue, ZH
AU  - Zhou, BL
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - Driving safely requires multiple capabilities from human and intelligent agents, such as the generalizability to unseen environments, the safety awareness of the surrounding traffic, and the decision-making in complex multi-agent settings. Despite the great success of Reinforcement Learning (RL), most of the RL research works investigate each capability separately due to the lack of integrated environments. In this work, we develop a new driving simulation platform called MetaDrive to support the research of generalizable reinforcement learning algorithms for machine autonomy. MetaDrive is highly compositional, which can generate an infinite number of diverse driving scenarios from both the procedural generation and the real data importing. Based on MetaDrive, we construct a variety of RL tasks and baselines in both single-agent and multi-agent settings, including benchmarking generalizability across unseen scenes, safe exploration, and learning multi-agent traffic. The generalization experiments conducted on both procedurally generated scenarios and real-world scenarios show that increasing the diversity and the size of the training set leads to the improvement of the RL agent's generalizability. We further evaluate various safe reinforcement learning and multi-agent reinforcement learning algorithms in MetaDrive environments and provide the benchmarks. Source code, documentation, and demo video are available at https://metadriverse.github.io/metadrive.
DA  - 2023/03/01/
PY  - 2023
DO  - 10.1109/TPAMI.2022.3190471
VL  - 45
IS  - 3
SP  - 3461
EP  - 3475
SN  - 0162-8828
AN  - WOS:000966735000001
ER  - 

TY  - JOUR
TI  - Detecting Anomalies in Simulated Nuclear Data Using Autoencoders
AU  - Mena, P
AU  - Borrelli, RA
AU  - Kerby, L
T2  - NUCLEAR TECHNOLOGY
AB  - Concerns over cybersecurity in critical systems have grown significantly over the last decade. The increase in the successful attacks against infrastructure, major corporations, and governments has led to major investment in mitigating and preventing cyberattacks. At the same time, there has been a significant interest in utilizing data in operations, with machine learning applications becoming a popular area of study. One industry exploring machine learning applications is the nuclear industry. Because of the sensitive nature of nuclear systems, the question if attacks on nuclear data can be detected has begun to take urgency. This study explores the use of autoencoders to detect anomalies in nuclear data that could be potentially used to evaluate the operating status of a nuclear system. Data from a generic pressurized water reactor simulator used in a previous study to diagnose transients was used to train an autoencoder model using Keras. A separate portion of these data was altered by adding statistical noise for validation. Four different levels of noise were used in this experiment. Once the autoencoder was trained, a threshold was calculated using the average mean square error of the predictions and the standard deviation from that loss. Points above the threshold were classified as anomalies while points below were considered unaltered. For the initial level of noise, the model was able to score near perfect in recall, capturing all but 13 of the 13 884 altered points. However, in terms of precision, the model misclassified a number of unaltered points as altered, resulting in a score of 73.76%. To test the sensitivity of the model, the amount of noise was reduced three times, and as expected, the performance of the model worsened with each reduction. Still, the high performance in identifying altered points for higher levels of noise is an encouraging first step in developing anomaly detection systems for nuclear data.
DA  - 2023/07/01/
PY  - 2023
DO  - 10.1080/00295450.2023.2214257
SN  - 0029-5450
AN  - WOS:001025561800001
KW  - Machine learning
KW  - Anomaly detection
KW  - Performance
KW  - Machine-learning
KW  - anomaly detection
KW  - Machine learning applications
KW  - Mean square error
KW  - Cyber security
KW  - Cybersecurity
KW  - Investments
KW  - data science
KW  - Auto encoders
KW  - Nuclear safety
KW  - Pressurized water reactors
KW  - nuclear safety
KW  - Nuclear industry
KW  - Nuclear data
KW  - nuclear simulation
KW  - Nuclear simulation
KW  - Nuclear systems
ER  - 

TY  - CONF
TI  - A Big Data Approach to Support Information Distribution in Crisis Response
AU  - Netten, N
AU  - van den Braak, S
AU  - Choenni, S
AU  - van Someren, M
T2  - 9TH INTERNATIONAL CONFERENCE ON THEORY AND PRACTICE OF ELECTRONIC GOVERNANCE (ICEGOV 2016)
A2  - Bertot, J
A2  - Estevez, E
A2  - Mellouli, S
AB  - Crisis response organizations operate in very dynamic environments, in which it is essential for responders to acquire all information critical to their task execution in time. In reality, the responders are often faced with information overload, incomplete information, or a combination of both. This hampers their decision-making process, workflow, situational awareness and, consequently, effective execution of collaborative crisis response. Therefore, getting the right information to the right person at the right time is of crucial importance.
The task of processing all data during crisis response situations and determining for whom at a particular moment the information is relevant is not straightforward. When developing an information system to support this task, some important challenges have to be taken into account. These challenges relate to the structure and truthfulness of the used data, the assessment of information relevance, and the dissemination of relevant information in time. While methods and techniques from big data can be used to collect and integrate data, machine learning can be used to build a model for relevance assessments. An example implementation of such a framework of big data is the TAID software system that collects and integrates data communicated between first responders and may send information to crisis responders that were not addressed in the initial communication. As an example of the impact of TAID on crisis response, we show its effect in a simulated crisis response scenario.
DA  - 2016///
PY  - 2016
DO  - 10.1145/2910019.2910033
SP  - 266
EP  - 275
SN  - 978-1-4503-3640-6
AN  - WOS:000391515800043
KW  - Artificial intelligence
KW  - Machine learning
KW  - Decision making
KW  - Learning systems
KW  - Data handling
KW  - Situational awareness
KW  - Big data
KW  - Public safety
KW  - Decision making process
KW  - Information dissemination
KW  - Crisis response for public safety
KW  - Government data processing
KW  - Incomplete information
KW  - Information distribution
KW  - Information distributions
KW  - Information overloads
KW  - Information relevances
KW  - Relevance assessments
ER  - 

TY  - JOUR
TI  - Safe and Stable RL (S2RL) Driving Policies Using Control Barrier and Control Lyapunov Functions
AU  - Gangopadhyay, B
AU  - Dasgupta, P
AU  - Dey, S
T2  - IEEE TRANSACTIONS ON INTELLIGENT VEHICLES
AB  - Deep Reinforcement Learning (DRL) has been successfully applied to learn policies for safety-critical systems with unknown model dynamics in simulation. DRL controllers though optimal in terms of reward, do not provide any safety and stability guarantees. With reliance on model information, safety conditions can be expressed as Control Barrier Functions (CBF's) and performance objectives can be expressed as Control Lyapunov Functions (CLF's) for real-time optimization-based controllers. In this work, we use an amalgamation of model-free RL and model-based controllers to establish safety and stability. We first design CLF, CBF Quadratic Programs (QP's) for different driving manoeuvres on nominal vehicle dynamics. Reinforcement Learning (RL) agents are trained to learn policies for the actual vehicle with enhanced dynamics. In order to incorporate safety and stability while retaining optimal behaviour we selectively guide the RL agents using CLF, CBF QP's. This results in both safe and stable ((SRL)-R-2) policies. We empirically validate the proposed methodology on different driving manoeuvres.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1109/TIV.2022.3160202
VL  - 8
IS  - 2
SP  - 1889
EP  - 1899
SN  - 2379-8858
AN  - WOS:000966106400001
ER  - 

TY  - JOUR
TI  - Learning Domain-Invariant and Discriminative Features for Homogeneous Unsupervised Domain AdaptationInspec keywordsOther keywordsKey words
AU  - Zhang, Y
AU  - Wang, NB
AU  - Cai, SB
T2  - CHINESE JOURNAL OF ELECTRONICS
AB  - A classifier trained on the label-rich source dataset tends to perform poorly on the unlabeled target dataset because of the distribution discrepancy across different datasets. Unsupervised domain adaptation aims to transfer knowledge from the labeled source dataset to the unlabeled target dataset to solve this problem. Most of the existing unsupervised domain adaptation methods only concentrate on learning domain-invariant features across different domains, but they neglect the discriminability of the learned features to satisfy the cluster assumption. In this paper, we propose Semantic pairwise centroid alignment (SPCA), which is a point-wise method to learn both domain-invariant and discriminative features for homogeneous unsupervised domain adaptation. SPCA utilizes a novel semantic centroid loss to reduce the intraclass distance in feature space by using source data and target High-confidence centroid points (HCCPs). Then a classifier trained on source features is expected to generalize well on target features. Extensive experiments on visual recognition tasks verify the effectiveness of the proposed SPCA and also demonstrate that both domaininvariant and discriminative features learned by SPCA can significantly boost the performance of homogeneous unsupervised domain adaptation.
DA  - 2020/11//undefined
PY  - 2020
DO  - 10.1049/cje.2020.09.013
VL  - 29
IS  - 6
SP  - 1119
EP  - 1125
SN  - 1022-4653
AN  - WOS:000609935600015
ER  - 

TY  - JOUR
TI  - Pharmacovigilance strategy: opportunities for cross-national learning
AU  - Fermont, I
T2  - ISRAEL JOURNAL OF HEALTH POLICY RESEARCH
AB  - The Israeli Ministry of Health has set up the foundations of a National Pharmacovigilance System. The next step is to adopt the best of the international ideas, trends and approaches which are shaping the future of pharmacovigilance. Specifically: 1) The risk management approach requires proactively preventing or minimizing risks, starting in early clinical development and extending all along the lifecycle of a pharmaceutical. 2) Drug safety is a multidisciplinary discipline where all stakeholders should be involved. 3) Clinical trials provide an ideal safety profile limited to the restrictive conditions of the trial. Only real-world data, from the post marketing period, will reveal the real risk/benefit balance for the use of a pharmaceutical in regular clinical care. 4) Artificial intelligence is needed to analyze the large amount of data collected through the post-marketing studies, electronic medical records and the internet. Many AI tools have been developed to support better use of pharmaceuticals. 5) Quality-oriented, thorough inspections and audits are critical for achieving patient safety. 6) Patients should be recognized as active players in their treatment who can, and should, have access to safety information through the major agencies' websites.Israel can benefit from several of its key assets to reach a higher level of pharmacovigilance: 1) Israel's four HMOs are organized in a way that allows them to have quick and efficient dialogue with healthcare professionals and with patients. Moreover, a new project named, Big Data in Health, will pool the epidemiologic databases of the HMOs, providing precious information for understanding risk factors, detecting alerts, and developing personalized medicine. 2) Formal risk management activities have long been part of the culture of hospitals and should be applied increasingly to ensuring drug safety.Israel has the organizational, scientific, technological and cultural resources needed to quickly overcome the challenges and go beyond its current state to build a unique pharmacovigilance system which could serve as an example for other countries.
DA  - 2019/06/19/
PY  - 2019
DO  - 10.1186/s13584-019-0319-3
VL  - 8
SN  - 2045-4015
AN  - WOS:000472204200001
ER  - 

TY  - JOUR
TI  - Using machine learning methods in airline flight data monitoring to generate new operational safety knowledge from existing data
AU  - Oehling, J
AU  - Barry, DJ
T2  - SAFETY SCIENCE
AB  - The aim of this work is to investigate the possibility of using machine learning (ML) methods in order to generate novel, safety-relevant knowledge from existing flight data. Airlines routinely generate vast amounts of flight data from routine monitoring, but the concept of extracting safety knowledge from this data is still based on detecting exceedances of expert-defined thresholds. This system is conceptually unable to detect novel occurrences for which no such filters exist. ML techniques are able to close this gap.
This paper first reviews the literature to select an appropriate ML method. A form of unsupervised learning called "Local Outlier Probability" is selected. Next, an appropriate feature space is developed and implemented in the flight data monitoring system of a supporting airline to generate the dataset. This dataset is cleaned and the outlier calculation performed. The results are statistically analysed. Furthermore, the top outliers are reviewed by the airline's review pilots in the same way as the traditional exceedance events. Last, the severities and safety relevance of both types of events are compared.
This work successfully shows that the chosen approach is able to reduce the number of undetected safety-relevant occurrences by finding novel occurrence types which were undetected by a contemporary and mature flight data monitoring system.
This research builds on recent literature by developing a novel method which can be scaled to work in an airline production environment with large datasets, as demonstrated by the efficient analysis of 1.2 million flights.
DA  - 2019/04//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2018.12.018
VL  - 114
SP  - 89
EP  - 104
SN  - 0925-7535
AN  - WOS:000459839300010
KW  - machine learning
KW  - Artificial intelligence
KW  - standardization
KW  - Learning systems
KW  - safety
KW  - algorithm
KW  - Article
KW  - priority journal
KW  - calculation
KW  - Machine learning methods
KW  - artificial neural network
KW  - Statistics
KW  - probability
KW  - Operational safety
KW  - Air transportation
KW  - Aviation
KW  - Monitoring
KW  - knowledge
KW  - monitoring
KW  - statistical analysis
KW  - aircraft
KW  - Efficient analysis
KW  - flight
KW  - Flight data monitoring
KW  - Local outliers
KW  - Production environments
KW  - Routine monitoring
KW  - Safety knowledge
ER  - 

TY  - JOUR
TI  - Deep Learning-Based Black Spot Identification on Greek Road Networks
AU  - Karamanlis, I
AU  - Kokkalis, A
AU  - Profillidis, V
AU  - Botzoris, G
AU  - Kiourt, C
AU  - Sevetlidis, V
AU  - Pavlidis, G
T2  - DATA
AB  - Black spot identification, a spatiotemporal phenomenon, involves analysing the geographical location and time-based occurrence of road accidents. Typically, this analysis examines specific locations on road networks during set time periods to pinpoint areas with a higher concentration of accidents, known as black spots. By evaluating these problem areas, researchers can uncover the underlying causes and reasons for increased collision rates, such as road design, traffic volume, driver behaviour, weather, and infrastructure. However, challenges in identifying black spots include limited data availability, data quality, and assessing contributing factors. Additionally, evolving road design, infrastructure, and vehicle safety technology can affect black spot analysis and determination. This study focused on traffic accidents in Greek road networks to recognize black spots, utilizing data from police and government-issued car crash reports. The study produced a publicly available dataset called Black Spots of North Greece (BSNG) and a highly accurate identification method. Dataset: https://github.com/iokarama/BSNG-dataset (accessed on 15 June 2023). Dataset License: CC-BY-NC
DA  - 2023/06//undefined
PY  - 2023
DO  - 10.3390/data8060110
VL  - 8
IS  - 6
SN  - 2306-5729
AN  - WOS:001016989200001
ER  - 

TY  - CONF
TI  - Data-Driven Optimal Tracking with Constrained Approximate Dynamic Programming for Servomotor Systems
AU  - Chakrabarty, A
AU  - Danielson, C
AU  - Wang, YB
AU  - IEEE
T2  - 2020 IEEE CONFERENCE ON CONTROL TECHNOLOGY AND APPLICATIONS (CCTA)
AB  - We design real-time optimal tracking controllers for servomotor systems engaged in single-axis point-to-point positioning tasks. The design is challenging due to the presence of unmodeled dynamics, along with speed and acceleration constraints. As model-based optimal control design methods cannot be applied directly to this uncertain system, we propose a data-driven approximate dynamic programming approach to learn an optimal tracking controller that is constraint-enforcing. The potential of our proposed method is illustrated on a servomotor that positions the head of a laser drilling machine.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ccta41146.2020.9206315
SP  - 352
EP  - 357
SN  - 978-1-7281-7140-1
AN  - WOS:000668042200056
KW  - Real time systems
KW  - Controllers
KW  - Safe reinforcement learning
KW  - Drilling machines (machine tools)
KW  - Model-based OPC
KW  - Dynamic programming
KW  - Data driven
KW  - Approximate dynamic programming
KW  - Data-driven methods
KW  - Invariant sets
KW  - Unmodeled dynamics
KW  - Constrained control
KW  - Convex programming
KW  - Optimal control design
KW  - Optimal tracking
KW  - Output tracking
KW  - Point to point
KW  - Servomotors
KW  - Single-axis
ER  - 

TY  - JOUR
TI  - Investigation of Machine Learning Methods for Structural Safety Assessment under Variability in Data: Comparative Studies and New Approaches
AU  - Sarmadi, H
T2  - JOURNAL OF PERFORMANCE OF CONSTRUCTED FACILITIES
AB  - Due to the importance of civil structures and infrastructures, structural safety assessment or structural health monitoring has become a basic necessity for every society. Recent developments of sensing and data acquisition systems enable civil engineers to exploit machine learning methods based on data-driven strategies for structural safety assessment and damage detection. However, the choice of an appropriate machine learning method may be problematic, particularly under some challenging issues such as the negative effects of environmental and/or operational variability (EOV), and the necessity of estimating some influential unknown elements of parametric machine learning methods called hyperparameters. Accordingly, this article focuses on three main aspects: (1) comparing various machine learning methods, (2) developing semiparametric algorithms, and (3) proposing automated algorithms for hyperparameter optimization of semiparametric and parametric machine learning methods. An innovative automated output-only approach is proposed to qualitatively and relatively predict the levels of EOV in terms of strong or weak variability. The main contributions of this article include comparing various machine learning methods, which will enable civil engineers to choose the most appropriate technique, and proposing automated approaches to hyperparameter optimization and variability level prediction. Dynamic and statistical features extracted from measured vibration data of two full-scale bridges were considered to perform the comparative studies and investigate the proposed methods. The results demonstrated that the semiparametric methods provide the best performance when their unknown parameters are determined appropriately.
DA  - 2021/12/01/
PY  - 2021
DO  - 10.1061/(ASCE)CF.1943-5509.0001664
VL  - 35
IS  - 6
SN  - 0887-3828
AN  - WOS:000708125400005
KW  - Machine learning
KW  - Automation
KW  - Machine learning methods
KW  - Safety engineering
KW  - Safety assessments
KW  - Parameter estimation
KW  - Data acquisition
KW  - Hyper-parameter optimizations
KW  - Damage detection
KW  - Structural safety
KW  - New approaches
KW  - Bridges
KW  - Structural health monitoring
KW  - Structural optimization
KW  - Civil infrastructures
KW  - Civil structure
KW  - Comparatives studies
KW  - Environmental and operational variability
KW  - Hyperparameter optimization
KW  - Semiparametric
ER  - 

TY  - JOUR
TI  - Data alignments in machinery remaining useful life prediction using deep adversarial neural networks
AU  - Li, X
AU  - Zhang, W
AU  - Ma, H
AU  - Luo, Z
AU  - Li, X
T2  - KNOWLEDGE-BASED SYSTEMS
AB  - Recently, intelligent data-driven machinery prognostics and health management have been attracting increasing attention due to the great merits of high accuracy, fast response and easy implementation. While promising prognostic performance has been achieved, the first predicting time for remaining useful life is generally difficult to be determined, and the data distribution discrepancy between different machines is mostly ignored, which leads to deterioration in prognostics. In this paper, a deep learning-based prognostic method is proposed to address the problems. Generative adversarial networks are used to learn the distributions of data in machine healthy states, and a health indicator is proposed to determine the first predicting time. Afterwards, adversarial training is further introduced to achieve data alignments of different machine entities in order to extract generalized prognostic knowledge. Experiments of remaining useful life prediction on two rotating machinery datasets are implemented, and the promising prognostic results validate the effectiveness of the proposed method. (C) 2020 Elsevier B.V. All rights reserved.
DA  - 2020/06/07/
PY  - 2020
DO  - 10.1016/j.knosys.2020.105843
VL  - 197
SN  - 0950-7051
AN  - WOS:000528878400010
KW  - Deep learning
KW  - Deep neural networks
KW  - Systems engineering
KW  - Forecasting
KW  - Deterioration
KW  - Intelligent data
KW  - Adversarial training
KW  - Health indicators
KW  - Remaining useful lives
KW  - Machinery
KW  - Data distribution
KW  - Adversarial networks
KW  - Data alignments
KW  - Data alignment
KW  - Prognostics and health managements
KW  - Remaining useful life prediction
KW  - Remaining useful life predictions
KW  - Rotating machines
ER  - 

TY  - JOUR
TI  - Statistical Safety Factor in Lightning Performance Analysis of Overhead Distribution Lines
AU  - Sarajcev, P
AU  - Lovric, D
AU  - Garma, T
T2  - ENERGIES
AB  - This paper introduces a novel machine learning (ML) model for the lightning performance analysis of overhead distribution lines (OHLs), which facilitates a data-centrist and statistical view of the problem. The ML model is a bagging ensemble of support vector machines (SVMs), which introduces two significant features. Firstly, support vectors from the SVMs serve as a scaffolding, and at the same time give rise to the so-called curve of limiting parameters for the line. Secondly, the model itself serves as a foundation for the introduction of the statistical safety factor to the lightning performance analysis of OHLs. Both these aspects bolster an end-to-end statistical approach to the OHL insulation coordination and lightning flashover analysis. Furthermore, the ML paradigm brings the added benefit of learning from a large corpus of data amassed by the lightning location networks and fostering, in the process, a "big data" approach to this important engineering problem. Finally, a relationship between safety factor and risk is elucidated. THe benefits of the proposed approach are demonstrated on a typical medium-voltage OHL.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.3390/en15218248
VL  - 15
IS  - 21
SN  - 1996-1073
AN  - WOS:000884118300001
KW  - machine learning
KW  - Support vector machines
KW  - Machine-learning
KW  - Machine learning models
KW  - Factor analysis
KW  - Safety factor
KW  - support vector machine
KW  - Support vectors machine
KW  - Scaffolds
KW  - Performances analysis
KW  - bagging ensemble
KW  - Bagging ensemble
KW  - distribution line
KW  - Distribution lines
KW  - Ensemble of support vector machines
KW  - insulation coordination
KW  - Lightning performance
KW  - lightning protection
KW  - Lightning protection
KW  - Overhead distribution line
KW  - safety factor
KW  - Support vector
ER  - 

TY  - JOUR
TI  - Applications of data science for responsible gambling: a scoping review
AU  - Ghaharian, K
AU  - Abarbanel, B
AU  - Phung, D
AU  - Puranik, P
AU  - Kraus, S
AU  - Feldman, A
AU  - Bernhard, B
T2  - INTERNATIONAL GAMBLING STUDIES
AB  - Technological innovations in the gambling industry have revolutionized the availability, storage, and use-cases of data. How this data may be leveraged for responsible gambling has emerged as a popular field of inquiry. We conducted a scoping review following PRISMA guidelines to understand the current state of data science applications for responsible gambling by exploring the aims, study designs, and methods used by researchers. Thirty-seven studies were included in the final review that spanned three categories: (1) cluster analysis (n = 14), (2) supervised machine learning with behavioral tracking data (n = 17), and (3) other data science applications (n = 6). Over half of the studies were published between 2018 and 2021. Existing research focuses on the development of responsible gambling tools centered around customer profiling and risk-detection. Our analysis of the records revealed limitations in terms of generalizability and reproducibility, as well as a considerable lack of peer-reviewed work. The current evidence suggests that the utility and adoption of data science in practice remains largely unexplored. Future work may focus on additional data science techniques with novel datasets and in situ research.
DA  - 2023/05/04/
PY  - 2023
DO  - 10.1080/14459795.2022.2135753
VL  - 23
IS  - 2
SP  - 289
EP  - 312
SN  - 1445-9795
AN  - WOS:000881338900001
KW  - machine learning
KW  - systematic review
KW  - data science
KW  - Responsible gambling
KW  - gambling
ER  - 

TY  - CONF
TI  - Vessel Collision Risk Assessment using AIS Data: A Machine Learning Approach
AU  - Tritsarolis, A
AU  - Chondrodima, E
AU  - Pelekis, N
AU  - Theodoridis, Y
AU  - IEEE
T2  - 2022 23RD IEEE INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2022)
AB  - The wide spread of Automatic Identification System (AIS) and tools based on it has motivated several maritime analytics operations. One of the most critical operations for the purpose of maritime safety is the so-called Vessel Collision Risk Assessment (VCRA). Accurate VCRA is a challenging task as maritime traffic is quite volatile, often affected by external factors, such as weather, etc. Addressing this problem by using complex models introduces a trade-off between accuracy quality and responsiveness. On the other hand, Machine Learning (ML) methods can better address this tradeoff. In this paper, we study the VCRA problem from the ML perspective, by proposing an architecture based on the Multi-Layered Perceptron (MLP) model. Our preliminary experimental study over a large-scale AIS dataset shows that the proposed methodology outperforms the kinematic equations-based approach.
DA  - 2022///
PY  - 2022
DO  - 10.1109/MDM55031.2022.00093
SP  - 425
EP  - 430
SN  - 1551-6245
AN  - WOS:000861618300073
KW  - Machine learning
KW  - Automation
KW  - Machine Learning
KW  - Machine-learning
KW  - Economic and social effects
KW  - Risk assessment
KW  - Safety engineering
KW  - Machine learning approaches
KW  - Large dataset
KW  - Maritime safety
KW  - Maritime Safety
KW  - Wide spreads
KW  - Automatic identification system
KW  - Automatic identification system data
KW  - Maritime traffic
KW  - AIS Data
KW  - Collision risk assessment
KW  - Collision Risk Assessment
KW  - Critical operations
KW  - Identification tools
ER  - 

TY  - JOUR
TI  - Nuclear Reactor Transient Diagnostics Using Classification and AutoML
AU  - Mena, P
AU  - Borrelli, RA
AU  - Kerby, L
T2  - NUCLEAR TECHNOLOGY
AB  - Artificial intelligence is becoming a larger part of operations for many industries. One industry where this is occurring rapidly is the nuclear industry. Researchers from around the world are looking to implement this technology in various areas of the nuclear industry. This paper explores the use of machine learning to diagnose problems. This project makes use of synthetic data collected from a Generic Pressurized Water Reactor (GPWR) simulator on whether a reactor is operating normally or experiencing one of four different transient events. A dataset was created consisting of over 30 000 reactor operational states. The data were explored and wrangled using Python and the Pandas package, using a variety of methods. Once ready, the data were randomly shuffled, with half the data being used for training and the other half being used for testing. Six different machine learning models were created using scikit-learn and the AutoML package Tree-based Pipeline Optimization Tool (TPOT). These models were created using six data scaling methods along with six feature reduction/selection methods. These models were validated using accuracy, precision, recall, and F1 score. The accuracy of the individual transients was also calculated. All six of the models had validation scores above 95%, with the decision tree and logistic regression models performing the best. These results are promising for the possible future use of machine learning in reactor diagnostics.
DA  - 2022/02/01/
PY  - 2022
DO  - 10.1080/00295450.2021.1905470
VL  - 208
IS  - 2
SP  - 232
EP  - 245
SN  - 0029-5450
AN  - WOS:000662087800001
KW  - Decision trees
KW  - Machine learning
KW  - Machine learning models
KW  - Possible futures
KW  - Logistic regression
KW  - data science
KW  - Pressurized water reactors
KW  - AutoML
KW  - nuclear safety
KW  - Logistic regression models
KW  - Nuclear industry
KW  - Transient events
KW  - Feature reduction
KW  - nuclear power
KW  - Operational state
KW  - Pipeline optimization
KW  - Reactor transients
ER  - 

TY  - JOUR
TI  - Development of a predictive inpatient falls risk model using machine learning
AU  - Ladios-Martin, M
AU  - Cabañero-Martínez, MJ
AU  - Fernández-de-Maya, J
AU  - Ballesta-López, FJ
AU  - Belso-Garzas, A
AU  - Zamora-Aznar, FM
AU  - Cabrero-Garcia, J
T2  - JOURNAL OF NURSING MANAGEMENT
AB  - Aim The aims of this study were to create a model that detects the population at risk of falls taking into account a fall prevention variable and to know the effect on the model's performance when not considering it. Background Traditionally, instruments for detecting fall risk are based on risk factors, not mitigating factors. Machine learning, which allows working with a wider range of variables, could improve patient risk identification. Methods The sample was composed of adult patients admitted to the Internal Medicine service (total, n = 22,515; training, n = 11,134; validation, n = 11,381). A retrospective cohort design was used and we applied machine learning technics. Variables were extracted from electronic medical records electronic medical records. Results The Two-Class Bayes Point Machine algorithm was selected. Model-A (with a fall prevention variable) obtained better results than Model-B (without it) in sensitivity (0.74 vs. 0.71), specificity (0.82 vs. 0.74), and AUC (0.82 vs. 0.78). Conclusions Fall prevention was a key variable. The model that included it detected the risk of falls better than the model without it. Implications for Nursing Management We created a decision-making support tool that helps nurses to identify patients at risk of falling. When it is integrated in the electronic medical records, it decreases nurses' workloads by not having to collect information manually.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.1111/jonm.13760
VL  - 30
IS  - 8
SP  - 3777
EP  - 3786
SN  - 0966-0429
AN  - WOS:000847450200001
KW  - machine learning
KW  - risk assessment
KW  - Machine Learning
KW  - adult
KW  - article
KW  - female
KW  - human
KW  - Humans
KW  - male
KW  - algorithm
KW  - procedures
KW  - Adult
KW  - prevention and control
KW  - Risk Assessment
KW  - major clinical study
KW  - retrospective study
KW  - sensitivity and specificity
KW  - decision making
KW  - patient safety
KW  - Bayes theorem
KW  - Bayes Theorem
KW  - data mining
KW  - electronic health record
KW  - hospital patient
KW  - Retrospective Studies
KW  - risk factor
KW  - Risk Factors
KW  - cohort analysis
KW  - electronic medical record
KW  - human tissue
KW  - workload
KW  - Electronic Health Records
KW  - falling
KW  - nurse
KW  - Accidental Falls
KW  - fall risk
KW  - falls
KW  - Inpatients
KW  - internal medicine
KW  - nursing management
KW  - patient risk
KW  - risk model
ER  - 

TY  - CONF
TI  - EMPHASISE MACHINE SAFETY THROUGH THE USE OF AN E-RESOURCE
AU  - Stuart, A
T2  - 2011 4TH INTERNATIONAL CONFERENCE OF EDUCATION, RESEARCH AND INNOVATION (ICERI)
A2  - Torres, IC
A2  - Chova, LG
A2  - Martinez, AL
AB  - With the introduction of safer and more sophisticated wood working machines to the Timber Industry, one would expect accident levels to reduce. Contrary to this belief, the number of accidents is still higher than other manufacturing industries. This paper discusses the development and subsequent use of an e-resource, designed to emphasise the importance of machine safety to first year Timber Product Technology students at the Dublin Institute of Technology.
DA  - 2011///
PY  - 2011
SP  - 3354
EP  - 3358
SN  - 978-84-615-3324-4
AN  - WOS:000317080003055
ER  - 

TY  - JOUR
TI  - A data analytics framework for anomaly detection in flight operations
AU  - Silva, LCE
AU  - Murça, MCR
T2  - JOURNAL OF AIR TRANSPORT MANAGEMENT
AB  - In the air transport system, there has been a continuous effort to develop policies, tools, and methodologies that increase and standardize safety levels across the entire commercial aviation market, while also enhancing operational efficiency. Furthermore, there is a current focus on proactive approaches for aviation performance management. Within this context, data mining initiatives such as anomaly detection have become more prominent. Dealing with anomalies is a natural step for achieving the goals regarding operational safety and efficiency, as anomalies are often related to hazardous and inefficient operations. In this work, we propose a systematic flight data analytics framework for anomaly detection in flight operations in order to provide a comprehensive and reusable pipeline for model building, application, and explanation. The solution is designed to be applicable to both online and offline regimes and at multiple scales, while also building on domain-expert analysis. We demonstrate the framework applicability in two scenarios of routine flight operations monitoring considering both airline and air traffic management perspectives. In the first one, the framework is applied to aircraft performance data within an unsupervised learning setting with a density -based clustering approach for anomaly detection in landing operations at Minneapolis-Saint Paul International Airport (KMSP). The results are compared with those obtained with exceedance-based methods used in the current practice, revealing the detection of operationally significant anomalies beyond the benchmark. In the second case study, we apply the framework on flight tracking data within a supervised learning setting with the development of an autoencoder classifier for offline anomaly detection in terminal airspace arrival operations at Sao Paulo/Guarulhos International Airport (SBGR). Additionally, supervised learning models are developed for anomaly explanation. The autoencoder classifier was able to detect operationally significant anomalies, while the explanatory models provided novel insights about contributing factors to the anomalies identified. For instance, we learned that anomalous arrival trajectories are more likely to be associated with landing operations on runway 27 under wind scenarios, with an increase in the odds ratio of 62% and 58% for tailwinds and headwinds, respectively. In addition, we also observed a positive association between anomalies and wind gusts situations.
DA  - 2023/07//undefined
PY  - 2023
DO  - 10.1016/j.jairtraman.2023.102409
VL  - 110
SN  - 0969-6997
AN  - WOS:000988656800001
KW  - machine learning
KW  - Machine learning
KW  - United States
KW  - Anomaly detection
KW  - transportation safety
KW  - data mining
KW  - model
KW  - Aviation safety
KW  - air transportation
KW  - arrival time
KW  - Brazil
KW  - Flight data analysis
KW  - Minneapolis
KW  - Minnesota
KW  - Sao Paulo [Brazil]
ER  - 

TY  - JOUR
TI  - Simultaneous Data Rate and Transmission Power Adaptation in V2V Communications: A Deep Reinforcement Learning Approach
AU  - Aznar-Poveda, J
AU  - Garcia-Sanchez, AJ
AU  - Egea-Lopez, E
AU  - Garcia-Haro, J
T2  - IEEE ACCESS
AB  - In Vehicle-to-Vehicle (V2V) communications, channel load is key to ensuring the appropriate operation of safety applications as well as driver-assistance systems. As the number of vehicles increases, so do their communication messages. Therefore, channel congestion may arise, negatively impacting channel performance. Through suitable adjustment of the data rate, this problem would be mitigated. However, this usually involves using different modulation schemes, which can jeopardize the robustness of the solution due to unfavorable channel conditions. To date, little effort has been made to adjust the data rate, alone or together with other parameters, and its effects on the aforementioned sensitive safety applications remain to be investigated. In this paper, we employ an analytical model which balances the data rate and transmission power in a non-cooperative scheme. In particular, we train a Deep Neural Network (DNN) to precisely optimize both parameters for each vehicle without using additional information from neighbors, and without requiring any additional infrastructure to be deployed on the road. The results obtained reveal that our approach, called NNDP, not only alleviates congestion, leaving a certain fraction of the channel available for emergency-related messages, but also provides enough transmission power to fulfill the application layer requirements at a given coverage distance. Finally, NNDP is thoroughly tested and evaluated in three realistic scenarios and under different channel conditions, demonstrating its robustness and excellent performance in comparison with other solutions found in the scientific literature.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3109422
VL  - 9
SP  - 122067
EP  - 122081
SN  - 2169-3536
AN  - WOS:000694693500001
ER  - 

TY  - JOUR
TI  - Prediction of Prednisolone Dose Correction Using Machine Learning
AU  - Sato, H
AU  - Kimura, Y
AU  - Ohba, M
AU  - Ara, Y
AU  - Wakabayashi, S
AU  - Watanabe, H
T2  - JOURNAL OF HEALTHCARE INFORMATICS RESEARCH
AB  - Wrong dose, a common prescription error, can cause serious patient harm, especially in the case of high-risk drugs like oral corticosteroids. This study aims to build a machine learning model to predict dose-related prescription modifications for oral prednisolone tablets (i.e., highly imbalanced data with very few positive cases). Prescription data were obtained from the electronic medical records at a single institute. Cluster analysis classified the clinical departments into six clusters with similar patterns of prednisolone prescription. Two patterns of training datasets were created with/without preprocessing by the SMOTE method. Five ML models (SVM, KNN, GB, RF, and BRF) and logistic regression (LR) models were constructed by Python. The model was internally validated by five-fold stratified cross-validation and was validated with a 30% holdout test dataset. Eighty-two thousand five hundred fifty-three prescribing data for prednisolone tablets containing 135 dose-corrected positive cases were obtained. In the original dataset (without SMOTE), only the BRF model showed a good performance (in test dataset, ROC-AUC:0.917, recall: 0.951). In the training dataset preprocessed by SMOTE, performance was improved on all models. The highest performance models with SMOTE were SVM (in test dataset, ROC-AUC: 0.820, recall: 0.659) and BRF (ROC-AUC: 0.814, recall: 0.634). Although the prescribing data for dose-related collection are highly imbalanced, various techniques such as the following have allowed us to build high-performance prediction models: data preprocessing by SMOTE, stratified cross-validation, and BRF classifier corresponding to imbalanced data. ML is useful in complicated dose audits such as oral prednisolone.
DA  - 2023/03//undefined
PY  - 2023
DO  - 10.1007/s41666-023-00128-3
VL  - 7
IS  - 1
SP  - 84
EP  - 103
SN  - 2509-4971
AN  - WOS:000936713000002
KW  - Machine learning
KW  - Support vector machines
KW  - Performance
KW  - Machine-learning
KW  - Classification (of information)
KW  - Forecasting
KW  - Machine learning models
KW  - Statistical tests
KW  - Drug safety
KW  - Medical computing
KW  - Python
KW  - Training dataset
KW  - Cluster analysis
KW  - Imbalanced data
KW  - Drug dosage
KW  - Cross validation
KW  - Dose correction
KW  - Prednisolone
KW  - Prescription error
KW  - Prescription errors
ER  - 

TY  - CONF
TI  - Predictive Analytics to Improve Road Safety
AU  - Gräler, B
AU  - Klatt, II
AU  - Pontius, M
AU  - Remke, A
AU  - IEEE
T2  - 2020 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER INFORMATION TECHNOLOGIES (ACIT)
AB  - Worldwide around 1.35 million people died in traffic accidents in 2016 and up to 50 million were injured [1]. While much research has already been conducted and accident prevention measures have been installed the emerge of new data and technologies in recent years has broadened the potential of in-depth research and traffic accident prediction. In this article, we present an overview about relevant data in the city of Bremen, Germany, and assess how these data can be used to understand and predict traffic risks.
DA  - 2020///
PY  - 2020
SP  - 362
EP  - 367
SN  - 978-1-7281-6760-2
AN  - WOS:000593848900078
KW  - machine learning
KW  - Accidents
KW  - big data
KW  - Accident prevention
KW  - Predictive analytics
KW  - Traffic control
KW  - Motor transportation
KW  - Risk assessment
KW  - road safety
KW  - accident
KW  - Road safety
KW  - Accident prediction
KW  - Bremen , Germany
KW  - predictive policing
ER  - 

TY  - CONF
TI  - 3rd International Workshop on Underpinnings for Safe Distributed AI
AU  - Van Tooren, M
AU  - Larsen, M
AU  - Reti, D
T2  - COMPUTER SAFETY, RELIABILITY, AND SECURITY, SAFECOMP 2022 WORKSHOPS
A2  - Trapp, M
A2  - Schoitsch, E
A2  - Guiochet, J
A2  - Bitsch, F
DA  - 2022///
PY  - 2022
VL  - 13415
SP  - 232
EP  - 234
SN  - 0302-9743
AN  - WOS:000866543800021
ER  - 

TY  - JOUR
TI  - Transformer-Based User Alignment Model across Social Networks
AU  - Lei, TL
AU  - Ji, LX
AU  - Wang, GR
AU  - Liu, SX
AU  - Wu, L
AU  - Pan, F
T2  - ELECTRONICS
AB  - Cross-social network user identification refers to finding users with the same identity in multiple social networks, which is widely used in the cross-network recommendation, link prediction, personality recommendation, and data mining. At present, the traditional method is to obtain network structure information from neighboring nodes through graph convolution, and embed social networks into the low-dimensional vector space. However, as the network depth increases, the effect of the model will decrease. Therefore, in order to better obtain the network embedding representation, a Transformer-based user alignment model (TUAM) across social networks is proposed. This model converts the node information and network structure information from the graph data form into sequence data through a specific encoding method. Then, it inputs the data to the proposed model to learn the low-dimensional vector representation of the user. Finally, it maps the two social networks to the same feature space for alignment. Experiments on real datasets show that compared with GAT, TUAM improved ACC@10 indicators by 11.61% and 16.53% on Facebook-Twitter and Weibo-Douban datasets, respectively. This illustrates that the proposed model has a better performance compared to other user alignment models.
DA  - 2023/04//undefined
PY  - 2023
DO  - 10.3390/electronics12071686
VL  - 12
IS  - 7
SN  - 2079-9292
AN  - WOS:000983331100001
KW  - machine learning
KW  - data mining
KW  - cross-social networks
KW  - user alignment
ER  - 

TY  - JOUR
TI  - An interpretable machine learning approach for evaluating the feature importance affecting lost workdays at construction sites
AU  - Kang, KS
AU  - Koo, C
AU  - Ryu, HG
T2  - JOURNAL OF BUILDING ENGINEERING
AB  - This study investigates the intensity of accidents by considering the lost workdays based on real data and derived the feature importance quantitatively. Occupational injuries lead to lost workdays for construction workers. The term "lost workdays " refers to a period in which workers cannot perform regular jobs because of severe physical or mental damage from occupational injuries. Many studies focusing on type analysis, accident prediction, and risk management of construction accidents, combined with the intensity and frequency of accidents, have been conducted to prevent and minimize accidents. However, the existing method for measuring the intensity of occupational accidents/injuries is a qualitative method that reflects experts' opinions, mainly using brainstorming, the Delphi method, and the analytic hierarchy process. Thus, we propose a framework that combines traditional analysis and interpretable machine learning approaches. The random forest model was trained with 11,223 injured worker samples, feature importance and frequency analysis with the chi-squared test, and local interpretable model agnostic data. According to the results of this study, optimal safety management is possible if appropriate resources are allocated. If the risk of accidents is measured with objective and quantitative data, the prevention and analysis of accidents can be more reliable, and resources can be more efficiently allocated.
DA  - 2022/08/01/
PY  - 2022
DO  - 10.1016/j.jobe.2022.104534
VL  - 53
SN  - 2352-7102
AN  - WOS:000797957100002
KW  - Decision trees
KW  - Machine learning
KW  - Risk management
KW  - Accidents
KW  - Data analysis
KW  - Interpretable machine learning
KW  - Risk assessment
KW  - Machine learning approaches
KW  - Occupational risks
KW  - Workers'
KW  - Construction safety
KW  - Construction workers
KW  - Construction sites
KW  - Accident risks
KW  - Lose workday
KW  - Lost workdays
KW  - Occupational injury
KW  - Type analysis
ER  - 

TY  - CONF
TI  - The Need of Standardised Metadata to Encode Causal Relationships: Towards Safer Data-Driven Machine Learning Biological Solutions
AU  - Cruz, BGS
AU  - Vega, C
AU  - Hertel, F
T2  - COMPUTATIONAL INTELLIGENCE METHODS FOR BIOINFORMATICS AND BIOSTATISTICS, CIBB 2021
A2  - Chicco, D
A2  - Facchiano, A
A2  - Tavazzi, E
A2  - Longato, E
A2  - Vettoretti, M
A2  - Bernasconi, A
A2  - Avesani, S
A2  - Cazzaniga, P
AB  - In this paper, we discuss the importance of considering causal relations in the development of machine learning solutions to prevent factors hampering the robustness and generalisation capacity of the models, such as induced biases. This issue often arises when the algorithm decision is affected by confounding factors. In this work, we argue that the integration of research assumptions as causal relationships can help identify potential confounders. Together with metadata information, it can enable meta-comparison of data acquisition pipelines. We call for standardised meta-information practices as a crucial step for proper machine learning solutions development, validation, and data sharing. Such practices include detailing the data acquisition process, aiming for automatic integration of causal relationships and actionable metadata.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20837-9_16
VL  - 13483
SP  - 200
EP  - 216
SN  - 0302-9743
AN  - WOS:000895973300016
KW  - Machine learning
KW  - Causality
KW  - Machine-learning
KW  - Data acquisition
KW  - Metadata
KW  - Data driven
KW  - Confounder
KW  - Systems biology
KW  - Generalization capacity
KW  - Biological solutions
KW  - Causal relations
KW  - Causal relationships
KW  - Confounders
KW  - Metadata information
ER  - 

TY  - JOUR
TI  - Differentially Private XGBoost Algorithm for Traceability of Rice Varieties
AU  - Yu, RZ
AU  - Yang, W
AU  - Yang, CY
T2  - APPLIED SCIENCES-BASEL
AB  - Privacy protection in agricultural traceability has received more and more attention. Most of the existing methods only protect the original data information from the perspective of cryptography and ignore the availability of the protected information. In fact, after data is processed by cryptography, blockchain, and other technologies, it cannot be directly used for machine learning model training. Therefore, differential privacy has great potential value for privacy protection in agricultural traceability, which can enable data to participate in classification tasks under privacy protection. In this paper, we propose an integrated algorithm for agricultural traceability called Differentially Private XGBoost (DP-XGB), which can protect the privacy of the original data during the training process and obtain high model utility under the condition of a small sample size. We inject Gaussian noise into the gradient operator and Hesse operator of the original XGBoost and give the calculation method of the resulting privacy budget. Experiments show that our method can effectively obtain differential privacy guarantees and achieves very high classification accuracy when the noise is small.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.3390/app122111037
VL  - 12
IS  - 21
SN  - 2076-3417
AN  - WOS:000880944300001
KW  - machine learning
KW  - differential privacy
KW  - rice data safety
KW  - variety traceability
ER  - 

TY  - JOUR
TI  - Comparing AI cardiovascular safety data: Trial comparators and outcomes
AU  - Monnier, A
T2  - ANNALS OF ONCOLOGY
DA  - 2006///
PY  - 2006
VL  - 17
SP  - 100
EP  - 100
SN  - 0923-7534
AN  - WOS:000248078900277
ER  - 

TY  - JOUR
TI  - Safe batch constrained deep reinforcement learning with generative adversarial network
AU  - Dong, WB
AU  - Liu, SF
AU  - Sun, SL
T2  - INFORMATION SCIENCES
AB  - Batch-constrained reinforcement learning constrains the learned policy to be close to the behavior policy, which holds a tremendous promise for alleviating the distributional shift in offline reinforcement learning. Existing batch-constrained techniques rely on perturbation models to adjust the actions generated from the generative model to maximize the estimated value function. However, the perturbation model deviates from the distribution of the offline datasets and introduces a new distribution drift problem, which affects the performance of the learned policies. In addition, since offline reinforcement learning cannot learn by trial and error, the final policies are often prone to failure in reality or make unsafe decisions when trained with a noisy or small size dataset. To address the above issues, this paper employs constrained generative adversarial network to generate actions with given states. Specifically, we train the generator to maximize the estimated value and constrain the state-action pairs to follow the dataset distribution. The perturbation model is trained to maximize the probability of the perturbed actions belonging to the dataset and minimize the likelihood of taking dangerous actions. Moreover, we utilize safety critics to predict the risk of the actions under a state. Experimental results show that the proposed method is effective and can choose safe actions while maintaining a high performance in offline settings.
DA  - 2023/07//undefined
PY  - 2023
DO  - 10.1016/j.ins.2023.03.108
VL  - 634
SP  - 259
EP  - 270
SN  - 0020-0255
AN  - WOS:000962845200001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Performance
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Safety engineering
KW  - Offline
KW  - Perturbation techniques
KW  - Generative adversarial networks
KW  - Generative model
KW  - Batch-constrained technique
KW  - Batch-constrained techniques
KW  - Behavior policy
KW  - Distributional shift
KW  - Generative adversarial network
KW  - Perturbation model
KW  - Safety critic
KW  - Safety critics
ER  - 

TY  - JOUR
TI  - An investigation of information alignment and collaboration as complements to supply chain agility in humanitarian supply chain
AU  - Dubey, R
AU  - Bryde, DJ
AU  - Foropon, C
AU  - Tiwari, M
AU  - Dwivedi, Y
AU  - Schiffling, S
T2  - INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH
AB  - Our study examines the relationship between information alignment (IA), collaboration (CO) and supply chain agility (SCAG) under the moderating effects of artificial intelligence-driven big data analytics capability (AI-BDAC) and intergroup leadership (IGL). We have grounded our theoretical model in the resource-based view (RBV) and contingency theory and further tested our research hypotheses using multi-informant data collected using a web-based pre-tested instrument from 613 individuals working in 193 humanitarian organisations drawn from 24 countries located on various continents across the globe. We tested our research hypotheses using variance-based structural equation modelling (PLS-SEM). Our study offers interesting results which help to advance the theoretical debates surrounding technology-driven supply chain agility in the context of humanitarian settings. We further provide some directions to managers engaged in disaster relief operations, who are contemplating using emerging technologies to enhance collaboration and supply chain agility. Finally, we have outlined the limitations of our study and offer some future research directions.
DA  - 2021/03/04/
PY  - 2021
DO  - 10.1080/00207543.2020.1865583
VL  - 59
IS  - 5
SP  - 1586
EP  - 1605
SN  - 0020-7543
AN  - WOS:000603859900001
ER  - 

TY  - JOUR
TI  - Reinforcement learning approach for coordinated passenger inflow control of urban rail transit in peak hours
AU  - Jiang, ZB
AU  - Fan, W
AU  - Liu, W
AU  - Zhu, BQ
AU  - Gu, JJ
T2  - TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES
AB  - In peak hours, when the limited transportation capacity of urban rail transit is not adequate enough to meet the travel demands, the density of the passengers waiting at the platform can exceed the critical density of the platform. Coordinated passenger inflow control strategy is required to adjust/meter the inflow volume and relieve some of the demand pressure at crowded metro stations so as to ensure both operational efficiency and safety at such stations for all passengers. However, such strategy is usually developed by the operation staff at each station based on their practical working experience. As such, the best strategy/decision cannot always be made and sometimes can even be highly undesirable due to their inability to account for the dynamic performance of all metro stations in the entire rail transit network. In this paper, a new reinforcement learning-based method is developed to optimize the inflow volume during a certain period of time at each station with the aim of minimizing the safety risks imposed on passengers at the metro stations. Basic principles and fundamental components of the reinforcement learning, as well as the reinforcement learning-based problem-specific algorithm are presented. The simulation experiment carried out on a real-world metro line in Shanghai is constructed to test the performance of the approach. Simulation results show that the reinforcement learning based inflow volume control strategy is highly effective in minimizing the safety risks by reducing the frequency of passengers being stranded. Additionally, the strategy also helps to relieve the passenger congestion at certain stations.
DA  - 2018/03//undefined
PY  - 2018
DO  - 10.1016/j.trc.2018.01.008
VL  - 88
SP  - 1
EP  - 16
SN  - 0968-090X
AN  - WOS:000428494000001
KW  - Reinforcement learning
KW  - algorithm
KW  - China
KW  - learning
KW  - Coordinated passenger inflow control
KW  - Inflow control
KW  - Light rail transit
KW  - Operation safety
KW  - Operational efficiencies
KW  - Problem-specific algorithms
KW  - railway
KW  - Reinforcement learning approach
KW  - Shanghai
KW  - strategic approach
KW  - Subway stations
KW  - Train capacity
KW  - Transportation capacity
KW  - transportation safety
KW  - travel demand
KW  - urban area
KW  - Urban rail transit
KW  - Urban transportation
ER  - 

TY  - JOUR
TI  - Predicting unsafe driving risk among commercial truck drivers using machine learning: Lessons learned from the surveillance of 20 million driving miles
AU  - Mehdizadeh, A
AU  - Yazdi, MAA
AU  - Cai, M
AU  - Hu, Q
AU  - Vinel, A
AU  - Rigdon, SE
AU  - Davis, K
AU  - Megahed, FM
T2  - ACCIDENT ANALYSIS AND PREVENTION
AB  - The emergence of sensor-based Internet of Things (IoT) monitoring technologies have paved the way for conducting large-scale naturalistic driving studies, where continuous kinematic driver-based data are generated, capturing crash/near-crash safety critical events (SCEs) and their precursors. However, it is unknown whether the SCEs risk can be predicted to inform driver decisions in the medium term (e.g., hours ahead) since the literature has focused on SCE predictions either for a given road segment or for automated breaking applications, i.e., immediately before the event. In this paper, we examine the SCE data generated from 20+ million miles driven by 496 commercial truck drivers to address three main questions. First, whether SCEs can be predicted using disparate driving-related data sources. Second, if so, what the relative importance of the different predictors examined is. Third, whether the prediction models can be generalized to new drivers and future time periods. We show that SCEs can be predicted 30 min in advance, using machine learning techniques and dependent variables capturing the driver's characteristics, weather conditions, and day/time categories, where an area under the curve (AUC) up to 76% can be achieved. Moreover, the predictive performance remains relatively stable when tested on new (i.e., not in the training set) drivers and a future two-month time period. Our results can inform dispatching and routing applications, and lead to the development of technological interventions to improve driver safety.
DA  - 2021/09//undefined
PY  - 2021
DO  - 10.1016/j.aap.2021.106285
VL  - 159
SN  - 0001-4575
AN  - WOS:000691794200009
ER  - 

TY  - JOUR
TI  - Artificial Intelligence and Liability for its Work
AU  - Laptev, VA
T2  - PRAVO-ZHURNAL VYSSHEI SHKOLY EKONOMIKI
AB  - Industrial revolution transformed idea of ways and means of production. Introducing robots in the real sector of economy became inevitable process. Degree impact of the person on production cycle decreases gradually and replaced by programs determining behavior of robots and a mentality of artificial intelligence by digital algorithms. Primary researches of artificial intelligence have found reflections in works of software engineers. The legal treatment of the nature of artificial intelligence and a regulation of his use became the big task for domestic jurists. The analysis of possible approaches to disclosure of the concept "artificial intelligence" as legal category and his ratio with the concepts of robot and cyberphysical system is provided in the article. Issues of liability for work of artificial intelligence are revealed. The possibility of recognition for the robot (car) with artificial intelligence, status of a legal entity is studied. The possibility of recognition of legal personality of artificial intelligence in cyberphysical space is separately considered. Work purpose is to offer ways of development of the legislation in the conditions of digitalization of Russian economy and introduction of artificial intelligence. Methods of analysis, synthesis, generalization, induction and deduction, interpretation, classification and comparative methods were used. The research will allow to improve legal regulation of artificial intelligence in economy. Author's look to disclosure of categories of artificial intelligence, intellectual systems and robot from a position of Russian law is offered. Mechanisms of attraction to legal responsibility of appropriate subjects of the right are defined. Author allocates three stages: short-term, medium-term and long-term temporary prospects of development of the legislation defining legal capacity of the robot and artificial intelligence in cyberphysical space, the maintenance of the cyberphysical relations and also the bases of attraction to legal responsibility of participants of the considered relations. Legal regulation of economic activity with use of artificial intelligence has to be based on the principle of convergence of technology and rules of law.
DA  - 2019///
PY  - 2019
DO  - 10.17323/2072-8166.2019.2.79.102
IS  - 2
SP  - 79
EP  - 102
SN  - 2072-8166
AN  - WOS:000472957800004
ER  - 

TY  - JOUR
TI  - Anomaly Detection of UAV State Data Based on Single-Class Triangular Global Alignment Kernel Extreme Learning Machine
AU  - Hu, FS
AU  - Wang, Q
AU  - Shao, HJ
AU  - Gao, S
AU  - Yu, HL
T2  - CMES-COMPUTER MODELING IN ENGINEERING & SCIENCES
AB  - Unmanned Aerial Vehicles (UAVs) are widely used and meet many demands in military and civilian fields. With the continuous enrichment and extensive expansion of application scenarios, the safety of UAVs is constantly being challenged. To address this challenge, we propose algorithms to detect anomalous data collected from drones to improve drone safety. We deployed a one-class kernel extreme learning machine (OCKELM) to detect anomalies in drone data. By default, OCKELM uses the radial basis (RBF) kernel function as the kernel function of the model. To improve the performance of OCKELM, we choose a Triangular Global Alignment Kernel (TGAK) instead of an RBF Kernel and introduce the Fast Independent Component Analysis (FastICA) algorithm to reconstruct UAV data. Based on the above improvements, we create a novel anomaly detection strategy FastICA-TGAK-OCELM. The method is finally validated on the UCI dataset and detected on the Aeronautical Laboratory Failures and Anomalies (ALFA) dataset. The experimental results show that compared with other methods, the accuracy of this method is improved by more than 30%, and point anomalies are effectively detected.
DA  - 2023///
PY  - 2023
DO  - 10.32604/cmes.2023.026732
VL  - 136
IS  - 3
SP  - 2405
EP  - 2424
SN  - 1526-1492
AN  - WOS:000960786100001
KW  - Machine learning
KW  - Vehicle safety
KW  - Anomaly detection
KW  - Vehicle state
KW  - Knowledge acquisition
KW  - Learning machines
KW  - Principal component analysis
KW  - Antennas
KW  - Radial basis function networks
KW  - Drones
KW  - Aerial vehicle
KW  - Alignment
KW  - Aircraft detection
KW  - Global alignment
KW  - Laboratories
KW  - fast independent component analysis
KW  - Fast independent component analysis
KW  - Independent component analysis
KW  - kernel extreme learning machine
KW  - Kernel extreme learning machine
KW  - triangular global alignment kernel
KW  - Triangular global alignment kernel
KW  - UAV safety
KW  - Unmanned aerial vehicle safety
ER  - 

TY  - CONF
TI  - Citizen security using Machine Learning algorithms through Open Data
AU  - Rocca, GB
AU  - Castillo-Cara, M
AU  - Lévano, RA
AU  - Herrera, JV
AU  - Orozco-Barbosa, L
AU  - IEEE
T2  - 2016 8TH IEEE LATIN-AMERICAN CONFERENCE ON COMMUNICATIONS (LATINCOM)
AB  - The following work is an application proposal based on machine learning algorithms for a possible solution for the public safety problem in a South American city. The aim of this application is to reduce the threat risk of the physical integrity of pedestrians by geolocating, in real-time, safer places to walk. In this context for a city, San Isidro, a business district of Lima, has been established as study case. The district has been divided into map sectors and subsectors, so that by using the GPS location service integrated in mobile devices, it is possible to identify areas that have the highest incidence of different types of incidents. This functionality will allow users to choose safer routes by taking into account the information provided for each sector. The data used in this application has been obtained from an Open Data platform managed by the San Isidro municipality. In this application, we have processed the data enabling the easy and friendly access to the information by the end user.
The importance of this work is how we have used the machine learning algorithm for incident rates in real and future time, trying to make predictions that can not only provide safe routes to users, but also predict disasters and allow public authorities to act in advance, thus minimizing the impact of future incidents.
DA  - 2016///
PY  - 2016
SN  - 2330-989X
AN  - WOS:000405491400007
KW  - Artificial intelligence
KW  - Machine learning
KW  - Data mining
KW  - Learning systems
KW  - Data analytics
KW  - Smart city
KW  - Learning algorithms
KW  - Android
KW  - Smart City
KW  - Open Data
KW  - citizen security
KW  - Open datum
KW  - safe routes
ER  - 

TY  - JOUR
TI  - Deep Spatio-Temporal Neural Networks for Risk Prediction and Decision Support in Aviation Operations
AU  - Lee, H
AU  - Puranik, TG
AU  - Mavris, DN
T2  - JOURNAL OF COMPUTING AND INFORMATION SCIENCE IN ENGINEERING
AB  - The maintenance and improvement of safety are among the most critical concerns in civil aviation operations. Due to the increased availability of data and improvements in computing power, applying artificial intelligence technologies to reduce risk in aviation safety has gained momentum. In this paper, a framework is developed to build a predictive model of future aircraft trajectory that can be utilized online to assist air crews in their decision-making during approach. Flight data parameters from the approach phase between certain approach altitudes (also called gates) are utilized for training an offline model that predicts the aircraft's ground speed at future points. This model is developed by combining convolutional neural networks (CNNs) and long short-term memory (LSTM) layers. Due to the myriad of model combinations possible, hyperband algorithm is used to automate the hyperparameter tuning process to choose the best possible model. The validated offline model can then be used to predict the aircraft's future states and provide decision-support to air crews. The method is demonstrated using publicly available Flight Operations Quality Assurance (FOQA) data from the National Aeronautics and Space Administration (NASA). The developed model can predict the ground speed at an accuracy between 1.27% and 2.69% relative root-mean-square error. A safety score is also evaluated considering the upper and lower bounds of variation observed within the available data set. Thus, the developed model represents an improved performance over existing techniques in literature and shows significant promise for decision-support in aviation operations.
DA  - 2021/08/01/
PY  - 2021
DO  - 10.1115/1.4049992
VL  - 21
IS  - 4
SN  - 1530-9827
AN  - WOS:000671876500010
KW  - Deep neural networks
KW  - Convolutional neural networks
KW  - Predictive modeling
KW  - Predictive analytics
KW  - Forecasting
KW  - Decision support systems
KW  - Safety engineering
KW  - Long short-term memory
KW  - Artificial intelligence technologies
KW  - Safety assessment
KW  - NASA
KW  - Aircraft trajectory
KW  - Aviation
KW  - Training aircraft
KW  - Mean square error
KW  - Root mean square errors
KW  - Multilayer neural networks
KW  - Data-driven engineering
KW  - Quality assurance
KW  - Machine learning for engineering applications
KW  - Public administration
KW  - Aviation operations
KW  - Big data and analytics
KW  - Flight operations quality assurances
KW  - Model combination
KW  - Upper and lower bounds
ER  - 

TY  - JOUR
TI  - Towards Context-Aware Facial Emotion Reaction Database for Dyadic Interaction Settings
AU  - Sham, AH
AU  - Khan, A
AU  - Lamas, D
AU  - Tikka, P
AU  - Anbarjafari, G
T2  - SENSORS
AB  - Emotion recognition is a significant issue in many sectors that use human emotion reactions as communication for marketing, technological equipment, or human-robot interaction. The realistic facial behavior of social robots and artificial agents is still a challenge, limiting their emotional credibility in dyadic face-to-face situations with humans. One obstacle is the lack of appropriate training data on how humans typically interact in such settings. This article focused on collecting the facial behavior of 60 participants to create a new type of dyadic emotion reaction database. For this purpose, we propose a methodology that automatically captures the facial expressions of participants via webcam while they are engaged with other people (facial videos) in emotionally primed contexts. The data were then analyzed using three different Facial Expression Analysis (FEA) tools: iMotions, the Mini-Xception model, and the Py-Feat FEA toolkit. Although the emotion reactions were reported as genuine, the comparative analysis between the aforementioned models could not agree with a single emotion reaction prediction. Based on this result, a more-robust and -effective model for emotion reaction prediction is needed. The relevance of this work for human-computer interaction studies lies in its novel approach to developing adaptive behaviors for synthetic human-like beings (virtual or robotic), allowing them to simulate human facial interaction behavior in contextually varying dyadic situations with humans. This article should be useful for researchers using human emotion analysis while deciding on a suitable methodology to collect facial expression reactions in a dyadic setting.
DA  - 2023/01//undefined
PY  - 2023
DO  - 10.3390/s23010458
VL  - 23
IS  - 1
SN  - 1424-8220
AN  - WOS:000909739200001
ER  - 

TY  - JOUR
TI  - Exploring Consumers' Attitudes towards Food Products Derived by New Plant Breeding Techniques
AU  - Vindigni, G
AU  - Peri, I
AU  - Consentino, F
AU  - Selvaggi, R
AU  - Spina, D
T2  - SUSTAINABILITY
AB  - New plant breeding techniques (NPBTs) are seen as promising and innovative tools to achieve food security and food safety. Biotechnological innovations have great potential to address sustainable food development, and they are expected in the near future to play a critical role in feeding a growing population without exerting added pressure on the environment. There is, however, a considerable debate as to how these new techniques should be regulated and whether some or all of them should fall within the scope of EU legislation on genetically modified organisms (GMOs), despite the product obtained being free from genes foreign to the species. In the EU, the adoption of these methods does not rely only on the scientific community but requires social acceptance and a political process that leads to an improved regulatory framework. In this paper, we present the results of an online survey carried out in Italy with 700 randomly selected participants on consumer attitudes towards food obtained by NPBTs. By applying the decision tree machine learning algorithm J48 to our dataset, we identified significant attributes to predict the main drivers of purchasing such products. A classification model accuracy assessment has also been developed to evaluate the overall performance of the classifier. The result of the model highlighted the role of consumers' self-perceived knowledge and their trust in the European approval process for NPBT, as well as the need for a detailed label. Our findings may support decision makers and underpin the development of NPBT products in the market.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.3390/su14105995
VL  - 14
IS  - 10
SN  - 2071-1050
AN  - WOS:000804869800001
KW  - machine learning
KW  - public attitude
KW  - data mining
KW  - accuracy assessment
KW  - food safety
KW  - Italy
KW  - food security
KW  - agricultural biotechnology
KW  - biotechnology
KW  - consumers’ attitude
KW  - new plant breeding technique
KW  - NPBT
KW  - plant breeding
KW  - political process
ER  - 

TY  - JOUR
TI  - Evaluating navigational risk of port approach manoeuvrings with expert assessments and machine learning
AU  - Ozturk, U
AU  - Birbil, SI
AU  - Cicek, K
T2  - OCEAN ENGINEERING
AB  - Various methods have been proposed to assess the navigational collision risk of maritime transportation in open sea and restricted waterways. However, there is a gap in the literature concerning an effective method that studies the same risk in port approach manoeuvrings. In this study, we fill this gap with a method stemming from two proposals: First, we present three new parameters (distance, area and speed) to improve the navigational collision risk models applied in port basins. Second, we propose a novel methodology based on machine learning and fuzzy inference to assess the risk of collision in port approach. To support our discussion, we conduct ship-handling simulation experiments with 20 expert pilots and compile a large dataset. Furthermore, we test our methodology in a port approach manoeuvring scenario. Overall, our simulation results show that the proposed method is adequate for weighing both the severity of the port approach manoeuvrings and the relative importance of the involved parameters.
DA  - 2019/11/15/
PY  - 2019
DO  - 10.1016/j.oceaneng.2019.106558
VL  - 192
SN  - 0029-8018
AN  - WOS:000501655100027
KW  - machine learning
KW  - Machine learning
KW  - Data analysis
KW  - Learning systems
KW  - Navigation
KW  - Risk assessment
KW  - Air navigation
KW  - transportation safety
KW  - Data reduction
KW  - Collision risks
KW  - navigation
KW  - Large dataset
KW  - Fuzzy inference
KW  - data set
KW  - Maritime safety
KW  - assessment method
KW  - Novel methodology
KW  - port operation
KW  - maritime transportation
KW  - collision
KW  - Collision risk evaluation
KW  - Expert assessment
KW  - Maritime transportation
KW  - Navigation risk parameters
KW  - Port approach manoeuvring
KW  - Restricted waterway
KW  - Risk parameter
KW  - Waterway transportation
ER  - 

TY  - JOUR
TI  - Social Coordination and Altruism in Autonomous Driving
AU  - Toghi, B
AU  - Valiente, R
AU  - Sadigh, D
AU  - Pedarsani, R
AU  - Fallah, YP
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Despite the advances in the autonomous driving domain, autonomous vehicles (AVs) are still inefficient and limited in terms of cooperating with each other or coordinating with vehicles operated by humans. A group of autonomous and human-driven vehicles (HVs) which work together to optimize an altruistic social utility can co-exist seamlessly and assure safety and efficiency on the road. Achieving this mission without explicit coordination among agents is challenging, mainly due to the difficulty of predicting the behavior of humans with heterogeneous preferences in mixed-autonomy environments. Formally, we model an AV's maneuver planning in mixed-autonomy traffic as a partially-observable stochastic game and attempt to derive optimal policies that lead to socially-desirable outcomes using a multi-agent reinforcement learning framework (MARL), and propose a semi-sequential multi-agent training and policy dissemination algorithm for our MARL problem. We introduce a quantitative representation of the AVs' social preferences and design a distributed reward structure that induces altruism into their decision-making process. Altruistic AVs are able to form alliances, guide the traffic, and affect the behavior of the HVs to handle competitive driving scenarios. We compare egoistic AVs to our altruistic autonomous agents in a highway merging setting and demonstrate the emerging behaviors that lead to improvement in the number of successful merges and the overall traffic flow and safety.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1109/TITS.2022.3207872
VL  - 23
IS  - 12
SP  - 24791
EP  - 24804
SN  - 1524-9050
AN  - WOS:000862374500001
ER  - 

TY  - JOUR
TI  - Generalized adaptive intelligent binning of multiway data
AU  - Worley, B
AU  - Powers, R
T2  - CHEMOMETRICS AND INTELLIGENT LABORATORY SYSTEMS
AB  - NMR metabolic fingerprinting methods almost exclusively rely upon the use of one-dimensional (1D) H-1 NMR data to gain insights into chemical differences between two or more experimental classes. While 1D H-1 NMR spectroscopy is a powerful, highly informative technique that can rapidly and nondestructively report details of complex metabolite mixtures, it suffers from significant signal overlap that hinders interpretation and quantification of individual analytes. Two-dimensional (2D) NMR methods that report heteronuclear connectivities can reduce spectral overlap, but their use in metabolic fingerprinting studies is limited. We describe a generalization of Adaptive Intelligent binning that enables its use on multidimensional datasets, allowing the direct use of nD NMR spectroscopic data in bilinear factorizations such as principal component analysis (PCA) and partial least squares (PLS). (C) 2015 Elsevier BY. All rights reserved.
DA  - 2015/08/15/
PY  - 2015
DO  - 10.1016/j.chemolab.2015.05.005
VL  - 146
SP  - 42
EP  - 46
SN  - 0169-7439
AN  - WOS:000360595100005
ER  - 

TY  - JOUR
TI  - A Virtual Reality Platform for Safety Training in Coal Mines with AI and Cloud Computing
AU  - Li, M
AU  - Sun, ZM
AU  - Jiang, Z
AU  - Tan, Z
AU  - Chen, JC
T2  - DISCRETE DYNAMICS IN NATURE AND SOCIETY
AB  - Coal mining, regarded as a high-risk industry, has a strong demand for virtual reality (VR) to fulfill safety and emergency rescue training. In the past ten years, VR technology has significantly improved miner training on both the hardware and software side. However, it still has some drawbacks, such as expensive and unsuitable hardware, lack of satisfactory user experience, without direct browser access, and lack of humanized and intelligent design. To solve these problems, a cloud-based VR system is designed for the training of coal miners in this paper. The system, with browser/client architecture, includes eight modules demonstrating the full procedure of an underground coal mine. The online cloud-rendered video streaming is adopted to provide enough computing and rendering power and hence a better browser-based user experience. Furthermore, game artificial intelligence (AI) is also introduced into the system to increase the emotional exchange between the system and users. Unlike traditional VR training software, this system designs two virtual miners to enhance the experience of trainees. The first virtual miner is a task-oriented non-player-character (NPC) which conveys general knowledge about the mine and guides the users in visiting the underground work sites. The second virtual miner is a disaster-oriented character which prepares the users for typical disasters. The system has been successfully implemented in a laboratory environment, and its performance has been validated. Yet, further practices are needed to stimulate more innovative applications of VR-based miner training and disaster drilling.
DA  - 2020/10/23/
PY  - 2020
DO  - 10.1155/2020/6243085
VL  - 2020
SN  - 1026-0226
AN  - WOS:000590994900003
ER  - 

TY  - JOUR
TI  - Construction safety management in the data-rich era: A hybrid review based upon three perspectives of nature of dataset, machine learning approach, and research topic
AU  - Zhou, ZP
AU  - Wei, LX
AU  - Yuan, JF
AU  - Cui, JQ
AU  - Zhang, ZY
AU  - Zhuo, W
AU  - Lin, D
T2  - ADVANCED ENGINEERING INFORMATICS
AB  - Although substantial progress in safety management performance has been made in the construction industry, continuing fatalities and injuries at workplaces hinder sustainable development of this labor-intensive industry. Many machine learning approaches using different types of data such as text, image, video, and audio were adopted for safety risk analysis at construction sites. Our paper aimed to implement a hybrid review of construction safety research based upon machine learning. This hybrid review focused on various attributes from three perspectives: Nature of dataset, machine learning approach, and research topic. After the review of individual attributes, intra-relationships between attributes in each perspective and inter-relationships between attributes across the three perspectives were determined. According to risk recognition, risk prediction, and risk control, feasible research paths were developed from both intra-relationships and inter-relationships between multiple attributes for reference in future studies. Finally, gaps and opportunities were discussed in detail for research agendas on this subject. This hybrid review contributes to outlining the framework of construction safety management based upon machine learning. It is able to provide new entrants with a systematic idea of promising research trends for the future. Research findings are helpful for academia and industry to fill in the gaps between study and practice in the area of construction safety, in order to assist in sustainable development of the construction industry by use of machine learning.
DA  - 2023/10//undefined
PY  - 2023
DO  - 10.1016/j.aei.2023.102144
VL  - 58
SN  - 1474-0346
AN  - WOS:001063111000001
KW  - Deep learning
KW  - Machine learning
KW  - Learning systems
KW  - Accident prevention
KW  - Machine-learning
KW  - Risk assessment
KW  - Machine learning approaches
KW  - Safety management
KW  - Sustainable development
KW  - Construction safety
KW  - Construction industry
KW  - Risk analysis
KW  - Safety risks
KW  - Machine learning research
KW  - Research topics
KW  - Hybrid review
KW  - Safety risk analyse
KW  - Safety risk analysis
ER  - 

TY  - JOUR
TI  - Towards a Convolutional Neural Network model for classifying regional ship collision risk levels for waterway risk analysis
AU  - Zhang, WB
AU  - Feng, XY
AU  - Goerlandt, F
AU  - Liu, Q
T2  - RELIABILITY ENGINEERING & SYSTEM SAFETY
AB  - Estimating the navigational risk of vessels operating in sea and waterway areas is important for waterway risk management and pollution preparedness and response planning. Existing methods relying on a model-informed expert judgment of ship-ship collision risk are of limited practical use because periodic risk monitoring is feasible only when this can be done without extensive use of organizational resources. To alleviate such limitations, this article presents a new approach based Convolutional Neural Networks (CNNs) and image recognition to interpret and classify ship-ship collision risks in encounter scenarios. The specific aim of the article is to investigate whether a CNN-based model can quickly and accurately interpret images constructed based on data from the Automatic Identification System (AIS) in terms of collision risk. To test this, estimates derived from training data are compared to validation data. It is also investigated whether adding additional navigational information based on AIS data improves the model's predictive accuracy. A case study with data from the Baltic Sea area is implemented, where various model design alternatives are tested as a proof-of-concept. The main finding of this work is that a CNN-based approach can indeed meet the specified design requirements, suggesting that this is a fruitful direction for future work. Several issues requiring further research and developed are discussed, with the validity of the risk ratings underlying the image classification seen as the most significant conceptual challenge before a CNN-model can be put to practical use.
DA  - 2020/12//undefined
PY  - 2020
DO  - 10.1016/j.ress.2020.107127
VL  - 204
SN  - 0951-8320
AN  - WOS:000583913400015
KW  - Machine learning
KW  - Risk management
KW  - Image recognition
KW  - Convolutional neural networks
KW  - Convolutional Neural Network
KW  - Risk perception
KW  - Convolution
KW  - Risk assessment
KW  - Proof of concept
KW  - Collision risks
KW  - Ships
KW  - Risk analysis
KW  - Predictive accuracy
KW  - Maritime Safety
KW  - Water pollution
KW  - Pollution control
KW  - AIS data
KW  - Automatic identification system
KW  - Automatic identification
KW  - Expert judgment
KW  - Navigational information
KW  - Preparedness and response
KW  - Ship-ship collision
KW  - Validation data
ER  - 

TY  - JOUR
TI  - Development and validation of a machine learning-based detection system to improve precision screening for medication errors in the neonatal intensive care unit
AU  - Yalçin, N
AU  - Kasikci, M
AU  - Çelik, HT
AU  - Allegaert, K
AU  - Demirkan, K
AU  - Yigit, S
AU  - Yurdakök, M
T2  - FRONTIERS IN PHARMACOLOGY
AB  - Aim: To develop models that predict the presence of medication errors (MEs) (prescription, preparation, administration, and monitoring) using machine learning in NICU patients.Design: Prospective, observational cohort study randomized with machine learning (ML) algorithms.Setting: A 22-bed capacity NICU in Ankara, Turkey, between February 2020 and July 2021.Results: A total of 11,908 medication orders (28.9 orders/patient) for 412 NICU patients (5.53 drugs/patient/day) who received 2,280 prescriptions over 32,925 patient days were analyzed. At least one physician-related ME and nurse-related ME were found in 174 (42.2%) and 235 (57.0%) of the patients, respectively. The parameters that had the highest correlation with ME occurrence and subsequently included in the model were: total number of drugs, anti-infective drugs, nervous system drugs, 5-min APGAR score, postnatal age, alimentary tract and metabolism drugs, and respiratory system drugs as patient-related parameters, and weekly working hours of nurses, weekly working hours of physicians, and number of nurses' monthly shifts as care provider-related parameters. The obtained model showed high performance to predict ME (AUC: 0.920; 95% CI: 0.876-0.970) presence and is accessible online (http://softmed.hacettepe.edu.tr/NEODEER_Medication_Error/).Conclusion: This is the first developed and validated model to predict the presence of ME using work environment and pharmacotherapy parameters with high-performance ML algorithms in NICU patients. This approach and the current model hold the promise of implementation of targeted/precision screening to prevent MEs in neonates.
DA  - 2023/04/14/
PY  - 2023
DO  - 10.3389/fphar.2023.1151560
VL  - 14
SN  - 1663-9812
AN  - WOS:000979962500001
KW  - machine learning
KW  - controlled study
KW  - human
KW  - randomized controlled trial
KW  - Article
KW  - diagnostic test accuracy study
KW  - major clinical study
KW  - receiver operating characteristic
KW  - sensitivity and specificity
KW  - information processing
KW  - drug safety
KW  - correlation analysis
KW  - adverse drug reaction
KW  - learning algorithm
KW  - medication error
KW  - detection algorithm
KW  - predictive model
KW  - work environment
KW  - Turkey (republic)
KW  - cohort analysis
KW  - physician
KW  - predictive value
KW  - prescription
KW  - newborn
KW  - confidence interval
KW  - drug metabolism
KW  - workload
KW  - drug monitoring
KW  - validation study
KW  - agents affecting metabolism
KW  - antiinfective agent
KW  - Apgar score
KW  - central nervous system agents
KW  - clinical pharmacy
KW  - data collection
KW  - digestive system
KW  - digestive tract agent
KW  - neonatal intensive care unit
KW  - nurse
KW  - observational study
KW  - prospective study
KW  - respiratory tract agent
KW  - screening test
KW  - working time
ER  - 

TY  - JOUR
TI  - Lane-Changing Recognition of Urban Expressway Exit Using Natural Driving Data
AU  - Zhao, L
AU  - Xu, T
AU  - Zhang, ZS
AU  - Hao, YJ
T2  - APPLIED SCIENCES-BASEL
AB  - The traffic environment at the exit of the urban expressway is complex, and vehicle lane-changing behavior occurs frequently, making it prone to traffic conflict and congestion. To study the traffic conditions at the exit of the urban expressway and improve the road operation capacity, this paper analyzes the characteristics of lane-changing behaviors at the exit, adds driving style into the influencing factors of lane-changing, and recognizes one's lane-changing intention based on driving data. A UAV (unmanned aerial vehicle) is used to collect the natural driving track data of the urban expressway diverge area, the track segments of vehicle lane-changing that meet the standards are extracted, and 374 lane-changing segments are obtained. K-means++ is used to cluster the driving style of the lane-changing segments which is grouped into three clusters, corresponding to "ordinary", "radical", and "conservative". Through the random forest model used to identify and predict driving style, the accuracy reaches 93%. Considering the characteristics of a single time point and the characteristics of the historical time window, XGBoost, LightGBM, and the Stacking fusion model are established to recognize one's lane-changing intention. The results show that the models can well recognize the lane-changing intention of drivers. The Stacking fusion model has the highest accuracy, while the LightGBM model takes less time; the model considering the characteristics of the historical time window performs better than the other one, which can better improve the prediction accuracy of lane-changing behavior.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.3390/app12199762
VL  - 12
IS  - 19
SN  - 2076-3417
AN  - WOS:000866563000001
KW  - machine learning
KW  - traffic safety
KW  - data driving
KW  - driving style
KW  - lane-changing intention
KW  - urban expressway exit
ER  - 

TY  - CONF
TI  - Safe Design of Stable Neural Networks for Fault Detection in Small UAVs
AU  - Gupta, K
AU  - Kaakai, F
AU  - Pesquet-Popescu, B
AU  - Pesquet, JC
T2  - COMPUTER SAFETY, RELIABILITY, AND SECURITY, SAFECOMP 2022 WORKSHOPS
A2  - Trapp, M
A2  - Schoitsch, E
A2  - Guiochet, J
A2  - Bitsch, F
AB  - Stability of a machine learning model is the extent to which a model can continue to operate correctly despite small perturbations in its inputs. A formal method to measure stability is the Lipschitz constant of the model which allows to evaluate how small perturbations in the inputs impact the output variations. Variations in the outputs may lead to high errors for regression tasks or unintended changes in the classes for classification tasks. Verification of the stability of ML models is crucial in many industrial domains such as aeronautics, space, automotive etc. It has been recognized that data-driven models are intrinsically extremely sensitive to small perturbation of the inputs. Therefore, the need to design methods for verifying the stability of ML models is of importance for manufacturers developing safety critical products.
In this work, we focus on Small Unmanned Aerial Vehicles (UAVs) which are in the frontage of new technology solutions for intelligent systems. However, real-time fault detection/diagnosis in such UAVs remains a challenge from data collection to prediction tasks. This work presents application of neural networks to detect in real-time elevon positioning faults. We show the efficiency of a formal method based on the Lipschitz constant for quantifying the stability of neural network models. We also present how this method can be coupled with spectral normalization constraints at the design phase to control the internal parameters of the model and make it more stable while keeping a high level of performance (accuracy-stability trade-off).
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-14862-0_19
VL  - 13415
SP  - 263
EP  - 275
SN  - 0302-9743
AN  - WOS:000866543800025
KW  - Safety
KW  - Machine learning
KW  - Intelligent systems
KW  - Neural networks
KW  - UAV
KW  - Machine-learning
KW  - Economic and social effects
KW  - Chemical detection
KW  - Safety engineering
KW  - Fault tolerance
KW  - Fault detection
KW  - Unmanned aerial vehicles (UAV)
KW  - Neural-networks
KW  - Antennas
KW  - Verification
KW  - Adversarial attack
KW  - Stability
KW  - Aerial vehicle
KW  - Unmanned aerial vehicle
KW  - Adversarial attacks
KW  - Product design
KW  - Aircraft detection
KW  - Tabular data
KW  - Lipschitz constant
KW  - Safe designs
KW  - Small perturbations
KW  - Small unmanned aerial vehicles
ER  - 

TY  - JOUR
TI  - Comparative Analysis of Parametric and Non-Parametric Data-Driven Models to Predict Road Crash Severity among Elderly Drivers Using Synthetic Resampling Techniques
AU  - Alrumaidhi, M
AU  - Farag, MMG
AU  - Rakha, HA
T2  - SUSTAINABILITY
AB  - As the global elderly population continues to rise, the risk of severe crashes among elderly drivers has become a pressing concern. This study presents a comprehensive examination of crash severity among this demographic, employing machine learning models and data gathered from Virginia, United States of America, between 2014 and 2021. The analysis integrates parametric models, namely logistic regression and linear discriminant analysis (LDA), as well as non-parametric models like random forest (RF) and extreme gradient boosting (XGBoost). Central to this study is the application of resampling techniques, specifically, random over-sampling examples (ROSE) and the synthetic minority over-sampling technique (SMOTE), to address the dataset's inherent imbalance and enhance the models' predictive performance. Our findings reveal that the inclusion of these resampling techniques significantly improves the predictive power of parametric models, notably increasing the true positive rate for severe crash prediction from 6% to 60% and boosting the geometric mean from 25% to 69% in logistic regression. Likewise, employing SMOTE resulted in a notable improvement in the non-parametric models' performance, leading to a true positive rate increase from 8% to 36% in XGBoost. Moreover, the study established the superiority of parametric models over non-parametric counterparts when balanced resampling techniques are utilized. Beyond predictive modeling, the study delves into the effects of various contributing factors on crash severity, enhancing the understanding of how these factors influence elderly road safety. Ultimately, these findings underscore the immense potential of machine learning models in analyzing complex crash data, pinpointing factors that heighten crash severity, and informing targeted interventions to mitigate the risks of elderly driving.
DA  - 2023/07//undefined
PY  - 2023
DO  - 10.3390/su15139878
VL  - 15
IS  - 13
SN  - 2071-1050
AN  - WOS:001028353300001
KW  - machine learning
KW  - risk assessment
KW  - United States
KW  - comparative study
KW  - road safety
KW  - discriminant analysis
KW  - transportation safety
KW  - crash severity
KW  - elderly drivers
KW  - elderly population
KW  - imbalance data
KW  - resampling techniques
KW  - Virginia
ER  - 

TY  - JOUR
TI  - DQ-GAT: Towards Safe and Efficient Autonomous Driving With Deep Q-Learning and Graph Attention Networks
AU  - Cai, PD
AU  - Wang, HL
AU  - Sun, YX
AU  - Liu, M
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Autonomous driving in multi-agent dynamic traffic scenarios is challenging: the behaviors of road users are uncertain and are hard to model explicitly, and the ego-vehicle should apply complicated negotiation skills with them, such as yielding, merging and taking turns, to achieve both safe and efficient driving in various settings. Traditional planning methods are largely rule-based and scale poorly in these complex dynamic scenarios, often leading to reactive or even overly conservative behaviors. Therefore, they require tedious human efforts to maintain workability. Recently, deep learning-based methods have shown promising results with better generalization capability but less hand engineering efforts. However, they are either implemented with supervised imitation learning (IL), which suffers from dataset bias and distribution mismatch issues, or are trained with deep reinforcement learning (DRL) but focus on one specific traffic scenario. In this work, we propose DQ-GAT to achieve scalable and proactive autonomous driving, where graph attention-based networks are used to implicitly model interactions, and deep Q-learning is employed to train the network end-to-end in an unsupervised manner. Extensive experiments in a high-fidelity driving simulator show that our method achieves higher success rates than previous learning-based methods and a traditional rule-based method, and better trades off safety and efficiency in both seen and unseen scenarios. Moreover, qualitative results on a trajectory dataset indicate that our learned policy can be transferred to the real world for practical applications with real-time speeds. Demonstration videos are available at https://caipeide.github.io/dq-gat/.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.1109/TITS.2022.3184990
VL  - 23
IS  - 11
SP  - 21102
EP  - 21112
SN  - 1524-9050
AN  - WOS:000826074700001
ER  - 

TY  - JOUR
TI  - Self-Learned Intelligence for Integrated Decision and Control of Automated Vehicles at Signalized Intersections
AU  - Ren, YG
AU  - Jiang, JH
AU  - Zhan, GJ
AU  - Li, SE
AU  - Chen, C
AU  - Li, KQ
AU  - Duan, JL
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Intersection is one of the most accident-prone urban scenarios for autonomous driving wherein making safe and computationally efficient decisions is non-trivial. Current research mainly focuses on the simplified traffic conditions while ignoring the existence of mixed traffic flows, i.e., vehicles, cyclists and pedestrians. For urban roads, different participants lead to a quite dynamic and complex interaction, posing great difficulty to learn an intelligent policy. This paper develops the dynamic permutation state representation in the framework of integrated decision and control (IDC) to handle signalized intersections with mixed traffic flows. Specially, this representation introduces an encoding function and summation operator to construct driving states from environmental observation, capable of dealing with different types and variant number of traffic participants. A constrained optimal control problem is built wherein the objective involves tracking performance and the constraints for different participants, roads and signal lights are designed respectively to assure safety. We solve this problem by gradient-based optimization, wherein the reasonable state will be given by the encoding function and then served as the input of policy and value function. An off-policy training is designed to reuse observations from driving environment and backpropagation through time is utilized to update the policy function and encoding function jointly. Verification result shows that the dynamic permutation state representation can enhance the driving performance of IDC, including comfort, decision compliance and safety with a large margin. The trained driving policy can realize efficient and smooth passing in the complex intersection, guaranteeing driving intelligence and safety simultaneously.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1109/TITS.2022.3196167
VL  - 23
IS  - 12
SP  - 24145
EP  - 24156
SN  - 1524-9050
AN  - WOS:000842733500001
ER  - 

TY  - JOUR
TI  - Sparse Learning-Based Approximate Dynamic Programming With Barrier Constraints
AU  - Greene, ML
AU  - Deptula, P
AU  - Nivison, S
AU  - Dixon, WE
T2  - IEEE CONTROL SYSTEMS LETTERS
AB  - This letter provides an approximate online adaptive solution to the infinite-horizon optimal control problem for control-affine continuous-time nonlinear systems while formalizing system safety using barrier certificates. The use of a barrier function transform provides safety certificates to formalize system behavior. Specifically, using a barrier function, the system is transformed to aid in developing a controller which maintains the system in a pre-defined constrained region. To aid in online learning of the value function, the state-space is segmented into a number of user-defined segments. Off-policy trajectories are selected in each segment, and sparse Bellman error extrapolation is performed within each respective segment to generate an optimal policy within each segment. A Lyapunov-like stability analysis is included which proves uniformly ultimately bounded regulation in the presence of the barrier function transform and discontinuities. Simulation results are provided for a two-state dynamical system to compare the performance of the developed method to existing methods.
DA  - 2020/07//undefined
PY  - 2020
DO  - 10.1109/LCSYS.2020.2977927
VL  - 4
IS  - 3
SP  - 743
EP  - 748
SN  - 2475-1456
AN  - WOS:000538080200008
ER  - 

TY  - CONF
TI  - Towards Building a Responsible Data Economy
AU  - Song, D
AU  - ASSOC COMP MACHINERY
T2  - CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY
DA  - 2021///
PY  - 2021
DO  - 10.1145/3460120.3482789
SP  - 3
EP  - 3
SN  - 978-1-4503-8454-4
AN  - WOS:000768478300002
ER  - 

TY  - JOUR
TI  - Digital twin-driven virtual sensor approach for safe construction operations of trailing suction hopper dredger
AU  - Li, MC
AU  - Lu, QR
AU  - Bai, S
AU  - Zhang, MX
AU  - Tian, HJ
AU  - Qin, L
T2  - AUTOMATION IN CONSTRUCTION
AB  - The stable and safe operation of Trailing suction hopper dredger (TSHD) is one of the most crucial considerations for ensuring its high dredging productivity. However, the instability and sudden failure of physical sensors pose challenges to the monitoring of dredging process. To address these issues, we propose a structure of digital twin driven virtual sensor (DTDVS) for the construction safety of TSHD. Considering the potential internal relations among construction data, we compare the performance of four machine learning algorithms in predicting the torsional vibration in mechanical failure. The results showed that these algorithms provide high prediction accuracy (R-2 > 0.9). Then the DBN model with the best performance was selected as a part of the virtual sensors to predict and analyze the status of TSHD. The digital twin technology provides a more stable and environmentally friendly scheme for TSHD construction safety control. On the one hand, the DTDVS assists physical sensors to monitor the construction state, overcoming the limitation of the sensors on detection targets which are difficult or costly to measure directly. On the other hand, by analyzing the residual between the physical sensor and the virtual sensor, the construction behavior can be diagnosed, and the fault situation can be pre-warned accurately. This improves the time utilization of TSHD and provides an important guarantee for the construction safety.
DA  - 2021/12//undefined
PY  - 2021
DO  - 10.1016/j.autcon.2021.103961
VL  - 132
SN  - 0926-5805
AN  - WOS:000701923200001
KW  - Machine learning
KW  - Data mining
KW  - Machine learning algorithms
KW  - Digital twin
KW  - Learning algorithms
KW  - Performance
KW  - E-learning
KW  - Forecasting
KW  - Construction safety
KW  - Safe operation
KW  - Failure (mechanical)
KW  - Construction data
KW  - Construction operations
KW  - Dredging
KW  - Physical sensors
KW  - Stable operation
KW  - Trailing suction hopper dredger
KW  - Vibrations (mechanical)
KW  - Virtual sensor
ER  - 

TY  - JOUR
TI  - Classification of motor vehicle crash injury severity: A hybrid approach for imbalanced data
AU  - Jeong, H
AU  - Jang, YC
AU  - Bowman, PJ
AU  - Masoud, N
T2  - ACCIDENT ANALYSIS AND PREVENTION
AB  - This study aims to classify the injury severity in motor-vehicle crashes with both high accuracy and sensitivity rates. The dataset used in this study contains 297,113 vehicle crashes, obtained from the Michigan Traffic Crash Facts (MTCF) dataset, from 2016-2017. Similar to any other crash dataset, different accident severity classes are not equally represented in MTCF. To account for the imbalanced classes, several techniques have been used, including under-sampling and over-sampling. Using five classification learning models (i.e., Logistic regression, Decision tree, Neural network, Gradient boosting model, and Naive Bayes classifier), we classify the levels of injury severity and attempt to improve the classification performance by two training-testing methods including Bootstrap aggregation (or bagging) and majority voting. Furthermore, due to the imbalance present in the dataset, we use the geometric mean (G-mean) to evaluate the classification performance. We show that the classification performance is the highest when bagging is used with decision trees, with over-sampling treatment for imbalanced data. The effect of treatments for the imbalanced data is maximized when under-sampling is combined with bagging. In addition to the original five classes of injury severity in the MTCF dataset, we consider two additional classification problems, one with two classes and the other with three classes, to (1) investigate the impact of the number of classes on the performance of classification models, and (2) enable comparing our results with the literature.
DA  - 2018/11//undefined
PY  - 2018
DO  - 10.1016/j.aap.2018.08.025
VL  - 120
SP  - 250
EP  - 261
SN  - 0001-4575
AN  - WOS:000446144800025
KW  - Decision trees
KW  - Machine learning
KW  - Accidents
KW  - Vehicles
KW  - Testing
KW  - Learning systems
KW  - Automated vehicles
KW  - Data analytics
KW  - Classification (of information)
KW  - Trees (mathematics)
KW  - Statistical methods
KW  - Injury severity
KW  - Imbalanced data
KW  - Automated vehicle safety
KW  - Injury severity classification
KW  - Vehicle crashes
ER  - 

TY  - CONF
TI  - Automatic Database Alignment Method to Improve Failure Data Quality
AU  - Liang, YP
AU  - Blancke, O
AU  - Gaha, M
AU  - Côté, A
AU  - St-Jean, G
AU  - Aïmeur, E
AU  - IEEE
T2  - 2022 68TH ANNUAL RELIABILITY AND MAINTAINABILITY SYMPOSIUM (RAMS 2022)
AB  - Life-cycle data analysis mainly relies on coherent failure data. Generally, in the industry, failure data are recorded in various Enterprise Resource Planning (ERP) databases and can lead to inconsistent failure data analysis. The aim of this paper is to propose a new method to automatically merge existing failure datasets into one main database to reduce inconsistency and allow valuable analysis and stochastic/predictive models. The methodology is as follows. First, the data is cleaned using rules from domain knowledge. Second, similar features between the two databases were evaluated by applying correlation technique. Finally, we developed a rule-based engine to merge existing failure datasets into one main database. Our rule-based engine was calibrated according to the distribution of the observed distance between similar features. At first, we were able to match the failure data by 65%, then we enhanced our algorithm using Natural Language Processing (NLP) technique and we were able to reach an outstanding score of 85%. Traditionally this data alignment is done yearly by human experts. This is an extremely time-consuming task, and our automatic matching algorithm reduces workload by 70% and biases in life-cycle data analysis. With a confidence level our algorithm interactively suggests matches according to their distances.
DA  - 2022///
PY  - 2022
DO  - 10.1109/RAMS51457.2022.9893932
SN  - 0149-144X
AN  - WOS:000942487400018
KW  - machine learning
KW  - Machine learning
KW  - Natural language processing
KW  - Data handling
KW  - Learning algorithms
KW  - Machine-learning
KW  - Systems engineering
KW  - Quality control
KW  - Natural language processing systems
KW  - Database systems
KW  - Data quality
KW  - Stochastic models
KW  - Stochastic systems
KW  - Life cycle
KW  - Trees (mathematics)
KW  - Engines
KW  - Alignment
KW  - Language processing
KW  - Natural languages
KW  - Domain Knowledge
KW  - natural language processing
KW  - Rule based
KW  - Enterprise resource planning
KW  - data quality
KW  - Data alignments
KW  - Cycle data
KW  - data alignment
KW  - decision trees
KW  - Failure data
KW  - life data analysis
KW  - Life Data Analysis
ER  - 

TY  - JOUR
TI  - Blockchain-Enabled Intelligent Transportation Systems: A Distributed Crowdsensing Framework
AU  - Ning, ZL
AU  - Sun, SM
AU  - Wang, XJ
AU  - Guo, L
AU  - Guo, S
AU  - Hu, XP
AU  - Hu, B
AU  - Kwok, RYK
T2  - IEEE TRANSACTIONS ON MOBILE COMPUTING
AB  - Intelligent Transportation System (ITS) is critical to cope with traffic events, e.g., traffic jams and accidents, and provide services for personal traveling. However, existing researches have not jointly considered the user data safety, utility and system latency comprehensively, to the best of our knowledge. Since both safe and efficient transmissions are significant for ITS, we construct a blockchain-enabled crowdsensing framework for distributed traffic management. First, we illustrate the system model and formulate a multi-objective optimization problem. Due to its complexity, we decompose it into two subproblems, and propose the corresponding schemes, i.e., a Deep Reinforcement Learning (DRL)-based algorithm and a DIstributed Alternating Direction mEthod of Multipliers (DIADEM) algorithm. Extensive experiments are carried out to evaluate the performance of our solutions, and experimental results demonstrate that the DRL-based algorithm can legitimately select active miners and transactions to make a satisfied trade-off between the blockchain safety and latency, and the DIADEM algorithm can effectively select task computation modes for vehicles in a distributed way to maximize their social welfare.
DA  - 2022/12/01/
PY  - 2022
DO  - 10.1109/TMC.2021.3079984
VL  - 21
IS  - 12
SP  - 4201
EP  - 4217
SN  - 1536-1233
AN  - WOS:000879041300001
ER  - 

TY  - CONF
TI  - Progressive Alignment and Discriminative Error Correction for Multiple OCR Engines
AU  - Lund, WB
AU  - Walker, DD
AU  - Ringger, EK
AU  - IEEE
T2  - 11TH INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION (ICDAR 2011)
AB  - This paper presents a novel method for improving optical character recognition (OCR). The method employs the progressive alignment of hypotheses from multiple OCR engines followed by final hypothesis selection using maximum entropy classification methods. The maximum entropy models are trained on a synthetic calibration data set. Although progressive alignment is not guaranteed to be optimal, the results are nonetheless strong. The synthetic data set used to train or calibrate the selection models is chosen without regard to the test data set; hence, we refer to it as "out of domain." It is synthetic in the sense that document images have been generated from the original digital text and degraded using realistic error models. Along with the true transcripts and OCR hypotheses, the calibration data contains sufficient information to produce good models of how to select the best OCR hypothesis and thus correct mistaken OCR hypotheses. Maximum entropy methods leverage that information using carefully chosen feature functions to choose the best possible correction. Our method shows a 24.6% relative improvement over the word error rate (WER) of the best performing of the five OCR engines employed in this work. Relative to the average WER of all five OCR engines, our method yields a 69.1% relative reduction in the error rate. Furthermore, 52.2% of the documents achieve a new low WER.
DA  - 2011///
PY  - 2011
DO  - 10.1109/ICDAR.2011.303
SP  - 764
EP  - 768
SN  - 1520-5363
AN  - WOS:000343450700150
KW  - Machine learning
KW  - Maximum entropy
KW  - Machine-learning
KW  - Statistical tests
KW  - Classification methods
KW  - Entropy
KW  - Error correction
KW  - Alignment
KW  - Software testing
KW  - Multiple sequence alignments
KW  - Maximum entropy methods
KW  - Synthetic datasets
KW  - Calibration
KW  - Test data
KW  - Synthetic training data
KW  - Optical character recognition
KW  - Calibration data
KW  - Digital text
KW  - Document images
KW  - Error model
KW  - Error rate
KW  - Feature function
KW  - Maximum entropy models
KW  - Multiple sequence alignment
KW  - OCR engines
KW  - Optical character recognition software
KW  - Progressive alignment
KW  - Progressive text alignment
KW  - Relative reduction
KW  - Selection model
KW  - Synthetic training data set
KW  - Word error rate
ER  - 

TY  - JOUR
TI  - The horizon of pediatric cardiac critical care
AU  - Pollak, U
AU  - Feinstein, Y
AU  - Mannarino, CN
AU  - McBride, ME
AU  - Mendonca, M
AU  - Keizman, E
AU  - Mishaly, D
AU  - van Leeuwen, G
AU  - Roeleveld, PP
AU  - Koers, L
AU  - Klugman, D
T2  - FRONTIERS IN PEDIATRICS
AB  - Pediatric Cardiac Critical Care (PCCC) is a challenging discipline where decisions require a high degree of preparation and clinical expertise. In the modern era, outcomes of neonates and children with congenital heart defects have dramatically improved, largely by transformative technologies and an expanding collection of pharmacotherapies. Exponential advances in science and technology are occurring at a breathtaking rate, and applying these advances to the PCCC patient is essential to further advancing the science and practice of the field. In this article, we identified and elaborate on seven key elements within the PCCC that will pave the way for the future.
DA  - 2022/09/16/
PY  - 2022
DO  - 10.3389/fped.2022.863868
VL  - 10
SN  - 2296-2360
AN  - WOS:000862573100001
ER  - 

TY  - JOUR
TI  - A Practitioner Survey Exploring the Value of Forensic Tools, AI, Filtering, & Safer Presentation for Investigating Child Sexual Abuse Material (CSAM)
AU  - Sanchez, L
AU  - Grajeda, C
AU  - Baggili, I
AU  - Hall, C
T2  - DIGITAL INVESTIGATION
AB  - For those investigating cases of Child Sexual Abuse Material (CSAM), there is the potential harm of experiencing trauma after illicit content exposure over a period of time. Research has shown that those working on such cases can experience psychological distress. As a result, there has been a greater effort to create and implement technologies that reduce exposure to CSAM. However, not much work has explored gathering insight regarding the functionality, effectiveness, accuracy, and importance of digital forensic tools and data science technologies from practitioners who use them. This study focused specifically on examining the value practitioners give to the tools and technologies they utilize to investigate CSAM cases. General findings indicated that implementing filtering technologies is more important than safe-viewing technologies; false positives are a greater concern than false negatives; resources such as time, personnel, and money continue to be a concern; and an improved workflow is highly desirable. Results also showed that practitioners are not well-versed in data science and Artificial Intelligence (AI), which is alarming given that tools already implement these techniques and that practitioners face large amounts of data during investigations. Finally, the data exemplified that practitioners are generally not taking advantage of tools that implement data science techniques, and that the biggest need for them is in automated child nudity detection, age estimation and skin tone detection. (C) 2019 The Author(s). Published by Elsevier Ltd on behalf of DFRWS.
DA  - 2019/07//undefined
PY  - 2019
DO  - 10.1016/j.diin.2019.04.005
VL  - 29
SP  - S124
EP  - S142
SN  - 1742-2876
AN  - WOS:000475407000014
ER  - 

TY  - JOUR
TI  - Safe multi-agent deep reinforcement learning for real-time decentralized control of inverter based renewable energy resources considering communication delay
AU  - Guo, GD
AU  - Zhang, MF
AU  - Gong, YF
AU  - Xu, QW
T2  - APPLIED ENERGY
AB  - The increasing penetration of distributed renewable energy resources brings a great challenge for real-time voltage security of distribution grids. The paper proposes a safe multi-agent deep reinforcement learning (MADRL) algorithm for real-time control of inverter-based Volt-Var control (VVC) in distribution grids consid-ering communication delay to minimize the network power loss, while maintaining the nodal voltages in a safe range. The multi-agent VVC is modeled as a constrained Markov game, which is solved by the MADRL algorithm. In the training stage, the safety projection is added to the combined policy to analytically solve an action correction formulation to promote more efficient and safe exploration. In the real-time decision-making stage, a state synchronization block is designed to impute the data under the latest timestamp as the input of the agents deployed in a distributed manner, to avoid instability caused by communication delay. The simulation results show that the proposed algorithm performs well in safe exploration, and also achieves better performance under communication delay.
DA  - 2023/11/01/
PY  - 2023
DO  - 10.1016/j.apenergy.2023.121648
VL  - 349
SN  - 0306-2619
AN  - WOS:001053289400001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Decision making
KW  - Communication delays
KW  - algorithm
KW  - Multi agent systems
KW  - Multi-agent reinforcement learning
KW  - Real time control
KW  - Renewable energy resources
KW  - Real- time
KW  - Electric inverters
KW  - Electric power system control
KW  - Reinforcement learning algorithms
KW  - Multi agent
KW  - Electric power distribution
KW  - Voltage control
KW  - Reactive power
KW  - Electric load dispatching
KW  - Inverter-based
KW  - control system
KW  - Safe exploration
KW  - real time
KW  - Distribution grid
KW  - exploration
KW  - alternative energy
KW  - Communication delay
KW  - Decentralised control
KW  - Decentralized control
KW  - Distribution grids
KW  - energy resource
KW  - Inverte based renewable energy resource
KW  - Inverter based renewable energy resources
KW  - policy approach
ER  - 

TY  - JOUR
TI  - In pursuit of socially-minded data-intensive innovation in banking: A focus group study of public expectations of digital innovation in banking
AU  - Aitken, M
AU  - Ng, M
AU  - Horsfall, D
AU  - Coopamootoo, KPL
AU  - van Moorsel, A
AU  - Elliott, K
T2  - TECHNOLOGY IN SOCIETY
AB  - While the field of data ethics is increasingly engaging with the complex socio-technical nature of data practices and their impacts, in the private sector, data ethics continues to be pursued largely through limited instrumental measures. This paper addresses the following research question: How can socially-minded data-intensive innovation be pursued in the private sector? It reports the findings of a series of five focus groups to explore the role of public deliberation in informing ethical data practices in banking. The findings indicate that deliberative forms of public engagement present valuable opportunities to incorporate diverse views and perspectives and to enable critical reflection on organisational practices and the trajectory of innovation. We conclude that public engagement is vital to ensure that private sector organisations move beyond "ethics-washing" or tokenistic efforts at Corporate Digital Responsibility (CDR) to meaningfully address public concerns and reflect public values in all innovation processes.
DA  - 2021/08//undefined
PY  - 2021
DO  - 10.1016/j.techsoc.2021.101666
VL  - 66
SN  - 0160-791X
AN  - WOS:000713715100007
ER  - 

TY  - JOUR
TI  - Looking at Vehicles in the Night: Detection and Dynamics of Rear Lights
AU  - Satzoda, RK
AU  - Trivedi, MM
T2  - IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Existing nighttime vehicle detection methods use color as the primary cue for detecting vehicles. However, complex road and ambient lighting conditions, and camera configurations can influence the effectiveness of such explicit rule and threshold-based methods. In this paper, there are three main contributions. First, we present a novel method to detect vehicles during nighttime involving both learned classifiers and explicit rules, which can operate in the presence of varying ambient lighting conditions. The proposed method that is titled as Vehicle Detection using Active-learning during Nighttime (VeDANt) employs a modified form of active learning for training Adaboost classifiers with Haar-like features using gray-level input images. The hypothesis windows are then further verified using the proposed techniques involving perspective geometries and color information of the taillights. Second, VeDANt is extended to analyze the dynamics of the vehicles during nighttime by detecting three taillight activities-braking, turning left, and turning right. Third, we release three new and fully annotated Laboratory for Intelligent and Safe Automobiles-Night data sets with over 5000 frames for evaluation and benchmarking, which capture a variety of complex traffic and lighting conditions. Such comprehensively annotated and complex public data sets are a first in the area of nighttime vehicle detection. We show that VeDANt is able to detect vehicles during nighttime with over 98 accuracy and less than 1 false detections.
DA  - 2019/12//undefined
PY  - 2019
DO  - 10.1109/TITS.2016.2614545
VL  - 20
IS  - 12
SP  - 4297
EP  - 4307
SN  - 1524-9050
AN  - WOS:000505522400003
ER  - 

TY  - JOUR
TI  - Getting into the engine room: a blueprint to investigate the shadowy steps of AI ethics
AU  - Rochel, J
AU  - Evéquoz, F
T2  - AI & SOCIETY
AB  - Enacting an AI system typically requires three iterative phases where AI engineers are in command: selection and preparation of the data, selection and configuration of algorithmic tools, and fine-tuning of the different parameters on the basis of intermediate results. Our main hypothesis is that these phases involve practices with ethical questions. This paper maps these ethical questions and proposes a way to address them in light of a neo-republican understanding of freedom, defined as absence of domination. We thereby identify different types of responsibility held by AI engineers and link them to concrete suggestions on how to improve professional practices. This paper contributes to the literature on AI and ethics by focusing on the work necessary to configure AI systems, thereby offering an input to better practices and an input for societal debates.
DA  - 2021/06//undefined
PY  - 2021
DO  - 10.1007/s00146-020-01069-w
VL  - 36
IS  - 2
SP  - 609
EP  - 622
SN  - 0951-5666
AN  - WOS:000570445900001
ER  - 

TY  - JOUR
TI  - Fuzzy Kernel Alignment With Application to Attribute Reduction of Heterogeneous Data
AU  - Chen, LL
AU  - Chen, DG
AU  - Wang, H
T2  - IEEE TRANSACTIONS ON FUZZY SYSTEMS
AB  - Fuzzy similarity relation is a function to measure the similarity between two samples. It is widely used to learn knowledge under the framework of fuzzy machine learning. The selection of a suitable fuzzy similarity relation is important for the learning task. It has been pointed out that fuzzy similarity relations can be brought into the framework of kernel functions in machine learning. This fact motivates us to study fuzzy similarity relation selection for fuzzy machine learning utilizing kernel selection methods in machine learning. Kernel alignment is a kernel selection method that is effective and has low computational complexity. In this paper, we present novel methods for fuzzy similarity relation selection based on the kernel alignment, and their use in attribution reduction for heterogeneous data. First, we define an ideal kernel for classification problems, based on which a novel fuzzy kernel alignment model is proposed. Second, we present a method for the fuzzy similarity relation selection based on the minimization of the fuzzy alignment between the defined ideal kernel and a kernel for the learning problem at hand. In order to show the correctness of this selection method, we prove that the lower bound of the classification accuracy of a support vector machine will increase with the decrease of the fuzzy alignment value. Furthermore, we apply the proposed fuzzy similarity relation selection to attribute reduction for heterogeneous data. Finally, we present experimental results to show that the proposed method of fuzzy similarity relation selection based on the fuzzy kernel alignment is effective.
DA  - 2019/07//undefined
PY  - 2019
DO  - 10.1109/TFUZZ.2018.2880933
VL  - 27
IS  - 7
SP  - 1469
EP  - 1478
SN  - 1063-6706
AN  - WOS:000473644200012
KW  - Artificial intelligence
KW  - Learning systems
KW  - Fuzzy logic
KW  - Classification accuracy
KW  - Data reduction
KW  - Heterogeneous data
KW  - heterogeneous data
KW  - Attribute reduction
KW  - Attribution reduction
KW  - Fuzzy kernel
KW  - fuzzy kernel alignment
KW  - fuzzy machine learning fuzzy similarity relation
KW  - Fuzzy similarity relation
KW  - Low computational complexity
KW  - Selection methods
ER  - 

TY  - JOUR
TI  - Securing instant messaging based on blockchain with machine learning
AU  - Yi, HB
T2  - SAFETY SCIENCE
AB  - Instant Messaging (IM) offers real-time communications between two or more participants on Internet. Nowadays, most Ms take place on mobile applications, such as WhatsApp, WeChat, Viber and Facebook Messenger, which have more users than social networks, such as Twitter and Facebook. Among the applications of IMs, online shopping has become a part of our everyday life, primarily those who are busiest. However, transaction disputes are often occurred online shopping. Since most IMs are centralized and message history is not stored in the center, the messaging between users and owners of online shops are not reliable and traceable. In China, online shopping sales have soared from practically zero in 2003 to nearly 600 hundred million dollars last year, and now top those in the United States. It is very crucial to secure the instant messaging in online shopping in China. We present techniques to exploit blockchain and machine learning algorithms to secure instant messaging. Since the cryptography of Chinese national standard is encouraged to adopt in security applications of China, we propose a blockchain-based IM scheme with the Chinese cryptographic bases. First, we design a message authentication model based on SM2 to avoid the counterfeit attack and replay attack. Second, we design a cryptographic hash mode based on SM3 to verify the integrity of message. Third, we design a message encryption model based on SM4 to protect the privacy of users. Besides, we propose a method based on machine learning algorithms to monitor the activity on blockchain to detect anomaly. To prove and verify the blockchain-based IM scheme, a blockchain-based IM system has been designed on Linux platforms. The implementation result shows that it is a practical and secure IM system, which can be applied to a variety of instant messaging applications directly.
DA  - 2019/12//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2019.06.025
VL  - 120
SP  - 6
EP  - 13
SN  - 0925-7535
AN  - WOS:000496335100002
KW  - machine learning
KW  - privacy
KW  - Machine learning
KW  - Blockchain
KW  - Learning systems
KW  - United States
KW  - Learning algorithms
KW  - article
KW  - human
KW  - human experiment
KW  - China
KW  - clinical article
KW  - Social networking (online)
KW  - Electronic commerce
KW  - Safety and securities
KW  - Cryptography
KW  - Security application
KW  - Safety and security
KW  - Instant messaging
KW  - case report
KW  - BlockChain
KW  - Chinese national standard
KW  - Computer operating systems
KW  - Distributed Ledger Technology (DLT)
KW  - Instant Messaging (IM)
KW  - Message authentication
KW  - Message passing
KW  - Real-time communication
KW  - Secure instant messaging
KW  - shopping
ER  - 

TY  - JOUR
TI  - Discriminative feature-based adaptive distribution alignment (DFADA) for rotating machine fault diagnosis under variable working conditions
AU  - Qian, WW
AU  - Li, SM
AU  - Yao, T
AU  - Xu, K
T2  - APPLIED SOFT COMPUTING
AB  - Recent years, cross-domain fault diagnosis of rotating machinery has been a hot topic, and various kinds of methods taking advantage of transfer learning are proposed correspondingly. Despite their success, they mainly focus on marginal distribution alignments, which ignore weighing between marginal and conditional distributions in network training. However, this kind of weighting can boost diagnosis network performance further and make it more robust. Hence, a novel transfer learning method called discriminative feature-based adaptive distribution alignment (DFADA) is proposed, which can extract discriminative features and conduct a two-stage adaptive distribution alignment on L2 ball. In DFADA, maximum mean discrepancy (MMD) and graph Laplacian regularization are fused to extract discriminative and task-specific features. Meanwhile, for comprehensive and adaptive distribution alignments, the distributions of datasets are pre-matched via MMD and further matched in feature classifier via dynamic distribution alignment (DDA), which can not only reduce both marginal and conditional distribution discrepancies but also weigh their importance adaptively. Finally, a DFADA-based fault diagnosis method for rotating machinery with volatile working conditions is constructed correspondingly. The validity of the proposed method is also confirmed by extensive experiments and comparisons with some state of the arts on 18 transfer learning cases. (C) 2020 Elsevier B.V. All rights reserved.
DA  - 2021/02//undefined
PY  - 2021
DO  - 10.1016/j.asoc.2020.106886
VL  - 99
SN  - 1568-4946
AN  - WOS:000608174400004
KW  - Learning systems
KW  - Transfer learning
KW  - Classification (of information)
KW  - Failure analysis
KW  - Fault detection
KW  - Machine fault diagnosis
KW  - Alignment
KW  - Conditional distribution
KW  - Marginal distribution
KW  - Discriminative features
KW  - Fault diagnosis method
KW  - Dynamic distribution
KW  - Dynamic distribution alignment
KW  - Fault diagnosis of rotating machineries
KW  - Feature classifiers
KW  - Graph Laplacian regularization
KW  - Rotating machinery
KW  - Sparse filtering
KW  - Transfer learning methods
ER  - 

TY  - JOUR
TI  - Comparing immersive virtual reality and powerpoint as methods for delivering safety training: Impacts on risk perception, learning, and decision making
AU  - Leder, J
AU  - Horlitz, T
AU  - Puschmann, P
AU  - Wittstock, V
AU  - Schütz, A
T2  - SAFETY SCIENCE
AB  - In two experimental studies, we compared safety training given via immersive virtual reality with safety training given via PowerPoint in their effects on risk perception, learning, and risky choices. In Study 1, we compared the two methods in a sample of apprentices (N = 53) and also investigated whether participants' conscientiousness and locus of control moderated the effects of safety training. In Study 1, we found an effect of training method on the change in risk perception in terms of probability judgments and on risky decisions but not on learning. In Study 2 (N = 68), we sought to replicate Study 1 and also tested whether domain-specific risk attitudes affected risk perception and choice. Furthermore, long-term effects of safety training on information recall and risk perception after a 6-month interval were assessed. The effects found in Study 1 could not be replicated in Study 2. Neither study found an interaction between presentation medium and personality. We conclude that the costly procedure of immersive virtual reality (VR) does not seem justified for safety training because the less costly PowerPoint procedure with vivid film scenes did not fare significantly worse with respect to changes in risk perception, learning outcomes, or decision making.
DA  - 2019/01//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2018.07.021
VL  - 111
SP  - 271
EP  - 286
SN  - 0925-7535
AN  - WOS:000449124900026
KW  - risk assessment
KW  - Accidents
KW  - Learning
KW  - virtual reality
KW  - Virtual reality
KW  - perception
KW  - E-learning
KW  - experimental study
KW  - adult
KW  - article
KW  - controlled study
KW  - female
KW  - human
KW  - human experiment
KW  - male
KW  - Risk perception
KW  - Risk assessment
KW  - major clinical study
KW  - Long-term effects
KW  - decision making
KW  - Safety engineering
KW  - learning
KW  - probability
KW  - drug safety
KW  - Safety training
KW  - accident
KW  - Training methods
KW  - recall
KW  - Immersive virtual reality
KW  - Effects of safety
KW  - Hazardous machines
KW  - Information recalls
KW  - locus of control
KW  - machine
KW  - Risky choices
KW  - student
KW  - MARKER
ER  - 

TY  - JOUR
TI  - A theoretical framework for data-driven artificial intelligence decision making for enhancing the asset integrity management system in the oil & gas sector
AU  - Sattari, F
AU  - Lefsrud, L
AU  - Kurian, D
AU  - Macciotta, R
T2  - JOURNAL OF LOSS PREVENTION IN THE PROCESS INDUSTRIES
AB  - Asset integrity and reliability is one of the 20 elements of Process Safety Management (PSM) as defined by the Center for Chemical Process Safety (CCPS). We combine expert knowledge and data analytics (Artificial Intel-ligence, Machine Learning, and Keyword Analysis) to create a reaction network for Asset Integrity Management (AIM) and provide a theoretical and practical basis for handling uncertainty in large data sets such as company incident databases. The purpose of the current study is to control and minimize the total number of incidents that occur within an oil and gas operation by applying a multidisciplinary approach to explore and develop AIM. This systematic approach can improve AIM to better understand PSM as a whole and the underlying dynamics ever-present in the system. In this study, AIM is divided into 2 major groups - asset and human factors - and then, in order to get more detailed results, each group is divided into 9 and 5 subcategories, respectively. To analyze the relationships between the different factors of AIM, two score-based (Tabu and Hill Climbing) and one hybrid (Max-Min Hill-Climbing) Bayesian networks are used to develop one final viable solution. The findings of these techniques point towards the same results for reducing incident rates. Four factors related to assets, including construction, testing, inspection, and maintenance, account for more than half the incidents (54.78%). Addi-tionally, there must be a greater emphasis placed on the impact of human factors as they are directly (23.58%) and indirectly (11.10%) responsible for accidents as well as other technological malfunctions. By focusing on AIM which is a key element of PSM, it will be possible to gain a better understanding of one of the most sig-nificant and problematic sources of risk in process safety.
DA  - 2022/01//undefined
PY  - 2022
DO  - 10.1016/j.jlp.2021.104648
VL  - 74
SN  - 0950-4230
AN  - WOS:000713396900004
KW  - Machine learning
KW  - Bayesian network
KW  - Decision making
KW  - Gas industry
KW  - Machine-learning
KW  - Human engineering
KW  - Bayesian networks
KW  - Safety engineering
KW  - Uncertainty analysis
KW  - Data Analytics
KW  - Information management
KW  - Data driven
KW  - Process safety management
KW  - Process safety
KW  - Bayesia n networks
KW  - Theoretical framework
KW  - Incident data
KW  - Asset integrity management
KW  - Asset integrity managements
KW  - Hill climbing
KW  - Keyword analysis
KW  - Keywords analysis
ER  - 

TY  - JOUR
TI  - Predicting types of occupational accidents at construction sites in Korea using random forest model
AU  - Kang, K
AU  - Ryu, H
T2  - SAFETY SCIENCE
AB  - Although industrial accident rates are gradually decreasing in Korea, the construction industry's accident rate is still higher compared with other industries. Human errors, mentally unstable workers, insufficient safety training, and safety policy affect the occurrence of construction accidents. Owing to the characteristics of this industry, occupational accident types, such as fall from height, collision with objects, rollover, and those due to falling objects, can be related to the weather data.
Therefore, to reduce and prevent occupational injury, it is necessary to classify and predict occupational accident types in detail. In this study, we built a model to classify and predict occupational accident types using a random forest (RF). We extracted important factors that affect the occupational accident types at construction sites using feature importance, and we analyzed the relationship between these factors and occupational accident types. The accuracy score of the RF model was obtained as 71.3%, and we presented key construction safety factors considering the feature importance. For future research, we will collect data and develop models to predict occupational accident types in real-time. Real-time construction accident prediction research will reduce accident at construction sites.
DA  - 2019/12//undefined
PY  - 2019
DO  - 10.1016/j.ssci.2019.06.034
VL  - 120
SP  - 226
EP  - 236
SN  - 0925-7535
AN  - WOS:000496335100023
KW  - machine learning
KW  - Decision trees
KW  - Machine learning
KW  - Accidents
KW  - Data analysis
KW  - Learning systems
KW  - Feature importance
KW  - prediction
KW  - controlled study
KW  - human
KW  - Traffic control
KW  - algorithm
KW  - Forecasting
KW  - Article
KW  - priority journal
KW  - medical research
KW  - population research
KW  - incidence
KW  - Safety factor
KW  - random forest
KW  - Random forests
KW  - Data reduction
KW  - Random forest modeling
KW  - Occupational risks
KW  - Construction accidents
KW  - Construction safety
KW  - Random forest
KW  - Construction industry
KW  - Industrial hygiene
KW  - occupational accident
KW  - measurement accuracy
KW  - South Korea
KW  - validation process
KW  - Occupational accident
KW  - construction work
KW  - Occupational diseases
KW  - Occupational injury
KW  - health care policy
KW  - humidity
KW  - Occupational accident types
KW  - precipitation
KW  - Real-time construction
KW  - seasonal variation
ER  - 

TY  - JOUR
TI  - A Big Data Analytics Method for the Evaluation of Ship - Ship Collision Risk reflecting Hydrometeorological Conditions
AU  - Zhang, MY
AU  - Montewka, J
AU  - Manderbacka, T
AU  - Kujala, P
AU  - Hirdaris, S
T2  - RELIABILITY ENGINEERING & SYSTEM SAFETY
AB  - This paper presents a big data analytics method for the evaluation of ship-ship collision risk in real operational conditions. The approach makes use of big data from Automatic Identification System (AIS) and nowcast data corresponding to time-dependent traffic situations and hydro-meteorological conditions respectively. An Avoidance Behavior-based Collision Detection Model (ABCD-M) is introduced to identify potential collision scenarios and Collision Risk Indices (CRIs) are quantified when evasive actions are taken for each detected collision scenario in various voyages. The method is applied on Ro-Pax ships operating over 13 months of the ice-free period in the Gulf of Finland. Results indicate that collision risk estimates may be extremely diverse among voyages, and in 97.5% of potential collision scenarios the evasive actions are triggered only when risk is at 45% or more of its maximum value. The overall CRI for ships operating over the given area tends to be lower for adverse hydro-meteorological conditions. It is therefore concluded that the proposed method may assist with the (1) identification of critical scenarios in various voyages not currently accounted for by existing accident databases, (2) definition of commonly agreed risk criteria to set off alarms, (3) the estimation of risk profile over the life cycle of fleet operations.
DA  - 2021/09//undefined
PY  - 2021
DO  - 10.1016/j.ress.2021.107674
VL  - 213
SN  - 0951-8320
AN  - WOS:000663910500017
KW  - Machine learning
KW  - Automation
KW  - Learning systems
KW  - Data analytics
KW  - Fleet operations
KW  - Machine-learning
KW  - Risk perception
KW  - Big data
KW  - Life cycle
KW  - Advanced Analytics
KW  - Analytic method
KW  - Big data analytics
KW  - Collision
KW  - Collision risks
KW  - Collision scenarios
KW  - Collisions
KW  - Data Analytics
KW  - Gulf of Finland
KW  - Maritime operation
KW  - Maritime operations
KW  - Ship collision
KW  - Ship safety
KW  - Ships
ER  - 

TY  - JOUR
TI  - Alignment-Free Sequence Comparison: A Systematic Survey From a Machine Learning Perspective
AU  - Bohnsack, KS
AU  - Kaden, M
AU  - Abel, J
AU  - Villmann, T
T2  - IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS
AB  - The encounter of large amounts of biological sequence data generated during the last decades and the algorithmic and hardware improvements have offered the possibility to apply machine learning techniques in bioinformatics. While the machine learning community is aware of the necessity to rigorously distinguish data transformation from data comparison and adopt reasonable combinations thereof, this awareness is often lacking in the field of comparative sequence analysis. With realization of the disadvantages of alignments for sequence comparison, some typical applications use more and more so-called alignment-free approaches. In light of this development, we present a conceptual framework for alignment-free sequence comparison, which highlights the delineation of: 1) the sequence data transformation comprising of adequate mathematical sequence coding and feature generation, from 2) the subsequent (dis-)similarity evaluation of the transformed data by means of problem-specific but mathematically consistent proximity measures. We consider coding to be an information-loss free data transformation in order to get an appropriate representation, whereas feature generation is inevitably information-lossy with the intention to extract just the task-relevant information. This distinction sheds light on the plethora of methods available and assists in identifying suitable methods in machine learning and data analysis to compare the sequences under these premises.
DA  - 2023/01//undefined
PY  - 2023
DO  - 10.1109/TCBB.2022.3140873
VL  - 20
IS  - 1
SP  - 119
EP  - 135
SN  - 1545-5963
AN  - WOS:001013148100010
KW  - machine learning
KW  - Machine learning
KW  - Task analysis
KW  - Hardware
KW  - Machine learning algorithms
KW  - Machine Learning
KW  - Learning systems
KW  - Data handling
KW  - Algorithms
KW  - Job analysis
KW  - Learning algorithms
KW  - Machine-learning
KW  - algorithm
KW  - sequence analysis
KW  - Bioinformatics
KW  - Metadata
KW  - sequence alignment
KW  - Sequence Alignment
KW  - Systematic
KW  - feature generation
KW  - Feature generation
KW  - Mathematics
KW  - Alignment-free sequence comparison
KW  - data transformation
KW  - Datum transformation
KW  - mathematics
KW  - Proximity measure
KW  - proximity measures
KW  - Sequence Analysis
KW  - Systematisation
KW  - systematization
ER  - 

TY  - JOUR
TI  - Beat alignment ability is associated with formal musical training not current music playing
AU  - Spiech, C
AU  - Endestad, T
AU  - Laeng, B
AU  - Danielsen, A
AU  - Haghish, EF
T2  - FRONTIERS IN PSYCHOLOGY
AB  - The ability to perceive the beat in music is crucial for both music listeners and players with expert musicians being notably skilled at noticing fine deviations in the beat. However, it is unclear whether this beat perception ability is enhanced in trained musicians who continue to practice relative to musicians who no longer play. Thus, we investigated this by comparing active musicians', inactive musicians', and nonmusicians' beat alignment ability scores on the Computerized Adaptive Beat Alignment Test (CA-BAT). 97 adults with diverse musical experience participated in the study, reporting their years of formal musical training, number of instruments played, hours of weekly music playing, and hours of weekly music listening, in addition to their demographic information. While initial tests between groups indicated active musicians outperformed inactive musicians and nonmusicians on the CA-BAT, a generalized linear regression analysis showed that there was no significant difference once differences in musical training had been accounted for. To ensure that our results were not impacted by multicollinearity between music-related variables, nonparametric and nonlinear machine learning regressions were employed and confirmed that years of formal musical training was the only significant predictor of beat alignment ability. These results suggest that expertly perceiving fine differences in the beat is not a use-dependent ability that degrades without regular maintenance through practice or musical engagement. Instead, better beat alignment appears to be associated with more musical training regardless of continued use.
DA  - 2023/01/30/
PY  - 2023
DO  - 10.3389/fpsyg.2023.1034561
VL  - 14
SN  - 1664-1078
AN  - WOS:001060699400001
KW  - machine learning
KW  - active musicians
KW  - beat alignment
KW  - beat perception
KW  - inactive musicians
KW  - musical training
KW  - nonmusicians
ER  - 

TY  - JOUR
TI  - Distributed Privacy-Preserving Collaborative Intrusion Detection Systems for VANETs
AU  - Zhang, T
AU  - Zhu, QY
T2  - IEEE TRANSACTIONS ON SIGNAL AND INFORMATION PROCESSING OVER NETWORKS
AB  - Vehicular ad hoc network (VANET) is an enabling technology in modern transportation systems for providing safety and valuable information, and yet vulnerable to a number of attacks from passive eavesdropping to active interfering. Intrusion detection systems (IDSs) are important devices that can mitigate the threats by detecting malicious behaviors. Furthermore, the collaborations among vehicles in VANETs can improve the detection accuracy by communicating their experiences between nodes. To this end, distributed machine learning is a suitable framework for the design of scalable and implementable collaborative detection algorithms over VANETs. One fundamental barrier to collaborative learning is the privacy concern as nodes exchange data among them. A malicious node can obtain sensitive information of other nodes by inferring from the observed data. In this paper, we propose a privacy-preserving machine-learning based collaborative IDS (PML-CIDS) for VANETs. The proposed algorithm employs the alternating direction method of multipliers to a class of empirical risk minimization problems and trains a classifier to detect the intrusions in the VANETs. We use the differential privacy to capture the privacy notation of the PML-CIDS and propose amethod of dual-variable perturbation to provide dynamic differential privacy. We analyze theoretical performance and characterize the fundamental tradeoff between the security and privacy of the PML-CIDS. We also conduct numerical experiments using the network security laboratory-knowledge discovery and data mining (NSL-KDD) dataset to corroborate the results on the detection accuracy, security-privacy tradeoffs, and design.
DA  - 2018/03//undefined
PY  - 2018
DO  - 10.1109/TSIPN.2018.2801622
VL  - 4
IS  - 1
SP  - 148
EP  - 161
SN  - 2373-776X
AN  - WOS:000426036000013
KW  - machine learning
KW  - Vehicular ad hoc networks
KW  - Artificial intelligence
KW  - Vehicle safety
KW  - Data mining
KW  - Intrusion detection
KW  - Learning systems
KW  - Network security
KW  - Safety engineering
KW  - Computer crime
KW  - data processing
KW  - Data privacy
KW  - Distributed computer systems
KW  - vehicle safety
KW  - Alternating direction method of multipliers
KW  - Distributed machine learning
KW  - network security
KW  - Differential privacies
KW  - differential privacy
KW  - distributed computing
KW  - ADMM
KW  - Data processing
KW  - Empirical risk minimization
KW  - Collaborative intrusion detection system
KW  - Detecting malicious behaviors
KW  - vehicular ad hoc networks
ER  - 

TY  - CONF
TI  - Human Safety Devices using IoT and Machine Learning: A Review
AU  - Sharma, K
AU  - Londhe, DD
AU  - IEEE
T2  - 2018 3RD INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT)
AB  - Human safety has become one of the most targeted field for the researchers, owning it to its grave importance and the increased competition in the market for human safety gadgets. Hundreds and thousands of human safety devices (HSD) are being developed because of the rapid advancement in the field of Internet of things (IoT) that involve sensing technologies, embedded systems, wireless communication technologies, variety of sensors etc. An essential function of these devices is human activity recognition (HAR).Present human safety devices continuously track human activities with the help of sensors and track down any unusual activity by performing sensor data analysis (SDA)using machine learning (ML) algorithms. This paper aims at reviewing the latest reported systems for human safety and listing down the various sensors that can be used in human safety devices to detect unusual activities along with the machine learning algorithms that are used for the sensor data analysis.
DA  - 2018///
PY  - 2018
SN  - 978-1-5386-4273-3
AN  - WOS:000519596600025
KW  - machine learning
KW  - Artificial intelligence
KW  - Pattern recognition
KW  - sensors
KW  - Learning systems
KW  - Data handling
KW  - Internet of things
KW  - Learning algorithms
KW  - Safety devices
KW  - Embedded systems
KW  - Information analysis
KW  - Sensors
KW  - Human activity recognition
KW  - IoT
KW  - Human safety
KW  - Internet of Things (IOT)
KW  - Wireless telecommunication systems
KW  - Human activities
KW  - Sensing technology
KW  - human activity recognition
KW  - human safety devices
KW  - sensor data analysis
KW  - Sensor data analysis
KW  - Wireless communication technology
ER  - 

TY  - JOUR
TI  - Efficient matching of very complex time series
AU  - Boucheham, B
T2  - INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
AB  - We propose a novel method (FANSEA) that performs very complex time series matching. The matching here includes comparison and alignment of time series, for diverse needs: diagnosis, clustering, retrieval, mining, etc. The complexity stands in the fact that the method is able to match quasi-periodic time series, that are eventually phase shifted, of different lengths, composed of different number of periods, characterized by local morphological changes and that might be shifted scaled on the time/magnitude axis. This is the most complex case that can occur in time series matching. The efficiency stands in the fact that the newly developed FANSEA method produces alignments that are comparable to those of the previously published SEA method. However and as a result of data reduction, FANSEA consumes much less time and data; hence, allowing for faster matching and lower storage space. Basically, FANSEA is composed of two main steps: Data reduction by curve simplification of the time series traces and matching through exchange of extracted signatures between the time series under process. Due to the quasi-periodic nature of the electrocardiogram (ECG), the tests were conducted on records selected from the Massachusetts Institute of Technology-Beth Israel Hospital database (MIT-BIH). Numerically, the new method data reduction was up to 80 % and the time reduction was up to 95 %. Accordingly and among many possible applications, the new method is very suitable for searching, querying and mining of large time series databases.
DA  - 2013/10//undefined
PY  - 2013
DO  - 10.1007/s13042-012-0117-5
VL  - 4
IS  - 5
SP  - 537
EP  - 550
SN  - 1868-8071
AN  - WOS:000209204300012
KW  - Machine learning
KW  - Data mining
KW  - Learning systems
KW  - Query processing
KW  - Data reduction
KW  - Digital storage
KW  - Electrocardiography
KW  - Time series
KW  - Alignment
KW  - Pattern matching
KW  - Complex time series
KW  - Curve simplification
KW  - Data retrieval
KW  - Large time series database
KW  - Morphological changes
KW  - Quasi-periodic
KW  - Series alignments
KW  - Time reduction
KW  - Time series alignment
ER  - 

TY  - JOUR
TI  - Machine Learning Techniques Supplementing Conventional Data Analytics to Identify Cohorts of Women with Screen Detected Breast Cancer Who May Safely Avoid Axillary Surgery
AU  - Farshid, G
AU  - Whitfield, R
AU  - Bochner, M
AU  - Edwards, S
AU  - Pradhan, M
T2  - MODERN PATHOLOGY
DA  - 2020/03//undefined
PY  - 2020
VL  - 33
IS  - SUPPL 2
SP  - 138
EP  - 139
SN  - 0893-3952
AN  - WOS:000518328900154
ER  - 

TY  - JOUR
TI  - A Safe Driving Decision-Making Methodology Based on Cascade Imitation Learning Network for Automated Commercial Vehicles
AU  - Hu, WM
AU  - Li, X
AU  - Hu, JC
AU  - Kong, D
AU  - Hu, Y
AU  - Xu, QM
AU  - Liu, Y
AU  - Song, X
AU  - Dong, X
T2  - IEEE SENSORS JOURNAL
AB  - Safe driving decision-making is particularly important for automated commercial vehicles (ACVs). Small passenger vehicles pay more attention to collision prevention, while commercial vehicles with a longer brake distance and worse roll stability need to consider both anti-collision and anti-rollover. The widely studied driving decision-making methods for small passenger vehicles cannot be simply and directly applied to commercial vehicles. This article proposes a safe driving decision-making methodology based on a cascade imitation learning network (CILN). The CILN integrates two parts, namely, the supervised learning part and the imitation learning part. The first part learns safe driving maneuvers extracted from naturalistic vehicle sensor data. Through sensor data processing, it develops decision-making at a humanoid level, such as avoiding jerky driving actions. In the second part, generative adversarial imitation learning (GAIL) is introduced to further learn safe driving decisions under conditions prone to collision and rollover. Finally, both highD dataset and simulation of urban mobility (SUMO) are used to train and verify the performance of the CILN. By comparing the evaluation indicators of time to collision (TTC), reverse TTC (RTTC), deceleration rate to avoid the crash (DRAC), distance headway, and lateral acceleration, the CILN outperforms the other decision-making algorithms. Experimental results show that the CILN can provide safe driving decision-making and ensure the driving safety of ACVs in dense traffic flow.
DA  - 2023/06/01/
PY  - 2023
DO  - 10.1109/JSEN.2023.3256704
VL  - 23
IS  - 11
SP  - 11285
EP  - 11295
SN  - 1530-437X
AN  - WOS:001003468000017
ER  - 

TY  - JOUR
TI  - Design and Implementation of a Smart Home System Using Multisensor Data Fusion Technology
AU  - Hsu, YL
AU  - Chou, PH
AU  - Chang, HC
AU  - Lin, SL
AU  - Yang, SC
AU  - Su, HY
AU  - Chang, CC
AU  - Cheng, YS
AU  - Kuo, YC
T2  - SENSORS
AB  - This paper aims to develop a multisensor data fusion technology-based smart home system by integrating wearable intelligent technology, artificial intelligence, and sensor fusion technology. We have developed the following three systems to create an intelligent smart home environment: (1) a wearable motion sensing device to be placed on residents' wrists and its corresponding 3D gesture recognition algorithm to implement a convenient automated household appliance control system; (2) a wearable motion sensing device mounted on a resident's feet and its indoor positioning algorithm to realize an effective indoor pedestrian navigation system for smart energy management; (3) a multisensor circuit module and an intelligent fire detection and alarm algorithm to realize a home safety and fire detection system. In addition, an intelligent monitoring interface is developed to provide in real-time information about the smart home system, such as environmental temperatures, CO concentrations, communicative environmental alarms, household appliance status, human motion signals, and the results of gesture recognition and indoor positioning. Furthermore, an experimental testbed for validating the effectiveness and feasibility of the smart home system was built and verified experimentally. The results showed that the 3D gesture recognition algorithm could achieve recognition rates for automated household appliance control of 92.0%, 94.8%, 95.3%, and 87.7% by the 2-fold cross-validation, 5-fold cross-validation, 10-fold cross-validation, and leave-one-subject-out cross-validation strategies. For indoor positioning and smart energy management, the distance accuracy and positioning accuracy were around 0.22% and 3.36% of the total traveled distance in the indoor environment. For home safety and fire detection, the classification rate achieved 98.81% accuracy for determining the conditions of the indoor living environment.
DA  - 2017/07//undefined
PY  - 2017
DO  - 10.3390/s17071631
VL  - 17
IS  - 7
SN  - 1424-8220
AN  - WOS:000407517600170
ER  - 

TY  - JOUR
TI  - Anomaly Score-Based Risk Early Warning System for Rapidly Controlling Food Safety Risk
AU  - Zuo, EG
AU  - Du, XS
AU  - Aysa, A
AU  - Lv, XY
AU  - Muhammat, M
AU  - Zhao, YX
AU  - Ubul, K
T2  - FOODS
AB  - Food safety is a high-priority issue for all countries. Early warning analysis and risk control are essential for food safety management practices. This paper innovatively proposes an anomaly score-based risk early warning system (ASRWS) via an unsupervised auto-encoder (AE) for the effective early warning of detection products, which classifies qualified and unqualified products by reconstructing errors. The early warning analysis of qualified samples is carried out by early warning thresholds. The proposed method is applied to a batch of dairy product testing data from a Chinese province. Extensive experimental results show that the unsupervised anomaly detection model AE can effectively analyze the dairy product testing data, with a prediction accuracy and fault detection rate of 0.9954 and 0.9024, respectively, within only 0.54 s. We provided an early warning threshold-based method to conduct the risk analysis, and then a panel of food safety experts performed a risk revision on the prediction results produced by the proposed method. In this way, AI improves the panel's efficiency, whereas the panel enhances the model's reliability. This study provides a fast and cost-effective, food safety early warning method for detection data and assists market supervision departments in controlling food safety risk.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.3390/foods11142076
VL  - 11
IS  - 14
SN  - 2304-8158
AN  - WOS:000831816000001
KW  - machine learning
KW  - anomaly detection
KW  - auto-encoder
KW  - detection data
KW  - food safety risk early warning
ER  - 

TY  - CONF
TI  - Safe-DS: A Domain Specific Language to Make Data Science Safe
AU  - Reimann, L
AU  - Kniesel-Wünsche, G
T2  - 2023 IEEE/ACM 45TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING-NEW IDEAS AND EMERGING RESULTS, ICSE-NIER
AB  - Due to the long runtime of Data Science (DS) pipelines, even small programming mistakes can be very costly, if they are not detected statically. However, even basic static type checking of DS pipelines is difficult because most are written in Python. Static typing is available in Python only via external linters. These require static type annotations for parameters or results of functions, which many DS libraries do not provide.
In this paper, we show how the wealth of Python DS libraries can be used in a statically safe way via Safe-DS, a domain specific language (DSL) for DS. Safe-DS catches conventional type errors plus errors related to range restrictions, data manipulation, and call order of functions, going well beyond the abilities of current Python linters. Python libraries are integrated into Safe-DS via a stub language for specifying the interface of its declarations, and an API-Editor that is able to extract type information from the code and documentation of Python libraries, and automatically generate suitable stubs.
Moreover, Safe-DS complements textual DS pipelines with a graphical representation that eases safe development by preventing syntax errors. The seamless synchronization of textual and graphic view lets developers always choose the one best suited for their skills and current task.
We think that Safe-DS can make DS development easier, faster, and more reliable, significantly reducing development costs.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICSE-NIER58687.2023.00019
SP  - 72
EP  - 77
SN  - 2832-7624
AN  - WOS:001032816400013
KW  - Machine learning
KW  - Machine Learning
KW  - Pipelines
KW  - Machine-learning
KW  - 'current
KW  - Errors
KW  - Application programming interfaces (API)
KW  - Python
KW  - Libraries
KW  - Runtimes
KW  - Object oriented programming
KW  - Data Science
KW  - Domain Specific Language
KW  - Domains specific languages
KW  - Problem oriented languages
KW  - Refined type
KW  - Refined Types
KW  - Schema type
KW  - Schema Types
KW  - Science libraries
KW  - Static safety
KW  - Static Safety
KW  - Static type checking
KW  - Static typing
ER  - 

TY  - CONF
TI  - Curating Datasets for Visual Runway Detection
AU  - Lindén, J
AU  - Forsberg, H
AU  - Haddad, J
AU  - Tagebrand, E
AU  - Cedernaes, E
AU  - Ek, EG
AU  - Daneshtalab, M
AU  - IEEE
T2  - 2021 IEEE/AIAA 40TH DIGITAL AVIONICS SYSTEMS CONFERENCE (DASC)
AB  - In Machine Learning systems, several factors impact the performance of a trained model. The most important ones include model architecture, the amount of training time, the dataset size and diversity. In the realm of safety-critical machine learning the used datasets need to reflect the environment in which the system is intended to operate, in order to minimize the generalization gap between trained and real-world inputs. Datasets should be thoroughly prepared and requirements on the properties and characteristics of the collected data need to be specified. In our work we present a case study in which generating a synthetic dataset is accomplished based on real-world flight data from the ADS-B system, containing thousands of approaches to several airports to identify real-world statistical distributions of relevant variables to vary within our dataset sampling space. We also investigate what the effects are of training a model on synthetic data to different extents, including training on translated image sets (using domain adaptation). Our results indicate airport location to be the most critical parameter to vary. We also conclude that all experiments did benefit in performance from pre-training on synthetic data rather than using only real data, however this did not hold true in general for domain adaptation-translated images.
DA  - 2021///
PY  - 2021
DO  - 10.1109/DASC52595.2021.9594400
SN  - 2155-7195
AN  - WOS:000739652600102
KW  - machine learning
KW  - domain adaptation
KW  - Deep neural networks
KW  - Performance
KW  - Real-world
KW  - Safety engineering
KW  - Sampling
KW  - Machine learning systems
KW  - Synthetic data
KW  - Domain adaptation
KW  - Generalisation
KW  - Dataset
KW  - Training time
KW  - safety-critical
KW  - dataset
KW  - Avionics
KW  - synthetic data
KW  - avionics
KW  - Data set size
KW  - deep neural networks
KW  - Modeling architecture
ER  - 

TY  - JOUR
TI  - The evaluation of wastewater treatment plant performance: a data mining approach
AU  - Aldaghi, T
AU  - Javanmard, S
T2  - JOURNAL OF ENGINEERING DESIGN AND TECHNOLOGY
AB  - Purpose This paper aims to evaluate the performance of the Mashhad No. 5 wastewater treatment plant (WWTP) using a combination of data mining (regression) algorithms and artificial neural networks. Design/methodology/approach In this research, the performance of WWTP located in Mashhad, Iran, has been evaluated using two data mining models, neural network and regression model. Findings The proposed model has the potential of implementing in other WWTPs in Iran or other countries. Originality/value The authors would also like to thank Mashhad No.5 WWTP for data access.
DA  - 2021/10/28/
PY  - 2021
DO  - 10.1108/JEDT-07-2021-0394
SN  - 1726-0531
AN  - WOS:000713111400001
ER  - 

TY  - JOUR
TI  - Code-Aligned Autoencoders for Unsupervised Change Detection in Multimodal Remote Sensing Images
AU  - Luppino, LT
AU  - Hansen, MA
AU  - Kampffmeyer, M
AU  - Bianchi, FM
AU  - Moser, G
AU  - Jenssen, R
AU  - Anfinsen, SN
T2  - IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
AB  - Image translation with convolutional autoencoders has recently been used as an approach to multimodal change detection (CD) in bitemporal satellite images. A main challenge is the alignment of the code spaces by reducing the contribution of change pixels to the learning of the translation function. Many existing approaches train the networks by exploiting supervised information of the change areas, which, however, is not always available. We propose to extract relational pixel information captured by domain-specific affinity matrices at the input and use this to enforce alignment of the code spaces and reduce the impact of change pixels on the learning objective. A change prior is derived in an unsupervised fashion from pixel pair affinities that are comparable across domains. To achieve code space alignment, we enforce pixels with similar affinity relations in the input domains to be correlated also in code space. We demonstrate the utility of this procedure in combination with cycle consistency. The proposed approach is compared with the state-of-the-art machine learning and deep learning algorithms. Experiments conducted on four real and representative datasets show the effectiveness of our methodology.
DA  - 2022/05/12/
PY  - 2022
DO  - 10.1109/TNNLS.2022.3172183
SN  - 2162-237X
AN  - WOS:000795121800001
KW  - Deep learning
KW  - deep learning
KW  - Training
KW  - Learning algorithms
KW  - Synthetic aperture radar
KW  - Decoding
KW  - Remote sensing
KW  - Space optics
KW  - Alignment
KW  - Tensors
KW  - Pixels
KW  - Heterogeneous data
KW  - Code
KW  - Auto encoders
KW  - Remote-sensing
KW  - Image-analysis
KW  - Codes (symbols)
KW  - Codes
KW  - Affinity matrix
KW  - Aligned autoencoder
KW  - aligned autoencoders
KW  - heterogeneous data
KW  - image regression
KW  - Image regression
KW  - Multimodal image analyse
KW  - multimodal image analysis
KW  - Multimodal images
KW  - Space-based radar
KW  - Unsupervised change detection
KW  - Unsupervised change detection .
KW  - unsupervised change detection (CD).
ER  - 

TY  - JOUR
TI  - Unsupervised Doppler Radar Based Activity Recognition for e-Healthcare
AU  - Karayaneva, Y
AU  - Sharifzadeh, S
AU  - Li, WD
AU  - Jing, YG
AU  - Tan, B
T2  - IEEE ACCESS
AB  - Passive radio frequency (RF) sensing and monitoring of human daily activities in elderly care homes is an emerging topic. Micro-Doppler radars are an appealing solution considering their non-intrusiveness, deep penetration, and high-distance range. Unsupervised activity recognition using Doppler radar data has not received attention, in spite of its importance in case of unlabelled or poorly labelled activities in real scenarios. This study proposes two unsupervised feature extraction methods for the purpose of human activity monitoring using Doppler-streams. These include a local Discrete Cosine Transform (DCT)-based feature extraction method and a local entropy-based feature extraction method. In addition, a novel application of Convolutional Variational Autoencoder (CVAE) feature extraction is employed for the first time for Doppler radar data. The three feature extraction architectures are compared with the previously used Convolutional Autoencoder (CAE) and linear feature extraction based on Principal Component Analysis (PCA) and 2DPCA. Unsupervised clustering is performed using K-Means and K-Medoids. The results show the superiority of DCT-based method, entropy-based method, and CVAE features compared to CAE, PCA, and 2DPCA, with more than 5%-20% average accuracy. In regards to computation time, the two proposed methods are noticeably much faster than the existing CVAE. Furthermore, for high-dimensional data visualisation, three manifold learning techniques are considered. The methods are compared for the projection of raw data as well as the encoded CVAE features. All three methods show an improved visualisation ability when applied to the encoded CVAE features.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3074088
VL  - 9
SP  - 62984
EP  - 63001
SN  - 2169-3536
AN  - WOS:000645860000001
KW  - Feature extraction
KW  - Visualization
KW  - Learning systems
KW  - Convolution
KW  - Data visualization
KW  - Extraction
KW  - Entropy
KW  - unsupervised learning
KW  - data visualization
KW  - K-means clustering
KW  - Activity recognition
KW  - health and safety
KW  - Discrete cosine transforms
KW  - Unsupervised clustering
KW  - High dimensional data
KW  - DCT analysis
KW  - Discrete Cosine Transform(DCT)
KW  - Doppler radar
KW  - Entropy-based methods
KW  - Feature extraction methods
KW  - Human Activity Monitoring
KW  - Linear feature extraction
ER  - 

TY  - JOUR
TI  - Robustness and Adaptability of Reinforcement Learning-Based Cooperative Autonomous Driving in Mixed-Autonomy Traffic
AU  - Valiente, R
AU  - Toghi, B
AU  - Pedarsani, R
AU  - Fallah, YP
T2  - IEEE OPEN JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS
AB  - Building autonomous vehicles (AVs) is a complex problem, but enabling them to operate in the real world where they will be surrounded by human-driven vehicles (HVs) is extremely challenging. Prior works have shown the possibilities of creating inter-agent cooperation between a group of AVs that follow a social utility. Such altruistic AVs can form alliances and affect the behavior of HVs to achieve socially desirable outcomes. We identify two major challenges in the co-existence of AVs and HVs. First, social preferences and individual traits of a given human driver, e.g., selflessness and aggressiveness are unknown to an AV, and it is almost impossible to infer them in real-time during a short AV-HV interaction. Second, contrary to AVs that are expected to follow a policy, HVs do not necessarily follow a stationary policy and therefore are extremely hard to predict. To alleviate the above-mentioned challenges, we formulate the mixed-autonomy problem as a multi-agent reinforcement learning (MARL) problem and propose a decentralized framework and reward function for training cooperative AVs. Our approach enables AVs to learn the decision-making of HVs implicitly from experience, optimizes for a social utility while prioritizing safety and allowing adaptability; robustifying altruistic AVs to different human behaviors and constraining them to a safe action space. Finally, we investigate the robustness, safety and sensitivity of AVs to various HVs behavioral traits and present the settings in which the AVs can learn cooperative policies that are adaptable to different situations.
DA  - 2022///
PY  - 2022
DO  - 10.1109/OJITS.2022.3172981
VL  - 3
SP  - 397
EP  - 410
SN  - 2687-7813
AN  - WOS:000795103000002
ER  - 

TY  - JOUR
TI  - The Many Facets of Data Equity
AU  - Jagadish, H
AU  - Stoyanovich, J
AU  - Howe, B
T2  - ACM JOURNAL OF DATA AND INFORMATION QUALITY
AB  - Data-driven systems can induce, operationalize, and amplify systemic discrimination in a variety of ways. As data scientists, we tend to prefer to isolate and formalize equity problems to make them amenable to narrow technical solutions. However, this reductionist approach is inadequate in practice. In this article, we attempt to address data equity broadly, identify different ways in which it is manifest in data-driven systems, and propose a research agenda.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1145/3533425
VL  - 14
IS  - 4
SN  - 1936-1955
AN  - WOS:000934494600006
ER  - 

TY  - CONF
TI  - Responsible Data Integration: Next-generation Challenges
AU  - Nargesian, F
AU  - Asudeh, A
AU  - Jagadish, HV
AU  - ACM
T2  - PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA (SIGMOD '22)
AB  - Data integration has been extensively studied by the data management community and is a core task in the data pre-processing step of ML pipelines. When the integrated data is used for analysis and model training, responsible data science requires addressing concerns about data quality and bias. We present a tutorial on data integration and responsibility, highlighting the existing efforts in responsible data integration along with research opportunities and challenges. In this tutorial, we encourage the community to audit data integration tasks with responsibility measures and develop integration techniques that optimize the requirements of responsible data science. We focus on three critical aspects: (1) the requirements to be considered for evaluating and auditing data integration tasks for quality and bias; (2) the data integration tasks that elicit attention to data responsibility measures and methods to satisfy these requirements; and, (3) techniques, tasks, and open problems in data integration that help achieve data responsibility.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3514221.3522567
SP  - 2458
EP  - 2464
SN  - 0730-8078
AN  - WOS:000852705400194
ER  - 

TY  - JOUR
TI  - Open Set Domain Adaptation via Instance Affinity Metric and Fine-Grained Alignment for Remote Sensing Scene Classification
AU  - Niu, B
AU  - Pan, ZX
AU  - Chen, KY
AU  - Hu, YX
AU  - Lei, B
T2  - IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
AB  - In the practical application of remote sensing scene classification (RSSC), domain adaptation is introduced to handle the situation where the distribution of training data (source) and test data (target) is different. Compared to general domain adaptation, open set domain adaptation (OSDA) is suitable for more realistic situations where there are additional unknown classes in the target domain. The key to solving this problem is to separate unknown samples from target data to avoid negative transfer caused by mismatching unknown/known samples. In this letter, we propose a novel and effective method, named instance affinity metric-based fine-grained adaptation network (IAFAN), for OSDA in RSSC. Concretely, an unknown sample separation (USS) mechanism based on the instance affinity-aware matrix is pioneeringly proposed to endow the model with the ability to distinguish unknown samples. In addition, considering the high interclass similarity and rich intraclass diversity of remote sensing images, we introduce the sample discriminability enhancement (SDE) loss to further increase the interclass distance and narrow the intraclass difference, thereby alleviating the negative transfer caused by sample misclassification and mismatching. In the feature confusion stage, we specially design Mask-mmd for OSDA as an adaptation metric to conduct semantic fine-grained cross-domain alignment of known samples while keeping unknown samples out of alignment, which avoids negative transfer during the adaptation process. Finally, we evaluate IAFAN on transfer tasks between different public remote sensing datasets, and the results verify that our method significantly outperforms previous methods in RSSC.
DA  - 2023///
PY  - 2023
DO  - 10.1109/LGRS.2023.3276968
VL  - 20
SN  - 1545-598X
AN  - WOS:001000622900001
ER  - 

TY  - CONF
TI  - Adversarial Training on Joint Energy Based Model for Robust Classification and Out-of-Distribution Detection
AU  - Lee, K
AU  - Yang, H
AU  - Oh, SY
T2  - 2020 20TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS)
AB  - Deep neural networks tend to be erroneous when the training and test distribution differ. Especially, neural classifiers are brittle to adversarial examples, and highly overconfident to out-of-distribution examples. Hybrid modeling of generative and discriminative distribution shown to be effective for out-of-distribution detection, but is not robust to adversarial attacks. Otherwise, defense methods for adversarial attacks cannot distinguish out-of-distribution examples. In this work, we present a hybrid model that can deal with both adversarial and out-of-distribution examples. Our method is built upon the joint energy based model and adversarial training. Through experiments on CIFAR-10 dataset, we show that our method has state-of-the-art performanced among hybrid models. Furthermore, we show that our model exhibits more perceptually-aligned feature than other methods, by showing the gradient sensitivity map with newly proposed score function.
DA  - 2020///
PY  - 2020
DO  - 10.23919/iccas50221.2020.9268406
SP  - 17
EP  - 21
SN  - 2093-7121
AN  - WOS:000681746000004
KW  - Deep learning
KW  - Deep neural networks
KW  - State of the art
KW  - Control engineering
KW  - Adversarial attack
KW  - Robust classification
KW  - Hybrid model
KW  - Out-of-distribution detection
KW  - Energy-based models
KW  - Gradient sensitivity
KW  - Machine vision and perception
KW  - Neural classifiers
KW  - Score function
KW  - Security and safety of deep learning
ER  - 

TY  - CONF
TI  - Classification of CSR Using Latent Dirichlet Allocation and Analysis of the Relationship Between CSR and Corporate Value
AU  - Uekado, K
AU  - Feng, L
AU  - Suzuki, M
AU  - Ohwada, H
T2  - KNOWLEDGE MANAGEMENT AND ACQUISITION FOR INTELLIGENT SYSTEMS (PKAW 2018)
A2  - Yoshida, K
A2  - Lee, M
AB  - Corporate social responsibility (CSR) is a business approach that aims to help address social or environmental problems. Many researchers conducted empirical research to identify the relationship between CSR activities and corporate value. Some researchers explain that CSR is positively correlated with corporate value, others explain that CSR is negatively correlated with corporate value. This disagreement among the researchers has arisen because CSR standards are ambiguous. Therefore, we use topic classification to create a CSR standard. We rank the CSR activities. Our approach involves two steps. First, a CSR standard is constructed using a topic model from CSR reports. Second, the CSR rankings are calculated by using a random forest to calculate the importance of features related to CSR activities. The results show a new CSR standard. Topics represents activities related to reducing CO2 emissions or diversity promotion, however it is not helpful to consider too many topics: with more topics, more unrelated topics appear. CSR rankings show that medical activities have the strongest relationship with corporate value.
DA  - 2018///
PY  - 2018
DO  - 10.1007/978-3-319-97289-3_21
VL  - 11016
SP  - 261
EP  - 270
SN  - 0302-9743
AN  - WOS:000492876100021
KW  - Decision trees
KW  - Machine learning
KW  - Data mining
KW  - Intelligent systems
KW  - Learning systems
KW  - Topic Modeling
KW  - Knowledge acquisition
KW  - Statistics
KW  - Corporate social responsibility
KW  - Knowledge management
KW  - Latent Dirichlet allocation
KW  - Environmental problems
KW  - Corporate social responsibilities (CSR)
KW  - Corporate values
KW  - Empirical research
KW  - Latent Diriclet allocation
KW  - Topic classification
KW  - Topic Classification
ER  - 

TY  - JOUR
TI  - A modular extreme learning machine with linguistic interpreter and accelerated chaotic distributor for evaluating the safety of robot maneuvers in laparoscopic surgery
AU  - Mozaffari, A
AU  - Behzadipour, S
T2  - NEUROCOMPUTING
AB  - In this investigation, a systematic sequential intelligent system is proposed to provide the surgeon with an estimation of the state of the tool-tissue interaction force in laparoscopic surgery. To train the proposed intelligent system, a 3D model of an in vivo porcine liver was built for different probing tasks. To capture the required knowledge, three different geometric features, i.e. Y displacement of the nodes on the upper surface and slopes on the closest node to the deforming area of the upper edge in both X-Y and Z-Y planes, were extracted experimentally. The numerical simulations are conducted in three independent successive stages. At the first step, a well-known partition-based clustering technique called accelerated chaotic particle swarm optimization (ACPSO) is used to cluster the information of database into a number of partitions. Thereafter, a modular extreme learning machine (M-ELM) is used to model the characteristics of each cluster. Finally, the output of M-ELM is fed to a Mamdani fuzzy inference system (MFIS) to interpret the safety of robot maneuvers in laparoscopic surgery. The proposed intelligent framework is used for real-time applications so that the surgeon can adjust the movements of the robot to avoid operational hazards. Based on a rigor comparative study, it is indicated that not only the proposed intelligent technique can effectively handle the considered problem but also is a reliable alternative to physical sensors and measurement tools. (C) 2014 Elsevier B.V. All rights reserved.
DA  - 2015/03/05/
PY  - 2015
DO  - 10.1016/j.neucom.2014.10.003
VL  - 151
SP  - 913
EP  - 932
SN  - 0925-2312
AN  - WOS:000347753500043
KW  - machine learning
KW  - Machine learning
KW  - Intelligent systems
KW  - robotics
KW  - Article
KW  - intelligence
KW  - computer simulation
KW  - equipment design
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - mathematical computing
KW  - Intelligent robots
KW  - linguistics
KW  - Surgery
KW  - Surgical equipment
KW  - Clustering
KW  - liver
KW  - Fuzzy inference
KW  - process optimization
KW  - Fuzzy systems
KW  - Particle swarm optimization (PSO)
KW  - System identification
KW  - fuzzy system
KW  - Robotic surgery
KW  - Tissue
KW  - Fuzzy inference system
KW  - Fuzzy inference systems
KW  - Medical robotics
KW  - Identification (control systems)
KW  - three dimensional imaging
KW  - analytic method
KW  - in vivo study
KW  - 3D modeling
KW  - accelerated chaotic particle swarm optimization
KW  - Chaotic particle swarm optimizations
KW  - laparoscopic surgery
KW  - Laparoscopic surgery
KW  - Laparoscopy
KW  - Mamdani fuzzy inference system
KW  - Mamdani fuzzy inferences
KW  - modular extreme learning machine
KW  - Partition-based clustering
KW  - Soft tissue modeling
KW  - swine
ER  - 

TY  - JOUR
TI  - Establishing standards for battery data and pathways towards its validation
AU  - Hayman, D
AU  - Dufek, EJ
AU  - Mukherjee, PP
AU  - Sholklapper, T
AU  - Love, CT
T2  - FRONTIERS IN ENERGY RESEARCH
DA  - 2023/08/18/
PY  - 2023
DO  - 10.3389/fenrg.2023.1271196
VL  - 11
SN  - 2296-598X
AN  - WOS:001059580400001
KW  - machine learning
KW  - standardization
KW  - validation
KW  - lithium-ion battery
KW  - data
KW  - battery safety
KW  - testing protocol
ER  - 

TY  - JOUR
TI  - Estimating Electric Motor Temperatures With Deep Residual Machine Learning
AU  - Kirchgässner, W
AU  - Wallscheid, O
AU  - Böcker, J
T2  - IEEE TRANSACTIONS ON POWER ELECTRONICS
AB  - Most traction drive applications lack accurate temperature monitoring capabilities, ensuring safe operation through expensive oversized motor designs. Classic thermal modeling requires expertise in model parameter choice, which is affected by motor geometry, cooling dynamics, and hot spot definition. Moreover, their major advantage over data-driven approaches, which is physical interpretability, tends to deteriorate as soon as their degrees of freedom are curtailed in order to meet the real-time requirement. In this article, deep recurrent and convolutional neural networks (NNs) with residual connections are empirically evaluated for their feasibility on predicting latent high-dynamic temperatures continuously inside permanent magnet synchronous motors. Here, the temperature profile in the stator teeth, winding, and yoke as well as the rotor's permanent magnets are estimated while their ground truth is available as test bench data. With an automated hyperparameter search through Bayesian optimization and a manual merge of target estimators into a multihead architecture, lean models are presented that exhibit a strong estimation performance at minimal model sizes. It has been found that the mean squared error and maximum absolute deviation performances of both, deep recurrent and convolutional NNs with residual connections, meet those of classic thermodynamics-based approaches, without requiring domain expertise nor specific drive train specifications for their topological design. Finally, learning curves for varying training set sizes and interpretations of model estimates through expected gradients are presented.
DA  - 2021/07//undefined
PY  - 2021
DO  - 10.1109/TPEL.2020.3045596
VL  - 36
IS  - 7
SP  - 7480
EP  - 7488
SN  - 0885-8993
AN  - WOS:000626599400020
ER  - 

TY  - JOUR
TI  - Ship trajectory prediction based on machine learning and deep learning: A systematic review and methods analysis
AU  - Li, HH
AU  - Jiao, H
AU  - Yang, ZL
T2  - ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
AB  - Ship trajectory prediction based on Automatic Identification System (AIS) data has attracted increasing interest as it helps prevent collision accidents and eliminate potential navigational conflicts. Therefore, it is necessary and urgent to conduct a systematic analysis of all the prediction methods to help reveal their advantages to ensure safety at sea in different scenarios. It is particularly important and significant within the context of unmanned ships forming a new hybrid maritime traffic together with manned ships in the future. This paper aims to conduct a comparative analysis of the up-to-date ship trajectory prediction algorithms based on machine learning and deep learning methods. To do so, five classical machine learning methods (i.e., Kalman Filter, Gaussian Process Regression, Support Vector Regression, Random Forest, and Back Propagation Network) and eight deep learning methods (i.e., Recurrent Neural Networks, Long Short-Term Memory, Bi-directional Long Short-Term Memory, Gate Recurrent Unit, Bi-directional Gate Recurrent Unit, Sequence to Sequence, Spatio-Temporal Graph Convolutional Network, and Transformer) are thoroughly analysed and compared from the algorithm essence and applications to excavate their features and adaptability for manned and unmanned ships. The findings reveal the characteristics of various prediction methods and provide valuable implications for different stakeholders to guide the best-fit choice of a particular method as the solution under a specific circumstance. It also makes contributions to the extraction of the research difficulties of ship trajectory prediction and the corresponding solutions that are put forward to guide the development of future research.
DA  - 2023/11//undefined
PY  - 2023
DO  - 10.1016/j.engappai.2023.107062
VL  - 126
SN  - 0952-1976
AN  - WOS:001072250400001
KW  - Deep learning
KW  - Machine learning
KW  - Automation
KW  - Convolutional neural networks
KW  - Learning systems
KW  - Machine-learning
KW  - Forecasting
KW  - Long short-term memory
KW  - Ships
KW  - Trajectories
KW  - Trajectory prediction
KW  - Brain
KW  - On-machines
KW  - Maritime safety
KW  - Prediction-based
KW  - AIS data
KW  - Automatic identification system
KW  - Automatic identification system data
KW  - Hybrid maritime traffic
KW  - Maritime traffic
ER  - 

TY  - JOUR
TI  - A deep learning approach for imbalanced crash data in predicting highway-rail grade crossings accidents
AU  - Gao, L
AU  - Lu, P
AU  - Ren, YH
T2  - RELIABILITY ENGINEERING & SYSTEM SAFETY
AB  - Accurate accident prediction for highway-rail grade crossings (HRGCs) is critically important for assisting at-grade safety improvement decision making. Numerous machine-learning methods were developed focusing on predicting accidents and identifying contributing physical and operational characteristics. A more advanced deep learning-based model is explored as a more accurate means of predicting HRGC crashes compared to machine learning-based approaches. In particular, the prediction performance of the convolution neural network (CNN) model is compared to the most commonly used machine learning methods, such as decision tree (DT) and random forests (RF). A 19-year HRGCs data in North Dakota (ND) is used in this study. Training a machine learning model on an imbalanced data (e.g., unequal distribution of labeled data in accident and no-accident classes) introduce unique challenges for accurate prediction especially for minority class. In this paper, a resampling approach was used to address the imbalanced data issue. Various performance measurements are used to compare the models' prediction performance. The results indicate that resampling the imbalanced dataset significantly improves the recall rate. The results also show that the proposed deep learning-based approach which deepens the layer levels and adapts to the training dataset has better prediction performance compared to other machine learning-based methods.
DA  - 2021/12//undefined
PY  - 2021
DO  - 10.1016/j.ress.2021.108019
VL  - 216
SN  - 0951-8320
AN  - WOS:000702351700085
KW  - Decision trees
KW  - Deep learning
KW  - Safety
KW  - Machine learning
KW  - Accident prevention
KW  - Machine-learning
KW  - Forecasting
KW  - Machine learning methods
KW  - Prediction performance
KW  - Learning-based approach
KW  - Imbalanced data
KW  - Grade crossing
KW  - Rail grades
KW  - Prediction accuracy
KW  - Highway rail grade crossing
ER  - 

TY  - CONF
TI  - Web Data Extraction Techniques: A Review
AU  - Kamanwar, NV
AU  - Kale, SG
AU  - IEEE
T2  - 2016 WORLD CONFERENCE ON FUTURISTIC TRENDS IN RESEARCH AND INNOVATION FOR SOCIAL WELFARE (STARTUP CONCLAVE)
AB  - Web data extraction is the process of extracting user required information from websites. The web document contains data which is not in structured format. From the word web data extraction, we mean the extraction of data that is present in the web documents in HTML format. Then removing the unwanted stuff such as tags, advertisements, videos and so on. Then learning the information or patterns or features present in that data. Today, most researchers uses web data extractors because the internet contains huge data which makes the process of manual information extraction from the web documents complicated. In this paper, we have studied about different techniques for data extraction used by different authors that takes the user required data from a set of web pages. A comparative analysis of web data extraction techniques is given.
DA  - 2016///
PY  - 2016
SN  - 978-1-4673-9214-3
AN  - WOS:000390231300014
KW  - Data mining
KW  - Websites
KW  - Unsupervised learning
KW  - Map-reduce
KW  - Alignment
KW  - alignment
KW  - Visual feature
KW  - MapReduce
KW  - Data Path
KW  - Data paths
KW  - Hadoop
KW  - subject detection
KW  - Trinity
KW  - visual features
KW  - Web data extraction
KW  - Web Data Extraction
KW  - wrapper
ER  - 

TY  - JOUR
TI  - Deep Reinforcement Learning Coordinated Receiver Beamforming for Millimeter-Wave Train-Ground Communications
AU  - Zhou, XT
AU  - Zhang, XF
AU  - Chen, C
AU  - Niu, Y
AU  - Han, Z
AU  - Wang, H
AU  - Sun, CJ
AU  - Ai, B
AU  - Wang, N
T2  - IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY
AB  - As more and more people choose high-speed rail (HSR) as a means of transportation for short trips, there is ever growing demand of high quality of multimedia services. With its rich spectrum resources, millimeter wave (mm-wave) communications can satisfy the high network capacity requirements for HSR. Also, it is possible for receivers (RXs) to be equipped with antenna arrays in mm-wave communication systems due to its short wavelength. However, as HSRs run with high speed, the received signal power (RSP) varies rapidly over a cell and it is the lowest at the edge of the cell compared to other locations. Consequently, it is necessary to conduct research on RX beamforming for HSR in mm-wave band to improve the quality of the received signal. In this paper, we focus on RX beamforming for a mm-wave train-ground communication system. To improve the RSP, we propose an effective RX beamforming scheme based on deep reinforcement learning (DRL), and develop a deep Q-network (DQN) algorithm to train and determine the optimal RX beam direction with the purpose of maximizing average RSP. Through extensive simulations, we demonstrate that the proposed scheme has better performance than the four baseline schemes in terms of average RSP at most positions on the railway.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.1109/TVT.2022.3153928
VL  - 71
IS  - 5
SP  - 5156
EP  - 5171
SN  - 0018-9545
AN  - WOS:000799654900053
ER  - 

TY  - JOUR
TI  - Data Science Meets Law Learning Responsible AI together
AU  - Hod, S
AU  - Chagal-Feferkorn, K
AU  - Elkin-Koren, N
AU  - Gal, A
T2  - COMMUNICATIONS OF THE ACM
DA  - 2022/02//undefined
PY  - 2022
DO  - 10.1145/3506575
VL  - 65
IS  - 2
SP  - 35
EP  - 39
SN  - 0001-0782
AN  - WOS:000750874100012
ER  - 

TY  - JOUR
TI  - Use of DFT Distance Metrics for Classification of SARS-CoV-2 Genomes
AU  - Thornton, M
AU  - Mcgee, M
T2  - JOURNAL OF COMPUTATIONAL BIOLOGY
AB  - In this work, we investigate using Fourier coefficients (FCs) for capturing useful information about viral sequences in a computationally efficient and compact manner. Specifically, we extract geographic submission location from SARS-CoV-2 sequence headers submitted to the GISAID Initiative, calculate corresponding FCs, and use the FCs to classify these sequences according to geographic location. We show that the FCs serve as useful numerical summaries for sequences that allow manipulation, identification, and differentiation via classical mathematical and statistical methods that are not readily applicable for character strings. Further, we argue that subsets of the FCs may be usable for the same purposes, which results in a reduction in storage requirements. We conclude by offering extensions of the research and potential future directions for subsequent analyses, such as the use of other series transforms for discreetly indexed signals such as genomes.
DA  - 2022/05/01/
PY  - 2022
DO  - 10.1089/cmb.2021.0229
VL  - 29
IS  - 5
SP  - 453
EP  - 464
SN  - 1066-5277
AN  - WOS:000798648900001
KW  - supervised learning
KW  - alignment-free methods
KW  - Fourier transform
KW  - genomic sequences
KW  - visualization of high-dimensional data
ER  - 

TY  - JOUR
TI  - Data Analysis and Knowledge Mining of Machine Learning in Soil Corrosion Factors of the Pipeline Safety
AU  - Zhao, ZF
AU  - Chen, MY
AU  - Fan, H
AU  - Zhang, NL
T2  - COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
AB  - The purpose of this research is to enhance the ability of data analysis and knowledge mining in soil corrosion factors of the pipeline. According to its multifactor characteristics, the rough set algorithm is directly used to analyze and process the observation data without considering any prior information. We apply rough set algorithm to delete the duplicate same information and redundant items and simplify the condition attributes and decision indicators from the decision table. Combined with the simplified index, the decision tree method is used to analyze the root node and branch node of it, and the knowledge decision model is constructed. With the Python machine learning language and PyCharm Community Edition software, the algorithm functions of rough set and decision tree are realized, so as to carry out artificial intelligence analysis and judgment of the soil corrosion factor data in pipeline. Taking the area of loam soil corrosion as an example, the data analysis and knowledge mining of its multifactors original data are carried out through the model. The example verifies that the evaluation and classification rules of the model meet the requirements, and there are no problems such as inconsistency and heterogeneity. It provides decision-making service and theoretical basis for the soil corrosion management of pipeline.
DA  - 2022/05/06/
PY  - 2022
DO  - 10.1155/2022/9523878
VL  - 2022
SN  - 1687-5265
AN  - WOS:000797676700017
KW  - machine learning
KW  - Decision trees
KW  - Artificial Intelligence
KW  - artificial intelligence
KW  - Machine learning
KW  - Data mining
KW  - Machine Learning
KW  - Pipelines
KW  - Algorithms
KW  - Machine-learning
KW  - algorithm
KW  - soil
KW  - Soil
KW  - Computer software
KW  - data mining
KW  - Data Mining
KW  - Corrosion
KW  - data analysis
KW  - Multi-factor
KW  - Soils
KW  - corrosion
KW  - Set algorithm
KW  - Pipeline safety
KW  - Condition attributes
KW  - Corrosion factor
KW  - Data Analysis
KW  - Decision tables
KW  - Knowledge mining
KW  - Observation data
KW  - Pipeline corrosion
KW  - Prior information
KW  - Soil corrosion
KW  - Steel corrosion
KW  - Underground corrosion
ER  - 

TY  - JOUR
TI  - Impact of measurement error on deep neural networks for nuclear material accountancy
AU  - Shoman, N
AU  - Burr, T
T2  - NUCLEAR ENGINEERING AND DESIGN
AB  - Continued growth in the nuclear industry is resulting in an increased burden for regulators due to the costs associated with implementing traditional safeguards. One such stakeholder, the International Atomic Energy Agency (IAEA), has published a research and development roadmap of suggested improvements that would help safeguards remain effective and efficient in the face of growing demands. These priorities include identifying, evaluating, and testing promising applications of robotics and machine learning/artificial intelligence (ML/AI) to improve safeguards. Nuclear material accountancy (NMA) is of particular interest because traditional approaches require time and resource intensive destructive assay (DA) measurements. One desirable improvement would be utilization of unattended measurements in order to reduce the burden of frequent DA measurements required at large throughput facilities, even though such unattended measurements would likely have higher uncertainty. The application of ML could improve detection of small changes, potentially due to material theft, in these higher uncertainty measurements collected at nuclear facilities to enable near real time anomaly detection. However, unique challenges arise when attempting to use deep neural networks with datasets containing errors that are characterized by models commonly associated with safeguards measurements. The purpose of this paper is to outline both traditional and ML based approaches to NMA and compare them through example. It can be shown that traditional methods for NMA often offers superior performance to the proposed ML pipeline, which consists supervised regression and unsupervised classification, when trained on datasets that contain measurement errors. ML approaches may still be competitive with traditional methods for NMA, however, special care must be taken to mitigate the impact of measurement error that disproportionately affects deep learning approaches.
DA  - 2023/02//undefined
PY  - 2023
DO  - 10.1016/j.nucengdes.2022.112113
VL  - 402
SN  - 0029-5493
AN  - WOS:000953929800001
KW  - Machine learning
KW  - Deep neural networks
KW  - Learning systems
KW  - Anomaly detection
KW  - Machine-learning
KW  - Classification (of information)
KW  - Traditional approaches
KW  - Uncertainty analysis
KW  - Data science
KW  - Measurement errors
KW  - Research and development
KW  - Robotic learning
KW  - Development roadmap
KW  - Growing demand
KW  - International atomic energy agency
KW  - Nuclear industry
KW  - Nuclear material accountancy
KW  - Research roadmap
KW  - Safeguard
KW  - Safeguards
ER  - 

TY  - JOUR
TI  - Analysis of public opinion on food safety in Greater China with big data and machine learning
AU  - Zhang, HY
AU  - Zhang, DC
AU  - Wei, ZS
AU  - Li, Y
AU  - Wu, SJ
AU  - Mao, ZH
AU  - He, CM
AU  - Ma, HR
AU  - Zeng, X
AU  - Xie, XL
AU  - Kou, XR
AU  - Zhang, BW
T2  - CURRENT RESEARCH IN FOOD SCIENCE
AB  - The Internet contains a wealth of public opinion on food safety, including views on food adulteration, food-borne diseases, agricultural pollution, irregular food distribution, and food production issues. To systematically collect and analyze public opinion on food safety in Greater China, we developed IFoodCloud, which automatically collects data from more than 3,100 public sources. Meanwhile, we constructed sentiment classification models using multiple lexicon-based and machine learning-based algorithms integrated with IFoodCloud that provide an unprecedented rapid means of understanding the public sentiment toward specific food safety incidents. Our best model's F1 score achieved 0.9737, demonstrating its great predictive ability and robustness. Using IFoodCloud, we analyzed public sentiment on food safety in Greater China and the changing trend of public opinion at the early stage of the 2019 Coronavirus Disease pandemic, demonstrating the potential of big data and machine learning for promoting risk communication and decision-making.
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.crfs.2023.100468
VL  - 6
SN  - 2665-9271
AN  - WOS:000974518500001
KW  - machine learning
KW  - Deep learning
KW  - deep learning
KW  - Machine learning
KW  - big data
KW  - public opinion
KW  - Natural language processing
KW  - controlled study
KW  - human
KW  - classification
KW  - China
KW  - interpersonal communication
KW  - Article
KW  - decision making
KW  - pandemic
KW  - Big data
KW  - support vector machine
KW  - learning algorithm
KW  - long short term memory network
KW  - risk factor
KW  - natural language processing
KW  - food safety
KW  - classification algorithm
KW  - multilayer perceptron
KW  - Coronavirinae
KW  - epidemiological data
KW  - foodinformatics
KW  - Foodinformatics
KW  - information science
KW  - lexicon based sentiment classification
KW  - sentiment classification
KW  - storage
ER  - 

TY  - JOUR
TI  - Towards objective human performance measurement for maritime safety: A new psychophysiological data-driven machine learning method
AU  - Fan, SQ
AU  - Yang, ZL
T2  - RELIABILITY ENGINEERING & SYSTEM SAFETY
AB  - Human errors significantly contribute to transport accidents. Human performance measurement (HPM) is crucial to ensure human reliability and reduce human errors. However, how to address and reduce the subjective bias introduced by assessors in HPM and seafarer certification remains a key research challenge. This paper aims to develop a new psychophysiological data-driven machine learning method to realize the effective HPM in the maritime sector. It conducts experiments using a functional Near-Infrared Spectroscopy (fNIRS) technology and compares the performance of two groups in a maritime case (i.e. experienced and inexperienced seafarers in terms of different qualifications by certificates), via an Artificial Neural Network (ANN) model. The results have generated insightful implications and new contributions, including (1) the introduction of an objective criterion for assessors to monitor, assess, and support seafarer training and certification for maritime authorities; (2) the quantification of human response under specific missions, which serves as an index for a shipping company to evaluate seafarer reliability; (3) a supportive tool to evaluate human performance in complex emerging systems (e.g. Maritime Autonomous Surface Ship (MASS)) design for ship manufactures and shipbuilders.
DA  - 2023/05//undefined
PY  - 2023
DO  - 10.1016/j.ress.2023.109103
VL  - 233
SN  - 0951-8320
AN  - WOS:000964796900001
KW  - Machine learning
KW  - Neural networks
KW  - Errors
KW  - Reliability
KW  - Ships
KW  - Data driven
KW  - Human errors
KW  - Infrared devices
KW  - Near infrared spectroscopy
KW  - Maritime safety
KW  - Human performance
KW  - Education and training
KW  - Human reliability
KW  - Maritime education
KW  - Maritime education and training
KW  - Maritime training
KW  - Maritime transport
KW  - Performance measurements
ER  - 

TY  - JOUR
TI  - Measuring heterogeneous perception of urban space with massive data and machine learning: An application to safety
AU  - Ramírez, T
AU  - Hurtubia, R
AU  - Lobel, H
AU  - Rossetti, T
T2  - LANDSCAPE AND URBAN PLANNING
AB  - In the last decade, large street imagery data sets and machine learning developments have allowed increasing scalability of methodologies to understand the effects of landscape attributes on the way they are perceived. However, these new methodologies have not incorporated individual heterogeneity in their analysis, even though differences by gender and other sociodemographic characteristics in the perception of safety and other aspects of landscapes and public spaces have been widely studied in social sciences and urban planning in lower scale studies. In the present study, we combine computational and statistical tools to develop a methodological proposal with high scalability and low implementation cost, which helps to identify and measure heterogeneous perception and its correlation to the presence of elements in the landscape. To achieve this, we implement a survey of perception of public spaces, collecting sociodemographic information of respondents. Then, we fit a discrete choice model to quantify perceptions of these spaces using a parametrization of images that jointly considers semantic segmentation and object detection as input. Our results show heterogeneity in the perception of safety in public spaces according to gender and the observer's habitual mobility choices. The model is then applied to the city of Santiago, Chile. This produces a map of safety perception for different types of users. The proposed method and the obtained results can be a relevant input for the design of public spaces and decision making in the urban planning process.
DA  - 2021/04//undefined
PY  - 2021
DO  - 10.1016/j.landurbplan.2020.104002
VL  - 208
SN  - 0169-2046
AN  - WOS:000614249100006
KW  - machine learning
KW  - Machine learning
KW  - perception
KW  - safety
KW  - methodology
KW  - decision making
KW  - heterogeneity
KW  - data set
KW  - Built environment
KW  - landscape ecology
KW  - Chile
KW  - Heterogeneous perception
KW  - Metropolitana
KW  - planning process
KW  - public space
KW  - urban planning
KW  - urban region
KW  - Urban space safety
ER  - 

TY  - CONF
TI  - Are We Training with The Right Data? Evaluating Collective Confidence in Training Data using Dempster Shafer Theory
AU  - Dey, S
AU  - Lee, SW
AU  - IEEE Computer Society
T2  - 2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING RESULTS (ICSE-NIER 2022)
AB  - The latest trend of incorporating various data-centric machine learning (ML) models in software-intensive systems has posed new challenges in the quality assurance practice of software engineering, especially in a high-risk environment. ML experts are now focusing on explaining ML models to assure the safe behavior of ML-based systems. However, not enough attention has been paid to explain the inherent uncertainty of the training data. The current practice of ML-based system engineering lacks transparency in the systematic fitness assessment process of the training data before engaging in the rigorous ML model training. We propose a method of assessing the collective confidence in the quality of a training dataset by using Dempster Shafer theory and its modified combination rule (Yager's rule). With the example of training datasets for pedestrian detection of autonomous vehicles, we demonstrate how the proposed approach can be used by the stakeholders with diverse expertise to combine their beliefs in the quality arguments and evidences about the data. Our results open up a scope of future research on data requirements engineering that can facilitate evidence-based data assurance for ML-based safety-critical systems.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3510455.3512779
SP  - 11
EP  - 15
SN  - 978-1-6654-9596-7
AN  - WOS:000850192800003
ER  - 

TY  - CONF
TI  - Detection of Water Safety Conditions in Distribution Systems Based on Artificial Neural Network and Support Vector Machine
AU  - Mohammed, H
AU  - Hameed, IA
AU  - Seidu, R
T2  - PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ADVANCED INTELLIGENT SYSTEMS AND INFORMATICS 2018
A2  - Hassanien, AE
A2  - Tolba, MF
A2  - Shaalan, K
A2  - Azar, AT
AB  - This study presents the development of artificial neural network (ANN) and support vector machine (SVM) classification models for predicting the safety conditions of water in distribution pipes. The study was based on 504 monthly records of water quality parameters; pH, turbidity, color and bacteria counts taken from nine different locations across the water distribution network in the city of Alesund, Norway. The models predicted the safety conditions of the water samples in the pipes with 98% accuracy and 94% respectively during testing. The high accuracy achieved in the model results indicate that contamination events in distribution systems that result in unsafe values of the water quality parameters can be detected using these classification models. This can provide water utility managers with real time information about the safety conditions of treated water at different locations of distribution pipes before water reaches consumers.
DA  - 2019///
PY  - 2019
DO  - 10.1007/978-3-319-99010-1_52
VL  - 845
SP  - 567
EP  - 576
SN  - 2194-5357
AN  - WOS:000455368700052
KW  - Machine learning
KW  - Intelligent systems
KW  - Neural networks
KW  - Support vector machines
KW  - Learning systems
KW  - Classification models
KW  - Safety testing
KW  - Electric power distribution
KW  - Water quality
KW  - Water distribution systems
KW  - Water safety
KW  - Water treatment
KW  - Real-time information
KW  - Contaminant detection
KW  - Contamination events
KW  - Distribution network
KW  - Pollution detection
KW  - Water distribution networks
KW  - Water quality parameters
KW  - Water utility managers
ER  - 

TY  - JOUR
TI  - Toward AI-supported evaluation for safety control measures against near-miss events in pharmaceutical products
AU  - Okamoto, R
AU  - Kojima, R
AU  - Nakatsui, M
T2  - SAFETY SCIENCE
AB  - The Japan Council for Quality Health Care (JCQHC) promotes medical safety by providing health professionals in pharmacies and the public with information regarding near-miss events from pharmacies. The Pharmaceuticals and Medical Devices Agency (PMDA) evaluates the pharmaceutical near-miss events published by the JCQHC to determine whether safety measures need to be taken in terms of drug names and packaging. We propose an artificial intelligence (AI) evaluation model that performs efficient and reproducible evaluations to support PMDA reviewers. We prepared a dataset consisting of pairs of pharmaceutical near-miss events and their human-annotated evaluation in consultation with the PMDA Safe Use Measures Review Committee reports. Pharmaceutical near-miss events consist of semi-structured texts such as drug names and free descriptive comments. To extract text features such as the similarity of drug names from the semi-structured text and predict the evaluation from these text features, a light gradient boosting machine was used. The AI model was evaluated by ablation experiments on these features. Model construction using the metrics of precision, recall, f1-score, and macro-f1 and verification were performed using cross-validation. The developed AI model classified events with a high degree of accuracy close to that of PMDA's human evaluation; however, achieving human classification accuracy proved difficult. Further study is needed to improve the accuracy of the classification evaluation model. The developed model should serve as an operational rule for primary screening in PMDA operations.
DA  - 2023/12//undefined
PY  - 2023
DO  - 10.1016/j.ssci.2023.106314
VL  - 168
SN  - 0925-7535
AN  - WOS:001082281200001
ER  - 

TY  - CONF
TI  - A Gaze Data-Based Comparative Study to Build a Trustworthy Human-AI Collaboration in Crash Anticipation
AU  - Li, Y
AU  - Karim, MM
AU  - Qin, R
T2  - INTERNATIONAL CONFERENCE ON TRANSPORTATION AND DEVELOPMENT 2023: TRANSPORTATION PLANNING, OPERATIONS, AND TRANSIT
A2  - Wei, H
AB  - Vehicles with a safety function for anticipating crashes in advance can enhance drivers' ability to avoid crashes. As dashboard cameras have become a low-cost sensor device accessible to almost every vehicle, deep neural networks for crash anticipation from a dashboard camera are receiving growing interest. However, drivers' trust in the Artificial Intelligence (AI)-enabled safety function is built on the validation of its safety enhancement toward zero deaths. This paper is motivated to establish a method that uses gaze data and corresponding measures to evaluate human drivers' ability to anticipate crashes. A laboratory experiment is designed and performed, wherein a screenbased eye tracker collects the gaze data of six volunteers while watching 100 driving videos that include both normal and crash scenarios. Statistical analyses of the experimental data show that, on average, drivers can anticipate a crash up to 2.61 s before it occurs in this pilot study. The chance that drivers have successfully anticipated crashes before they occur is 92.8%. A state of the art AI model can anticipate crashes 1.02 s earlier than drivers on average. The study finds that crash-involving traffic agents in the driving videos can vary drivers' instant attention level, average attention level, and spatial attention distribution. This finding supports the development of a spatial-temporal attention mechanism for AI models to strengthen their ability to anticipate crashes. Results from the comparison also suggest the development of collaborative intelligence that keeps human-in-the-loop of AI models to further enhance the reliability of AI-enabled safety functions.
DA  - 2023///
PY  - 2023
SP  - 737
EP  - 748
SN  - 978-0-7844-8488-3
AN  - WOS:001038419000064
ER  - 

TY  - CONF
TI  - Artificial Intelligence for Emergency Management
AU  - Freeman, S
T2  - ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR MULTI-DOMAIN OPERATIONS APPLICATIONS II
A2  - Pham, T
A2  - Solomon, L
A2  - Rainey, K
AB  - The Protection Systems Branch of Combat Capabilities Development Command Armaments Center develops and sustains Emergency Management systems focusing on Homeland Defense technologies and interoperability. Artificial Intelligence computing algorithms and methods and the intelligent fusion of multiple Emergency Management correlated data sources including social media and extremist forums, as well as criminal, government, and medical databases can be used as a decision aid in the identification, prevention, response, and recovery of subversive incidents. This research and application can ultimately provide law enforcement and Emergency Management personnel with predictive trends, which would feed decision-making during all phases of an emergency.
DA  - 2020///
PY  - 2020
DO  - 10.1117/12.2561636
VL  - 11413
SN  - 0277-786X
AN  - WOS:000672603900035
ER  - 

TY  - JOUR
TI  - Anomaly detection in wearable location trackers for child safety
AU  - Aliyu, MB
AU  - Amr, A
AU  - Ahmad, IS
T2  - MICROPROCESSORS AND MICROSYSTEMS
AB  - Child Location trackers are widely available devices but the ability of these trackers to detect outlying incidents remain untapped. The main goal of this research is to incorporate anomaly detection in wearable child location trackers using machine learning, with a primary focus on unsupervised outlier detection techniques. Therefore, a low powered gyroscope-enabled electronic tracker using Low Drop Out (LDO) converters was fabricated as a building block for the software/hardware integration. Common unsupervised techniques were adopted for experimentation including the Local Outlier Factor (LOF), the k-Nearest Neighbor (kNN) Global Anomaly Score and the Histogram-based Outlier Score (HBOS). The results obtained show that LOF performs well in detecting local outliers as well as identifying new patterns to prevent false alarms, however, the paths to the newly identified locations bring about false alarms. The kNN Global Outlier Score is only capable of detecting global outliers where k is greater than 15. HBOS, on the other hand, performs better than the kNN Global Outlier Score but is unable to learn new locations that become part of the normal pattern. The proposed model is a potential candidate for an outlier detection system for combating child loss and kidnapping cases, thereby ensuring child safety globally.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1016/j.micpro.2022.104545
VL  - 91
SN  - 0141-9331
AN  - WOS:000805839900001
KW  - Machine learning
KW  - Data handling
KW  - Anomaly detection
KW  - Nearest neighbor search
KW  - Statistics
KW  - Errors
KW  - Unsupervised learning
KW  - Local Outlier Factor
KW  - Location
KW  - Outlier Detection
KW  - Child safety
KW  - Gyroscopes
KW  - Building blockes
KW  - Gyroscope-enabled
KW  - Location tracker
KW  - Low drop outs
KW  - Low-power electronics
KW  - Spatial data
ER  - 

TY  - JOUR
TI  - Exploring the impact of safety culture on incident reporting: Lessons learned from machine learning analysis of NHS England staff survey and incident data
AU  - Kaya, GK
AU  - Ustebay, S
AU  - Nixon, J
AU  - Pilbeam, C
AU  - Sujan, M
T2  - SAFETY SCIENCE
AB  - Safety culture is one of the key factors contributing to safety, even though limited evidence supports its impact on safety outcomes. This study uses supervised machine learning algorithms to explore the association between safety culture and incident reporting. The study used National Health Service (NHS) England annual staff survey data as a proxy of safety culture to predict eighteen incident reporting variables. The study did not achieve high accuracy rates in the prediction models. The highest association was found between safety culture and the number of incidents reported in class low, medium and high. LightGBM was the best-performed algorithm. SHAP plots were used to explain the model. Findings suggest that compassionate culture, violence and harassment and work pressure are critical in predicting the number of incidents reported. More specifically, the violence and harassment had a more significant impact on predicting the number of incidents reported in class high than in class medium and low. The involvement had more effect on predicting class low. The results demonstrated different behaviours in predicting different incident reporting classes. The findings facilitate lessons learned from staff surveys and incident reporting data in NHS England. Consequently, the findings can contribute to improving the safety culture in hospitals.
DA  - 2023/10//undefined
PY  - 2023
DO  - 10.1016/j.ssci.2023.106260
VL  - 166
SN  - 0925-7535
AN  - WOS:001048111100001
KW  - machine learning
KW  - Safety
KW  - Machine learning
KW  - prediction
KW  - Supervised learning
KW  - Learning algorithms
KW  - Machine-learning
KW  - article
KW  - human
KW  - algorithm
KW  - Forecasting
KW  - supervised machine learning
KW  - Safety culture
KW  - Healthcare
KW  - England
KW  - accident analysis
KW  - safety culture
KW  - violence
KW  - Key factors
KW  - harassment
KW  - health survey
KW  - Incident analysis
KW  - Incident data
KW  - Incident reporting
KW  - national health service
KW  - National health services
KW  - Survey data
ER  - 

TY  - CONF
TI  - Machine Learning and Deep Learning Methods used in Safety Management of Nuclear Power Plants: A Survey
AU  - Shi, Y
AU  - Xue, XD
AU  - Qu, Y
AU  - Xue, JY
AU  - Zhang, LZ
T2  - 21ST IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS ICDMW 2021
A2  - Xue, B
A2  - Pechenizkiy, M
A2  - Koh, YS
AB  - The nuclear power industry is currently a strategic sector in the national economy, along with nuclear energy being considered to be an essential source of national power supply and security. Under such circumstances, nuclear power plants (NPPs) have been constructed globally in recent decades, providing stable and large amounts of electricity to many countries and regions for quite a long time. However, due to the specialty of NPPs, safety management is always the top priority in their daily operations, like fault diagnosis and monitoring. At the same time, with the great development of artificial intelligence, machine learning and deep learning methods have been infiltrating lots of disciplines and resulting in more intelligent transformations in real industries. By the strength of better performance, machine learning and deep learning models have been introduced into research and practice of safety management in NPPs, not only producing more academic papers but also ensuring stable and safe operations of NPPs. Focusing on the safety management of NPPs, this article starts with the common trend of data analytics, also the evolving process of algorithms applied in academia and real practice, which is from model-driven methods to data-driven approaches. Then detailed applications of conventional machine learning, advanced deep learning and other related intelligent approaches used in the safety management of NPPs are comprehensively categorized and reviewed. Further, we make necessary summaries and discussions, proposing new ideas and perspectives to better promote the theoretical and practical development of safety management in NPPs.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICDMW53433.2021.00120
SP  - 917
EP  - 924
SN  - 2375-9232
AN  - WOS:000779306300113
KW  - Deep learning
KW  - Machine learning
KW  - Accident prevention
KW  - Machine-learning
KW  - Man machine systems
KW  - Learning methods
KW  - Data Analytics
KW  - Safety management
KW  - Nuclear fuels
KW  - Nuclear power plant
KW  - Nuclear power plants
KW  - Data-driven methods
KW  - Electric industry
KW  - Nuclear industry
KW  - National economy
KW  - National power
KW  - Nuclear energy
KW  - Nuclear-power industry
KW  - Power supply
KW  - Strategic sectors
ER  - 

TY  - JOUR
TI  - Predicting Visual Political Bias Using Webly Supervised Data and an Auxiliary Task
AU  - Thomas, C
AU  - Kovashka, A
T2  - INTERNATIONAL JOURNAL OF COMPUTER VISION
AB  - The news media shape public opinion, and often, the visual bias they contain is evident for careful human observers. This bias can be inferred from how different media sources portray different subjects or topics. In this paper, we model visual political bias in contemporary media sources at scale, using webly supervised data. We collect a dataset of over one million unique images and associated news articles from left- and right-leaning news sources, and develop a method to predict the image's political leaning. This problem is particularly challenging because of the enormous intra-class visual and semantic diversity of our data. We propose two stages of training to tackle this problem. In the first stage, the model is forced to learn relevant visual concepts that, when joined with document embeddings computed from articles paired with the images, enable the model to predict bias. In the second stage, we remove the requirement of the text domain and train a visual classifier from the features of the former model. We show this two-stage approach that relies on an auxiliary task leveraging text, facilitates learning and outperforms several strong baselines. We present extensive quantitative and qualitative results analyzing our dataset. Our results reveal disparities in how different sides of the political spectrum portray individuals, groups, and topics.
DA  - 2021/11//undefined
PY  - 2021
DO  - 10.1007/s11263-021-01506-3
VL  - 129
IS  - 11
SP  - 2978
EP  - 3003
SN  - 0920-5691
AN  - WOS:000690351900002
KW  - Semantics
KW  - Forecasting
KW  - Two stage approach
KW  - Social aspects
KW  - Curriculum learning
KW  - Noisy data
KW  - Human observers
KW  - Image-text alignment
KW  - Intra class
KW  - News articles
KW  - News media
KW  - News sources
KW  - Privileged information
KW  - Public opinions
KW  - Unsupervised discovery
KW  - Visual concept
KW  - Visual rhetoric
KW  - Weak supervision
ER  - 

TY  - JOUR
TI  - Safe deep reinforcement learning-based adaptive control for USV interception mission
AU  - Du, B
AU  - Lin, B
AU  - Zhang, CM
AU  - Dong, BT
AU  - Zhang, WD
T2  - OCEAN ENGINEERING
AB  - This paper aims to develop a safe learning scheme of the USV interception mission. A safe Lyapunov boundary deep deterministic policy gradient (SLDDPG) algorithm is presented for the USV interception mission. The uniformly ultimate bounded (UUB) stability of control systems is analyzed under finite safety constraints. A single neuron proportional adaptive control (SNPAC) is applied to pre-train the deep policy network for speeding up the training process. The proposed method is evaluated by a series of simulations of the USVs interception and tracking mission. Compared with the existing results, our method can fast converge to the feasible solution subject to safety constraints and demonstrate a high performance in stability and safety by virtual-reality experiments.
DA  - 2022/02/15/
PY  - 2022
DO  - 10.1016/j.oceaneng.2021.110477
VL  - 246
SN  - 0029-8018
AN  - WOS:000778810100001
KW  - Deep learning
KW  - Reinforcement learning
KW  - Virtual reality
KW  - unmanned vehicle
KW  - Adaptive control systems
KW  - learning
KW  - Safe reinforcement learning
KW  - Adaptive Control
KW  - reinforcement
KW  - Safety constraint
KW  - stability analysis
KW  - Learning schemes
KW  - Unmanned surface vehicles
KW  - Learning control
KW  - Bounded stability
KW  - data management
KW  - Data-based learning control
KW  - Interception mission
KW  - policy implementation
KW  - Uniformly ultimate bounded stability
KW  - Unmanned surface vessels
KW  - vessel
ER  - 

TY  - CONF
TI  - Early Safety Warnings for Long-Distance Pipelines: A Distributed Optical Fiber Sensor Machine Learning Approach
AU  - Yang, YY
AU  - Li, Y
AU  - Zhang, TJ
AU  - Zhou, Y
AU  - Zhang, HF
AU  - Assoc Advancement Artificial Intelligence
T2  - THIRTY-FIFTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THIRTY-THIRD CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE AND THE ELEVENTH SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE
AB  - Automated pipeline safety early warning (PSEW) systems are designed to automatically identify and locate third-party damage events on oil and gas pipelines. They are intended to replace traditional, inefficient manual inspection methods. However, current PSEW methods cannot achieve universality for various complex environments because they are sensitive to the spatiotemporal stability of the signal obtained by its distributed sensors at various locations and times. Our research aimed to improve the accuracy of long-distance oil- gas PSEW systems through machine learning. In this paper, we propose a novel real-time action recognition method for long-distance PSEW systems based on a coherent Rayleigh scattering distributed optical fiber sensor. More specifically, we put forward two complementary feature calculation methods to describe signals and build a new action recognition deep learning network based on those features. Encouraging empirical results on the data collected at a real location confirm that the features can effectively describe signals in an environment with strong noise and weak signals, and the entire approach can identify and locate third-party damage events quickly under various hardware conditions with accuracies of 99.26% (500 Hz) and 97.20% (100 Hz). More generically, our method can be applied to other fields as well.
DA  - 2021///
PY  - 2021
VL  - 35
SP  - 14991
EP  - 14999
SN  - 2159-5399
AN  - WOS:000681269806076
KW  - Deep learning
KW  - Pipelines
KW  - Real time systems
KW  - Machine learning approaches
KW  - Early Warning System
KW  - Action recognition
KW  - Optical fibers
KW  - Coherent scattering
KW  - Damage events
KW  - Distributed optical fibers sensor
KW  - Long distance pipelines
KW  - Manual inspection
KW  - Oil-and-Gas pipelines
KW  - Pipeline safety
KW  - Third party damage
ER  - 

TY  - JOUR
TI  - Human Resources Analytics: A systematic Review from a Sustainable Management Approach
AU  - Alvarez-Gutiérrez, FJ
AU  - Stone, DL
AU  - Castaño, AM
AU  - García-Izquierdo, AL
T2  - JOURNAL OF WORK AND ORGANIZATIONAL PSYCHOLOGY-REVISTA DE PSICOLOGIA DEL TRABAJO Y DE LAS ORGANIZACIONES
AB  - Human Resources Analytics (HRA) is drawing more attention every year, and will be crucial to human resource development. However, the literature around the topic would appear to be more promotional than descriptive. With this in mind, we conducted a systematic literature review and content analysis with the following objectives: first, to address the current state of HRA and second, to propose a framework for the development of HRA as a sustainable practice. We analyzed 79 articles from research databases and found 34 empirical studies for subsequent content analysis. While the main results reflect the relative newness of the field of HRA, with the majority of the empirical articles focusing on financial aspects, they also reveal the growing importance given to ethics. Finally, we propose a framework for the development of sustainable HRA based on the triple bottom line and discuss the implications of our findings for researchers and practitioners.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.5093/jwop2022a18
VL  - 38
IS  - 3
SP  - 129
EP  - 147
SN  - 1576-5962
AN  - WOS:000913066100001
ER  - 

TY  - JOUR
TI  - A machine learning approach to Cepheid variable star classification using data alignment and maximum likelihood
AU  - Vilalta, R
AU  - Gupta, KD
AU  - Macri, L
T2  - ASTRONOMY AND COMPUTING
AB  - Our study centers on the classification of two subtypes of Cepheid variable stars. Such a classification is relatively easy to obtain for nearby galaxies, but as we incorporate new galaxies, the cost of labeling stars calls for some form of model adaptation. Adapting a predictive model to differentiate Cepheids across galaxies is difficult because of the sample bias problem in star distribution (due to the limitation of telescopes in observing faint stars as we try to reach distant galaxies). In addition, estimating the luminosity of a star as we reach distant galaxies carries some inevitable shift in the data distribution. We propose an approach to predict the class of Cepheid stars on a target domain, by first building a model on an "anchor" source domain. Our methodology then shifts the target data until it is well aligned with the source data by maximizing two different likelihood functions. Experimental results with two galaxy datasets (Large Magellanic Cloud as the source domain, and M33 as the target domain), show the efficacy of the proposed method. (c) 2013 Elsevier B.V. All rights reserved.
DA  - 2013/08//undefined
PY  - 2013
DO  - 10.1016/j.ascom.2013.07.002
VL  - 2
SP  - 46
EP  - 53
SN  - 2213-1337
AN  - WOS:000209385600006
KW  - Artificial intelligence
KW  - Machine learning
KW  - Learning systems
KW  - Predictive modeling
KW  - Classification (of information)
KW  - Variational techniques
KW  - Machine learning approaches
KW  - Classification
KW  - Covariate shift
KW  - Covariate shifts
KW  - Galaxies
KW  - Stars
KW  - Data distribution
KW  - Dataset shifts
KW  - Likelihood functions
KW  - Maximum likelihood
KW  - Astrophysics
KW  - Cepheid stars
KW  - Cepheids
KW  - Dataset shift
KW  - Large magellanic clouds
ER  - 

TY  - JOUR
TI  - When Internet of Things Meets Metaverse: Convergence of Physical and Cyber Worlds
AU  - Li, K
AU  - Cui, YP
AU  - Li, WC
AU  - Lv, TJ
AU  - Yuan, X
AU  - Li, SH
AU  - Ni, W
AU  - Simsek, M
AU  - Dressler, F
T2  - IEEE INTERNET OF THINGS JOURNAL
AB  - In recent years, the Internet of Things (IoT) has been studied in the context of the Metaverse to provide users with immersive cyber-virtual experiences in mixed-reality environments. This survey introduces six typical IoT applications in the Metaverse, including collaborative healthcare, education, smart city, entertainment, real estate, and socialization. In the IoT-inspired Metaverse, we also comprehensively survey four pillar technologies that enable augmented reality (AR) and virtual reality (VR), namely, responsible artificial intelligence (AI), high-speed data communications, cost-effective mobile edge computing (MEC), and digital twins. According to the physical-world demands, we outline the current industrial efforts and seven key requirements for building the IoT-inspired Metaverse: immersion, variety, economy, civility, interactivity, authenticity, and independence. In addition, this survey describes the open issues in the IoT-inspired Metaverse, which need to be addressed to eventually achieve the convergence of physical and cyber worlds.
DA  - 2023/03/01/
PY  - 2023
DO  - 10.1109/JIOT.2022.3232845
VL  - 10
IS  - 5
SP  - 4148
EP  - 4173
SN  - 2327-4662
AN  - WOS:000967351900001
ER  - 

TY  - JOUR
TI  - Short Duration Crash Prediction for Rural Two-Lane Roadways: Applying Explainable Artificial Intelligence
AU  - Wei, ZH
AU  - Das, S
AU  - Zhang, YL
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Conventional traffic crash analysis methods often use highly aggregated data, making it difficult to understand the effects of time-varying factors on crash occurrence. In this study, the combined effect of roadway geometry, speed distribution, and weather conditions on crash occurrence and severity was investigated on short duration daily level crash data. This study collected data from four different sources on rural two-lane roadways in Texas. A machine learning method, XGBoost (eXtreme Gradient Boosting), was applied to train the data. To mitigate imbalanced data problems, a synthetic minority oversampling technique (SMOTE) was applied. The XGBoost model was trained separately on all crash occurrences and severe crash occurrences. Finally, an explainable artificial intelligence (AI) technique, SHAP (SHapley Additive exPlanation), was applied to investigate the contribution of all variables to the model's output. The results show that annual average daily traffic has a significant impact on all crash occurrences and severe crash (fatal and incapacitating injury) occurrences on rural two-lane roadways. Moreover, weather condition factors including daily precipitation, average visibility, and the standard deviation of visibility show association with high crash occurrences. The short duration crash prediction models of this study can provide more insights into the relationships between crash, geometric variables, traffic exposure, weather, and operating speed.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1177/03611981221096113
VL  - 2676
IS  - 12
SP  - 535
EP  - 549
SN  - 0361-1981
AN  - WOS:000811721100001
ER  - 

TY  - JOUR
TI  - Supervised locally tangent space alignment for machine fault diagnosis
AU  - Zhang, Y
AU  - Li, BW
AU  - Wang, W
AU  - Sun, T
AU  - Yang, XY
AU  - Wang, L
T2  - JOURNAL OF MECHANICAL SCIENCE AND TECHNOLOGY
AB  - How to deal with the high-dimensional and nonlinear data is a challenging problem for fault diagnosis. An unsupervised locally tangent space alignment (LTSA) has recently proven to be an effective unsupervised manifold learning algorithm for high-dimensional data analysis. In this paper, a supervised expansion of LTSA (named S-LTSA) is proposed, which takes full advantage of class label information to improve classification performance. Based on S-LTSA, a novel machine fault diagnosis approach is proposed to deal with the high-dimensional fault data that contain multiple manifolds corresponding to fault classes. The experiment results with bearing fault data show that the proposed approach outperforms the other fault pattern recognition approaches such PCA, ICA, LDA and LTSA.
DA  - 2014/08//undefined
PY  - 2014
DO  - 10.1007/s12206-014-0704-3
VL  - 28
IS  - 8
SP  - 2971
EP  - 2977
SN  - 1738-494X
AN  - WOS:000340667800004
KW  - Pattern recognition
KW  - Manifold learning
KW  - Clustering algorithms
KW  - Failure analysis
KW  - Machine fault diagnosis
KW  - Classification performance
KW  - High-dimensional
KW  - Fault diagnosis
KW  - Manifold learning algorithm
KW  - Class label informations
KW  - High dimensional data analysis
KW  - High-dimensional data analysis
KW  - Supervised locally tangent space alignment
KW  - Tangent space
ER  - 

TY  - JOUR
TI  - Artificial intelligence enables reliable and standardized measurements of implant alignment in long leg radiographs with total knee arthroplasties
AU  - Schwarz, GM
AU  - Simon, S
AU  - Mitterer, JA
AU  - Frank, BJH
AU  - Aichmair, A
AU  - Dominkus, M
AU  - Hofstaetter, JG
T2  - KNEE SURGERY SPORTS TRAUMATOLOGY ARTHROSCOPY
AB  - Purpose The purpose of this study was to evaluate the reliability of a newly developed AI-algorithm for the evaluation of long leg radiographs (LLR) after total knee arthroplasties (TKA). Methods In the validation cohort 200 calibrated LLRs of eight different common unconstrained and constrained knee systems were analysed. Accuracy and reproducibility of the AI-algorithm were compared to manual reads regarding the hip-knee-ankle (HKA) as well as femoral (FCA) and tibial component (TCA) angles. In the evaluation cohort all institutional LLRs with TKAs in 2018 (n = 1312) were evaluated to assess the algorithms' ability of handling large data sets. Intraclass correlation (ICC) coefficient and mean absolute deviation (sMAD) were calculated to assess conformity between the AI software and manual reads. Results Validation cohort: The AI-software was reproducible on 96% and reliable on 92.1% of LLRs with an output and showed excellent reliability in all measured angles (ICC > 0.97) compared to manual measurements. Excellent results were found for primary unconstrained TKAs. In constrained TKAs landmark setting on the femoral and tibial component failed in 12.5% of LLRs (n = 9). Evaluation cohort: Mean measurements for all postoperative TKAs (n = 1240) were 0.2 degrees varus +/- 2.5 degrees (HKA), 89.3 degrees +/- 1.9 degrees (FCA), and 89.1 degrees +/- 1.6 degrees (TCA). Mean measurements on preoperative revision TKAs (n = 74) were 1.6 varus +/- 6.4 degrees (HKA), 90.5 degrees +/- 3.1 degrees (FCA), and 88.9 degrees +/- 4.1 degrees (TCA). Conclusions AI-powered applications are reliable for automated analysis of lower limb alignment on LLRs with TKAs. They are capable of handling large data sets and could, therefore, lead to more standardized and efficient postoperative quality controls.
DA  - 2022/08//undefined
PY  - 2022
DO  - 10.1007/s00167-022-07037-9
VL  - 30
IS  - 8
SP  - 2538
EP  - 2547
SN  - 0942-2056
AN  - WOS:000823377800004
ER  - 

TY  - JOUR
TI  - Digital Twin Empowered Mobile Edge Computing for Intelligent Vehicular Lane-Changing
AU  - Fan, B
AU  - Wu, Y
AU  - He, ZB
AU  - Chen, YY
AU  - Quek, TQS
AU  - Xu, CZ
T2  - IEEE NETWORK
AB  - With automated driving forthcoming, lane-changing for Connected and Automated Vehicles (CAVs) has received wide attention. The main challenge is that lane-changing requires not only local CAV control but also interactions with the surrounding traffic. Nevertheless, the Line-of-Sight (LoS) sensing range of the CAVs imposes severe limitations on lane-changing safety, and the lane-changing decision that is made based only on self-interest ignores its impact on the traffic flow efficiency. To overcome these difficulties, this article proposes a Digital Twin (DT) empowered mobile edge computing (MEC) architecture. With MEC, the sensing and computing capabilities of the CAVs can be strengthened to guarantee real-time safety. The virtualization and offline learning capabilities of the DT can be leveraged to enable the CAVs to learn from the experience of the physical MEC network and make lane-changing decisions via a 'foresight intelligent' approach. A case study of lane-changing is provided where the DT is constituted by a cellular automata based road traffic simulator coupled with a LTE-V based MEC network simulator. Deep reinforcement learning is adopted to train the lane-changing strategy and results validate the effectiveness of our proposed architecture.
DA  - 2021/11//undefined
PY  - 2021
DO  - 10.1109/MNET.201.2000768
VL  - 35
IS  - 6
SP  - 194
EP  - 201
SN  - 0890-8044
AN  - WOS:000732816200001
ER  - 

TY  - JOUR
TI  - Expanded analysis of machine learning models for nuclear transient identification using TPOT
AU  - Mena, P
AU  - Borrelli, RA
AU  - Kerby, L
T2  - NUCLEAR ENGINEERING AND DESIGN
AB  - Industries around the world are becoming more and more data driven. The nuclear field is no exception with several different applications being proposed. One popular area of research is the use of machine learning in transient detection. This paper seeks to build upon a previous study which made use of the AutoML package TPOT to train traditional machine learning models to classify transient events occurring with a reactor. Synthetic data was once again collected using a GPWR reactor simulator. Data on 12 different events was collected using 15 different initial conditions. A dataset consisting of over 100,000 data points was compiled and used to train 7 different machine learning models using a pre-defined TPOT dictionary with 12 different preprocessing techniques. Three of the trained models were able to produce validation results in the 90s with the expanded dataset. Once the models were trained, it was possible to look into where during the simulation, misclassifications occurred. Using these three models, analysis was done to determine if TPOT could be used to train models that were effective if important features were missing. The results from this were positive with the newly trained models scoring close to the original models. Finally, to conclude this study, the three high performing models were retrained using different random states to see if there was any major variation when different states were used.
DA  - 2022/04/15/
PY  - 2022
DO  - 10.1016/j.nucengdes.2022.111694
VL  - 390
SN  - 0029-5493
AN  - WOS:000784305600001
KW  - Machine learning
KW  - Machine learning models
KW  - Data driven
KW  - Synthetic data
KW  - Data science
KW  - Reactor safety
KW  - Data Science
KW  - AutoML
KW  - Automl
KW  - Nuclear fields
KW  - Reactor simulator
KW  - Transient events
KW  - Transient identification
KW  - Transients detection
ER  - 

TY  - JOUR
TI  - Unsupervised image translation with distributional semantics awareness
AU  - Peng, ZX
AU  - Wang, H
AU  - Weng, YL
AU  - Yang, Y
AU  - Shao, TJ
T2  - COMPUTATIONAL VISUAL MEDIA
AB  - Unsupervised image translation (UIT) studies the mapping between two image domains. Since such mappings are under-constrained, existing research has pursued various desirable properties such as distributional matching or two-way consistency. In this paper, we re-examine UIT from a new perspective: distributional semantics consistency, based on the observation that data variations contain semantics, e.g., shoes varying in colors. Further, the semantics can be multi-dimensional, e.g., shoes also varying in style, functionality, etc. Given two image domains, matching these semantic dimensions during UIT will produce mappings with explicable correspondences, which has not been investigated previously. We propose distributional semantics mapping (DSM), the first UIT method which explicitly matches semantics between two domains. We show that distributional semantics has been rarely considered within and beyond UIT, even though it is a common problem in deep learning. We evaluate DSM on several benchmark datasets, demonstrating its general ability to capture distributional semantics. Extensive comparisons show that DSM not only produces explicable mappings, but also improves image quality in general.
DA  - 2023/09//undefined
PY  - 2023
DO  - 10.1007/s41095-022-0295-3
VL  - 9
IS  - 3
SP  - 619
EP  - 631
SN  - 2096-0433
AN  - WOS:000974409700001
KW  - Deep learning
KW  - Semantics
KW  - Image enhancement
KW  - Mapping
KW  - unsupervised learning
KW  - Semantic Web
KW  - Generative adversarial networks
KW  - Property
KW  - Image translation
KW  - image-to-image translation
KW  - Image-to-image translation
KW  - Matchings
KW  - Manifold alignments
KW  - Generative adversarial network
KW  - distributional semantics
KW  - Distributional semantics
KW  - generative adversarial networks (GANs)
KW  - Image domain
KW  - manifold alignment
KW  - Semantics mappings
KW  - Under-constrained
ER  - 

TY  - JOUR
TI  - Risk Bounds for Unsupervised Cross-Domain Mapping with IPMs
AU  - Galanti, T
AU  - Benaim, S
AU  - Wolf, L
T2  - JOURNAL OF MACHINE LEARNING RESEARCH
AB  - The recent empirical success of unsupervised cross-domain mapping algorithms, in mapping between two domains that share common characteristics, is not well-supported by theoretical justifications. This lacuna is especially troubling, given the clear ambiguity in such mappings.
We work with adversarial training methods based on integral probability metrics (IPMs) and derive a novel risk bound, which upper bounds the risk between the learned mapping h and the target mapping y, by a sum of three terms: (i) the risk between h and the most distant alternative mapping that was learned by the same cross-domain mapping algorithm, (ii) the minimal discrepancy between the target domain and the domain obtained by applying a hypothesis h* on the samples of the source domain, where h* is a hypothesis selectable by the same algorithm, and (iii) an approximation error term that decreases as the capacity of the class of discriminators increases and is empirically shown to be small. The bound is directly related to Occam's razor and encourages the selection of the minimal architecture that supports a small mapping discrepancy.
The bound leads to multiple algorithmic consequences, including a method for hyperparameter selection and early stopping in cross-domain mapping.
DA  - 2021///
PY  - 2021
VL  - 22
SN  - 1532-4435
AN  - WOS:000663145600001
KW  - Approximation algorithms
KW  - Unsupervised learning
KW  - Training methods
KW  - Hyper-parameter
KW  - Adversarial training
KW  - Approximation errors
KW  - Cross-domain
KW  - Conformal mapping
KW  - Target domain
KW  - Cross-domain alignment
KW  - Early stopping
KW  - Image to image translation
KW  - Integral probability metrics
KW  - Occam's razor
KW  - Probability metrics
ER  - 

TY  - CONF
TI  - Methods for Traffic Data Classification with regard to Potential Safety Hazards
AU  - Obereigner, G
AU  - Tkachenko, P
AU  - del Re, L
T2  - IFAC PAPERSONLINE
AB  - Traffic data are a key element for setting up scenarios for Advanced Driver Assistant Systems (ADAS) safety and performance testing. Testing will thus reflect in some way the data used. However, there is no clear understanding in which way and how to choose the data so that the evaluation results are reliable and comprehensive. Therefore, the important scenarios in a traffic data set in view of safety analysis have to be determined. The paper presents a method with which traffic situations from a given data set are classified into different safety classes according to easily measurable features. It is shown that taking the Time To Collision (TTC) as a measure of safety and a linear Support Vector Machine (SVM) as a classifier, 64.7 % of traffic situations of a validation data set were classified to the correct safety class considering only three measurable features. Thus, traffic situations from a data set can be classified fast into different safety categories, providing information to the ADAS tester if the developed device has been tested in a safe or unsafe environment. Copyright (C) 2021 The Authors.
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.ifaco1.2021.08.367
VL  - 54
SP  - 250
EP  - 255
SN  - 2405-8963
AN  - WOS:000696396200044
ER  - 

TY  - JOUR
TI  - Zero-Shot Learning via Discriminative Dual Semantic Auto-Encoder
AU  - Xing, N
AU  - Liu, Y
AU  - Zhu, H
AU  - Wang, J
AU  - Han, JG
T2  - IEEE ACCESS
AB  - Zero-shot learning (ZSL) is an effective method to perform the recognition task without any training samples of specific classes. Most existing ZSL models put emphasis on learning an embedding between visual space and semantic space directly. However, few ZSL models research whether the human-designed semantic features are discriminative enough to recognize different classes. Moreover, one-way mapping suffers from the project domain shift problem. In this article, we propose to learn a Discriminative Dual Semantic Auto-encoder (DDSA) based on the encoder-decoder paradigm to solve this problem. DDSA attempts to construct two bidirectional embeddings to connect the visual space and the semantic space with the help of the learned aligned space which includes discriminative information of the visual features and semantic features. Based on the DDSA, we additionally propose a Deep DDSA to capture deep aligned features that are more conducive to zero-shot classification. The key to the proposed framework is that it implicitly exact the principal information from visual space and semantic space to construct aligned features, which is not only semantic-preserving but also discriminative. Extensive experiments on five benchmarks (SUN, CUB, AWA1, AWA2 and aPY) demonstrate the effectiveness of the proposed framework with state-of-the-art performance obtained on both conventional ZSL and generalized ZSL settings.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2020.3046573
VL  - 9
SP  - 733
EP  - 742
SN  - 2169-3536
AN  - WOS:000606558300001
ER  - 

TY  - JOUR
TI  - Predicting Safe Parking Spaces: A Machine Learning Approach to Geospatial Urban and Crime Data
AU  - Matijosaitiene, I
AU  - McDowald, A
AU  - Juneja, V
T2  - SUSTAINABILITY
AB  - This research aims to identify spatial and time patterns of theft in Manhattan, NY, to reveal urban factors that contribute to thefts from motor vehicles and to build a prediction model for thefts. Methods include time series and hot spot analysis, linear regression, elastic-net, Support vector machines SVM with radial and linear kernels, decision tree, bagged CART, random forest, and stochastic gradient boosting. Machine learning methods reveal that linear models perform better on our data (linear regression, elastic-net), specifying that a higher number of subway entrances, graffiti, and restaurants on streets contribute to higher theft rates from motor vehicles. Although the prediction model for thefts meets almost all assumptions (five of six), its accuracy is 77%, suggesting that there are other undiscovered factors making a contribution to the generation of thefts. As an output demonstrating final results, the application prototype for searching safer parking in Manhattan, NY based on the prediction model, has been developed.
DA  - 2019/05/02/
PY  - 2019
DO  - 10.3390/su11102848
VL  - 11
IS  - 10
SN  - 2071-1050
AN  - WOS:000471010300131
KW  - machine learning
KW  - Machine learning
KW  - United States
KW  - automobile
KW  - time series analysis
KW  - Prediction model
KW  - urban planning
KW  - automobile industry
KW  - crime
KW  - Crime prevention through urban planning
KW  - Geospatial data
KW  - Manhattan
KW  - Manhattan Island
KW  - New York [New York (STT)]
KW  - New York [United States]
KW  - parking
KW  - Theft from motor vehicle
ER  - 

TY  - JOUR
TI  - AIS data-driven ship trajectory prediction modelling and analysis based on machine learning and deep learning methods
AU  - Li, HH
AU  - Jiao, H
AU  - Yang, ZL
T2  - TRANSPORTATION RESEARCH PART E-LOGISTICS AND TRANSPORTATION REVIEW
AB  - Maritime transport faces new safety challenges in an increasingly complex traffic environment caused by large-scale and high-speed ships, particularly with the introduction of intelligent and autonomous ships. It is evident that Automatic Identification System (AIS) data-driven ship tra-jectory prediction can effectively aid in identifying abnormal ship behaviours and reducing maritime risks such as collision, stranding, and contact. Furthermore, trajectory prediction is widely recognised as one of the critical technologies for realising safe autonomous navigation. The prediction methods and their performance are the key factors for future safe and automatic shipping. Currently, ship trajectory prediction lacks the real performance measurement and analysis of different algorithms, including classical machine learning and emerging deep learning methods. This paper aims to systematically analyse the performance of ship trajectory prediction methods and pioneer experimental tests to reveal their advantages and disadvantages as well as fitness in different scenarios involving complicated systems. To do so, five machine learning methods (i.e., Kalman Filter (KF), Support Vector Progression (SVR), Back Propagation network (BP), Gaussian Process Regression (GPR), and Random Forest (RF)) and seven deep learning methods (i.e., Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Gate Recurrent Unit (GRU), Bi-directional Long Short-Term Memory (Bi-LSTM), Sequence to Sequence (Seq2seq), Bi-directional Gate Recurrent Unit (Bi-GRU), and Transformer) are first extracted from the state-of-the-art literature review and then employed to implement the trajectory prediction and compare their prediction performance in the real world. Three AIS datasets are collected from the waters of representative traffic features, including a normal channel (i.e., the Chengshan Jiao Promontory), complex traffic (i.e., the Zhoushan Archipelago), and a port area (i.e., Caofeidian port). They are selected to test and analyse the performance of all twelve methods based on six evaluation indexes and explore the characteristics and effectiveness of the twelve trajectory prediction methods in detail. The experimental results provide a novel perspective, comparison, and benchmark for ship trajectory prediction research, which not only demonstrates the fitness of each method in different maritime traffic scenarios, but also makes significant contributions to maritime safety and autonomous shipping development.
DA  - 2023/07//undefined
PY  - 2023
DO  - 10.1016/j.tre.2023.103152
VL  - 175
SN  - 1366-5545
AN  - WOS:001058531100001
KW  - machine learning
KW  - Deep learning
KW  - Machine learning
KW  - Automation
KW  - Learning systems
KW  - prediction
KW  - Backpropagation
KW  - Performance
KW  - Machine-learning
KW  - Forecasting
KW  - Prediction methods
KW  - China
KW  - Long short-term memory
KW  - Complex networks
KW  - transportation safety
KW  - Learning methods
KW  - Ships
KW  - Trajectories
KW  - Trajectory prediction
KW  - Brain
KW  - Data driven
KW  - traffic management
KW  - Shandong
KW  - trajectory
KW  - Maritime safety
KW  - AIS data
KW  - Automatic identification system
KW  - Automatic identification system data
KW  - Chengshan Cape
KW  - identification method
KW  - port operation
KW  - ship handling
KW  - tracking
KW  - Zhejiang
KW  - Zhoushan Islands
ER  - 

TY  - JOUR
TI  - Performance of a Web-Based Reference Database With Natural Language Searching Capabilities: Usability Evaluation of DynaMed and Micromedex With Watson
AU  - Rui, A
AU  - Garabedian, PM
AU  - Marceau, M
AU  - Syrowatka, A
AU  - Volk, LA
AU  - Edrees, HH
AU  - Seger, DL
AU  - Amato, MG
AU  - Cambre, J
AU  - Dulgarian, S
AU  - Newmark, LP
AU  - Nanji, KC
AU  - Schultz, P
AU  - Jackson, GP
AU  - Rozenblum, R
AU  - Bates, DW
T2  - JMIR HUMAN FACTORS
AB  - Background: Evidence-based point-of-care information (POCI) tools can facilitate patient safety and care by helping clinicians to answer disease state and drug information questions in less time and with less effort. However, these tools may also be visually challenging to navigate or lack the comprehensiveness needed to sufficiently address a medical issue.Objective: This study aimed to collect clinicians' feedback and directly observe their use of the combined POCI tool DynaMed and Micromedex with Watson, now known as DynaMedex. EBSCO partnered with IBM Watson Health, now known as Merative, to develop the combined tool as a resource for clinicians. We aimed to identify areas for refinement based on participant feedback and examine participant perceptions to inform further development. Methods: Participants (N=43) within varying clinical roles and specialties were recruited from Brigham and Women's Hospital and Massachusetts General Hospital in Boston, Massachusetts, United States, between August 10, 2021, and December 16, 2021, to take part in usability sessions aimed at evaluating the efficiency and effectiveness of, as well as satisfaction with, the DynaMed and Micromedex with Watson tool. Usability testing methods, including think aloud and observations of user behavior, were used to identify challenges regarding the combined tool. Data collection included measurements of time on task; task ease; satisfaction with the answer; posttest feedback on likes, dislikes, and perceived reliability of the tool; and interest in recommending the tool to a colleague.Results: On a 7-point Likert scale, pharmacists rated ease (mean 5.98, SD 1.38) and satisfaction (mean 6.31, SD 1.34) with the combined POCI tool higher than the physicians, nurse practitioner, and physician's assistants (ease: mean 5.57, SD 1.64, and satisfaction: mean 5.82, SD 1.60). Pharmacists spent longer (mean 2 minutes, 26 seconds, SD 1 minute, 41 seconds) on average finding an answer to their question than the physicians, nurse practitioner, and physician's assistants (mean 1 minute, 40 seconds, SD 1 minute, 23 seconds).Conclusions: Overall, the tool performed well, but this usability evaluation identified multiple opportunities for improvement that would help inexperienced users.
DA  - 2023///
PY  - 2023
DO  - 10.2196/43960
VL  - 10
SN  - 2292-9495
AN  - WOS:001017203700004
ER  - 

TY  - JOUR
TI  - A Rear Anti-Collision Decision-Making Methodology Based on Deep Reinforcement Learning for Autonomous Commercial Vehicles
AU  - Hu, WM
AU  - Li, X
AU  - Hu, JC
AU  - Song, X
AU  - Dong, X
AU  - Kong, D
AU  - Xu, QM
AU  - Ren, CX
T2  - IEEE SENSORS JOURNAL
AB  - Driving decision-making determines the safety and rationality of autonomous commercial vehicles. Aiming at the issue of safe driving decision-making, herein, a rear anti-collision decision-making methodology based on deep reinforcement learning (RAD-DRL) was creatively proposed. Firstly, aiming at the dynamic coupling of rear anti-collision factors for safe driving, a driving decision network based on an actor-critic framework was proposed for sensor data processing. Then, inspired by the idea of multi-objective optimization, a refined reward function is developed. It comprehensively considers the impact of backward target types, safety clearance, and vehicle roll stability on the rear collision. Finally, the RAD-DRL was trained (with different values of random seeds), tested, and verified in a simulation environment where road network and traffic situations were built-in SUMO (Simulation of Urban Mobility). After 30,000 training episodes, effective and reliable rear anti-collision driving decisions were achieved by our proposed RAD-DRL. The simulated results indicated that the RAD-DRL has remarkable superiority in generalization and effectiveness in expressway scenarios with different driving cases. Especially, it maintained good decision performance in the corner case in which the backward vehicle suddenly accelerates.
DA  - 2022/08/15/
PY  - 2022
DO  - 10.1109/JSEN.2022.3190302
VL  - 22
IS  - 16
SP  - 16370
EP  - 16380
SN  - 1530-437X
AN  - WOS:000842120900079
ER  - 

TY  - CONF
TI  - Machine Learning and Big Data Analytics in Support of Fleet Safety During Severe Weather
AU  - Spielman, Z
AU  - Gertman, DI
AU  - Liu, HR
AU  - Pray, I
AU  - Traiteur, J
AU  - Wold, S
AU  - Wysmuller, S
T2  - ADVANCES IN HUMAN ASPECTS OF TRANSPORTATION
A2  - Stanton, NA
AB  - The US DoT estimates 22% of the 5.7 million vehicle crashes a year are weather related. At Idaho National Laboratories, home of the DOE's largest transit, heavy and light vehicle fleet in the nation, weather is a constant challenge for the 4000 employees traveling the 45 to 65 mile stretch of road. Driving conditions can vary immensely; micro-climate conditions at INL site locations highways go unmonitored and causing severe challenges. INL has taken the initiative to review applicable technologies determining that addressing severe weather and road conditions through the application of advanced modeling methods holds promise for enhancing driver safety and dispatch planning. INL engaged IBM Global Business Services Advanced Analytics Center of Competency (CoC) Team for support in this effort. This presentation reviews the benefits expected, data surveyed, and how to use integrated sources and cognitive analytics to improve real-time weather forecasting and INL site fleet and operations planning.
DA  - 2018///
PY  - 2018
DO  - 10.1007/978-3-319-60441-1_64
VL  - 597
SP  - 662
EP  - 671
SN  - 2194-5357
AN  - WOS:000448241200064
KW  - Artificial intelligence
KW  - Machine learning
KW  - Accidents
KW  - Human factors
KW  - Learning systems
KW  - Fleet operations
KW  - Human engineering
KW  - Roads and streets
KW  - Driving conditions
KW  - Transportation
KW  - Big data
KW  - Education
KW  - Weather forecasting
KW  - Advanced modeling
KW  - Global business services
KW  - Idaho national laboratories
KW  - Integrated sources
KW  - Light-vehicle fleet
KW  - Operations planning
KW  - Weather prediction
ER  - 

TY  - JOUR
TI  - A computer architecture based on disruptive information technologies for drug management in hospitals
AU  - Chalmeta, R
AU  - Navarro-Ruiz, A
AU  - Soriano-Irigaray, L
T2  - PEERJ COMPUTER SCIENCE
AB  - The drug management currently carried out in hospitals is inadequate due to several factors, such as processes carried out manually, the lack of visibility of the hospital supply chain, the lack of standardized identification of medicines, inefficient stock management, an inability to follow the traceability of medicines, and poor data exploitation. Disruptive information technologies could be used to develop and implement a drug management system in hospitals that is innovative in all its phases and allows these problems to be overcome. However, there are no examples in the literature that show how these technologies can be used and combined for efficient drug management in hospitals. To help solve this research gap in the literature, this article proposes a computer architecture for the whole drug management process in hospitals that uses and combines different disruptive computer technologies such as blockchain, radio frequency identification (RFID), quick response code (QR), Internet of Things (IoT), artificial intelligence and big data, for data capture, data storage and data exploitation throughout the whole drug management process, from the moment the drug enters the hospital until it is dispensed and eliminated.
DA  - 2023/06/29/
PY  - 2023
DO  - 10.7717/peerj-cs.1455
VL  - 9
SN  - 2376-5992
AN  - WOS:001025606400001
ER  - 

TY  - JOUR
TI  - A review on supervised machine learning for accident risk analysis: Challenges in Malaysia
AU  - Choo, BC
AU  - Razak, MA
AU  - Radiah, ABD
AU  - Tohir, MZM
AU  - Syafiie, S
T2  - PROCESS SAFETY PROGRESS
AB  - The new Fourth Industrial Revolution (IR 4.0) trend is driven by the concept of automation and artificial intelligence (AI). However, Malaysia is slightly behind Singapore in terms of adopting AI innovation among ASEAN countries. This paper aims to conduct a literature review of machine learning to overcome subjectivity and bias in risk ranking decision-making. An introduction to machine learning concerning accident risk analysis is presented, and the challenges of its application in Malaysia are discussed. Existing machine learning features were evaluated to identify the feasible application in industrial accident analysis and ensure safety decision-making consistency. This review observed how the IR 4.0 approaches were used in the risk analysis, especially on supervised machine learning. This study also highlights the finding from the previous works on challenges in utilizing supervised machine learning, which is the need to have publicly accessible large database from industries and agencies such as the Department of Occupational Safety and Health (DOSH) Malaysia for the development of algorithms, which can potentially improve accident risk analysis and safety, especially for Malaysian industries.
DA  - 2022/04//undefined
PY  - 2022
DO  - 10.1002/prs.12346
VL  - 41
SP  - S147
EP  - S158
SN  - 1066-8527
AN  - WOS:000759413600001
ER  - 

TY  - JOUR
TI  - Corporate digital responsibility (CDR) in the age of AI: implications for interactive marketing
AU  - Kunz, WH
AU  - Wirtz, J
T2  - JOURNAL OF RESEARCH IN INTERACTIVE MARKETING
AB  - PurposeDespite all the recent achievements in the field of interactive marketing and artificial intelligence (AI), it is important to consider the ethical implications of these technologies. This paper explains the concept of corporate digital responsibility (CDR) and how it is affected by new advances in AI.Design/methodology/approachThe authors build on the work of Wirtz et al., (2023) and derive several managerial implications for the challenges that AI poses to CDR. CDR refers to a service company's ethical and fair use of data and technology within its digital service ecosystem. It involves establishing standards, protecting customer privacy, conducting external audits and striving for an equitable power dynamic between service firms and their partners.FindingsDespite the risks involved, many companies are not prioritizing good CDR practices. Financial benefits from the collection and use of consumer data, improved customer experience through AI-driven customization and personalization, cost reduction through service automation and the trade-offs between organizational goals and CDR practices can prevent companies from prioritizing good CDR practices.Originality/valueThis is one of the first articles in the service domain to take the concept of CDR and apply it to recent developments in generative AI.Research limitations/implicationsThe emergence of powerful AI tools presents opportunities and challenges. Research opportunities include responsible business restructuring, responsible service automation to ensure fairness and human oversight, addressing dehumanization of service delivery, responsible customer profiling to address privacy and discrimination concerns and preventing AI misuse.
DA  - 2023/08/02/
PY  - 2023
DO  - 10.1108/JRIM-06-2023-0176
SN  - 2040-7122
AN  - WOS:001041119600001
ER  - 

TY  - CONF
TI  - An Unsupervised Cross-lingual Word Alignment Approach based on Cycle-GAN and Hybrid Training
AU  - Xiong, ZH
AU  - Tao, Q
AU  - IEEE
T2  - INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND ENERGY TECHNOLOGIES (ICECET 2021)
AB  - Cross-lingual word alignment is an important task which would produce an effect on many downstream tasks. Most work on cross-lingual word alignment learn a mapping between the word vector features of the two languages on large labeled parallel corpora. Without any labeled parallel corpora, most unsupervised methods learning an orthogonal mapping between the two monolingual spaces. However, the performance of these methods are limited by the degree of isomorphism of the two monolingual spaces. while the embedding spaces for the two languages are less isomorphic, these methods perform not well. To address this problem, this paper proposes a novel unsupervised cross-lingual word alignment approach based on cycle-GAN and hybrid training (FMGAN). It maps two monolingual spaces through correcting the consistency of bidirectional mapping, which performs better in low isomorphism language pairs. Experimental results demonstrate that our approach is better than several state-of-the-art approaches in cross-lingual word alignment task.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICECET52533.2021.9698442
SP  - 895
EP  - 900
SN  - 978-1-6654-4231-2
AN  - WOS:000814669100151
KW  - Performance
KW  - Mapping
KW  - Unsupervised learning
KW  - Learn+
KW  - Generative adversarial networks
KW  - Set theory
KW  - consistency loss
KW  - Parallel corpora
KW  - Cross-lingual
KW  - Down-stream
KW  - Word alignment
KW  - Consistency loss
KW  - Cross-lingual word alignment
KW  - Hybrid training
KW  - Word vectors
ER  - 

TY  - JOUR
TI  - Supervising Structured Learning Experiences for Students in New Jersey: Training Teachers in School-Based Occupational Health and Safety Practice
AU  - Shendell, DG
AU  - Hemminger, LE
AU  - Campell, JK
AU  - Schlegel, B
T2  - PUBLIC HEALTH REPORTS
AB  - This article describes the structured learning experience (SLE) supervisory training curriculum coordinated by the New Jersey Safe Schools Program, a project supported by the New Jersey Department of Education, Office of Career and Technical Education. The New Jersey SLE supervisory training program comprises training courses and resources for teachers who supervise secondary school minors (students aged 16 to 18 years and special needs students up to age 21) enrolled in various programs-college preparatory, general education, career and technical education, career academies, and special education. One goal of the program is to enhance knowledge and awareness of legal and scientific occupational safety and health principles to ensure safe, rewarding work experiences inside and outside classrooms.
This article describes our experiences and data available from November 2005 to January 2008. We summarize relevant federal and state laws and agencies; potential exposure agents and microenvironments of concern; stakeholders and training partners; process and immediate impact data from SLE supervisory trainings; and lessons learned to inform states that may adopt similar strategies or regulations.
DA  - 2009/07//undefined
PY  - 2009
DO  - 10.1177/00333549091244S109
VL  - 124
SP  - 74
EP  - 83
SN  - 0033-3549
AN  - WOS:000266795600009
ER  - 

TY  - CONF
TI  - Can we Estimate Truck Accident Risk from Telemetric Data using Machine Learning?
AU  - Héberet, A
AU  - Marineau, I
AU  - Gervais, G
AU  - Glatard, T
AU  - Jaumard, B
T2  - 2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
A2  - Chen, Y
A2  - Ludwig, H
A2  - Tu, Y
A2  - Fayyad, U
A2  - Zhu, X
A2  - Hu, X
A2  - Byna, S
A2  - Liu, X
A2  - Zhang, J
A2  - Pan, S
A2  - Papalexakis, V
A2  - Wang, J
A2  - Cuzzocrea, A
A2  - Ordonez, C
AB  - Road accidents have a high societal cost that could be reduced through improved risk predictions using machine learning. This study investigates whether telemetric data collected on long-distance trucks can be used to predict the risk of accidents associated with a driver. We use a dataset provided by a truck transportation company containing the driving data of 1,141 drivers for 18 months. We evaluate two different machine learning approaches to perform this task. In the first approach, features are extracted from the time series data using the FRESH algorithm and then used to estimate the risk using Random Forests. In the second approach, we use a convolutional neural network to directly estimate the risk from the time series data. We find that neither approach is able to successfully estimate the risk of accidents on this dataset, in spite of many methodological attempts. We discuss the difficulties o f u sing t elemetric d ata for the estimation of the risk of accidents that could explain this negative result.
DA  - 2021///
PY  - 2021
DO  - 10.1109/BigData52589.2021.9671967
SP  - 1827
EP  - 1836
SN  - 2639-1589
AN  - WOS:000800559501111
KW  - Decision trees
KW  - Machine learning
KW  - Accidents
KW  - Data mining
KW  - Convolutional neural networks
KW  - Machine-learning
KW  - Risk perception
KW  - Roads and streets
KW  - Motor transportation
KW  - Machine learning approaches
KW  - Data Mining
KW  - Time series
KW  - Time-series data
KW  - Large dataset
KW  - Road safety
KW  - Road Safety
KW  - Risk predictions
KW  - Accident risks
KW  - Risk of accidents
KW  - Societal costs
KW  - Telemetric data
KW  - Truck accidents
ER  - 

TY  - JOUR
TI  - Segment alignment based cross-subject motor imagery classification under fading data
AU  - Wan, ZT
AU  - Yang, R
AU  - Huang, MJ
AU  - Alsaadi, FE
AU  - Sheikh, MM
AU  - Wang, ZD
T2  - COMPUTERS IN BIOLOGY AND MEDICINE
AB  - Motor imagery (MI) aims to use brain imagination without actual body activities to support motor learning, and machine learning algorithms such as common spatial patterns (CSP) are proven effective in the analysis of MI signals. In the conventional machine learning-based approaches, there are two main difficulties in feature extraction and recognition of MI signals: high personalization and data fading. The high personalization problem is due to the multi-subject nature when collecting MI signals, and the data fading problem as a recurring issue in MI signal quality is first raised by us but is not widely discussed at present. Aiming to solve the above two mentioned problems, a cross-subject fading data classification approach with segment alignment is proposed to classify the fading data of one single target with the model trained with the normal data of multiple sources in this paper. he effectiveness of proposed method is verified via two experiments: a dataset-based experiment with the dataset from BCI Competition and a lab-based experiment designed and conducted by us. The experimental results obtained from both experiments show that the proposed method can obtain optimal classification performance effectively under different fading levels with data from different subjects.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.1016/j.compbiomed.2022.106267
VL  - 151
SN  - 0010-4825
AN  - WOS:000906142500003
KW  - machine learning
KW  - artificial intelligence
KW  - Artificial intelligence
KW  - Machine learning
KW  - Machine learning algorithms
KW  - signal processing
KW  - Transfer learning
KW  - Algorithms
KW  - Learning algorithms
KW  - Image classification
KW  - Classification (of information)
KW  - adult
KW  - article
KW  - human
KW  - human experiment
KW  - Humans
KW  - male
KW  - algorithm
KW  - procedures
KW  - Image segmentation
KW  - Electroencephalography
KW  - Brain
KW  - Signal Processing, Computer-Assisted
KW  - Alignment
KW  - transfer of learning
KW  - Brain computer interface
KW  - Signal analysis
KW  - Body activities
KW  - brain computer interface
KW  - Brain-Computer Interfaces
KW  - competition
KW  - Cross subject
KW  - data classification
KW  - Data fading
KW  - electroencephalography
KW  - imagery
KW  - imagination
KW  - Imagination
KW  - Motor imagery
KW  - Motor imagery classification
KW  - Motor learning
KW  - Personalizations
KW  - Segment alignment
ER  - 

TY  - JOUR
TI  - Artificial intelligence in laboratory medicine: fundamental ethical issues and normative key-points
AU  - Pennestrì, F
AU  - Banfi, G
T2  - CLINICAL CHEMISTRY AND LABORATORY MEDICINE
AB  - The contribution of laboratory medicine in delivering value-based care depends on active cooperation and trust between pathologist and clinician. The effectiveness of medicine more in general depends in turn on active cooperation and trust between clinician and patient. From the second half of the 20th century, the art of medicine is challenged by the spread of artificial intelligence (AI) technologies, recently showing comparable performances to flesh-and-bone doctors in some diagnostic specialties. Being the principle source of data in medicine, the laboratory is a natural ground where AI technologies can disclose the best of their potential. In order to maximize the expected outcomes and minimize risks, it is crucial to define ethical requirements for data collection and interpretation by-design, clarify whether they are enhanced or challenged by specific uses of AI technologies, and preserve these data under rigorous but feasible norms. From 2018 onwards, the European Commission (EC) is making efforts to lay the foundations of sustainable AI development among European countries and partners, both from a cultural and a normative perspective. Alongside with the work of the EC, the United Kingdom provided worthy-considering complementary advice in order to put science and technology at the service of patients and doctors. In this paper we discuss the main ethical challenges associated with the use of AI technologies in pathology and laboratory medicine, and summarize the most pertaining key-points from the guidelines and frameworks before-mentioned.
DA  - 2022/11/25/
PY  - 2022
DO  - 10.1515/cclm-2022-0096
VL  - 60
IS  - 12
SP  - 1867
EP  - 1874
SN  - 1434-6621
AN  - WOS:000781419400001
ER  - 

TY  - JOUR
TI  - Data-Driven Estimation of a Driving Safety Tolerance Zone Using Imbalanced Machine Learning
AU  - Garefalakis, T
AU  - Katrakazas, C
AU  - Yannis, G
T2  - SENSORS
AB  - Predicting driving behavior and crash risk in real-time is a problem that has been heavily researched in the past years. Although in-vehicle interventions and gamification features in post-trip dashboards have emerged, the connection between real-time driving behavior prediction and the triggering of such interventions is yet to be realized. This is the focus of the European Horizon2020 project "i-DREAMS", which aims at defining, developing, testing and validating a 'Safety Tolerance Zone' (STZ) in order to prevent drivers from risky driving behaviors using interventions both in real-time and post-trip. However, the data-driven conceptualization of STZ levels is a challenging task, and data class imbalance might hinder this process. Following the project principles and taking the aforementioned challenges into consideration, this paper proposes a framework to identify the level of risky driving behavior as well as the duration of the time spent in each risk level by private car drivers. This aim is accomplished by four classification algorithms, namely Support Vector Machines (SVMs), Random Forest (RFs), AdaBoost, and Multilayer Perceptron (MLP) Neural Networks and imbalanced learning using the Adaptive Synthetic technique (ADASYN) in order to deal with the unbalanced distribution of the dataset in the STZ levels. Moreover, as an alternative approach of risk prediction, three regression algorithms, namely Ridge, Lasso, and Elastic Net are used to predict time duration. The results showed that RF and MLP outperformed the rest of the classifiers with 84% and 82% overall accuracy, respectively, and that the maximum speed of the vehicle during a 30 s interval, is the most crucial predictor for identifying the driving time at each safety level.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.3390/s22145309
VL  - 22
IS  - 14
SN  - 1424-8220
AN  - WOS:000831694000001
KW  - machine learning
KW  - Decision trees
KW  - Support vector machines
KW  - Machine Learning
KW  - Machine-learning
KW  - Classification (of information)
KW  - Automobile Driving
KW  - car driving
KW  - Forecasting
KW  - Accidents, Traffic
KW  - prevention and control
KW  - traffic accident
KW  - Driving behaviour
KW  - Safety engineering
KW  - Long short-term memory
KW  - Adaptive boosting
KW  - support vector machine
KW  - Random forests
KW  - Real- time
KW  - Safety testing
KW  - Support Vector Machine
KW  - Multilayer neural networks
KW  - Neural Networks, Computer
KW  - Behavior analysis
KW  - Behaviour classification
KW  - driving behavior classification
KW  - Driving behavior classification
KW  - driving behavior analysis
KW  - Driving behavior analyse
KW  - imbalanced machine learning
KW  - Imbalanced machine learning
KW  - Tolerance zones
ER  - 

TY  - JOUR
TI  - Investigating occupational and operational industrial safety data through Business Intelligence and Machine Learning
AU  - Nakhal, AAJ
AU  - Patriarca, R
AU  - Di Gravio, G
AU  - Antonioni, G
AU  - Paltrinieri, N
T2  - JOURNAL OF LOSS PREVENTION IN THE PROCESS INDUSTRIES
AB  - Learning from previous events represents a crucial element to improve the design and operations of industrial processes, especially considering the many variables characterizing the functioning of a plant. This learning process aims to reduce the frequency of incidents and/or mitigate their severity, which are both continuous and open challenges. This paper is grounded on a large incident repository, i.e., the Major Hazard Incident Data Service (MHIDAS) database, which was developed in 1986 by the Health and Safety Executive (HSE) to provide a reliable source of data on major hazard incidents involving hazardous materials. The database includes more than 9000 reports collected over five decades (1950s-1990s). This paper aims to provide a novel understanding of the industrial incidents reported in MHIDAS and unveil possible ways of exploring occupational/operational incidents through descriptive and quantitative analyses. Consequently, this paper proposes the implementation of Business Intelligence (BI) tools to facilitate dynamic data visualization and Machine Learning (ML) algorithms for the extraction of knowledge from different data entries. Therefore, after engineering the MHIDAS data model, a set of BI dashboards was designed and complemented with a ML-driven categorization of incidents through representative key variables for occupational/operational incidents. The manuscript describes the process necessary to create a BI model for safety data management in an industrial context, and its integration with ML solutions that may support an in-depth multi-variate investigation of reported data. The investigation provides evidence on the importance of a precise reporting of safety events, thus unveiling the potential for lessons learned in the process industry.
DA  - 2021/11//undefined
PY  - 2021
DO  - 10.1016/j.jlp.2021.104608
VL  - 73
SN  - 0950-4230
AN  - WOS:000694797800006
KW  - Machine learning
KW  - Accident prevention
KW  - Machine-learning
KW  - Data visualization
KW  - Information analysis
KW  - Operational safety
KW  - Occupational risks
KW  - Safety data
KW  - Occupational safety
KW  - Industrial processs
KW  - Incident data
KW  - Business intelligence
KW  - Business-intelligence
KW  - Competitive intelligence
KW  - Data services
KW  - Industrial processes
KW  - Major hazard incident data service
KW  - Major hazards
KW  - MHIDAS
ER  - 

TY  - JOUR
TI  - A Deep Reinforcement Learning-Based Energy Management Framework With Lagrangian Relaxation for Plug-In Hybrid Electric Vehicle
AU  - Zhang, HL
AU  - Peng, JK
AU  - Tan, HC
AU  - Dong, HX
AU  - Ding, F
T2  - IEEE TRANSACTIONS ON TRANSPORTATION ELECTRIFICATION
AB  - Reinforcement learning (RL)-based energy management is one of the current hot spots of hybrid electric vehicles. Recent advances in RL-based energy management focus on energy-saving performance but less considers the constrained setting for training safety. This article proposes an RL framework named coach-actor-double-critic (CADC) for the optimization of energy management considered as the constrained Markov decision process (CMDP). A bilevel onboard controller includes a neural network (NN)-based strategy actor and rule-based strategy coach for online energy management. Once the output of the actor exceeds the constrained range of feasible solutions, the coach would take charge of energy management to ensure safety. By using the Lagrangian relaxation, the optimization for CMDP transforms into an unconstrained dual problem to minimize the energy consumption while minimizing the coach participation. The parameters of the actor are updated in a manner of policy gradient through RL training with the Lagrangian value function. Double-critic with the same structure synchronously estimates the value function to avoid overestimate bias. Several experiments with the bus trajectories data demonstrate the optimality, self-learning ability, and adaptability of CADC. The results indicate that CADC outperforms the existing RL-based strategies and reaches above 95% energy-saving rate of the off-line global optimum.
DA  - 2021/09//undefined
PY  - 2021
DO  - 10.1109/TTE.2020.3043239
VL  - 7
IS  - 3
SP  - 1146
EP  - 1160
SN  - 2332-7782
AN  - WOS:000686895100020
KW  - Deep learning
KW  - Reinforcement learning
KW  - Markov processes
KW  - Energy utilization
KW  - Lagrange multipliers
KW  - Constrained Markov decision process
KW  - Energy management
KW  - reinforcement learning (RL)
KW  - Management frameworks
KW  - Neural network (nn)
KW  - Energy conservation
KW  - Energy-saving rates
KW  - Lagrangian relaxation
KW  - LaGrangian relaxation
KW  - Plug in hybrid electric vehicles
KW  - plug-in hybrid electric vehicle (PHEV)
KW  - Plug-in hybrid vehicles
KW  - Rule-based strategy
KW  - Self-learning ability
KW  - training safety
ER  - 

TY  - JOUR
TI  - Autonomous Platoon Control With Integrated Deep Reinforcement Learning and Dynamic Programming
AU  - Liu, T
AU  - Lei, L
AU  - Zheng, K
AU  - Zhang, K
T2  - IEEE INTERNET OF THINGS JOURNAL
AB  - Autonomous vehicles in a platoon determine the control inputs based on the system state information collected and shared by the Internet of Things (IoT) devices. Deep reinforcement learning (DRL) is regarded as a potential method for car-following control and has been mostly studied to support a single following vehicle. However, it is more challenging to learn an efficient car-following policy with convergence stability when there are multiple following vehicles in a platoon, especially with unpredictable leading vehicle behavior. In this context, we adopt an integrated DRL and dynamic programming (DP) approach to learn autonomous platoon control policies, which embeds the deep deterministic policy gradient (DDPG) algorithm into a finite-horizon value iteration framework. Although the DP framework can improve the stability and performance of DDPG, it has the limitations of lower sampling and training efficiency. In this article, we propose an algorithm, namely, finite-horizon-DDPG with sweeping through reduced state space using stationary approximation (FH-DDPG-SS), which uses three key ideas to overcome the above limitations, i.e., transferring network weights backward in time, stationary policy approximation for earlier time steps, and sweeping through reduced state space. In order to verify the effectiveness of FH-DDPG-SS, simulation using real driving data is performed, where the performance of FH-DDPG-SS is compared with those of the benchmark algorithms. Finally, platoon safety and string stability for FH-DDPG-SS are demonstrated.
DA  - 2023/03/15/
PY  - 2023
DO  - 10.1109/JIOT.2022.3222128
VL  - 10
IS  - 6
SP  - 5476
EP  - 5489
SN  - 2327-4662
AN  - WOS:000965125200001
ER  - 

TY  - JOUR
TI  - Multi-Input Autonomous Driving Based on Deep Reinforcement Learning With Double Bias Experience Replay
AU  - Cui, JP
AU  - Yuan, L
AU  - He, L
AU  - Xiao, WD
AU  - Ran, T
AU  - Zhang, JB
T2  - IEEE SENSORS JOURNAL
AB  - It is still a challenge to realize safe and fast autonomous driving through deep reinforcement learning (DRL). Most autonomous driving reinforcement learning models are subject to a single experience replay approach for training agents and how to improve the driving speed and safety of agents has become the focus of research. Therefore, we present an improved double-bias experience replay (DBER) approach, which enables the agent to choose its own driving learning tendency. A new loss function is proposed to ameliorate the relationship between negative loss and positive loss. The proposed approach has been applied to three algorithms to verify: deep Q network (DQN), dueling double DQN (DD-DQN), and quantile regression DQN (QR-DQN). Compared with the existing approaches, the proposed approach show better performance and robustness of driving policy on the driving simulator, which is implemented by the unity machine learning (ML) agents. The approach makes the vehicle agent obtain better performance, such as higher reward, faster driving speed, less lane changing, and more in the same training time.
DA  - 2023/06/01/
PY  - 2023
DO  - 10.1109/JSEN.2023.3237206
VL  - 23
IS  - 11
SP  - 11253
EP  - 11261
SN  - 1530-437X
AN  - WOS:001003468000014
ER  - 

TY  - JOUR
TI  - Modeling Pedestrian Injury Severity: A Case Study of Using Extreme Gradient Boosting Vs Random Forest in Feature Selection
AU  - Wu, ZX
AU  - Misra, A
AU  - Bao, S
T2  - TRANSPORTATION RESEARCH RECORD
AB  - Walking and bicycling are lauded for their negative net carbon impact and for their health benefits. However, national crash statistics suggest that pedestrians are disproportionately harmed in any vehicle-pedestrian conflict situation. Although automated transportation in the future is anticipated to increase overall safety, multiple incidents involving automated vehicles have been reported recently, indicating that the technology needs more training on real-world scenarios and conflicts. This research is motivated by the need for contextual data and related levels of harm in potential conflict scenarios in mixed traffic and we use a national police reported crash dataset, CRSS, to address this need. Our study uses a new gradient boosting algorithm, XGBoost, to identify important features among a host of seemingly significant variables. We compare the performance of XGBoost with the more frequently used random forest method and find that XGBoost is more reliable and robust for handling an unbalanced and sparse dataset like crash data, and the features extracted are more aligned to findings from previous research on the topic. We also compare feature importance between NASS-GES and CRSS-two national crash databases with different sampling strategies but the same objective-and find that sampling strategy influences selection of feature importance. We further use the features extracted using XGBoost in a multiclass logistic regression to quantify the effect of these features on different levels of pedestrian injury. Our findings indicate that speed limit, light conditions, pre-crash movements, and location of pedestrian are important contributors to crash severity, along with driver distraction and impairment.
DA  - 2023/05/15/
PY  - 2023
DO  - 10.1177/03611981231170014
SN  - 0361-1981
AN  - WOS:001000941200001
ER  - 

TY  - CONF
TI  - Resilience by design is mandatory to support the certification of the embedded/artificial intelligence of an autonomous swarm of drones
AU  - Chaumette, S
AU  - IEEE
T2  - 2020 AIAA/IEEE 39TH DIGITAL AVIONICS SYSTEMS CONFERENCE (DASC) PROCEEDINGS
DA  - 2020///
PY  - 2020
DO  - 10.1109/dasc50938.2020.9256773
SN  - 2155-7195
AN  - WOS:000646035600155
ER  - 

TY  - CONF
TI  - Train Small, Deploy Big: Do Relative World Views Permit Swarm-Safety During Policy Transplantation for Multi-Agent Reinforcement Learning Problems?
AU  - Fraser, B
AU  - Laurito, G
T2  - AI 2020: ADVANCES IN ARTIFICIAL INTELLIGENCE
A2  - Gallagher, M
A2  - Moustafa, N
A2  - Lakshika, E
AB  - In order to 'train small, deploy big', agent control policies must be transplanted from one trained agent into a larger set of agents for deployment. Given that compute resources and training time generally scale with the number of agents, this approach to generating swarm control policies may be favourable for larger swarms. However, in order for this process to be successful, the agent control policy must be indistinct to the agent on which it is trained so that it can perform as required in its new host agent. Through extensive simulation of a cooperative multi-agent navigation task, it is shown that this indistinctness of agent policies, and therefore the success of the associated learned solution of the transplanted swarm, is dependent upon the way in which an agent views the world: absolute or relative. As a corollary to, and in contrary to naive intuition of, this result, we show that homogeneous agent capability is not enough to guarantee policy indistinctness. The article also discusses what general conditions may be required in order to enforce policy indistinctness.
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-64984-5_21
VL  - 12576
SP  - 269
EP  - 280
SN  - 2945-9133
AN  - WOS:001061406300021
KW  - Reinforcement learning
KW  - Multi agent systems
KW  - Multi-agent reinforcement learning
KW  - Multi-agent deep reinforcement learning
KW  - Control policy
KW  - Swarm intelligence
KW  - Extensive simulations
KW  - Training time
KW  - Agent control
KW  - Compute resources
KW  - Cooperative navigation
KW  - Homogeneous agents
KW  - Multi-agent navigations
KW  - Policy transplantation
KW  - Swarm-safety
ER  - 

TY  - CONF
TI  - Adversarial Domain Adaptation Network with Enhanced Feature Discriminability for Thyroid Ultrasound Images
AU  - Li, XW
AU  - Li, PJ
AU  - Zhang, RX
AU  - Wang, CH
AU  - Wei, X
AU  - Zhao, MK
AU  - IEEE
T2  - 2023 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, IJCNN
AB  - In recent years, computer-aided diagnosis technology has made breakthroughs in clinical medicine. However, due to the different models and configurations of ultrasound instruments, the thyroid ultrasound images collected by different medical centers have different visual characteristics. It leads to domain shift in multi-center data and the lower generalization of computer-aided diagnosis models. We consider this limitation may attribute to the minor inter-class differences in thyroid ultrasound images, resulting in confusion space before and after domain feature alignment. Therefore, we propose an adversarial domain adaptation network with enhanced feature discriminability method. Among them, the discriminative feature learning module strengthens the discriminability of the learned features, so that the class distribution in each domain presents a high cohesion and low coupling effect; the class alignment module reduces the distance between the same class samples across domains to achieve class alignment and further strengthen the discriminability of each class. Experiments show that our method outperforms other state-of-the-art algorithms on the internal thyroid ultrasound image dataset. The method can effectively improve the model's generalization ability on multi-center thyroid ultrasound images.
DA  - 2023///
PY  - 2023
DO  - 10.1109/IJCNN54540.2023.10191059
SN  - 2161-4393
AN  - WOS:001046198700026
KW  - Computer aided diagnosis
KW  - Image enhancement
KW  - Medical imaging
KW  - Domain adaptation
KW  - Unsupervised domain adaptation
KW  - Adversarial learning
KW  - adversarial learning
KW  - class alignment
KW  - Class alignment
KW  - Clinical medicine
KW  - Diagnosis technology
KW  - Discriminability
KW  - discrminative feature
KW  - Discrminative feature
KW  - thyroid ultrasound dataset
KW  - Thyroid ultrasound dataset
KW  - Ultrasonics
KW  - Ultrasound images
KW  - unsupervised domain adaptation
ER  - 

TY  - JOUR
TI  - An Unsupervised Learning Approach for Analyzing Unsafe Pilot Operations Based on Flight Data
AU  - Li, XY
AU  - Qian, Y
AU  - Chen, HN
AU  - Zheng, LJ
AU  - Wang, QX
AU  - Shang, JX
T2  - APPLIED SCIENCES-BASEL
AB  - Flight safety is a hot topic in the aviation industry. Statistics show that safety incidents during landing are closely related to the flare phase because this critical period requires extensive pilot operations. Many airlines require that pilots should avoid performing any forward stick inputs during the flare. However, our statistical results from about 86,504 flights show that this unsafe pilot operation occasionally happens. Although several case studies were conducted previously, systematic research, especially based on a large volume of flight data, is still missing. This paper aims to fill this gap and provide more insights into the issue of pilots' unsafe stick operations during the flare phase. Specifically, our work is based on the Quick Access Recorder (QAR) data, which consist of multivariate time-series data from various flight parameters. The raw data were carefully preprocessed, then key features were extracted based on flight expert experience, and a K-means clustering algorithm was utilized to divide the unsafe pilot operations into four categories. Based on the clustering results, we conducted an in-depth analysis to uncover the reasons for different types of unsafe pilot stick operations. In addition, extensive experiments were conducted to further investigate how these unsafe operations are correlated with different factors, including airlines, airports, and pilots. To the best of our knowledge, this is the first systematic study analyzing pilots' unsafe forward stick operations based on a large volume of flight data. The findings can be used by airlines to design more targeted pilot training programs in the future.
DA  - 2022/12//undefined
PY  - 2022
DO  - 10.3390/app122412789
VL  - 12
IS  - 24
SN  - 2076-3417
AN  - WOS:000900354600001
KW  - unsupervised learning
KW  - aviation safety
KW  - K-means clustering
KW  - flight data
KW  - pilot operation
KW  - QAR
ER  - 

TY  - JOUR
TI  - Operationalizing Responsible AI at Scale: CSIRO Data61's Pattern-Oriented Responsible AI Engineering Approach
AU  - Lu, QH
AU  - Zhu, LM
AU  - Xu, XW
AU  - Whittle, J
AU  - Zowghi, D
AU  - Jacquet, A
T2  - COMMUNICATIONS OF THE ACM
DA  - 2023/07//undefined
PY  - 2023
DO  - 10.1145/3589946
VL  - 66
IS  - 7
SP  - 64
EP  - 66
SN  - 0001-0782
AN  - WOS:001018481900023
ER  - 

TY  - JOUR
TI  - Big data, medicines safety and pharmacovigilance
AU  - Hussain, R
T2  - JOURNAL OF PHARMACEUTICAL POLICY AND PRACTICE
DA  - 2021/06/02/
PY  - 2021
DO  - 10.1186/s40545-021-00329-4
VL  - 14
IS  - 1
SN  - 2052-3211
AN  - WOS:000659128400001
ER  - 

TY  - JOUR
TI  - Artificial intelligence techniques for driving safety and vehicle crash prediction
AU  - Halim, Z
AU  - Kalsoom, R
AU  - Bashir, S
AU  - Abbas, G
T2  - ARTIFICIAL INTELLIGENCE REVIEW
AB  - Accident prediction is one of the most critical aspects of road safety, whereby an accident can be predicted before it actually occurs and precautionary measures taken to avoid it. For this purpose, accident prediction models are popular in road safety analysis. Artificial intelligence (AI) is used in many real world applications, especially where outcomes and data are not same all the time and are influenced by occurrence of random changes. This paper presents a study on the existing approaches for the detection of unsafe driving patterns of a vehicle used to predict accidents. The literature covered in this paper is from the past 10 years, from 2004 to 2014. AI techniques are surveyed for the detection of unsafe driving style and crash prediction. A number of statistical methods which are used to predict the accidents by using different vehicle and driving features are also covered in this paper. The approaches studied in this paper are compared in terms of datasets and prediction performance. We also provide a list of datasets and simulators available for the scientific community to conduct research in the subject domain. The paper also identifies some of the critical open questions that need to be addressed for road safety using AI techniques.
DA  - 2016/10//undefined
PY  - 2016
DO  - 10.1007/s10462-016-9467-9
VL  - 46
IS  - 3
SP  - 351
EP  - 387
SN  - 0269-2821
AN  - WOS:000382702800004
ER  - 

TY  - CONF
TI  - PCT: Partial Co-Alignment of Social Networks
AU  - Zhang, JW
AU  - Yu, PS
AU  - ACM
T2  - PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16)
AB  - People nowadays usually participate in multiple online social networks simultaneously to enjoy more social network services. Besides the common users, social networks providing similar services can also share many other kinds of information entities, e.g., locations, videos and products. However, these shared information entities in different networks are mostly isolated without any known corresponding connections. In this paper, we aim at inferring such potential corresponding connections linking multiple kinds of shared entities across networks simultaneously. Formally, the problem is referred to as the network "Partial Co-alignmenT" (PCT) problem. PCT is an important problem and can be the prerequisite for many concrete cross-network applications, like social network fusion, mutual information exchange and transfer. Meanwhile, the PCT problem is also very challenging to address due to various reasons, like (1) the heterogeneity of social networks, (2) lack of training instances to build models, and (3) one-to-one constraint on the correspondence connections. To resolve these challenges, a novel unsupervised network alignment framework, UNICOAT (UNsupervIsed COncurrent AlignmenT)), is introduced in this paper. Based on the heterogeneous information, uNiCOAT transforms the PCT problem into a joint optimization problem. To solve the objective function, the one-to-one constraint on the corresponding relationships is relaxed, and the redundant non-existing corresponding connections introduced by such a relaxation will be pruned with a novel network co-matching algorithm proposed in this paper. Extensive experiments conducted on real-world co aligned social network datasets demonstrate the effectiveness of uNiC OAT in addressing the PCT problem.
DA  - 2016///
PY  - 2016
DO  - 10.1145/2872427.2883038
SP  - 749
EP  - 759
SN  - 978-1-4503-4143-1
AN  - WOS:000461467400064
KW  - Data mining
KW  - Optimization
KW  - Social networking (online)
KW  - Data Mining
KW  - Unsupervised learning
KW  - Alignment
KW  - Objective functions
KW  - Problem solving
KW  - Unsupervised Learning
KW  - Mutual informations
KW  - World Wide Web
KW  - Joint optimization
KW  - On-line social networks
KW  - Unsupervised network
KW  - Heterogeneous information
KW  - Matching algorithm
KW  - Multiple Heterogeneous Social Networks
KW  - Partial Network Co-Alignment
KW  - Social network services
ER  - 

TY  - CONF
TI  - An Unsupervised Domain Adaptation Method for Multi-Modal Remote Sensing Image Classification
AU  - Liu, W
AU  - Qin, RJ
AU  - Su, FL
AU  - Hu, K
T2  - 2018 26TH INTERNATIONAL CONFERENCE ON GEOINFORMATICS (GEOINFORMATICS 2018)
A2  - Hu, S
A2  - Ye, X
A2  - Yang, K
A2  - Fan, H
AB  - Labeling remote sensing data for classification is costly and time-consuming in practical applications, while sufficient and representative labels are critical for achieving a high accuracy. Transfer learning emerges as an effective method for this issue by reusing samples from other domains. In this paper, we propose an unsupervised domain adaptation method which can align the marginal distribution and conditional distribution in source and target domain at the same time. Our method treats the importance of the marginal and conditional distribution discrepancies at different levels and maps the feature sets of source domain and target domain into Reproducing Kernel Hilbert Space (RKHS) to obtain similar feature sets. In particular, we apply the proposed method on the multi-modal remote sensing data including pixel-wise overlaid Orthophoto and Digital Surface Models (DSM). With experiments containing images of different cities with highly distinguishable land-cover patterns as source and target domain, we demonstrate that, as compared to several state-of-the-art domain adaptation (DA) algorithms, our method can achieve a satisfactory performance on the target domain by a simple statistical classifier trained only by samples in the source domain.
DA  - 2018///
PY  - 2018
SN  - 2161-024X
AN  - WOS:000459847200137
KW  - Transfer learning
KW  - Image classification
KW  - Classification (of information)
KW  - Multi-modal
KW  - Classification
KW  - Remote sensing
KW  - Domain adaptation
KW  - Unsupervised
KW  - Remote-sensing
KW  - Distribution alignment
KW  - Target domain
KW  - Adaptation methods
KW  - Domain adaptation (DA)
KW  - Remote sensing (RS)
ER  - 

TY  - CONF
TI  - Optimization of Cache-enabled Opportunistic Interference Alignment Wireless Networks: A Big Data Deep Reinforcement Learning Approach
AU  - He, Y
AU  - Liang, CC
AU  - Yu, FR
AU  - Zhao, N
AU  - Yin, HX
AU  - IEEE
T2  - 2017 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS (ICC)
AB  - Both caching and interference alignment (IA) are promising techniques for future wireless networks. Nevertheless, most of existing works on cache-enabled IA wireless networks assume that the channel is invariant, which is unrealistic considering the time-varying nature of practical wireless environments. In this paper, we consider realistic time-varying channels. Specifically, the channel is formulated as a finite-state Markov channel (FSMC). The complexity of the system is very high when we consider realistic FSMC models. Therefore, we propose a novel big data reinforcement learning approach in this paper. Deep reinforcement learning is an advanced reinforcement learning algorithm that uses deep Q network to approximate the Q value-action function. Deep reinforcement learning is used in this paper to obtain the optimal IA user selection policy in cache-enabled opportunistic IA wireless networks. Simulation results are presented to show the effectiveness of the proposed scheme.
DA  - 2017///
PY  - 2017
SN  - 1550-3607
AN  - WOS:000424872100013
KW  - deep reinforcement learning
KW  - Caching
KW  - interference alignment
ER  - 

TY  - JOUR
TI  - Exploiting Multi-Modal Fusion for Urban Autonomous Driving Using Latent Deep Reinforcement Learning
AU  - Khalil, YH
AU  - Mouftah, HT
T2  - IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY
AB  - Human driving decisions are the leading cause of road fatalities. Autonomous driving naturally eliminates such incompetent decisions and thus can improve traffic safety and efficiency. Deep reinforcement learning (DRL) has shown great potential in learning complex tasks. Recently, researchers investigated various DRL-based approaches for autonomous driving. However, exploiting multi-modal fusion to generate perception and motion prediction and then leveraging these predictions to train a latent DRL has not been targeted yet. To that end, we propose enhancing urban autonomous driving using multi-modal fusion with latent DRL. A single LIDAR sensor is used to extract bird's-eye view (BEV), range view (RV), and residual input images. These images are passed into LiCaNext, a real-time multi-modal fusion network, to produce accurate joint perception and motion prediction. Next, predictions are fed with another simple BEV image into the latent DRL to learn a complex end-to-end driving policy ensuring safety, efficiency, and comfort. A sequential latent model is deployed to learn more compact representations from inputs, leading to improved sampling efficiency for reinforcement learning. Our experiments are simulated on CARLA and evaluated against state-of-the-art DRL models. Results manifest that our method learns a better driving policy that outperforms other prevailing models. Further experiments are conducted to reveal the effectiveness of our proposed approach under different environments and varying weather conditions.
DA  - 2023/03//undefined
PY  - 2023
DO  - 10.1109/TVT.2022.3217299
VL  - 72
IS  - 3
SP  - 2921
EP  - 2935
SN  - 0018-9545
AN  - WOS:000965706100001
ER  - 

TY  - JOUR
TI  - Identifying Cases of Shoulder Injury Related to Vaccine Administration (SIRVA) in the United States: Development and Validation of a Natural Language Processing Method
AU  - Zheng, CY
AU  - Duffy, J
AU  - Liu, ILA
AU  - Sy, LS
AU  - Navarro, RA
AU  - Kim, SS
AU  - Ryan, DS
AU  - Chen, W
AU  - Qian, L
AU  - Mercado, C
AU  - Jacobsen, SJ
T2  - JMIR PUBLIC HEALTH AND SURVEILLANCE
AB  - Background: Shoulder injury related to vaccine administration (SIRVA) accounts for more than half of all claims received by the National Vaccine Injury Compensation Program. However, due to the difficulty of finding SIRVA cases in large health care databases, population-based studies are scarce. Objective: The goal of the research was to develop a natural language processing (NLP) method to identify SIRVA cases from clinical notes. Methods: We conducted the study among members of a large integrated health care organization who were vaccinated between April 1, 2016, and December 31, 2017, and had subsequent diagnosis codes indicative of shoulder injury. Based on a training data set with a chart review reference standard of 164 cases, we developed an NLP algorithm to extract shoulder disorder information, including prior vaccination, anatomic location, temporality and causality. The algorithm identified 3 groups of positive SIRVA cases (definite, probable, and possible) based on the strength of evidence. We compared NLP results to a chart review reference standard of 100 vaccinated cases. We then applied the final automated NLP algorithm to a broader cohort of vaccinated persons with a shoulder injury diagnosis code and performed manual chart confirmation on a random sample of NLP-identified definite cases and all NLP-identified probable and possible cases. Results: In the validation sample, the NLP algorithm had 100% accuracy for identifying 4 SIRVA cases and 96 cases without SIRVA. In the broader cohort of 53,585 vaccinations, the NLP algorithm identified 291 definite, 124 probable, and 52 possible SIRVA cases. The chart-confirmation rates for these groups were 95.5% (278/291), 67.7% (84/124), and 17.3% (9/52), respectively. Conclusions: The algorithm performed with high sensitivity and reasonable specificity in identifying positive SIRVA cases. The NLP algorithm can potentially be used in future population-based studies to identify this rare adverse event, avoiding labor-intensive chart review validation.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.2196/30426
VL  - 8
IS  - 5
SN  - 2369-2960
AN  - WOS:000809494600008
ER  - 

TY  - JOUR
TI  - Wireless Sensor Networks: Toward Smarter Railway Stations
AU  - Alawad, H
AU  - Kaewunruen, S
T2  - INFRASTRUCTURES
AB  - Railway industry plays a critical role in transportation and transit systems attributed to the ever-growing demand for catering to both freight and passengers. However, owing to many challenges faced by railway stations such as harsh environments, traffic flow, safety and security risks, new and adaptive systems employing new technology are recommended. In this review, several wireless sensor networks (WSNs) applications are proposed for use in railway station systems, including advanced WSNs, which will enhance security, safety, and decision-making processes to achieve more cost-effective management in railway stations, as well as the development of integrated systems. The size, efficiency, and cost of WSNs are influential factors that attract the railway industry to adopt these devices. This paper presents a review of WSNs that have been designed for uses in monitoring and securing railway stations. This article will first briefly focus on the presence of different WSN applications in diverse applications. In addition, it is important to note that exploitation of the state-of-the-art tools and techniques such as WSNs to gain an enormous amount of data from a railway station is a new and novel concept requiring the development of artificial intelligence methods, such machine learning, which will be vital for the future of the railway industry.
DA  - 2018/09//undefined
PY  - 2018
DO  - 10.3390/infrastructures3030024
VL  - 3
IS  - 3
SN  - 2412-3811
AN  - WOS:000623626100008
KW  - Machine learning in railway stations
KW  - Railway data
KW  - Railway station
KW  - Security and safety in a railway station
KW  - Smart railway stations
KW  - Wireless sensor network WSN
ER  - 

TY  - JOUR
TI  - A Hamiltonian Monte Carlo Method for Probabilistic Adversarial Attack and Learning
AU  - Wang, HJ
AU  - Li, GB
AU  - Liu, XB
AU  - Lin, L
T2  - IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
AB  - Although deep convolutional neural networks (CNNs) have demonstrated remarkable performance on multiple computer vision tasks, researches on adversarial learning have shown that deep models are vulnerable to adversarial examples, which are crafted by adding visually imperceptible perturbations to the input images. Most of the existing adversarial attack methods only create a single adversarial example for the input, which just gives a glimpse of the underlying data manifold of adversarial examples. An attractive solution is to explore the solution space of the adversarial examples and generate a diverse bunch of them, which could potentially improve the robustness of real-world systems and help prevent severe security threats and vulnerabilities. In this paper, we present an effective method, called Hamiltonian Monte Carlo with Accumulated Momentum (HMCAM), aiming to generate a sequence of adversarial examples. To improve the efficiency of HMC, we propose a new regime to automatically control the length of trajectories, which allows the algorithm to move with adaptive step sizes along the search direction at different positions. Moreover, we revisit the reason for high computational cost of adversarial training under the view of MCMC and design a new generative method called Contrastive Adversarial Training (CAT), which approaches equilibrium distribution of adversarial examples with only few iterations by building from small modifications of the standard Contrastive Divergence (CD) and achieve a trade-off between efficiency and accuracy. Both quantitative and qualitative analysis on several natural image datasets and practical systems have confirmed the superiority of the proposed algorithm.
DA  - 2022/04/01/
PY  - 2022
DO  - 10.1109/TPAMI.2020.3032061
VL  - 44
IS  - 4
SP  - 1725
EP  - 1737
SN  - 0162-8828
AN  - WOS:000764815300008
KW  - Deep neural networks
KW  - Algorithms
KW  - Performance
KW  - Economic and social effects
KW  - algorithm
KW  - Efficiency
KW  - Probabilistics
KW  - Adversarial example
KW  - adversarial training
KW  - Monte Carlo methods
KW  - Adversarial learning
KW  - Neural Networks, Computer
KW  - Attack methods
KW  - Adversarial training
KW  - Hamiltonians
KW  - Monte Carlo method
KW  - Input image
KW  - Hamiltonian Monte Carlo Method
KW  - Monte Carlo Method
KW  - Multiple computers
KW  - robustness and safety of machine learning
KW  - Robustness and safety of machine learning
ER  - 

TY  - JOUR
TI  - Deep Reinforcement Learning-Based Driving Strategy for Avoidance of Chain Collisions and Its Safety Efficiency Analysis in Autonomous Vehicles
AU  - Muzahid, AM
AU  - Kamarulzaman, SF
AU  - Rahman, MA
AU  - Alenezi, AH
T2  - IEEE ACCESS
AB  - Vehicle control in autonomous traffic flow is often handled using the best decision-making reinforcement learning methods. However, unexpected critical situations make the collisions more severe and, consequently, the chain collisions. In this work, we first review the leading causes of chain collisions and their subsequent chain events, which might provide an indication of how to prevent and mitigate the crash severity of chain collisions. Then, we consider the problem of chain collision avoidance as a Markov Decision Process problem in order to propose a reinforcement learning-based decision-making strategy and analyse the safety efficiency of existing methods in driving security. To address this, A reward function is being developed to deal with the challenge of multiple vehicle collision avoidance. A perception network structure based on formation and on actor-critic methodologies is employed to enhance the decision-making process. Finally, in the safety efficiency analysis phase, we investigated the safety efficiency performance of the agent vehicle in both single-agent and multi-agent autonomous driving environments. Three state-of-the-art contemporary actor-critic algorithms are used to create an extensive simulation in Unity3D. Moreover, to demonstrate the accuracy of the safety efficiency analysis, multiple training runs of the neural networks in respect of training performance, speed of training, success rate, and stability of rewards with a trade-off between exploitation and exploration during training are presented. Two aspects (single-agent and multi-agent) have assessed the efficiency of algorithms. Every aspect has been analyzed regarding the traffic flows: (1) the controlling efficiency of unexpected traffic situations by the sudden slowdown, (2) abrupt lane change, and (3) smoothly reaching the destination. All the findings of the analysis are intended to shed insight on the benefits of a greater, more reliable autonomous traffic set-up for academics and policymakers, and also to pave the way for the actual carry-out of a driver-less traffic world.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3167812
VL  - 10
SP  - 43303
EP  - 43319
SN  - 2169-3536
AN  - WOS:000788919000001
ER  - 

TY  - JOUR
TI  - Leveraging ChatGPT to Aid Construction Hazard Recognition and Support Safety Education and Training
AU  - Uddin, SMJ
AU  - Albert, A
AU  - Ovid, A
AU  - Alsharef, A
T2  - SUSTAINABILITY
AB  - Proper hazard recognition is fundamental to effective safety management in construction workplaces. Nevertheless, poor hazard recognition levels are a widespread and persistent problem in the construction industry. For example, recent investigations have demonstrated that a significant number of workplace hazards often remain unrecognized in construction workplaces. These unrecognized workplace hazards often remain unmanaged and can potentially translate into devastating and unexpected safety incidents. Therefore, interventions targeted at improving hazard recognition levels are foundational to enhancing safety management in construction workplaces. The main objective of the current investigation was to examine if ChatGPT, a language model recently launched by OpenAI, can aid hazard recognition when integrated into the curriculum of students pursuing a career in the construction industry. The investigation was carried out as an experimental effort with 42 students enrolled in the construction program at a major state university in the United States. First, prior to the introduction of ChatGPT as an intervention, the pre-intervention hazard recognition ability of the students was measured. Next, ChatGPT and its capabilities were introduced to the students in a classroom setting. Guidance was also offered on how the students could leverage ChatGPT to aid hazard recognition efforts. Finally, the post-intervention hazard recognition ability of the students was measured and compared against their earlier performance. The result suggests that ChatGPT can be leveraged to improve hazard recognition levels. Accordingly, integrating ChatGPT as part of safety education and training can yield benefits and prepare the next generation of construction professionals for industry success.
DA  - 2023/04/24/
PY  - 2023
DO  - 10.3390/su15097121
VL  - 15
IS  - 9
SN  - 2071-1050
AN  - WOS:000988134100001
ER  - 

TY  - JOUR
TI  - Threats From Unintentional Insiders: An Assessment of an Organization's Readiness Using Machine Learning
AU  - Rahman, MMH
AU  - Al Naeem, M
AU  - Abubakar, A
T2  - IEEE ACCESS
AB  - Today's organisations are facing a number of challenges, one of the most significant of which is ensuring the safety of their digital data. This is as a result of the fact that they are frequently faced with internal and external threats that can put the data they have been entrusted with in jeopardy of being compromised. As a result of this, this study investigates the dimension of threats associated to unintentional internal user of an organisation and utilises NARX to model and test a detection scheme associated to the menace. In addition, this study aims to provide a better understanding of the current state of the threat landscape. The data adopted for this research is primarily a "user activity logs" dataset from CERT (release version r4.2). From the data, the study conceptualized "Access", "Motivation", and "Action" to be the key dimensions influencing "insider", whereas "Intent", "+Action", "Method", and "knowledge" are the key dimension influencing "threats". Experimental analyses conducted by NARX within several numbers of partitions of the data point to a good detection capacity, with the greatest value of R2 coming in at 0.97. This indicates that NARX was able to detect the crucial dimension that was formulated for by the research to be the detections parameter of an inadvertent insider threat when operating under the best partition. In light of these findings, organisations can use the proposed approach to assess their preparedness for Insider attacks.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3214819
VL  - 10
SP  - 110294
EP  - 110308
SN  - 2169-3536
AN  - WOS:000873864300001
ER  - 

TY  - JOUR
TI  - Open innovation programmes related to data and AI: How do the entrepreneurial orientations of startups align with the objectives of public funders?
AU  - Priestley, M
AU  - Simperl, E
T2  - DATA & POLICY
AB  - Open innovation programmes related to data and artificial intelligence have interested European policy-makers as a means of supporting startups and small and medium-sized enterprises to succeed in the digital economy. We discuss the objectives behind the typical service offerings of such programmes and propose a case for exploring how they align with the motivations of individual companies who are targeted by these initiatives. Using a qualitative analysis of 50 startup applications from the Data Market Services Accelerator programme, we find that applicants wrote most frequently about fundraising, acceleration and data skills. A smaller number of startups expressed interest in services related to standardization or legal guidance on General Data Protection Regulation and intellectual property rights, which are some of the ongoing priority areas for the European Commission. We discuss how the value propositions of these less desired offerings can be amplified by appealing the existing business motivations of data-driven startups.
DA  - 2022///
PY  - 2022
DO  - 10.1017/dap.2022.8
VL  - 4
SN  - 2632-3249
AN  - WOS:000850908800016
ER  - 

TY  - CONF
TI  - GPS Alignment from Multiple Sources to Extract Aircraft Bearing in Aerial Surveys
AU  - Power, J
AU  - Jacoby, D
AU  - Drouin, MA
AU  - Durand, G
AU  - Coady, Y
AU  - Meng, JL
AU  - IEEE
T2  - 2023 IEEE/ION POSITION, LOCATION AND NAVIGATION SYMPOSIUM, PLANS
AB  - Methodical aerial population surveys monitoring critically endangered species in Canadian North Atlantic waters are instrumental in influencing government policies both in economic and conservational efforts. The primary factor hindering the success of these missions is poor visibility caused by glare. This paper builds off our foundational paper [1] and pushes the envelope toward a data-driven glare modelling system. Said data-driven system makes use of meteorological and astronomical data to assist aircraft in navigating in order to mitigate acquisition errors and optimize the quality of acquired data. It is found that reliably extracting aircraft orientation is critical to our approach, to that end, we present a GPS alignment methodology which makes use of the fusion of two GPS signals. Using the complementary strengths and weaknesses of these two signals a synthetic interpolation of fused data is used to generate more reliable flight tracks, substantially improving glare modelling. This methodology could be applied to any other applications with similar signal restrictions.
DA  - 2023///
PY  - 2023
DO  - 10.1109/PLANS53410.2023.10139941
SP  - 781
EP  - 792
SN  - 2153-358X
AN  - WOS:001022344800090
KW  - machine learning
KW  - context-aware
KW  - Machine learning
KW  - Machine-learning
KW  - Aircraft
KW  - Antennas
KW  - Data driven
KW  - Context-Aware
KW  - Mission planning
KW  - Global positioning system
KW  - Conservation
KW  - aerial survey
KW  - Aerial surveys
KW  - data-driven mission planning
KW  - Data-driven mission planning
KW  - glare
KW  - GPS alignment
KW  - image quality metric
KW  - Image-quality metrics
KW  - marine megafauna
KW  - Marine megafauna
KW  - Megafauna
KW  - multi-source GPS fusion
KW  - Multi-source GPS fusion
KW  - Multi-Sources
ER  - 

TY  - JOUR
TI  - LogRegX: An Explainable Regression Network for Cross-Well Geophysical Logs Generation
AU  - Lv, WJ
AU  - Yuan, CH
AU  - Wang, JC
AU  - Zhu, JB
AU  - Kang, Y
AU  - Chang, J
T2  - IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
AB  - Geophysical logging instruments continuously measure multiple geophysical properties of borehole rocks, thus providing a feasible way to fine borehole geology modeling. Since the missing problem of well logs is inevitable, it is essential to generate the missing logs by the available ones. Recently, a large body of interdisciplinary studies has demonstrated the effectiveness of applying machine learning to solve the missing logs generation problem, under which the training and testing datasets obey the independent and identical distribution (iid) assumption. This assumption, however, is not satisfied in the case of the cross-well missing logs generation task. A standard method to solve the non-iid issue is to map source and target data to a common feature space and then employ mean maximum discrepancy (MMD) to measure domain differences. However, this method suffers from high computational complexity and poor feature explainability when dealing with log generation tasks. To solve the above problems, we propose an explainable regression network for cross-well geophysical logs generation named LogRegX. LogRegX integrates single-well feature extraction, cross-well feature alignment, and missing logs prediction while maintaining the explainability of logging features. Specifically, LogRegX leverages the gating mechanism to fuse multiscale logging features to capture the response characteristics of well logs. The learned source and target feature representations are subject to domain discrepancy constraints, measured by random Fourier feature transform-induced MMD. Additionally, a target-domain information-retaining mechanism is introduced to maintain the structure of target data so that the transferred features are explainable. Experiments on real-world field data demonstrate the superiority and the explainability of LogRegX over the existing methods.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TIM.2023.3253897
VL  - 72
SN  - 0018-9456
AN  - WOS:000961115100003
ER  - 

TY  - JOUR
TI  - Relationships between Plantar Pressure Distribution and Rearfoot Alignment in the Taiwanese College Athletes with Plantar Fasciopathy during Static Standing and Walking
AU  - Chow, TH
AU  - Chen, YS
AU  - Hsu, CC
T2  - INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH
AB  - Background: Plantar fasciopathy (PF) is usually related to changes in foot arch, foot shape and rearfoot posture. However, little research has been implemented by using large-scale datasets, and even less has been conducted centering on plantar pressure distributions (PPDs) of different genders of PF athletes. This study aimed to investigate the relationships among the arch index (AI), the PPDs and the rearfoot postural alignment in hundreds of college athletes with PF during static standing and walking. Methods: Cross-sectional study of 100 male and 102 female athletes with PF was undertaken. The PF athletes' pain assessment and self-reported health status were examined for evaluating their musculoskeletal painful areas. Results: The PF athletes' PPDs mainly concentrated on inner feet in static standing, and transferred to lateral forefeet during the midstance phase of walking. The males' PPDs from the static standing to the midstance phase of walking mainly transferred to anterolateral feet. The females' PPDs mainly transferred to posterolateral feet. The PF athletes' static rearfoot alignment matched the valgus posture pattern. The medial band of plantar fascia and calcaneus were the common musculoskeletal pain areas. Conclusions: Characteristics of higher plantar loads beneath medial feet associated with rearfoot valgus in bipedal static stance could be the traceable features for PF-related foot diagrams. Higher plantar loads mainly exerted on the lateral forefoot during the midstance phase of walking, and specifically concentrated on outer feet during the transition from static to dynamic state. Pain profiles seem to echo PPDs, which could function as the traceable beginning for the possible link among pronated low-arched feet, PF, metatarsalgia, calcanitis and Achilles tendinitis.
DA  - 2021/12//undefined
PY  - 2021
DO  - 10.3390/ijerph182412942
VL  - 18
IS  - 24
SN  - 1660-4601
AN  - WOS:000738592900001
ER  - 

TY  - JOUR
TI  - Exploring Drivers of Staff Engagement in Healthcare Organizations Using Tree-Based Machine Learning Algorithms
AU  - Al-Nammari, R
AU  - Simsekler, MCE
AU  - Gabor, AF
AU  - Qazi, A
T2  - IEEE TRANSACTIONS ON ENGINEERING MANAGEMENT
AB  - Staff engagement in the work environment is vital to organizational success. Engaged staff are motivated and indulged in their work as they have a sense of belonging, commitment, and loyalty toward their employer, which eventually leads to better performance and outcomes. While various organizational factors are related to staff engagement, limited research is available regarding what drives staff engagement and the degree of their importance in healthcare. Leveraging data-driven approaches, in this article, we employ three machine learning algorithms, random forests, gradient boosting, and extra trees, to identify the relative importance of organizational factors affecting staff engagement. We use hospital-level aggregate survey data from hospitals in the U.K. While staff engagement is the outcome variable, the following factors are used as organizational factors in the prediction model and feature importance analysis: equality, diversity, and inclusion, safety culture, health and wellbeing, immediate managers, quality of appraisals, quality of care, bullying and harassment, violence, and team working. All the algorithms provide comparable prediction results with similar feature importance ranking with respect to prediction accuracy. The results suggest that safety culture is the most influential factor related to staff engagement, followed by the team working. Healthcare managers and decision makers can benefit from this data-driven application to make informed decisions in resource allocation and prioritization efforts to improve staff engagement.
DA  - 2023/08//undefined
PY  - 2023
DO  - 10.1109/TEM.2022.3209879
VL  - 70
IS  - 8
SP  - 2988
EP  - 2997
SN  - 0018-9391
AN  - WOS:001016776000028
KW  - Decision trees
KW  - Artificial intelligence
KW  - Machine learning
KW  - Prediction algorithms
KW  - Predictive models
KW  - Medical services
KW  - Learning systems
KW  - Data analytics
KW  - Human resource management
KW  - Machine-learning
KW  - Forecasting
KW  - Gradient boosting
KW  - Personnel training
KW  - Safety factor
KW  - Adaptive boosting
KW  - Health care
KW  - Random forests
KW  - Digital storage
KW  - Hospitals
KW  - Safety culture
KW  - machine learning (ML)
KW  - Random forest
KW  - Radiofrequencies
KW  - random forest (RF)
KW  - safety culture
KW  - Managers
KW  - Boosting
KW  - employee engagement
KW  - Employee engagement
KW  - gradient boosting (GB)
KW  - Health-care managements
KW  - healthcare management
KW  - organizational culture
KW  - Organizational cultures
KW  - staff engagement
KW  - Staff engagement
ER  - 

TY  - JOUR
TI  - IL-4/13 Blockade and sleep-related adverse drug reactions in over 37,000 Dupilumab reports from the World Health Organization Individual Case Safety reporting pharmacovigilance database (VigiBase™): a big data and machine learning analysis
AU  - Alroobaea, R
AU  - Rubaiee, S
AU  - Hanbazazah, AS
AU  - Jahrami, H
AU  - Garbarino, S
AU  - Damiani, G
AU  - Wu, J
AU  - Bragazzi, NL
T2  - EUROPEAN REVIEW FOR MEDICAL AND PHARMACOLOGICAL SCIENCES
AB  - OBJECTIVE: Atopic dermatitis displays a relevant sleep burden sustained by clinical (i.e., itch), psychological (i.e., inadequate coping strategies) and therapeutic (i.e., frequent loss of drug response) triggers. Dupilumab, the first biologic approved for atopic dermatitis, showed excellent effects on improving pruritus and sleep after only two weeks of treatment but, in some cases, may have paradoxical effects. The rate of sleep-related side-effects remains unknown. More specifically, adverse-drug reactions (ADRs) related to dupilumab have been investigated during the safety phase of randomized clinical trials or in small retrospective epidemiological surveys, but little is known about sleep-related ADRs in real-life settings. Therefore, we took advantage of a global large-scale pharmacovigilance database, carrying out a comprehensive data mining analysis to look at different sleep-related ADRs reported among patients under anti IL-4/13 therapy.
MATERIALS AND METHODS: We analyzed individual case study reports (ICSRs) in VigiBase (TM), the World Health Organization (WHO) global pharmacovigilance database of ADRs collected by national drug authorities in > 140 countries (> 90% of the world population). We looked for patterns of potentially sleep-related ADRs and we applied a disproportionality analysis based on Bayesian Confidence Propagation Neural Network (BCPNN). A meta-analytical approach was used to synthesize the overall effect size of sleep-related ADRs potentially associated to Dupilumab administration.
RESULTS: From inception up to March 9, 2021, 94,065 ADRs from 37,848 unique reports were included and analyzed in the present paper: 1,294 of them (1.4%) concerned sleep disturbances (n=27). Most of sleep-related complaints were generic sleep disorders (n=630). followed by insomnia (n=312). somnolence (n=81), lethargy (n=60). night sweats (n=30), middle insomnia (n=39), hypersomnia (n=25), poor-quality sleep (n=21). initial insomnia (n=17), sleep apnea syndrome (n=13), nightmares (n=11) and sleep deficit (n=11). Interestingly, restlessness and restless leg syndrome. nocturnal dyspnea, narcolepsy and bruxism were reported in 7. 6, 5, 4 and 3 cases. respectively. Only sleep deficit [OR 15.67 (95% CrI 8.61-28.51): IC 3.24 (95% CrI 2.26-3.97)], generic sleep disorder [OR 6.22 (95% CrI 5.74-6.73); IC 2.60 (95% CrI 2.48-2.71)], nocturnal dyspnea [OR 3.68 (95% CrI 1.53-8.87); IC 1.56 (95% CrI 0.03-2.56)] and middle insomnia [OR 1.87 (95% CrI 1.36-2.56); IC 0.88 (95% CrI 0.39-1.30)] achieved the statistical significance threshold.
CONCLUSIONS: In this work, we identified over 37,000 unique case-reports of Dupilumab side-effects reported on the WHO pharmacovigilance database. We specifically categorized those related to sleep issues. which were 1.294. Our findings from large numbers of cases provide data supporting the clinical observations that Dupilumab is usually effective in improving sleep quality and sleep disturbances/impairments, given the lack of statistical significance of several sleep-related ADRs. Further work is needed to closely scrutinize the impact of Dupilumab on sleep, in terms of underlying mechanisms. and to better understand residual sleep disorders in patients with atopic dermatitis and other allergic diseases treated with Dupilumab. Thus, sleep monitoring may be helpful for dermatologists in managing atopic dermatitis patients treated with dupilumab. The limitations of spontaneous reporting systems including underreporting and reporting bias, heterogeneity of sources and impossibility to infer any causal relationship merit consideration and further research is needed.
DA  - 2022///
PY  - 2022
DO  - 10.26355/eurrev_202206_28977
VL  - 26
IS  - 11
SP  - 4074
EP  - 4081
SN  - 1128-3602
AN  - WOS:000820248700034
KW  - machine learning
KW  - big data
KW  - Machine Learning
KW  - human
KW  - Humans
KW  - Big Data
KW  - Article
KW  - retrospective study
KW  - Bayes theorem
KW  - Bayes Theorem
KW  - drug safety
KW  - pharmacovigilance
KW  - Pharmacovigilance
KW  - personalized medicine
KW  - Adverse Drug Reaction Reporting Systems
KW  - data mining
KW  - drug surveillance program
KW  - insomnia
KW  - night sweat
KW  - nightmare
KW  - adverse drug reaction
KW  - Sleep
KW  - Adverse drug reaction
KW  - Retrospective Studies
KW  - Drug-Related Side Effects and Adverse Reactions
KW  - data base
KW  - pharmacoepidemiology
KW  - effect size
KW  - dermatologist
KW  - Antibodies, Monoclonal, Humanized
KW  - apnea hypopnea index
KW  - atopic dermatitis
KW  - Bayesian Confidence Propagation Neural Network (BCPNN)
KW  - Beck Anxiety Inventory
KW  - bruxism
KW  - case report
KW  - clinical observation
KW  - coping behavior
KW  - Dermatitis, Atopic
KW  - drug response
KW  - dupilumab
KW  - Dupilumab
KW  - dyspnea
KW  - Dyspnea
KW  - hypersomnia
KW  - interleukin 4
KW  - Interleukin-4
KW  - lethargy
KW  - monoclonal antibody
KW  - narcolepsy
KW  - Pharmacoepidemiology
KW  - polysomnography
KW  - reporting bias
KW  - restless legs syndrome
KW  - restlessness
KW  - sleep
KW  - sleep debt
KW  - sleep disorder
KW  - sleep disordered breathing
KW  - Sleep disorders
KW  - Sleep Initiation and Maintenance Disorders
KW  - sleep quality
KW  - Sleep Wake Disorders
KW  - somnolence
KW  - statistical significance
KW  - World Health Organization
ER  - 

TY  - JOUR
TI  - Does your team know how to respond safely to an operating room fire? Outcomes of a virtual reality, AI-enhanced simulation training
AU  - Truong, H
AU  - Qi, D
AU  - Ryason, A
AU  - Sullivan, AM
AU  - Cudmore, J
AU  - Alfred, S
AU  - Jones, SB
AU  - Parra, JM
AU  - De, S
AU  - Jones, DB
T2  - SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES
AB  - Background Operating room (OR) fires are rare but devastating events requiring immediate and effective response. Virtual Reality (VR) simulation training can provide a safe environment for practice of skills in such highly stressful situation. This study assessed interprofessional participants' ability to respond to VR-simulated OR fire scenarios, attitudes, numbers of attempt of the VR simulation do participants need to successfully respond to OR fires and does prior experience, confidence level, or professional role predict the number of attempts needed to demonstrate safety and pass the simulation. Methods 180 surgical team members volunteered to participate in this study at Beth Israel Deaconess Medical Center, Boston, MA. Each participant completed five VR OR simulation trials; the final two trials incorporated AI assistance. Primary outcomes were performance scores, number of attempts needed to pass, and pre- and post-survey results describing participant confidence and experiences. Differences across professional or training role were assessed using chi-square tests and analyses of variance. Differences in pass rates over time were assessed using repeated measures logistic regression. Results One hundred eighty participants completed simulation testing; 170 (94.4%) completed surveys. Participants included surgeons (17.2%), anesthesiologists (10.0%), allied health professionals (41.7%), and medical trainees (31.1%). Prior to training, 45.4% of participants reported feeling moderately or very confident in their ability to respond to an OR fire. Eight participants (4.4%) responded safely on the first simulation attempt. Forty-three participants (23.9%) passed by the third attempt (VR only); an additional 97 participants (53.9%) passed within the 4-5th attempt (VR with AI assistance). Conclusions Providers are unprepared to respond to OR fires. VR-based simulation training provides a practical platform for individuals to improve their knowledge and performance in the management of OR fires with a 79% pass rate in our study. A VR AI approach to teaching this essential skill is innovative, feasible, and effective.
DA  - 2022/05//undefined
PY  - 2022
DO  - 10.1007/s00464-021-08602-y
VL  - 36
IS  - 5
SP  - 3059
EP  - 3067
SN  - 0930-2794
AN  - WOS:000673887200001
ER  - 

TY  - JOUR
TI  - Semisupervised Heterogeneous Domain Adaptation via Dynamic Joint Correlation Alignment Network for Ship Classification in SAR Imagery
AU  - Yang, GA
AU  - Lang, HT
T2  - IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
AB  - Improving ship classification performance in synthetic aperture radar (SAR) imagery by transferring knowledge from the related domain is a newly emerging research topic. Existing methods follow supervised or unsupervised homogeneous transfer learning (TL) techniques with certain restrictions on the use of features (homogeneous rather than heterogeneous) and data [ignoring to excavate the potential of unlabeled target domain (TD) data], which may hinder further performance improvements. To address these problems, this letter proposes a dynamic joint correlation alignment (DJ-CORAL) network to conduct semisupervised heterogeneous domain adaptation (HDA). Specifically, DJ-CORAL first transforms the heterogeneous features from the source and TDs into a common subspace to eliminate the heterogeneity and then simultaneously performs classifier adaptation and joint marginal, and conditional distribution alignment (CDA) to facilitate the domain shift minimization. Comprehensive experiments validate the superiority of the proposed DJ-CORAL network against state-of-the-art HDA methods. The codes are available at https://github.com/BUCT-RS-ML/DJ-CORAL.
DA  - 2022///
PY  - 2022
DO  - 10.1109/LGRS.2022.3175056
VL  - 19
SN  - 1545-598X
AN  - WOS:000801851500001
ER  - 

TY  - CONF
TI  - A Model of Computing and Communication for Public Safety Integrating FirstNet, Edge Computing, and Internet of Things
AU  - Zahid, JL
AU  - Hussain, F
AU  - Ferworn, A
T2  - 2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON)
A2  - Chakrabarti, S
A2  - Saha, HN
AB  - A Public Safety Network (PSN) is an essential element of the Emergency Management System (EMS) for any country to deal with natural or man-made disasters. PSN is an information and communication infrastructure that assists managing first responders during incident operations. In this article we propose a model of computation and communication that could represent a future alternative public safety network. Our concept is based on the integration of emerging technologies like Fog/Edge Computing, Internet of Things (IoT), and FirstNet network partly in operation in the United States. Our model proposes a synergy between these technologies and forms a platform for highly qualified people (HQP) in training to develop and experiment with their research work. As the technology is similar to that in actual operation, any research results may be more easily adopted by PSNs in actual operations. Mobile edge devices like smart phones, dones, robots, and aerial platforms form part of deployed devices. These are interconnected via gateways to the Internet for providing useful information to incident command centers where managers can make timely decisions. Our model is implemented using off-the-shelf devices both for computing and communication tasks.
DA  - 2019///
PY  - 2019
DO  - 10.1109/iemcon.2019.8936153
SP  - 619
EP  - 623
SN  - 978-1-7281-2530-5
AN  - WOS:000529790700097
KW  - Risk management
KW  - Robots
KW  - Machine Learning
KW  - Blockchain
KW  - Learning systems
KW  - Internet of things
KW  - Personnel training
KW  - Big data
KW  - Emergency management
KW  - Unmanned aerial vehicles (UAV)
KW  - Antennas
KW  - Edge computing
KW  - Emergency services
KW  - Disaster prevention
KW  - Public safety
KW  - Smartphones
KW  - Distributed database
KW  - Internet of Things (IoT)
KW  - Mobile telecommunication systems
KW  - Public Safety
KW  - Fog computing
KW  - Internet of Things (IOT)
KW  - Civil defense
KW  - Disaster Response (DR) Emergency Management
KW  - Distributed Database
KW  - FirstNet
KW  - Fog/Edge Computing
KW  - Unmanned Aerial Vehicles (UAV)
ER  - 

TY  - JOUR
TI  - A Comprehensive Review of Computational Methods For Drug-Drug Interaction Detection
AU  - Qiu, Y
AU  - Zhang, Y
AU  - Deng, YF
AU  - Liu, SC
AU  - Zhang, W
T2  - IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS
AB  - The detection of drug-drug interactions (DDIs) is a crucial task for drug safety surveillance, which provides effective and safe co-prescriptions of multiple drugs. Since laboratory researches are often complicated, costly and time-consuming, it's urgent to develop computational approaches to detect drug-drug interactions. In this paper, we conduct a comprehensive review of state-of-the-art computational methods falling into three categories: literature-based extraction methods, machine learning-based prediction methods and pharmacovigilance-based data mining methods. Literature-based extraction methods detect DDIs from published literature using natural language processing techniques; machine learning-based prediction methods build prediction models based on the known DDIs in databases and predict novel ones; pharmacovigilance-based data mining methods usually apply statistical techniques on various electronic data to detect drug-drug interaction signals. We first present the taxonomy of drug-drug interaction detection methods and provide the outlines of three categories of methods. Afterwards, we respectively introduce research backgrounds and data sources of three categories, and illustrate their representative approaches as well as evaluation metrics. Finally, we discuss the current challenges of existing methods and highlight potential opportunities for future directions.
DA  - 2022/07//undefined
PY  - 2022
DO  - 10.1109/TCBB.2021.3081268
VL  - 19
IS  - 4
SP  - 1968
EP  - 1985
SN  - 1545-5963
AN  - WOS:000840575900006
ER  - 

TY  - JOUR
TI  - A Transformer-Based Machine Learning Approach for Sustainable E-Waste Management: A Comparative Policy Analysis between the Swiss and Canadian Systems
AU  - Ali, S
AU  - Shirazi, F
T2  - SUSTAINABILITY
AB  - Efficient e-waste management is crucial to successfully achieve sustainable urban growth universally. The upsurge in e-waste has resulted in countries, including Canada, adopting a wide array of policies associated with sustainable management. In this study, we conducted a mixed-method analysis of Canadian e-waste management policies to showcase the opportunities and limitations of the current system. We examine and compare the effectiveness of electronic waste management strategies in Canada and Switzerland using a comparative policy evaluation and by quantitatively measuring their efficiencies through two efficiency methods, namely a transformer-based, bidirectional, unsupervised machine learning model for natural language processing (NLP) and data envelopment analysis (DEA). Switzerland is utilized as a comparison case due to its robust legal framework that has been in place for proper management e-waste in order to enhance Canada's electronic waste management system. The policy considerations presented in this study are directed toward urban planners, policy makers, and corporate strategists. These involve a mix of political, economic, social, and environmental planning tools concerning how to communicate and foster competent e-waste management in these countries. This is the first study to incorporate DEA and NLP-based BERT analysis to identify the most efficient policy deployment concerning e-waste management.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.3390/su142013220
VL  - 14
IS  - 20
SN  - 2071-1050
AN  - WOS:000873628300001
KW  - machine learning
KW  - sustainability
KW  - Canada
KW  - natural language processing
KW  - policy approach
KW  - BERT
KW  - CO2 emission
KW  - data envelopment analysis
KW  - e-waste
KW  - electronic waste
KW  - extended producer responsibility
KW  - recycler qualification program
KW  - recycling
KW  - Switzerland
KW  - waste management
ER  - 

TY  - JOUR
TI  - Bipedal Static Supination and Dynamic Forefoot Loading Characteristics in Taiwanese College Badminton Players: A Cross-Sectional Study
AU  - Chow, TH
AU  - Hsu, CC
AU  - Chen, CC
AU  - Hsu, CH
T2  - BIOENGINEERING-BASEL
AB  - Context: Badminton is a unilateral sport that involves repetitive jumping, lunging and quick changes of direction with the lower limb, thus, plantar pressure profiles and foot postural profiles are critical to maintaining balance and coordination. Objective: The purpose of this study was to explore the characteristics of static and dynamic plantar pressure profiles with rearfoot posture in elite and recreational badminton players as well as assess the transitional changes of plantar loads between static and dynamic states. Methods: A cross-sectional survey was conducted among 65 college-level elite male badminton players (mean age: 20.2 +/- 1.2 years; mean height: 177.4 +/- 4.6 cm; mean weight: 72.6 +/- 4.6 kg) and 68 recreational badminton players of the same gender (mean age: 19.9 +/- 0.8 years; mean height: 170.3 +/- 3.9 cm; mean weight: 67.7 +/- 3.2 kg). The JC Mat was used to evaluate the arch index (AI), plantar pressure distribution (PPD), centers of gravity, and the characteristics of the footprint. Static foot posture was determined by examining the rearfoot alignment. Results: Both groups' AI fell within the normal range. The static plantar loads of the elite group were distributed at the bipedal lateral part of longitudinal arches and heels (p < 0.01), while the right foot experienced higher centers of gravity (p < 0.05). The elite group's static rearfoot postural alignment exhibited a higher degree of rearfoot varus than the recreational group (p < 0.05). In addition, the elite group's dynamic plantar loads were mainly exerted at the medial and lateral metatarsals of both feet (p < 0.05). During the transition state, the recreational group's plantar loads were mainly shifted to the bipedal lateral part of metatarsals and heels (p < 0.05), whereas the elite group's bipedal lateral longitudinal arches as well as the medial and lateral heels experienced a reduction in plantar loads (p < 0.01). Conclusion: For elite badminton players, the findings revealed a possible connection among the static supinated foot, centers of gravity tending towards the right foot, and increased forefoot plantar loads in the dynamic state. The finding merits further exploration of the possible links between transitional changes in plantar pressure distribution in both states and related foot injuries resulting from intense competition and regular training in badminton.
DA  - 2023/04//undefined
PY  - 2023
DO  - 10.3390/bioengineering10040498
VL  - 10
IS  - 4
SN  - 2306-5354
AN  - WOS:000979299700001
ER  - 

TY  - JOUR
TI  - Manifold Learning and Clustering for Automated Phase Identification and Alignment in Data Driven Modeling of Batch Processes
AU  - López, CAM
AU  - Bhonsale, S
AU  - Peeters, K
AU  - Van Impe, JFM
T2  - FRONTIERS IN CHEMICAL ENGINEERING
AB  - Processing data that originates from uneven, multi-phase batches is a challenge in data-driven modeling. Training predictive and monitoring models requires the data to be in the right shape to be informative. Only then can a model learn meaningful features that describe the deterministic variability of the process. The presence of multiple phases in the data, which display different correlation patterns and have an uneven duration from batch to batch, reduces the performance of the data-driven modeling methods significantly. Therefore, phase identification and alignment is a critical step and can lead to an unsuccessful modeling exercise if not applied correctly. In this paper, a novel approach is proposed to perform unsupervised phase identification and alignment based on the correlation patterns found in the data. Phase identification is performed via manifold learning using t-Distributed Stochastic Neighbor Embedding (t-SNE), which is a state-of-the-art machine learning algorithm for non-linear dimensionality reduction. The application of t-SNE to a reduced cross-correlation matrix of every batch with respect to a reference batch results in data clustering in the embedded space. Models based on support vector machines (SVMs) are trained to, 1) reproduce the manifold learning obtained via t-SNE, and 2) determine the membership of the data points to a process phase. Compared to previously proposed clustering approaches for phase identification, this is an unsupervised, non-linear method. The perplexity parameter of the t-SNE algorithm can be interpreted as the estimated duration of the shortest phase in the process. The advantages of the proposed method are demonstrated through its application on an in-silico benchmark case study, and on real industrial data from two unit-operations in the large scale production of an active pharmaceutical ingredients (API). The efficacy and robustness of the method are evidenced in the successful phase identification and alignment obtained for these three distinct processes, displaying smooth, sudden and repetitive phase changes. Additionally, the low complexity of the method makes feasible its online implementation.
DA  - 2020/11/27/
PY  - 2020
DO  - 10.3389/fceng.2020.582126
VL  - 2
SN  - 2673-2718
AN  - WOS:000994378000001
ER  - 

TY  - JOUR
TI  - Impacts of Daily Travel by Distances on the Spread of COVID-19: An Artificial Neural Network Model
AU  - Truong, D
AU  - Truong, MD
T2  - TRANSPORTATION RESEARCH RECORD
AB  - The continued spread of COVID-19 poses significant threats to the safety of the community. Since it is still uncertain when the pandemic will end, it is vital to understand the factors contributing to new cases of COVID-19, especially from the transportation perspective. This paper examines the effect of the United States residents' daily trips by distances on the spread of COVID-19 in the community. The artificial neural network method is used to construct and test the predictive model using data collected from two sources: Bureau of Transportation Statistics and the COVID-19 Tracking Project. The dataset uses ten daily travel variables by distances and new tests from March to September 2020, with a sample size of 10,914. The results indicate the importance of daily trips at different distances in predicting the spread of COVID-19. More specifically, trips shorter than 3 mi and trips between 250 and 500 mi contribute most to predicting daily new cases of COVID-19. Additionally, daily new tests and trips between 10 and 25 mi are among the variables with the lowest effects. This study's findings can help governmental authorities evaluate the risk of COVID-19 infection based on residents' daily travel behaviors and form necessary strategies to mitigate the risks. The developed neural network can be used to predict the infection rate and construct various scenarios for risk assessment and control.
DA  - 2023/04//undefined
PY  - 2023
DO  - 10.1177/03611981211066899
VL  - 2677
IS  - 4
SP  - 934
EP  - 945
SN  - 0361-1981
AN  - WOS:000751413500001
ER  - 

TY  - CONF
TI  - Automated identification of retained surgical items in radiological images
AU  - Agam, G
AU  - Gan, L
AU  - Moric, M
AU  - Gluncic, V
T2  - MEDICAL IMAGING 2015: PACS AND IMAGING INFORMATICS: NEXT GENERATION AND INNOVATIONS
A2  - Cook, TS
A2  - Zhang, J
AB  - Retained surgical items (RSIs) in patients is a major operating room (OR) patient safety concern. An RSI is any surgical tool, sponge, needle or other item inadvertently left in a patients body during the course of surgery. If left undetected, RSIs may lead to serious negative health consequences such as sepsis, internal bleeding, and even death. To help physicians efficiently and effectively detect RSIs, we are developing computer-aided detection (CADe) software for X-ray (XR) image analysis, utilizing large amounts of currently available image data to produce a clinically effective RSI detection system. Physician analysis of XRs for the purpose of RSI detection is a relatively lengthy process that may take up to 45 minutes to complete. It is also error prone due to the relatively low acuity of the human eye for RSIs in XR images. The system we are developing is based on computer vision and machine learning algorithms. We address the problem of low incidence by proposing synthesis algorithms. The CADe software we are developing may be integrated into a picture archiving and communication system (PACS), be implemented as a stand-alone software application, or be integrated into portable XR machine software through application programming interfaces. Preliminary experimental results on actual XR images demonstrate the effectiveness of the proposed approach.
DA  - 2015///
PY  - 2015
DO  - 10.1117/12.2082384
VL  - 9418
SN  - 0277-786X
AN  - WOS:000359469100028
KW  - machine learning
KW  - Artificial intelligence
KW  - big data
KW  - Learning systems
KW  - Learning algorithms
KW  - Computer vision
KW  - patient safety
KW  - Big data
KW  - Medical imaging
KW  - Application programs
KW  - Patient safety
KW  - Application programming interfaces (API)
KW  - Automated identification
KW  - Computer aided analysis
KW  - computer aided detection
KW  - Computer aided detection
KW  - Computer aided instruction
KW  - Computer software
KW  - Computer systems programming
KW  - computer vision
KW  - Health consequences
KW  - Information science
KW  - Medical applications
KW  - Medical computing
KW  - operating room efficiency
KW  - Operating rooms
KW  - PACS
KW  - Picture archiving and communication systems
KW  - Picture archiving and communication systems (PACS)
KW  - Radiological images
KW  - Retained surgical item detection
KW  - Stand-alone software
KW  - Surgery
KW  - Surgical equipment
KW  - Synthesis algorithms
KW  - Transplantation (surgical)
ER  - 

TY  - JOUR
TI  - Intelligent Edge-Enabled Efficient Multi-Source Data Fusion for Autonomous Surface Vehicles in Maritime Internet of Things
AU  - Liu, RW
AU  - Guo, Y
AU  - Nie, JT
AU  - Hu, Q
AU  - Xiong, ZH
AU  - Yu, H
AU  - Guizani, M
T2  - IEEE TRANSACTIONS ON GREEN COMMUNICATIONS AND NETWORKING
AB  - With the rapid development of low-end Internet of Things (IoT) devices and shipborne sensors, efficient multi-source data fusion methods for autonomous surface vehicles (ASVs) have recently attracted significant research interest in intelligent edge-enabled maritime applications. The data fusion capacity can enhance the situation awareness of ASVs, leading to improved efficacy and safety in ASV-empowered maritime IoT (MIoT). Both cameras and automatic identification system (AIS) equipment, which provide visual and positioning information, respectively, have become the commonly adopted cost-effective sensors. In this work, we first introduce a lightweight YOLOX-s network with transfer learning to accurately and robustly detect the moving vessels at different scales in real time. A data augmentation method is then proposed to promote its generalization ability. The detected vessels and synchronous AIS messages are finally fused to make full use of the multi-source sensing data, contributing to an augmented reality (AR)-based maritime navigation system at the shipborne intelligent edges. The AR system is able to superimpose both static and dynamic information from the collected AIS messages onto the video-captured images. It has the capacity of providing auxiliary information for early warning of navigation risks for ASVs in MIoT networks. Compared with traditional single-sensor-based navigation methods, our data fusion framework exhibits more reliable and robust results, and appears to have substantial practical potential applications. Extensive experiments have been conducted to demonstrate the superior performance of our framework under different navigational conditions.
DA  - 2022/09//undefined
PY  - 2022
DO  - 10.1109/TGCN.2022.3158004
VL  - 6
IS  - 3
SP  - 1574
EP  - 1587
SN  - 2473-2400
AN  - WOS:000842063800033
ER  - 

TY  - CONF
TI  - An evaluation of machine learning methods for domain name classification
AU  - Garg, A
AU  - Trivedi, N
AU  - Lu, JL
AU  - Eirinaki, M
AU  - Yu, B
AU  - Olumofin, F
T2  - 2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
A2  - Wu, XT
A2  - Jermaine, C
A2  - Xiong, L
A2  - Hu, XH
A2  - Kotevska, O
A2  - Lu, SY
A2  - Xu, WJ
A2  - Aluru, S
A2  - Zhai, CX
A2  - Al-Masri, E
A2  - Chen, ZY
A2  - Saltz, J
AB  - For a long time researchers have focused on the binary classification of domain names sent to DNS servers for resolutions to IP addresses. The objective is to identify malicious domains versus legitimate ones to protect networks from attacks. For legitimate domains, an emerging interest is to classify them into content categories to enable DNS servers deployed in an organization to monitor and potentially block the resolution of irrelevant domains. For example, a financial organization wants to flag gaming related domains, and an elementary school wants to block suspicious adult domains. Classifying a domain by just the domain name is a challenging task. Currently, there exist no publicly available datasets that include an extensive mapping of domains to content categories, since this is usually proprietary information. Our focus is three-fold in this work: a) to develop a data collection methodology and create rich labelled datasets that are appropriate for training such predictive models, b) to share the datasets with the research community by making them publicly available, and c) to evaluate and identify appropriate machine learning and deep learning algorithms for this problem domain. We consider two different datasets. The first is created following a SERP (Search Engine Response Page)mining approach, having a set of content categories as input. The second is an enhancement of the DMOZ dataset that is publicly available, including both domains and category names as input. In addition to the dataset creation input and methodology, these two datasets differ in the content category number and distribution, yielding different results in our analysis. Overall, we observe that the deep learning-based approach carefully considers the key features of the input data and hence outperforms existing traditional machine learning pipelines, achieving 98.37% and 79.29% accuracy on the respective datasets.
DA  - 2020///
PY  - 2020
DO  - 10.1109/BigData50022.2020.9377787
SP  - 4577
EP  - 4585
SN  - 2639-1589
AN  - WOS:000662554704081
KW  - Deep learning
KW  - Predictive models
KW  - Learning systems
KW  - Learning algorithms
KW  - Predictive analytics
KW  - Machine learning methods
KW  - Big data
KW  - Search engines
KW  - Learning-based approach
KW  - feature engineering
KW  - Research communities
KW  - Binary classification
KW  - content mining
KW  - DNS request classification
KW  - domain classification
KW  - Elementary schools
KW  - Financial organizations
KW  - Internet protocols
KW  - machine learning data collection
KW  - Proprietary information
KW  - safe network
KW  - secure network
KW  - SERP-mining
ER  - 

TY  - JOUR
TI  - Bayesian Decision Tool for the Analysis of Occupational Accidents in the Construction of Embankments
AU  - Gerassis, S
AU  - Martín, JE
AU  - García, JT
AU  - Saavedra, A
AU  - Taboada, J
T2  - JOURNAL OF CONSTRUCTION ENGINEERING AND MANAGEMENT
AB  - Instability and poor construction practices are responsible for the high accident rate in embankment construction in Spain. Applying a methodology based on data mining and attribute selection and using a 6-year database of accidents, key attributes in accidents associated with the construction of embankments were analyzed. Once the main predictors were identified, Bayesian networks in order to quantify the specific causes of different types of accidents were built. Thus, the main reasons for accidents as a preliminary phase to enhancing safety and embankment stability in mining and civil engineering works can be accurately identified and quantified. (C)2016 American Society of Civil Engineers.
DA  - 2017/02//undefined
PY  - 2017
DO  - 10.1061/(ASCE)CO.1943-7862.0001225
VL  - 143
IS  - 2
SN  - 0733-9364
AN  - WOS:000397269300009
KW  - Machine learning
KW  - Bayesian network
KW  - Accidents
KW  - Data mining
KW  - Learning systems
KW  - Bayesian networks
KW  - Safety engineering
KW  - Occupational accident
KW  - Engineering safety
KW  - Attribute selection
KW  - Civil engineering works
KW  - Construction of embankments
KW  - Construction practice
KW  - Embankment accidents
KW  - Embankment construction
KW  - Embankments
KW  - Labor and personnel issues
KW  - Mine and civil engineering safety
KW  - Personnel issues
KW  - Personnel selection
ER  - 

TY  - JOUR
TI  - Dual Consistency Alignment Based Self-Supervised Learning for SAR Target Recognition With Speckle Noise Resistance
AU  - Zhai, YK
AU  - Liao, JR
AU  - Sun, B
AU  - Jiang, ZY
AU  - Ying, ZL
AU  - Wang, WQ
AU  - Genovese, A
AU  - Piuri, V
AU  - Scotti, F
T2  - IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING
AB  - Deep-learning-based on convolutional neural networks (CNN) has been widely applied in synthetic aperture radar (SAR) target recognition and made significant progress. However, due to the physical effects of the equipment used to collect images, various degrees of speckle noise will be introduced into SAR images. Traditional CNN-based SAR target recognition methods are premised on the same noise intensity in the training and testing set, which is contrary to the target recognition in practice. To alleviate this problem, we propose a novel speckle noise resistant framework for SAR target recognition, called dual-consistency-alignment-based self-supervised learning. First, original SAR images are randomly added to speckle noise with different thresholds through multiplicative noise, after which contrastive pretraining is performed on unlabeled data. During this period, we combine instance pseudolabel consistency alignment and feature consistency alignment to align multiple threshold speckle noise views with original views under the same targets. Finally, the pretrained model is migrated to the downstream SAR speckle noise target recognition task. In this article, speckle noise modeling is conducted based on moving and stationary target capture and recognition data testing set, and experiment results reveal that this method can adapt to different intensities of speckle noise, is robust to modeled SAR image recognition, and maintains a high recognition rate even in small-sample learning.
DA  - 2023///
PY  - 2023
DO  - 10.1109/JSTARS.2023.3267824
VL  - 16
SP  - 3915
EP  - 3928
SN  - 1939-1404
AN  - WOS:000981930300004
ER  - 

TY  - JOUR
TI  - WHY YOU NEED AN AI ETHICS COMMITTEE Expert oversight will help you safe-guard your data and your brand
AU  - Blackman, R
T2  - HARVARD BUSINESS REVIEW
DA  - 2022/07//undefined
PY  - 2022
VL  - 100
IS  - 7-8
SP  - 118
EP  - 125
SN  - 0017-8012
AN  - WOS:000829466400024
ER  - 

TY  - CONF
TI  - A Software Tool to Measure the Alignment of Assessment Instrument with a Set of Learning Objectives of a Course
AU  - Ramesh, R
AU  - Sasikumar, M
AU  - Iyer, S
T2  - 2016 IEEE 16TH INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES (ICALT)
A2  - Spector, JM
A2  - Tsai, CC
A2  - Sampson, DG
A2  - Kinshuk
A2  - Huang, R
A2  - Chen, NS
A2  - Resta, P
AB  - In this paper, we present a software tool to measure alignment of Assessment instrument (AI) with a set of learning objectives (LOs) of a course. Alignment of syllabus, LO and AI is a major parameter determining the quality of an AI. The tool helps to considerably reduce the time and effort needed by teachers to ensure this alignment. It takes syllabus, a set of LOs and domain ontology as input. An ontology based knowledge representation mechanism is designed to integrate the contents of syllabus, LOs and AI. Alignment is measured in terms of both concepts covered and cognitive level used. The Data Structures course of second year engineering curriculum is chosen as the domain. The accuracy of this tool is tested by comparing the system generated alignment measure with the expert teachers and a confusion matrix is generated. We got an average accuracy of 90% for concepts alignment and 95% agreement in cognitive level alignment.
DA  - 2016///
PY  - 2016
DO  - 10.1109/ICALT.2016.10
SP  - 194
EP  - 198
SN  - 2161-3761
AN  - WOS:000392135700052
KW  - Knowledge representation
KW  - Ontology
KW  - Data structures
KW  - Computer software
KW  - Engineering education
KW  - Curricula
KW  - Learning objectives
KW  - Confusion matrices
KW  - Teaching
KW  - Alignment of AI with learning objectives
KW  - Assessment instruments
KW  - Cognitive levels
KW  - Domain ontologies
KW  - Domain Ontology
KW  - Engineering curriculum
KW  - Ontology-based
KW  - Quality of Assessment Instrument
ER  - 

TY  - JOUR
TI  - Review on the Application of Machine Learning Algorithms in the Sequence Data Mining of DNA
AU  - Yang, AM
AU  - Zhang, W
AU  - Wang, JH
AU  - Yang, K
AU  - Han, Y
AU  - Zhang, LM
T2  - FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY
AB  - Deoxyribonucleic acid (DNA) is a biological macromolecule. Its main function is information storage. At present, the advancement of sequencing technology had caused DNA sequence data to grow at an explosive rate, which has also pushed the study of DNA sequences in the wave of big data. Moreover, machine learning is a powerful technique for analyzing largescale data and learns spontaneously to gain knowledge. It has been widely used in DNA sequence data analysis and obtained a lot of research achievements. Firstly, the review introduces the development process of sequencing technology, expounds on the concept of DNA sequence data structure and sequence similarity. Then we analyze the basic process of data mining, summary several major machine learning algorithms, and put forward the challenges faced by machine learning algorithms in the mining of biological sequence data and possible solutions in the future. Then we review four typical applications of machine learning in DNA sequence data: DNA sequence alignment, DNA sequence classification, DNA sequence clustering, and DNA pattern mining. We analyze their corresponding biological application background and significance, and systematically summarized the development and potential problems in the field of DNA sequence data mining in recent years. Finally, we summarize the content of the review and look into the future of some research directions for the next step.
DA  - 2020/09/04/
PY  - 2020
DO  - 10.3389/fbioe.2020.01032
VL  - 8
SN  - 2296-4185
AN  - WOS:000573808900001
KW  - machine learning
KW  - Machine learning
KW  - Data mining
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Bioinformatics
KW  - Digital storage
KW  - data mining
KW  - DNA
KW  - DNA sequence
KW  - DNA sequences
KW  - DNA sequence alignments
KW  - Biological applications
KW  - Biological macromolecule
KW  - Biological sequence data
KW  - DNA pattern mining
KW  - DNA sequence alignment
KW  - DNA sequence classification
KW  - DNA sequence clustering
KW  - Gene encoding
KW  - Research achievements
KW  - Sequence classification
KW  - Sequence-data mining
ER  - 

TY  - JOUR
TI  - Spatial distribution characteristics of PM2.5 concentration around residential buildings in urban traffic-intensive areas: From the perspectives of health and safety
AU  - Meng, MR
AU  - Cao, SJ
AU  - Kumar, P
AU  - Tang, X
AU  - Feng, ZB
T2  - SAFETY SCIENCE
AB  - The impact of traffic pollution on the health and safety of residents that live in roadside residential buildings has been a major concern for governments. This study investigated the spatial distributions of PM2.5 concentration due to road traffic emissions and put forward a spatial distribution model for the estimation of PM2.5 concentration (SDC) based on Machine Learning. Meanwhile, based on the SDC model, the decrease in life expectancy (DLE) of residents was assessed. On-site monitoring of PM2.5 concentration was conducted on different floors of a typical residential building situated by the roadside. Computational Fluid Dynamics (CFD) simulation was conducted for the spatial distribution analysis of PM2.5 concentration, which was verified by measurements. The findings show the PM2.5 concentration decreased from 74 mu g/m(3) to 43 mu g/m(3) within 0 to 120 m distance from the road, and decreased from 73 mu g/m(3) to 42 mu g/m(3) within 0 to 60 m height; these locations had a maximum DLE of 5.11 years. The concentration of PM2.5 was stabilized within 40 to 45 mu g/m(3) when the height was above 60 m (roughly the 17th floor from the ground) and the distance was 120 m away from the road. The DLE in these locations was stabilized within 0.62 years to 0.91 years. The SDC model was established to efficiently predict the DLE of residents and PM2.5 concentration along roadside. These findings would facilitate the development of precaution guidelines for urban pollution as well as the future planning of urban health and safety buildings.
DA  - 2021/12//undefined
PY  - 2021
DO  - 10.1016/j.ssci.2021.105318
VL  - 141
SN  - 0925-7535
AN  - WOS:000660986400001
KW  - machine learning
KW  - simulation
KW  - Machine learning
KW  - Machine-learning
KW  - adult
KW  - article
KW  - human
KW  - Health
KW  - computational fluid dynamics
KW  - Health risks
KW  - Health and safety
KW  - Human safety
KW  - CFD Simulation
KW  - Computational fluid dynamics
KW  - Computational fluid dynamics simulations
KW  - Decrease in life expectancy assessment
KW  - DLE Assessment
KW  - Floors
KW  - Housing
KW  - Human health
KW  - Human health and safety
KW  - life expectancy
KW  - particulate matter 2.5
KW  - PM$-2.5$
KW  - PM2.5 concentration
KW  - PM2.5 Concentration
KW  - Pollution
KW  - resident
KW  - Roadsides
KW  - Spatial distribution
KW  - Spatial distribution analysis
KW  - Spatial Distribution Analysis
KW  - traffic pollution
KW  - Traffic pollution
KW  - Traffic Pollution
KW  - urban health
ER  - 

TY  - JOUR
TI  - ENGINERING SCIENTIFIC METHODS OF ENERGY AND RESOURCE EFFECTIVE INTENSIVE CHEMICAL PROCESS SYSTEMS IN DIGIT. ECONOMY CONDITIONS
AU  - Meshalkin, VP
T2  - IZVESTIYA VYSSHIKH UCHEBNYKH ZAVEDENII KHIMIYA I KHIMICHESKAYA TEKHNOLOGIYA
AB  - The history of the emergence and essence of a new scientific direction in chemical technology "Chemical Process Engineering" is briefly stated. The types of engineering at the stages of the life cycle of Chemical Process are described. A brief characteristic of scientifically grounded methods and techniques of energy and resource conservation in the Chemical Industry is given. A brief description of the principles of aided of optimal energy-resource-efficient environmentally friendly Chemical process is presented. The application of the basic concepts of of resource and energy saving logistics in the energy-efficient environmentally friendly Chemical process engineering and supply chains is described. Methods of ecological and economic optimization of Chemical Process, supply chains and gas supply systems of the chemical and petrochemical Industry are briefly described. The application of methods for optimizing reliability indicators, digitalized risk and safety management in the energy-resource-efficient Chemical Process engineering is described. The priority directions of scientific research on the of energy-resource-efficient chemical engineering and Chemical Process Engineering are described in detail, the most important of which are: methods of intensification, combination and minituarization of CTP; methods of digitalized engineering and logistics management of operation of energy-resource-efficient, environmentally safe, high-tech chemical-technological systems and CPUs of enterprises of chemical, petrochemical, biochemical, pharmaceutical and chemical-metallurgical complex; methods and methods of rational use of natural resources with a wide use of renewable natural resources, methods of combined energy-efficient and environmentally safe processing of industrial and municipal household waste and wastewater; methods of digitalized engineering of non-waste natural-like CTP and CTS and engineering of "green" CPUs in the real sector of the economy, etc.
DA  - 2021///
PY  - 2021
DO  - 10.6060/ivkkt.20216408.6423
VL  - 64
IS  - 8
SP  - 6
EP  - 23
SN  - 0579-2991
AN  - WOS:000695549100002
ER  - 

TY  - JOUR
TI  - AI-Based Safety Production Accident Prevention Mechanism in Smart Enterprises
AU  - Fu, J
AU  - Han, ZP
T2  - INTERNATIONAL JOURNAL OF DISTRIBUTED SYSTEMS AND TECHNOLOGIES
AB  - Enterprises have accumulated a large number of accident data resources for safety production, but the corresponding safety production information processing capacity is insufficient, resulting in the value of massive data not being effectively used, and further restricting the in-depth study of accidents. Enterprise safety managers cannot learn lessons from historical accidents in a timely manner and effectively prevent them, leading to repeated occurrences of similar accidents. Therefore, based on the above problems, this paper aims to construct a mining process for the cause of safety production accidents based on LDA topic model. According to the accident data structure, the article selects a data mining method suitable for its structural characteristics to maximize the utilization of accident data. According to the sequence of initial identification of accident information, discovery of safety problems, and transformation of safety knowledge, the valuable information in historical accident data can be fully excavated so as to provide effective suggestions for accident prevention.
DA  - 2022/04//undefined
PY  - 2022
DO  - 10.4018/IJDST.291082
VL  - 13
IS  - 2
SN  - 1947-3532
AN  - WOS:000821735600006
ER  - 

TY  - JOUR
TI  - Fatigue Monitoring Through Wearables: A State-of-the-Art Review
AU  - Martins, NAR
AU  - Annaheim, S
AU  - Spengler, CM
AU  - Rossi, RM
T2  - FRONTIERS IN PHYSIOLOGY
AB  - The objective measurement of fatigue is of critical relevance in areas such as occupational health and safety as fatigue impairs cognitive and motor performance, thus reducing productivity and increasing the risk of injury. Wearable systems represent highly promising solutions for fatigue monitoring as they enable continuous, long-term monitoring of biomedical signals in unattended settings, with the required comfort and non-intrusiveness. This is a p rerequisite for the development of accurate models for fatigue monitoring in real-time. However, monitoring fatigue through wearable devices imposes unique challenges. To provide an overview of the current state-of-the-art in monitoring variables associated with fatigue via wearables and to detect potential gaps and pitfalls in current knowledge, a systematic review was performed. The Scopus and PubMed databases were searched for articles published in English since 2015, having the terms "fatigue," "drowsiness," "vigilance," or "alertness" in the title, and proposing wearable device-based systems for non-invasive fatigue quantification. Of the 612 retrieved articles, 60 satisfied the inclusion criteria. Included studies were mainly of short duration and conducted in laboratory settings. In general, researchers developed fatigue models based on motion (MOT), electroencephalogram (EEG), photoplethysmogram (PPG), electrocardiogram (ECG), galvanic skin response (GSR), electromyogram (EMG), skin temperature (T-sk), eye movement (EYE), and respiratory (RES) data acquired by wearable devices available in the market. Supervised machine learning models, and more specifically, binary classification models, are predominant among the proposed fatigue quantification approaches. These models were considered to perform very well in detecting fatigue, however, little effort was made to ensure the use of high-quality data during model development. Together, the findings of this review reveal that methodological limitations have hindered the generalizability and real-world applicability of most of the proposed fatigue models. Considerably more work is needed to fully explore the potential of wearables for fatigue quantification as well as to better understand the relationship between fatigue and changes in physiological variables.
DA  - 2021/12/15/
PY  - 2021
DO  - 10.3389/fphys.2021.790292
VL  - 12
SN  - 1664-042X
AN  - WOS:000739106700001
KW  - machine learning
KW  - Review
KW  - human
KW  - systematic review
KW  - motion
KW  - electromyography
KW  - supervised machine learning
KW  - validation
KW  - electrocardiography
KW  - area under the curve
KW  - task performance
KW  - electroencephalography
KW  - limit of quantitation
KW  - electrodermal response
KW  - eye movement
KW  - fatigue monitoring
KW  - imbalanced datasets
KW  - mental fatigue
KW  - occupational health and safety
KW  - photoelectric plethysmography
KW  - physiological signal
KW  - respiratory tract parameters
KW  - signal quality assessment
KW  - skin temperature
KW  - wearable
ER  - 

TY  - JOUR
TI  - Poincare maps for visualization of large protein families
AU  - Susmelj, AK
AU  - Ren, YN
AU  - Vander Meersche, Y
AU  - Gelly, JC
AU  - Galochkina, T
T2  - BRIEFINGS IN BIOINFORMATICS
AB  - In the era of constantly increasing amounts of the available protein data, a relevant and interpretable visualization becomes crucial, especially for tasks requiring human expertise. Poincare disk projection has previously demonstrated its important efficiency for visualization of biological data such as single-cell RNAseq data. Here, we develop a new method PoincareMSA for visual representation of complex relationships between protein sequences based on Poincare maps embedding. We demonstrate its efficiency and potential for visualization of protein family topology as well as evolutionary and functional annotation of uncharacterized sequences. PoincareMSA is implemented in open source Python code with available interactive Google Colab notebooks as described at .
DA  - 2023/05/19/
PY  - 2023
DO  - 10.1093/bib/bbad103
VL  - 24
IS  - 3
SN  - 1467-5463
AN  - WOS:000957200100001
KW  - machine learning
KW  - article
KW  - human
KW  - amino acid sequence
KW  - embedding
KW  - data visualization
KW  - protein function
KW  - sequence alignment
KW  - multiple sequence alignment
KW  - protein family
KW  - dimensionality reduction
KW  - molecular evolution
KW  - protein evolution
KW  - protein sequence
KW  - sequence similarity
ER  - 

TY  - JOUR
TI  - Domain-Adversarial Network Alignment
AU  - Hong, HT
AU  - Li, X
AU  - Pan, YG
AU  - Tsang, IW
T2  - IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING
AB  - Network alignment is a critical task in a wide variety of fields. Many existing works leverage on representation learning to accomplish this task without eliminating domain representation bias induced by domain-dependent features, which yield inferior alignment performance. This paper proposes a unified deep architecture (DANA) to obtain a domain-invariant representation for network alignment via an adversarial domain classifier. Specifically, we employ the graph convolutional networks to perform network embedding under the domain adversarial principle, given a small set of observed anchors. Then, the semi-supervised learning framework is optimized by maximizing a posterior probability distribution of observed anchors and the loss of a domain classifier simultaneously. We also develop a few variants of our model, such as, direction-aware network alignment, weight-sharing for directed networks and simplification of parameter space. Experiments on three real-world social network datasets demonstrate that our proposed approaches achieve state-of-the-art alignment results.
DA  - 2022/07/01/
PY  - 2022
DO  - 10.1109/TKDE.2020.3023589
VL  - 34
IS  - 7
SP  - 3211
EP  - 3224
SN  - 1041-4347
AN  - WOS:000805787100014
ER  - 

TY  - JOUR
TI  - Computer Vision Based Inspection on Post-Earthquake With UAV Synthetic Dataset
AU  - Zarski, M
AU  - Wojcik, B
AU  - Miszczak, JA
AU  - Blachowski, B
AU  - Ostrowski, M
T2  - IEEE ACCESS
AB  - The area affected by the earthquake is vast and often difficult to entirely cover, and the earthquake itself is a sudden event that causes multiple defects simultaneously, that cannot be effectively traced using traditional, manual methods. This article presents an innovative approach to the problem of detecting damage after sudden events by using an interconnected set of deep machine learning models organized in a single pipeline and allowing for easy modification and swapping models seamlessly. Models in the pipeline were trained with a synthetic dataset and were adapted to be further evaluated and used with unmanned aerial vehicles (UAVs) in real-world conditions. Thanks to the methods presented in the article, it is possible to obtain high accuracy in detecting buildings defects, segmenting constructions into their components and estimating their technical condition based on a single drone flight.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3212918
VL  - 10
SP  - 108134
EP  - 108144
SN  - 2169-3536
AN  - WOS:000870216700001
ER  - 

TY  - CHAP
TI  - Predicting Protein Secondary Structure Using Consensus Data Mining (CDM) Based on Empirical Statistics and Evolutionary Information
AU  - Kandoi, G
AU  - Leelananda, SP
AU  - Jernigan, RL
AU  - Sen, TZ
T2  - PREDICTION OF PROTEIN SECONDARY STRUCTURE
A2  - Zhou, Y
A2  - Kloczkowski, A
A2  - Faraggi, E
A2  - Yang, Y
AB  - Predicting the secondary structure of a protein from its sequence still remains a challenging problem. The prediction accuracies remain around 80 %, and for very diverse methods. Using evolutionary information and machine learning algorithms in particular has had the most impact. In this chapter, we will first define secondary structures, then we will review the Consensus Data Mining (CDM) technique based on the robust GOR algorithm and Fragment Database Mining (FDM) approach. GOR V is an empirical method utilizing a sliding window approach to model the secondary structural elements of a protein by making use of generalized evolutionary information. FDM uses data mining from experimental structure fragments, and is able to successfully predict the secondary structure of a protein by combining experimentally determined structural fragments based on sequence similarities of the fragments. The CDM method combines predictions from GOR V and FDM in a hierarchical manner to produce consensus predictions for secondary structure. In other words, if sequence fragment are not available, then it uses GOR V to make the secondary structure prediction. The online server of CDM is available at http://gor.bb.iastate.edu/cdm/.
DA  - 2017///
PY  - 2017
VL  - 1484
SP  - 35
EP  - 44
SN  - 1064-3745
AN  - WOS:000400734600005
KW  - machine learning
KW  - Machine learning
KW  - Software
KW  - Algorithms
KW  - algorithm
KW  - procedures
KW  - software
KW  - amino acid sequence
KW  - Amino Acid Sequence
KW  - genetics
KW  - Proteins
KW  - chemistry
KW  - protein
KW  - data mining
KW  - Data Mining
KW  - Multiple sequence alignments
KW  - sequence alignment
KW  - Sequence Alignment
KW  - Consensus data mining
KW  - empirical research
KW  - Fragment database mining
KW  - GOR
KW  - protein secondary structure
KW  - Protein structure prediction
KW  - Protein Structure, Secondary
KW  - Secondary structure
ER  - 

TY  - JOUR
TI  - Unsupervised Domain Adaptation Network With Category-Centric Prototype Aligner for Biomedical Image Segmentation
AU  - Gong, P
AU  - Yu, WW
AU  - Sun, QW
AU  - Zhao, RH
AU  - Hu, JF
T2  - IEEE ACCESS
AB  - With the widespread success of deep learning in biomedical image segmentation, domain shift becomes a critical and challenging problem, as the gap between two domains can severely affect model performance when deployed to unseen data with heterogeneous features. To alleviate this problem, we present a novel unsupervised domain adaptation network, for generalizing models learned from the labeled source domain to the unlabeled target domain for cross-modality biomedical image segmentation. Specifically, our approach consists of two key modules, a conditional domain discriminator (CDD) and a category-centric prototype aligner (CCPA). The CDD, extended from conditional domain adversarial networks in classifier tasks, is effective and robust in handling complex cross-modality biomedical images. The CCPA, improved from the graph-induced prototype alignment mechanism in cross-domain object detection, can exploit precise instance-level features through an elaborate prototype representation. In addition, it can address the negative effect of class imbalance via entropy-based loss. Extensive experiments on a public benchmark for the cardiac substructure segmentation task demonstrate that our method significantly improves performance on the target domain.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3063634
VL  - 9
SP  - 36500
EP  - 36511
SN  - 2169-3536
AN  - WOS:000626499200001
ER  - 

TY  - JOUR
TI  - Research on intelligent financial information framework and smarter university campus
AU  - Yuan, LX
AU  - Du, JB
T2  - INTERNATIONAL JOURNAL OF KNOWLEDGE-BASED DEVELOPMENT
AB  - China has entered the big data cloud era, and college financial information construction is key. Good financial information in schools and universities promotes an 'Intelligent campus' and improves financial management. This paper reviews current smart city and smart campus successes. The report defines smart campus principles and a tactical approach for its parts. IoT and cloud technology were the app's key extra infrastructure. This paper analyses colleges' financial information concerns from an 'Intelligent campus' perspective. It evaluates elements affecting the smart-university campus adoption of an intelligent financial information system. China's universities were surveyed using a cross-sectional questionnaire. The framework was based on IoT and cloud computing as the main supporting infrastructure, with eight main criteria and 25 sub-applications such as Smart Card or E-Card, Smart Classrooms, Energy Management, Adaptive Learning, Smart Transportation, Security and Safety, Optimisation and Analytics Data Center and Smart Facilities Services and the optimisation strategy to promote the construction of an 'Intelligent campus' in our university.
DA  - 2022///
PY  - 2022
DO  - 10.1504/IJKBD.2022.128913
VL  - 12
IS  - 3-4
SP  - 409
EP  - 423
SN  - 2040-4468
AN  - WOS:000932430100013
ER  - 

TY  - JOUR
TI  - Electronic surveillance of patient safety events using natural language processing
AU  - Ozonoff, A
AU  - Milliren, CE
AU  - Fournier, K
AU  - Welcher, J
AU  - Landschaft, A
AU  - Samnaliev, M
AU  - Saluvan, M
AU  - Waltzman, M
AU  - Kimia, AA
T2  - HEALTH INFORMATICS JOURNAL
AB  - Objective We describe our approach to surveillance of reportable safety events captured in hospital data including free-text clinical notes. We hypothesize that a) some patient safety events are documented only in the clinical notes and not in any other accessible source; and b) large-scale abstraction of event data from clinical notes is feasible. Materials and Methods We use regular expressions to generate a training data set for a machine learning model and apply this model to the full set of clinical notes and conduct further review to identify safety events of interest. We demonstrate this approach on peripheral intravenous (PIV) infiltrations and extravasations (PIVIEs). Results During Phase 1, we collected 21,362 clinical notes, of which 2342 were reviewed. We identified 125 PIV events, of which 44 cases (35%) were not captured by other patient safety systems. During Phase 2, we collected 60,735 clinical notes and identified 440 infiltrate events. Our classifier demonstrated accuracy above 90%. Conclusion Our method to identify safety events from the free text of clinical documentation offers a feasible and scalable approach to enhance existing patient safety systems. Expert reviewers, using a machine learning model, can conduct routine surveillance of patient safety events.
DA  - 2022/10//undefined
PY  - 2022
DO  - 10.1177/14604582221132429
VL  - 28
IS  - 4
SN  - 1460-4582
AN  - WOS:000888036600001
KW  - machine learning
KW  - Machine Learning
KW  - human
KW  - Humans
KW  - patient safety
KW  - Natural Language Processing
KW  - electronic health record
KW  - natural language processing
KW  - text mining
KW  - Patient Safety
KW  - electronic health records
KW  - Electronic Health Records
KW  - databases and data mining
KW  - electronics
KW  - Electronics
KW  - IT healthcare evaluation
ER  - 

TY  - JOUR
TI  - Data-driven model for ship encounter intention inference in intersection waters based on AIS data
AU  - Ma, J
AU  - Liu, Q
AU  - Jia, CF
T2  - PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART M-JOURNAL OF ENGINEERING FOR THE MARITIME ENVIRONMENT
AB  - Frequent collision accidents of ships in intersection waters have caused huge casualties and property losses. Unclear encounter intention, poor communication, or inaccurate judgment of the encounter intention are often the major causes of ships falling into dangerous and urgent situations, leading to collision accidents. There are few methods and models for automatically inferring ship encounter intention. In this study, an intelligent model driven by AIS data is proposed to infer the ship encounter intention in intersection waters. The Hidden Markov Model (HMM) is adopted to formulate the encounter process and perform intention inference. The encounter intentions, including crossing, overtaking and head-on, are modeled as unobservable states of the formulated HMM. The observable measures of HMM extracted from AIS data, include the relative distance, relative speed, and course difference between two ships. Subsequently, the Forward-Backward algorithm is employed to obtain the model parameters and the Viterbi algorithm is exploited to estimate the hidden state with the highest probability, resulting in the inferred intention. The main advantage of the proposed model is its ability to capture the spatial-temporal characteristics of the encounter process, that is, the spatial interaction between ships and the dynamic evolution of states of the encounter process. The AIS data collected from the Lantau Strait intersection waters are adopted to verify the effectiveness of the proposed model. The experimental results reveal that the model can achieve an inference accuracy of 95%, 91.33%, and 92.67% for crossing, overtaking, and head-on, respectively. Moreover, it has real-time performance that ensures the encounter intentions can be recognized at an early stage, which is very critical for the safe navigation of any ships encountered. Our results show that our model can infer the encounter intentions in a timely manner and with high accuracy.
DA  - 2022/08//undefined
PY  - 2022
DO  - 10.1177/14750902211065243
VL  - 236
IS  - 3
SP  - 701
EP  - 712
SN  - 1475-0902
AN  - WOS:000731546300001
KW  - machine learning
KW  - Machine learning
KW  - Accidents
KW  - Big data
KW  - Ships
KW  - Data-driven model
KW  - Hidden Markov models
KW  - Hidden-Markov models
KW  - HMM
KW  - Maritime safety
KW  - Viterbi algorithm
KW  - AIS data
KW  - Collision/accident
KW  - Maritime big data analyse and mining
KW  - maritime big data analysis and mining
KW  - Property loss
KW  - ship encounter intention
KW  - Ship encounter intention
KW  - Ship encounters
KW  - Water based
ER  - 

TY  - JOUR
TI  - Cholec80-CVS: An open dataset with an evaluation of Strasberg's critical view of safety for AI
AU  - Ríos, MS
AU  - Molina-Rodriguez, MA
AU  - Londoño, D
AU  - Guillén, CA
AU  - Sierra, S
AU  - Zapata, F
AU  - Giraldo, LF
T2  - SCIENTIFIC DATA
AB  - Strasberg's criteria to detect a critical view of safety is a widely known strategy to reduce bile duct injuries during laparoscopic cholecystectomy. In spite of its popularity and efficiency, recent studies have shown that human miss-identification errors have led to important bile duct injuries occurrence rates. Developing tools based on artificial intelligence that facilitate the identification of a critical view of safety in cholecystectomy surgeries can potentially minimize the risk of such injuries. With this goal in mind, we present Cholec80-CVS, the first open dataset with video annotations of Strasberg's Critical View of Safety (CVS) criteria. Our dataset contains CVS criteria annotations provided by skilled surgeons for all videos in the well-known Cholec80 open video dataset. We consider that Cholec80-CVS is the first step towards the creation of intelligent systems that can assist humans during laparoscopic cholecystectomy.
DA  - 2023/04/08/
PY  - 2023
DO  - 10.1038/s41597-023-02073-7
VL  - 10
IS  - 1
SN  - 2052-4463
AN  - WOS:000966269200002
ER  - 

TY  - JOUR
TI  - Driving Style Analysis Using Recurrent Neural Networks with LSTM Cells
AU  - Würtz, S
AU  - Göhner, U
T2  - JOURNAL OF ADVANCES IN INFORMATION TECHNOLOGY
AB  - Many publications work on optimization of driving styles in motor vehicles. Most conclude that they can improve energy efficiency through training. In recent years the tools to address those problems evolved towards machine learning. To get appropriate data for learning algorithms we developed a method to judge a driving style with respect to energy efficiency. This approach leveraged handpicked criteria like acceleration extracted from GPS. Like related works, this method does not scale, since it requires substantial preprocessing. The goal of this evaluation was to reduce the resistance energy of a driven trip, while maintaining a natural traffic flow. This was accomplished by mimicking a low-pass filter on the speed profile. On top excessive speeding gets punished. It was possible to use our data with over 1 million kilometers for training a Recurrent Neural Network. In respect to the RNN the training data was used, to let it map the obtained function. The provided data was adjusted in different stages, until it was only the raw GPS data. The RNN learned to handle most GPS errors, only in initial phases the results are mixed. A RNN Network is well suited to handle GPS data and learn higher level features on its own. The result is a NN which judges the driving style using only raw GPS data.
DA  - 2020/02//undefined
PY  - 2020
DO  - 10.12720/jait.11.1.1-9
VL  - 11
IS  - 1
SP  - 1
EP  - 9
SN  - 1798-2340
AN  - WOS:000884921700001
KW  - Deep learning
KW  - Machine learning
KW  - Neural network
KW  - Energy efficiency
KW  - Sensor data
KW  - Driver behavior
KW  - LSTM
KW  - Driving style
KW  - Driving safety
KW  - RNN
KW  - GPS data
KW  - Intelligent vehicle control
ER  - 

TY  - CONF
TI  - safe.trAIn - Engineering and Assurance of a Driverless Regional Train
AU  - Zeller, M
AU  - Rothfelder, M
AU  - Klein, C
AU  - IEEE
T2  - 2023 IEEE/ACM 2ND INTERNATIONAL CONFERENCE ON AI ENGINEERING - SOFTWARE ENGINEERING FOR AI, CAIN
AB  - Traditional automation technologies alone are not sufficient to enable the fully automated operation of trains. However, Artificial Intelligence (AI) and Machine Learning (ML) offers great potential to realize the mandatory novel functions to replace the tasks of a human train driver, such as obstacle detection on the tracks. The problem, which still remains unresolved, is to find a practical way to link AI/ML techniques with the requirements and approval processes that are applied in the railway domain. The safe.trAIn project aims to lay the foundation for the safe use of AI/ML to achieve the driverless operation of rail vehicles and thus addresses this key technological challenge hindering the adoption of unmanned rail transport. The project goals are to develop guidelines and methods for the reliable engineering and safety assurance of ML in the railway domain. Therefore, the project investigates methods to reliable design ML models and to prove the trustworthiness of AI-based functions taking robustness, uncertainty, and transparency aspects of the AI/ML model into account.
DA  - 2023///
PY  - 2023
DO  - 10.1109/CAIN58948.2023.00036
SP  - 197
EP  - 197
SN  - 979-8-3503-0113-7
AN  - WOS:001031642200028
ER  - 

TY  - JOUR
TI  - Planning With Learned Dynamics: Probabilistic Guarantees on Safety and Reachability via Lipschitz Constants
AU  - Knuth, C
AU  - Chou, G
AU  - Ozay, N
AU  - Berenson, D
T2  - IEEE ROBOTICS AND AUTOMATION LETTERS
AB  - We present a method for feedback motion planning of systems with unknown dynamics which provides probabilistic guarantees on safety, reachability, and goal stability. To find a domain in which a learned control-affine approximation of the true dynamics can be trusted, we estimate the Lipschitz constant of the difference between the true and learned dynamics, and ensure the estimate is valid with a given probability. Provided the system has at least as many controls as states, we also derive existence conditions for a one-step feedback law which can keep the real system within a small bound of a nominal trajectory planned with the learned dynamics. Our method imposes the feedback law existence as a constraint in a sampling-based planner, which returns a feedback policy around a nominal plan ensuring that, if the Lipschitz constant estimate is valid, the true system is safe during plan execution, reaches the goal, and is ultimately invariant in a small set about the goal. We demonstrate our approach by planning using learned models of a 6D quadrotor and a 7DOF Kuka arm. We show that a baseline which plans using the same learned dynamics without considering the error bound or the existence of the feedback law can fail to stabilize around the plan and become unsafe.
DA  - 2021/07//undefined
PY  - 2021
DO  - 10.1109/LRA.2021.3068889
VL  - 6
IS  - 3
SP  - 5129
EP  - 5136
SN  - 2377-3766
AN  - WOS:000645056800005
ER  - 

TY  - JOUR
TI  - A food safety prescreening method with domain-specific information using online reviews
AU  - Zuo, EG
AU  - Aysa, A
AU  - Muhammat, M
AU  - Zhao, YX
AU  - Chen, B
AU  - Ubul, K
T2  - JOURNAL OF CONSUMER PROTECTION AND FOOD SAFETY
AB  - Food contamination and food poisoning are presenting a substantial safety risk to consumers worldwide. In the era of information quantity and availability, the potential of social-media data has attracted increasing attention from relevant government regulatory agencies, food companies, and consumers. This paper takes text data from online media as a research object and innovatively proposes a new type of food text-mining technology based on the associated attention mechanism to quickly screen for potential food safety issues. First, we used the mutual information between each review Chinese word segment(CWS) and label to calculate the correlation score between each word and food safety hazards. Then, the attention score in supervised deep learning was combined in order to assess whether foods sold online may be unsafe for consumers. We compared the method in this paper with existing text-mining methods on food- safety-related datasets and found that the proposed method performs markedly better than the benchmark model, achieving an accuracy rate of 96.95%. A team of food safety experts also performed a food risk assessment on the prediction results produced by the proposed model, and experimental results showed that the proposed tool can markedly reduce the time required to screen for food safety risks. This study provides a fast and cost-effective food-safety screening method and helps reduce consumer dietary safety hazards.
DA  - 2022/06//undefined
PY  - 2022
DO  - 10.1007/s00003-022-01367-z
VL  - 17
IS  - 2
SP  - 163
EP  - 175
SN  - 1661-5751
AN  - WOS:000770526600001
ER  - 

TY  - JOUR
TI  - Shifting Deep Reinforcement Learning Algorithm Toward Training Directly in Transient Real-World Environment: A Case Study in Powertrain Control
AU  - Hu, B
AU  - Li, JX
T2  - IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS
AB  - Deep reinforcement learning (DRL) excels at playing a wide variety of simulated games and allows for a generic learning process that does not consider a specific knowledge of the task. However, due to the fact that a large prohibitively number of interactions with the environment are required and that the initial policy behavior is almost random, such an algorithm cannot be trained directly in a real-world environment while satisfying given safety constraints. In this article, a control framework based on DRL that shifts toward training directly in the transient real-world environment is proposed. This research is working on the assumption that some demonstration knowledge that operates under previous controllers and an abstract of the agent environment dynamics are available. By encoding this prior knowledge into a sophisticated learning architecture, a warm-starting DRL algorithm with a safe exploration guarantee can be anticipated. Taking the boost control problem for a variable geometry turbocharger equipped diesel engine as an example, the proposed algorithm improves the initial performance by 74.6% and the learning efficiency by an order of magnitude in contrast to its vanilla counterpart. Compared with other existing DRL-based powertrain control methods, the proposed algorithm can realize the "model-free" concept in the strict sense, making it attractive for future DRL-based powertrain control algorithms to build on.
DA  - 2021/12//undefined
PY  - 2021
DO  - 10.1109/TII.2021.3063489
VL  - 17
IS  - 12
SP  - 8198
EP  - 8206
SN  - 1551-3203
AN  - WOS:000690940600032
KW  - Deep learning
KW  - Reinforcement learning
KW  - Safety
KW  - Task analysis
KW  - Training
KW  - Learning algorithms
KW  - Deep Reinforcement Learning
KW  - Learning architectures
KW  - Engines
KW  - Safety constraint
KW  - Control framework
KW  - Environment dynamics
KW  - Informatics
KW  - Transient analysis
KW  - Learning efficiency
KW  - Real world environments
KW  - Demonstration
KW  - Mechanical power transmission
KW  - Powertrain Control
KW  - Powertrains
KW  - Real-World Environment
KW  - Specific knowledge
KW  - Variable geometry turbocharger
ER  - 

TY  - JOUR
TI  - A Machine-Learning-Based Data-Centric Misbehavior Detection Model for Internet of Vehicles
AU  - Sharma, P
AU  - Liu, H
T2  - IEEE INTERNET OF THINGS JOURNAL
AB  - The Internet of Things (IoT) boosts road safety, efficiency, and infotainment by connecting vehicles to form the Internet of Vehicles (IoV). Specifically to safety, IoV complements autonomous cars beyond sensors' line-of-sight, facilitating vehicle-to-vehicle (V2V) communications in a smart transportation environment. The correctness of data exchanged among vehicles is paramount to ensure vehicles behave as per norms. Traditional misbehavior detection methods hardly defend vehicular security effectively due to rapid dynamics and location privacy. In particular, those node-centric classifiers become ill-fit in IoV. This work proposes a data-centric misbehavior detection model based on supervised machine learning (ML). The work also integrates plausibility checks with ML techniques and instantiates the model with six algorithms to demonstrate their comparative effectiveness. In addition to misbehavior detection, the model classifies attack types to support validating countermeasures. Specifically, the work analyzes the supervised learning algorithms for detecting misbehavior in IoV, compares their performance, and identifies their limitations. VeReMi, a vehicle-to-everything (V2X) position forgery attack built-in simulated road traffic data set, is used to test the effectiveness of the proposed model. The performance metrics include precision-recall (PR) and receiver operating characteristic (ROC) curves. The results demonstrate the effectiveness and significance of ML to detect misbehavior in IoV. The addition of plausibility checks improves the precision and recall by 5% and 2%, respectively.
DA  - 2021/03/15/
PY  - 2021
DO  - 10.1109/JIOT.2020.3035035
VL  - 8
IS  - 6
SP  - 4991
EP  - 4999
SN  - 2327-4662
AN  - WOS:000626569700069
ER  - 

TY  - JOUR
TI  - Using chemical and biological data and AI for predictive safety - fundamental concepts, new readouts, applications, limitations
AU  - Bender, A
T2  - TOXICOLOGY LETTERS
DA  - 2022/09/01/
PY  - 2022
DO  - 10.1016/j.toxlet.2022.07.045
VL  - 368
SP  - S11
EP  - S12
SN  - 0378-4274
AN  - WOS:000853725600037
ER  - 

TY  - JOUR
TI  - Hardware-Based Spiking Neural Network Using a TFT-Type AND Flash Memory Array Architecture Based on Direct Feedback Alignment
AU  - Kang, WM
AU  - Kwon, D
AU  - Woo, SY
AU  - Lee, S
AU  - Yoo, H
AU  - Kim, J
AU  - Park, BG
AU  - Lee, JH
T2  - IEEE ACCESS
AB  - A hardware-based neural network that enables on-chip training using a thin-film transistor-type AND flash memory array architecture is designed. The synaptic device constituting the array is characterized by a doped p-type body, a gate insulator stack composed of SiO2/Si3N4/Al2O3, and a partially curved poly-Si channel. The body reduces the circuit burden on the high voltage driver required for both the source and drain lines when changing the synaptic weights. The high-kappa material included in the gate insulator stack helps to lower the operating voltage of the device. As the device scales down, the structural characteristics of the device have the potential to increase the efficiency of the memory operation and the immunity to the voltage drop effect that occurs in the bit-lines of the array. In an AND array architecture using fabricated synaptic devices, a pulse scheme for selective memory operation is proposed and verified experimentally. Due to the direct feedback alignment (DFA) algorithm, which does not need to have the same synaptic weight in the forward path and backward path, the AND array architecture can be utilized in designing an efficient on-chip training neural network. Pulse schemes suitable for the proposed AND array architecture are also devised to implement the DFA algorithm in neural networks. In a system-level simulation, a recognition accuracy of up to 97.01% is obtained in the MNIST pattern learning task based on the proposed pulse scheme and computing architecture.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3080310
VL  - 9
SP  - 73121
EP  - 73132
SN  - 2169-3536
AN  - WOS:000673523400001
KW  - Neural networks
KW  - Network architecture
KW  - supervised learning
KW  - Feedback
KW  - Memory architecture
KW  - Alignment
KW  - spiking neural network
KW  - Pattern recognition systems
KW  - Spiking neural networks
KW  - Structural characteristics
KW  - AND type crossbar array
KW  - Computing architecture
KW  - direct feedback alignment
KW  - Flash memory
KW  - flash memory synaptic device
KW  - Hardware-based neural network
KW  - High-voltage drivers
KW  - Memory array architecture
KW  - on-chip training
KW  - Recognition accuracy
KW  - Silica
KW  - Silicon
KW  - System level simulation
KW  - Thin film transistors
KW  - Thin-film transistor (TFTs)
ER  - 

TY  - CONF
TI  - A cloud-based fire safety system for emergency responders and civic community
AU  - Majumdar, S
AU  - Kirkley, S
AU  - IEEE
T2  - 2023 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE, LISAT
AB  - The main goal of this research is to identify, demonstrate, and provide a secure approach to homeowners in creating fire-safety checklists and pre-incident plans of their homes, and uploading them through a secure cloud service to the centralized fire safety cloud-based system, ALIKE, which in turn provides updated and scalable views of the home interiors for their local fire departments. ALIKE is a cloud-based system that integrates 3D scans, AI, image recognition, and augmented reality to help homeowners improve the safety of their homes and conduct pre-incident planning with the local fire department. The ALIKE system provides for two modal approaches: the homeowner system approach and the firefighter system approach. Watson AI functionality within ALIKE system can identify potential fire safety issue in the home, examine the issue and recommend fire safe products to mitigate the potential hazard. Thus, the cause of residential fires would be reduced to a great extent, providing safer homes for residents.
DA  - 2023///
PY  - 2023
DO  - 10.1109/LISAT58403.2023.10179600
SN  - 979-8-3503-1116-7
AN  - WOS:001042445800012
ER  - 

TY  - JOUR
TI  - Automatic drug pills detection based on enhanced feature pyramid network and convolution neural networks
AU  - Ou, YY
AU  - Tsai, AC
AU  - Zhou, XP
AU  - Wang, JF
T2  - IET COMPUTER VISION
AB  - Drug pill detection is one of the most important tasks in medication safety. The correct identification of drug based on the visual appearance is a key step towards the improvement of medication safety. Previous studies have aimed to recognise a drug based on the front or back view of the drug under a fixed viewing angle. In cases with multiple drugs and randomly placed drugs, the previous methods have difficulties in detecting and recognising different drugs in practical applications. A convolution neural network-based detector is proposed in this work to overcome the difficulties and to assist patients in drug identification. The proposed system includes a localisation stage and a classification stage. The enhanced feature pyramid network (EFPN), is proposed for drug localisation, and Inception-ResNet v2 is used in drug classification. The proposed Drug Pills Image Database contains a collection of 612 categories of drug datasets for deep learning research in the pharmaceutical field. The proposed EFPN achieves over 96% accuracy in the localisation experiment. In the complete system evaluation, the proposed system has obtained the Top-1, Top-3, and Top-5 accuracies of 82.1, 92.4, and 94.7%, respectively.
DA  - 2020/02//undefined
PY  - 2020
DO  - 10.1049/iet-cvi.2019.0171
VL  - 14
IS  - 1
SP  - 9
EP  - 17
SN  - 1751-9632
AN  - WOS:000526681200002
ER  - 

TY  - JOUR
TI  - Target recognition in synthetic aperture radar image based on PCANet
AU  - Qi, BG
AU  - Jing, HT
AU  - Chen, H
AU  - Zhuang, Y
AU  - Yue, Z
AU  - Wang, CL
T2  - JOURNAL OF ENGINEERING-JOE
AB  - Automatic targets recognition (ATR) for synthetic aperture radar (SAR) image is very important. ATR can be used in traffic management, national frontier safety, and so on. Traditional algorithms for SAR ATR is composed of extraction features and training classifier. The features are essential for the classification accuracy. However, choosing good features by hand is a hard task. The deep convolutional neural networks (CNNs) which can learn features automatically have got a great performance in natural images. However, the CNNs have many parameters and need a lot of data to train such networks. The remote-sensing data of SAR is limited. Then, the authors need a simple network which needs not much data and easy to train. The principal component analysis network (PCANet) is a shallow network that performs well in the recognition task and needs no hand features choosing. Though this network has produced a wide application in the natural images, it is rarely used in the SAR images. The experimental result of the moving and stationary target acquisition and recognition (MSTAR) dataset shows that the PCANet can achieve over 99% accuracy on ten-class targets. This result is better than traditional algorithms and is very close to the results of deep-learning methods.
DA  - 2019/11//undefined
PY  - 2019
DO  - 10.1049/joe.2019.0238
VL  - 2019
IS  - 21
SP  - 7309
EP  - 7312
SN  - 2051-3305
AN  - WOS:000503273300003
ER  - 

TY  - JOUR
TI  - Long short-term memory and convolutional neural network for abnormal driving behaviour recognition
AU  - Jia, S
AU  - Hui, F
AU  - Li, SN
AU  - Zhao, XM
AU  - Khattak, AJ
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - Abnormal driving behaviours, such as rapid acceleration, emergency braking, and rapid lane changing, bring great uncertainty to traffic, and can easily lead to traffic accidents. The accurate identification of abnormal driving behaviour helps to judge the driver's driving style, inform surrounding vehicles, and ensure the road traffic safety. Most of the existing studies use clustering and shallow learning, it is difficult to accurately identify the types of abnormal driving behaviours. Aimed at addressing the difficulty of identifying driving behaviour, this study proposed a recognition model based on a long short-term memory network and convolutional neural network (LSTM-CNN). The extreme acceleration and deceleration points are detected through the statistical analysis of real vehicle driving data, and the driving behaviour recognition data set is established. By using the data set to train the model, the LSTM-CNN can achieve a better result.
DA  - 2020/05//undefined
PY  - 2020
DO  - 10.1049/iet-its.2019.0200
VL  - 14
IS  - 5
SP  - 306
EP  - 312
SN  - 1751-956X
AN  - WOS:000530480700006
ER  - 

TY  - JOUR
TI  - Automated visual inspection of target parts for train safety based on deep learning
AU  - Zhou, FQ
AU  - Song, Y
AU  - Liu, L
AU  - Zheng, DT
T2  - IET INTELLIGENT TRANSPORT SYSTEMS
AB  - Visual inspection of target parts is a common approach to ensuring train safety. However, some key parts, such as fastening bolts, do not possess sufficient feature information, because they are usually small, polluted, or obscured. These factors affect inspection accuracy and can lead to serious accidents. Therefore, traditional visual inspection relying on feature extraction cannot always meet the requirements of high-accuracy inspection. Deep learning has considerable advantages in image recognition for autonomous information mining, but it requires a considerable amount of computation. To resolve the issues mentioned above, this study proposes a method that combines traditional visual inspection with deep learning. Traditional feature extraction is used to locate the targets approximately, which makes the deep learning purposeful and efficient. A composite neural network, stacked auto-encoder convolutional neural network (SAE-CNN), is provided to further improve the training efficiency. A SAE is added to a CNN so that the network can obtain optimum results faster and more accurately. Taking the inspection of centre plate bolts in a moving freight car as an example, the overall system and specific processes are described. The study results showed satisfactory accuracy. A related analysis and comparative experiment were also conducted.
DA  - 2018/08//undefined
PY  - 2018
DO  - 10.1049/iet-its.2016.0338
VL  - 12
IS  - 6
SP  - 550
EP  - 555
SN  - 1751-956X
AN  - WOS:000437188000020
ER  - 

TY  - JOUR
TI  - Optimal Transport With Relaxed Marginal Constraints
AU  - Li, J
AU  - Lin, L
T2  - IEEE ACCESS
AB  - Optimal transport (OT) is a principled approach for matching, having achieved success in diverse applications such as tracking and cluster alignment. It is also the core computation problem for solving the Wasserstein metric between probabilistic distributions, which has been increasingly used in machine learning. Despite its popularity, the marginal constraints of OT impose fundamental limitations. For some matching or pattern extraction problems, the framework of OT is not suitable, and post-processing of the OT solution is often unsatisfactory. In this paper, we extend OT by a new optimization formulation called Optimal Transport with Relaxed Marginal Constraints (OT-RMC). Specifically, we relax the marginal constraints by introducing a penalty on the deviation from the constraints. Connections with the standard OT are revealed both theoretically and experimentally. We demonstrate how OT-RMC can easily adapt to various tasks by three highly different applications in image analysis and single-cell data analysis. Quantitative comparisons have been made with OT and another commonly used matching scheme to show the remarkable advantages of OT-RMC.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3072613
VL  - 9
SP  - 58142
EP  - 58160
SN  - 2169-3536
AN  - WOS:000641957000001
ER  - 

TY  - JOUR
TI  - A misbehavior detection system to detect novel position falsification attacks in the Internet of Vehicles
AU  - Ilango, HS
AU  - Ma, MD
AU  - Su, R
T2  - ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE
AB  - In the Internet of Vehicle (IoV) networks, vehicles exchange periodic Basic Safety Messages (BSMs) containing information regarding speed and position. Safety-critical applications like blind-spot warning and lane change warning systems use the BSMs to ensure the safety of road users. To create chaos in the network, an insider attacker may inject false information into the BSM and broadcast it to nearby vehicles. One such attack is the position falsification attack, where the attacker inserts false information regarding the position in the BSMs. The literature has explored the use of Misbehavior Detection Systems (MDSs) to detect such attacks. But the limitaitons of the existing approaches are that they either perform exceptionally well in specific environmental settings or have compromised detection accuracy favoring a generalized model. Moreover, all the current machine learning-based detection models are signature-based, which requires prior knowledge about the attacks for effective detection. Motivated by the research gap, we propose a Novel Position Falsification Attack Detection System for the Internet of Vehicles (NPFADS for the IoV) to learn and detect novel position falsification attacks emerging in IoV networks. The performance of NPFADS is analyzed using the metrics precision, recall, F1 score, ROC, and PR curves. The Vehicular Reference Misbehavior (VeReMi) dataset is used as the benchmark for the study. The system's performance is compared to existing MDSs in the literature. The analysis shows that our proposed system outperforms the existing supervised learning models even when initialized with zero knowledge about the novel position falsification attacks.
DA  - 2022/11//undefined
PY  - 2022
DO  - 10.1016/j.engappai.2022.105380
VL  - 116
SN  - 0952-1976
AN  - WOS:000862748800012
KW  - Machine learning
KW  - Vehicles
KW  - Anomaly detection
KW  - Machine-learning
KW  - Vehicle to vehicle communications
KW  - Crime
KW  - Safety engineering
KW  - Attack detection
KW  - Internet of vehicle
KW  - Basic safety message
KW  - Basic Safety Messages (BSMs)
KW  - Internet of Vehicles
KW  - Misbehaviour
KW  - Novel attack detection
KW  - Position falsification attack
KW  - Position falsification attacks
KW  - Safety messages
KW  - V2V communications
KW  - Vehicle to vehicles
KW  - Vehicle-to-vehicle (V2V) communication
KW  - Vehicle-to-Vehicle (V2V) communication
KW  - Vehicular reference misbehavior dataset
KW  - VeReMi dataset
ER  - 

TY  - JOUR
TI  - Finite-Set Direct Torque Control via Edge-Computing-Assisted Safe Reinforcement Learning for a Permanent-Magnet Synchronous Motor
AU  - Schenke, M.
AU  - Haucke-Korber, B.
AU  - Wallscheid, O.
T2  - IEEE Transactions on Power Electronics
AB  - Advances in the field of reinforcement learning (RL)-based drive control allow formulation of holistic optimization goals for the data-driven training phase. The resulting controllers feature efficient drive operation without the necessity of an a priori known plant model but, so far, conduction of the corresponding training phase in real-world drive systems has been applied only sparsely due to safety concerns. This contribution targets the challenging problem of self-learning torque control for a permanent-magnet synchronous motor assuming a finite control set, i.e., the direct selection of switching actions instead of a modulator-based setup. In order to allow a secure and effective online training with real-world drive systems, the RL controller is monitored by a safeguarding algorithm that prevents application of unsafe switching actions, e.g., such that result in overcurrent. The accruing amount of measurement data is handled with the use of an edge-computing pipeline to outsource the RL training from the embedded control hardware. The inference of the utilized artificial neural network in hard real time is realized with the use of a reconfigurable field-programmable gate array architecture. The resulting RL-based algorithm is able to learn a torque control policy in just 10 min, which has been validated during comprehensive real-world experiments.  © 1986-2012 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPEL.2023.3303651
VL  - 38
IS  - 11
SP  - 13741
EP  - 13756
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167785327&doi=10.1109%2fTPEL.2023.3303651&partnerID=40&md5=4ccec92cbdc4c6ea3e1db11768ed2937
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Neural networks
KW  - Internet of Things
KW  - Online systems
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Controllers
KW  - Electric machine control
KW  - Digital storage
KW  - Neural-networks
KW  - Optimal controls
KW  - edge computing
KW  - Edge computing
KW  - Data driven
KW  - Data-driven optimal control
KW  - DC motors
KW  - deep reinforcement learning (RL)
KW  - Direct torque control
KW  - direct torque control (DTC)
KW  - electric drive
KW  - Electric drives
KW  - Field programmable gate arrays (FPGA)
KW  - field-programmable gate array (FPGA)
KW  - neural network
KW  - Permanent magnet motor
KW  - Permanent magnets
KW  - Reconfigurable hardware
KW  - safe learning
KW  - Safe learning
KW  - synchronous motors
KW  - Synchronous motors
KW  - system identification
KW  - System-identification
KW  - Torque
KW  - Torque control
ER  - 

TY  - JOUR
TI  - Robustness assessment and enhancement of deep reinforcement learning-enabled load restoration for distribution systems
AU  - Xie, H.
AU  - Tang, L.
AU  - Zhu, H.
AU  - Cheng, X.
AU  - Bie, Z.
T2  - Reliability Engineering and System Safety
AB  - Efficient critical load restoration under extreme natural disasters is a promising solution to establish resilient distribution systems. Deep reinforcement learning (DRL) approaches are widely adopted in the load restoration problem to avoid incorporating the accurate distribution system model and improve online decision efficiency. However, the vulnerability of DRL towards adversarial examples may lead to unpracticable decisions and pose potential threats to load restoration. To address this issue, this paper proposes a robustness assessment and enhancement method for DRL-enabled distribution system load restoration. In particular, the distribution system load restoration problem is formulated as a Markov decision process, and a deep Q-network is adopted to learn the optimal decision policy. Then, an adversarial example generation optimization model incorporating the deep Q-network is established to implement the robustness assessment of the DRL-enabled load restoration against adversarial examples. Furthermore, adversarial training with the experience replay of adversarial examples is adopted to retrain the agent and improve the stability of the load restoration decision-making. Finally, the effectiveness of the proposed method is analyzed and verified in the modified IEEE 33-bus system and IEEE 123-bus system. The results show that robustness evaluation and enhancement significantly reduce the application risk of DRL in load restoration with safety-critical requirements. © 2023 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.ress.2023.109340
VL  - 237
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159852833&doi=10.1016%2fj.ress.2023.109340&partnerID=40&md5=dc48f9d06218350f44765a4ccc0ae81e
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Decision making
KW  - Learning systems
KW  - Behavioral research
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Markov processes
KW  - Distribution systems
KW  - Electric power distribution
KW  - Restoration
KW  - Adversarial example
KW  - Bus systems
KW  - Disasters
KW  - Load restoration
KW  - Resilient distribution system
KW  - Restoration problems
KW  - Robustness assessment
KW  - System loads
ER  - 

TY  - JOUR
TI  - Forecasting personal learning performance in virtual reality-based construction safety training using biometric responses
AU  - Choi, D.
AU  - Seo, S.
AU  - Park, H.
AU  - Hong, T.
AU  - Koo, C.
T2  - Automation in Construction
AB  - During virtual reality-based safety training, it is necessary to immediately and objectively evaluate personal learning performance. In light of this, this study proposed an interpretable machine learning approach for forecasting personal learning performance in VR-based construction safety training using real-time biometric responses. During VR-based safety training (‘fall accidents on scaffolding’), eye-tracking and EEG data were collected in real time from 30 participants (i.e., construction workers). The main findings can be summarized as follows. Compared to the full forecast model (FM), the support vector regression algorithm of the simplified forecast model (SM), which considers only principal features as independent variables, demonstrated better prediction performance (i.e., accuracy improvement: 0.087 of mean absolute error, overfitting: one-third level of the FM). This study creates new ground in the field of personalized safety training by enabling real-time monitoring and diagnosis for the cognitive states (i.e., learning performance) of construction workers during VR-based construction safety training. © 2023
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.autcon.2023.105115
VL  - 156
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173272856&doi=10.1016%2fj.autcon.2023.105115&partnerID=40&md5=32f735cb6f25663f44a543a066c3bf00
DB  - Scopus
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Virtual reality
KW  - Learning systems
KW  - Learning algorithms
KW  - E-learning
KW  - Forecasting
KW  - Real- time
KW  - Occupational risks
KW  - Learning performance
KW  - Biometric response
KW  - Biometrics
KW  - Construction safety
KW  - Construction worker
KW  - Construction workers
KW  - Eye tracking
KW  - Forecast model
KW  - Forecast models
KW  - Machine learning algorithm
KW  - Personal learning
KW  - Safety training
KW  - Scaffolds
KW  - VR-based construction safety training
ER  - 

TY  - CONF
TI  - Toward Model-Assisted Safe Reinforcement Learning for Data Center Cooling Control: A Lyapunov-based Approach
AU  - Cao, Z.
AU  - Wang, R.
AU  - Zhou, X.
AU  - Wen, Y.
T2  - e-Energy 2023 - Proceedings of the 2023 14th ACM International Conference on Future Energy Systems
AB  - This paper considers intelligent data center cooling control via the Deep Reinforcement Learning (DRL) approach to improve data center sustainability. Existing DRL-based controllers are trained with a simplified data hall thermodynamic model which assumes uniform room temperature distribution. This assumption is not valid for a real-world data center with highly nonuniform temperature distribution. Furthermore, most of them cannot guarantee thermal safety during the DRL learning process. To bridge these gaps, we propose LyaSafe, a model-assisted safe DRL approach for data center cooling control. To address the safety evaluation issue, we develop a coupled model that combines a differentiable surrogate data hall thermodynamics model with the energy model. It can simulate both data hall temperature distribution and the facility energy consumption. To address safe learning, we introduce a novel constrained Markov Decision Process (CMDP) formulation for data center cooling control by considering the Rack Cooling Index (RCI), the best-practice metric for evaluating compliance with ASHRAE data center thermal guidelines. The objective is to minimize data center carbon footprints while regulating the RCI within a threshold. We first derive the safety set based on the concept of the virtual queue and Lyapunov stability theory. Next, we rectify unsafe actions from the DRL agent by projecting them to the safety set. We evaluate LyaSafe in a data center hosting 20 racks and 299 servers. Evaluation results show that LyaSafe can ensure strict safety during the DRL learning while achieving up to 50 metric tons of annual carbon emission savings using Singapore's statistics. Moreover, we conduct root cause analysis for the savings, revealing the importance of joint control of the data hall and the chiller plant. © 2023 Owner/Author.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3575813.3597343
SP  - 333
EP  - 346
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163710520&doi=10.1145%2f3575813.3597343&partnerID=40&md5=1dc9339ab961305ece3ff37d09aca21b
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Markov processes
KW  - Energy utilization
KW  - Reinforcement learning approach
KW  - Safe reinforcement learning
KW  - safe reinforcement learning
KW  - Datacenter
KW  - Compliance control
KW  - Carbon footprint
KW  - Cooling
KW  - cooling control
KW  - Cooling control
KW  - Data center
KW  - Data center cooling
KW  - Intelligent data
KW  - Lyapunov stability theory
KW  - Lyapunov's stability theories
KW  - Rack cooling indices
KW  - Temperature distribution
KW  - Thermodynamic modelling
ER  - 

TY  - CONF
TI  - Adversarial Robustness of Phishing Email Detection Models
AU  - Gholampour, P.M.
AU  - Verma, R.M.
T2  - IWSPA 2023 - Proceedings of the 9th ACM International Workshop on Security and Privacy Analytics
AB  - Developing robust detection models against phishing emails has long been the main concern of the cyber defense community. Currently, public phishing/legitimate datasets lack adversarial email examples which keeps the detection models vulnerable. To address this problem, we developed an augmented phishing/legitimate email dataset, utilizing different adversarial text attack techniques. Next, the models were retrained with the adversarial dataset. Results showed that accuracy and F1 score of the models improved under subsequent attacks. In another experiment, synthetic phishing emails were generated using a fine-tuned GPT-2 model. The detection model was retrained with a newly formed synthetic dataset. Subsequently, we observed that the accuracy and robustness of the model did not improve significantly under black box attack methods. In the last experiment, we proposed a defensive technique to classify adversarial examples to their true labels using a K-Nearest Neighbor approach with 94% accuracy in our prediction.  © 2023 ACM.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3579987.3586567
SP  - 67
EP  - 76
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159123101&doi=10.1145%2f3579987.3586567&partnerID=40&md5=a1c834530dbd2c55d36ba67001fdbe55
DB  - Scopus
L1  - https://dl.acm.org/doi/pdf/10.1145/3579987.3586567
KW  - machine learning
KW  - Deep learning
KW  - deep learning
KW  - Learning systems
KW  - Machine-learning
KW  - Network security
KW  - Computer crime
KW  - Nearest neighbor search
KW  - Adversarial attack
KW  - Model robustness
KW  - adversarial attacks
KW  - data augmentation
KW  - Data augmentation
KW  - Electronic mail
KW  - generative ai
KW  - Generative ai
KW  - gpt-2
KW  - Gpt-2
KW  - model robustness
KW  - Phishing
KW  - phishing/legitimate dataset
KW  - Phishing/legitimate dataset
KW  - Transformer modeling
KW  - transformer models
ER  - 

TY  - CONF
TI  - Fairness in Ranking: From Values to Technical Choices and Back
AU  - Stoyanovich, J.
AU  - Zehlike, M.
AU  - Yang, K.
T2  - Proceedings of the ACM SIGMOD International Conference on Management of Data
AB  - In the past few years, there has been much work on incorporating fairness requirements into the design of algorithmic rankers, with contributions from the data management, algorithms, information retrieval, and recommender systems communities. In this tutorial, we give a systematic overview of this work, offering a broad perspective that connects formalizations and algorithmic approaches across subfields. During the first part of the tutorial, we present a classification framework for fairness-enhancing interventions, along which we will then relate the technical methods. This framework allows us to unify the presentation of mitigation objectives and of algorithmic techniques to help meet those objectives or identify trade-offs. Next, we discuss fairness in score-based ranking and in supervised learning-to-rank. We conclude with recommendations for practitioners, to help them select a fair ranking method based on the requirements of their specific application domain.  © 2023 Owner/Author.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3555041.3589405
SP  - 7
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162864132&doi=10.1145%2f3555041.3589405&partnerID=40&md5=80dafb103434e6b99a8aa98a5eb17843
DB  - Scopus
KW  - Recommender systems
KW  - Algorithmic fairness
KW  - responsible AI
KW  - Learning algorithms
KW  - Economic and social effects
KW  - Algorithmic approach
KW  - Responsible AI
KW  - Search engines
KW  - Algorithmics
KW  - Information management
KW  - algorithmic fairness
KW  - Classification framework
KW  - Formalisation
KW  - learning-to-rank
KW  - ranking
KW  - Ranking
KW  - responsible data management
KW  - Responsible data management
KW  - score-based ranking
KW  - Score-based ranking
KW  - Subfields
ER  - 

TY  - JOUR
TI  - Noise-Robust Machine Learning Models for Predictive Maintenance Applications
AU  - Suawa, P.F.
AU  - Halbinger, A.
AU  - Jongmanns, M.
AU  - Reichenbach, M.
T2  - IEEE Sensors Journal
AB  - [[gabstract]][] Predictive maintenance of equipment requires a set of data collected through sensors, from which models will learn behaviors that will allow the automatic detection or prediction of these behaviors. The objective is to anticipate unexpected situations such as sudden equipment stoppages. Industries are noisy environments due to production lines that involve a series of components. As a result, the data will always be obstructed by noise. Noise-robust predictive maintenance models, which include ensemble and deep learning models with and without data fusion, are proposed to enhance the monitoring of industrial equipment. The work reported in this article is based on two components, a milling tool, and a motor, with sound, vibration, and ultrasound data collected in real experiments. Four main tasks were performed, namely the construction of the datasets, the training of the monitoring models without adding artificial noise to the data, the evaluation of the robustness of the previously trained models by injecting several levels of noise into the test data, and the optimization of the models by a proposed noisy training approach. The results show that the models maintain their performances at over 95% accuracy despite adding noise in the test phase. These performances decrease by only 2% at a considerable noise level of 15-dB signal-to-noise ratio (SNR). The noisy training method proved to be an optimal solution for improving the noise robustness and accuracy of convolutional deep learning models, whose performance regression of 2% went from a noise level of 28 to 15 dB like the other models.  © 2001-2012 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/JSEN.2023.3273458
VL  - 23
IS  - 13
SP  - 15081
EP  - 15092
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159812391&doi=10.1109%2fJSEN.2023.3273458&partnerID=40&md5=e3f39b96d643e5156e88b9e5117ea6c4
DB  - Scopus
KW  - Deep learning
KW  - deep learning
KW  - Signal to noise ratio
KW  - predictive maintenance
KW  - Performance
KW  - Machine-learning
KW  - Learning models
KW  - machine learning (ML)
KW  - Gaussian noise (electronic)
KW  - Predictive maintenance
KW  - Accelerometer
KW  - Data fusion
KW  - ensemble learning
KW  - Ensemble learning
KW  - Maintenance
KW  - microphone
KW  - Noise robust
KW  - noise robustness
KW  - Noise robustness
KW  - noisy training
KW  - Noisy training
KW  - Ultrasonic applications
KW  - ultrasound
KW  - white Gaussian noise
KW  - White Gaussian Noise
ER  - 

TY  - JOUR
TI  - Robust Federated Learning With Noisy Labeled Data Through Loss Function Correction
AU  - Chen, L.
AU  - Ang, F.
AU  - Chen, Y.
AU  - Wang, W.
T2  - IEEE Transactions on Network Science and Engineering
AB  - Federated learning (FL) is a communication-efficient machine learning paradigm to leverage distributed data at the network edge. Nevertheless, FL usually fails to train a high-quality model from the networks, where the edge nodes collect noisy labeled data. To tackle this challenge, this paper focuses on developing an innovative robust FL. We consider two kinds of networks with different data distribution. Firstly, we design a reweighted FL under a full-data network, where all edge nodes are equipped with both numerous noisy labeled dataset and small clean dataset. The key idea is that edge devices learn to assign the local weights of loss functions in noisy labeled dataset, and cooperate with central server to update global weights. Secondly, we consider a part-data network where some edge nodes exclude clean dataset, and can not compute the weights locally. The broadcasting of the global weights is added to help those edge nodes without clean dataset to reweight their noisy loss functions. Both designs have a convergence rate of O(1/T2). Simulation results illustrate that the both proposed training processes improve the prediction accuracy due to the proper weights assignments of noisy loss function. © 2013 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNSE.2022.3227287
VL  - 10
IS  - 3
SP  - 1501
EP  - 1511
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144783924&doi=10.1109%2fTNSE.2022.3227287&partnerID=40&md5=3a73f67de23a187c9afb49c45465f69b
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - federated learning
KW  - Machine-learning
KW  - Federated learning
KW  - robust design
KW  - Robust designs
KW  - label noise
KW  - Convergence
KW  - Convex optimization
KW  - Distributed networks
KW  - Label noise
KW  - Loss measurement
KW  - Noise measurements
KW  - non-convex optimization
KW  - Nonconvex optimization
KW  - parallel and distributed algorithms
KW  - Parallel and distributed algorithms
KW  - Spurious signal noise
ER  - 

TY  - JOUR
TI  - Robust multi-objective load dispatch in microgrid involving unstable renewable generation
AU  - Wang, R.
AU  - Xu, T.
AU  - Xu, H.
AU  - Gao, G.
AU  - Zhang, Y.
AU  - Zhu, K.
T2  - International Journal of Electrical Power and Energy Systems
AB  - The microgrid improve productivity and performance by rational load balancing and intelligent energy management schemes. This paper addresses a robust multi-objective load dispatch problem to tactically schedule various resources for an microgrid equipped with controllable distributed generators and unstable renewable energy (RE) sources. Power generation cost and emissions are considered as the key indicators for the load dispatching. In such smart grid system, the indeterminate renewable energy generation (REG) imposes intractable dispatching challenges. To properly cope with the uncertain RE, a model with uncertain distribution is developed to depict the fluctuation in a flexible yet detailed manner. Chance constraint (CC) approximations and robust optimization (RO) methods are involved to change the prime issue to a more solvable form. We further explore a framework based on deep reinforcement learning (DRL) to deal with multi-objective optimization which is generally computational intractable. Real-world data-based simulation has verified the superiority of the proposed uncertain model in handling unstable REG. Furthermore, the DRL based framework is time-efficient in solving the multi-objective load dispatch problem and surpasses the state-of-art methods by having 56.74% and 15.62% better efficiencies on average. © 2023 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.ijepes.2023.108991
VL  - 148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147089277&doi=10.1016%2fj.ijepes.2023.108991&partnerID=40&md5=8cc315c0b50bf271f0e23a58253de086
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Smart power grids
KW  - Robust optimization
KW  - Microgrid
KW  - Renewable energy resources
KW  - Multiobjective optimization
KW  - Electric power distribution
KW  - Electric power plant loads
KW  - Microgrids
KW  - Deep reinforcement learning (DRL)
KW  - Distribution uncertainty model
KW  - Electric load dispatching
KW  - Load dispatch
KW  - Renewable energies
KW  - Renewable energy
KW  - Renewable energy (RE)
KW  - Robust optimization (RO)
KW  - Uncertainty models
ER  - 

TY  - CONF
TI  - Enhancing Traffic Safety by Developing Vehicle Safety Envelope with Real Time Data Interface and Machine Learning Based Sensor Fusion Platform
AU  - Soloiu, V.
AU  - Obando Lng, D.
AU  - Mehrzed, S.
AU  - Pierce, K.
AU  - Willis, J.
AU  - Rowell, A.
T2  - SAE Technical Papers
AB  - The effectiveness of obstacle avoidance response safety systems such as ADAS, has demonstrated the necessity to optimally integrate and enhance these systems in vehicles in the interest of increasing the road safety of vehicle occupants and pedestrians. Vehicle-pedestrian clearance can be achieved with a model safety envelope based on distance sensors designed to keep a threshold between the ego-vehicle and pedestrians or objects in the traffic environment. More accurate, reliable and robust distance measurements are possible by the implementation of multi-sensor fusion. This work presents the structure of a machine learning based sensor fusion algorithm that can accurately detect a vehicle safety envelope with the use of a HC-SR04 ultrasonic sensor, SF11/C microLiDAR sensor, and a 2D RPLiDAR A3M1 sensor. Sensors for the vehicle safety envelope and ADAS were calibrated for optimal performance and integration with versatile vehicle-sensor platforms. Results for this work include a robust distance sensor fusion algorithm that can correctly sense obstacles from 0.05m to 0.5m on average by 94.33% when trained as individual networks per distance. When the algorithm is trained as a common network of all distances, it can correctly sense obstacles at the same distances on average by 96.95%. Results were measured based on the precision and accuracy of the sensors' outputs by the time of activation of the safety response once a potential collision was detected. From the results of this work the platform has the potential to identify collision scenarios, warning the driver, and taking corrective action based on the coordinate at which the risk has been identified. © 2023 SAE International. All rights reserved.
DA  - 2023///
PY  - 2023
DO  - 10.4271/2023-01-0053
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160695118&doi=10.4271%2f2023-01-0053&partnerID=40&md5=1ec0592402b8e63da013f557047a84eb
DB  - Scopus
KW  - Machine learning
KW  - Vehicle safety
KW  - Machine-learning
KW  - Risk perception
KW  - Motor transportation
KW  - Pedestrian safety
KW  - Sensor fusion
KW  - Traffic safety
KW  - Obstacles avoidance
KW  - Robust distance
KW  - Ultrasonic applications
KW  - Data interfaces
KW  - Distance sensors
KW  - Real-time data
KW  - Sensor fusion algorithms
ER  - 

TY  - JOUR
TI  - Leveraging Adversarial Samples for Enhanced Classification of Malicious and Evasive PDF Files
AU  - Trad, F.
AU  - Hussein, A.
AU  - Chehab, A.
T2  - Applied Sciences (Switzerland)
AB  - The Portable Document Format (PDF) is considered one of the most popular formats due to its flexibility and portability across platforms. Although people have used machine learning techniques to detect malware in PDF files, the problem with these models is their weak resistance against evasion attacks, which constitutes a major security threat. The goal of this study is to introduce three machine learning-based systems that enhance malware detection in the presence of evasion attacks by substantially relying on evasive data to train malware and evasion detection models. To evaluate the robustness of the proposed systems, we used two testing datasets, a real dataset containing around 100,000 PDF samples and an evasive dataset containing 500,000 samples that we generated. We compared the results of the proposed systems to a baseline model that was not adversarially trained. When tested against the evasive dataset, the proposed systems provided an increase of around 80% in the f1-score compared to the baseline. This proves the value of the proposed approaches towards the ability to deal with evasive attacks. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/app13063472
VL  - 13
IS  - 6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152038546&doi=10.3390%2fapp13063472&partnerID=40&md5=d96a298bc6259c5c399ba4ee898edd55
DB  - Scopus
KW  - machine learning
KW  - model robustness
KW  - adversarial training
KW  - evasion attacks
KW  - evasion detection
KW  - evasive data generation
KW  - malicious documents
KW  - PDF malware detection
ER  - 

TY  - JOUR
TI  - Improving the robustness of machine reading comprehension via contrastive learning
AU  - Feng, J.
AU  - Sun, J.
AU  - Shao, D.
AU  - Cui, J.
T2  - Applied Intelligence
AB  - Pre-trained language models achieve high performance on machine reading comprehension task, but these models lack robustness and are vulnerable to adversarial samples. Most of the current methods for improving model robustness are based on data enrichment. However, these methods do not solve the problem of poor context representation of the machine reading comprehension model. We find that context representation plays a key role in the robustness of the machine reading comprehension model, dense context representation space results in poor model robustness. To deal with this, we propose a Multi-task machine Reading Comprehension learning framework via Contrastive Learning. Its main idea is to improve the context representation space encoded by the machine reading comprehension models through contrastive learning. This special contrastive learning we proposed called Contrastive Learning in Context Representation Space(CLCRS). CLCRS samples sentences containing context information from the context as positive and negative samples, expanding the distance between the answer sentence and other sentences in the context. Therefore, the context representation space of the machine reading comprehension model has been expanded. The model can better distinguish between sentence containing correct answers and misleading sentence. Thus, the robustness of the model is improved. Experiment results on adversarial datasets show that our method exceeds the comparison models and achieves state-of-the-art performance. © 2022, The Author(s).
DA  - 2023///
PY  - 2023
DO  - 10.1007/s10489-022-03947-w
VL  - 53
IS  - 8
SP  - 9103
EP  - 9114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135471276&doi=10.1007%2fs10489-022-03947-w&partnerID=40&md5=fc7c9cb364f44ccc930aa15c493e6cf4
DB  - Scopus
KW  - Learning systems
KW  - Robust
KW  - Multi tasks
KW  - Contrastive learning
KW  - Computational linguistics
KW  - Context representation
KW  - Language model
KW  - Machine reading comprehension
KW  - Multi task
KW  - Pre-train language model
KW  - Reading comprehension
KW  - Representation
KW  - Representation space
ER  - 

TY  - CONF
TI  - A Multi-layered Collaborative Framework for Evidence-driven Data Requirements Engineering for Machine Learning-based Safety-critical Systems
AU  - Dey, S.
AU  - Lee, S.-W.
T2  - Proceedings of the ACM Symposium on Applied Computing
AB  - In the days of AI, data-centric machine learning (ML) models are increasingly used in various complex systems. While many researchers are focusing on specifying ML-specific performance requirements, not enough guideline is provided to engineer the data requirements systematically involving diverse stakeholders. Lack of written agreement about the training data, collaboration bottlenecks, lack of data validation framework, etc. are posing new challenges to ensuring training data fitness for safety-critical ML components. To reduce these gaps, we propose a multi-layered framework that helps to perceive and elicit data requirements. We provide a template for verifiable data requirements specifications. Moreover, we show how such requirements can facilitate an evidence-driven assessment of the training data quality based on the experts' judgments about the satisfaction of the requirements. We use Dempster Shafer's theory to combine experts' subjective opinions in the process. A preliminary case study on the CityPersons dataset for the pedestrian detection feature of autonomous cars shows the usefulness of the proposed framework for data requirements understanding and the confidence assessment of the dataset.  © 2023 ACM.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3555776.3577647
SP  - 1404
EP  - 1413
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162869276&doi=10.1145%2f3555776.3577647&partnerID=40&md5=f371778982c09e76b7bdfe7aeb0c546f
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Training data
KW  - reliability
KW  - uncertainty
KW  - Machine-learning
KW  - safety
KW  - Machine learning models
KW  - Uncertainty
KW  - Safety engineering
KW  - Safety critical systems
KW  - Data centric
KW  - Collaborative framework
KW  - data requirements
KW  - Data requirements
KW  - Multi-layered
KW  - Requirement engineering
KW  - Requirements engineering
ER  - 

TY  - JOUR
TI  - A flexible framework to coordinate debris clearance and relief distribution operations: A robust machine learning approach
AU  - Vahdani, B.
T2  - Expert Systems with Applications
AB  - This study aims to offer an integrated, flexible action plan to bridge two vital operations in the response phase of disaster management, namely debris clearance and relief items distribution. On this subject, a broad range of associated decisions, including location-allocation, inventory, scheduling, and routing, are reflected in a multi-period environment. Also, so as to provide a pliable decision chain, two substantial kinds of flexibility are considered, including network design and due dates. So, a new bi-objective mathematical model is proposed, where the first objective minimizes the total cost, and the second one minimizes the total operation time. Since travel time information accuracy has an undeniable influence on system performance, a new two-phase data-driven methodology, including a hybrid machine learning model and the distributionally robust optimization with φ- divergence, is offered to estimate reliable travel time and tackle its uncertainty. Additionally, the application and validation of the recommended model and solution methodology are investigated in a real case study. What is more, in order to explain the superiority of the proposed solution approach concerning robustness solution, various simulation experiments are executed. Ultimately, several numerical experiments are implemented, and captured results manifest that the proposed framework can enhance the system's performance. The obtained results reveal that considering the flexibility in network design and delivery date reduces the total costs and operation time by 7 and 6 percent. © 2023 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.eswa.2023.120512
VL  - 229
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162212246&doi=10.1016%2fj.eswa.2023.120512&partnerID=40&md5=e1d80fac3f5263f72e4b786d95389938
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Uncertainty analysis
KW  - Optimization
KW  - Robust optimization
KW  - Distributionally robust optimization
KW  - Disasters
KW  - Debris
KW  - Debris clearance
KW  - Disaster prevention
KW  - Flexibility
KW  - Meta-heuristic
KW  - Metaheuristic
KW  - Network design
KW  - Operation time
KW  - Relief distribution
KW  - Systems performance
KW  - Travel time
ER  - 

TY  - JOUR
TI  - Data security of machine learning applied in low-carbon smart grid: A formal model for the physics-constrained robustness
AU  - Zhang, Z.
AU  - Yang, Z.
AU  - Yau, D.K.Y.
AU  - Tian, Y.
AU  - Ma, J.
T2  - Applied Energy
AB  - Towards the low-carbon goal, a smart grid features remote connection, data sharing, and cyber–physical integration to increase the flexibility of energy supplies, to reduce electricity wastage, and to enhance safety under intermittent renewables. In this context, machine learning (ML) is increasingly employed in smart grids to solve tasks that require deep data analytics. However, it is well recognized that ML models are vulnerable to adversarial examples that might be contained in open shared data, which creates opportunities for potential attackers to launch cyberattacks. In particular, system operating states acting as critical inputs to ML-based smart grid applications (MLsgAPPs) can be manipulated by malicious actors to mislead the system operator into making wrong decisions that in turn may cause major blackouts and other damaging cascading events. It is thus imperative to advance vulnerability assessment for MLsgAPPs. In this paper, we propose a physics-constrained robustness evaluation framework for MLsgAPPs, which is a first attempt of using tree ensemble (TE) models. Unlike adversarial attacks against prior studied image-classification tasks, adversarial examples against TE-based smart grid applications (TEsgAPPs) must not only cheat human intuition but also follow laws of physics and bypass error-checking mechanisms for power systems. Thus, formulation of the traditional robustness evaluation problem must be reconsidered to account for domain-specific misclassification, physical limit, power balance, and error-bypass constraints, in order to obtain tight lower bounds of the magnitudes of tolerated adversarial perturbations. We adopt a formal modeling approach to construct a discrete tree structure and to specify the model evasion conditions. We propose an efficient robustness evaluation method by transforming variables considering ℓ1 and ℓ∞ norms, followed by a generalization that expands the variable space to admit other types of norms. Using TE-based power system security assessment as an example, comprehensive simulations are conducted for evaluating the physics-constrained robustness under different TE models and model parameters. © 2023 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.apenergy.2023.121405
VL  - 347
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163166626&doi=10.1016%2fj.apenergy.2023.121405&partnerID=40&md5=baacb7df66e644166eab43d7176734d9
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - image classification
KW  - Machine-learning
KW  - Carbon
KW  - Smart grid
KW  - Smart power grids
KW  - Formal modeling
KW  - Data Analytics
KW  - Trees (mathematics)
KW  - Cybersecurity
KW  - Robustness evaluation
KW  - Adversarial example
KW  - error analysis
KW  - Low carbon
KW  - Low-carbon smart grid
KW  - Physic-constrained robustness
KW  - Physics-constrained robustness
KW  - smart grid
KW  - Smart grid applications
KW  - Tree ensembles
KW  - vulnerability
ER  - 

TY  - JOUR
TI  - Artificial Intelligence and Deep Learning Based Agri & Food Quality and Safety Detection System
AU  - Divyashree, D.
AU  - Abbaa, S.H.
AU  - Chauhan, Y.
AU  - Paliwal, M.K.
AU  - Pant, K.
AU  - Vidhate, D.A.
AU  - Shrivastava, A.
T2  - International Journal of Intelligent Systems and Applications in Engineering
AB  - Deep learning, also known as DL, is a technique that has been shown to be effective for evaluating enormous datasets, such as those that may be found in the fields of image processing, speech recognition, and popularity. Recent advancements have been made in this direction by the fields of food science and food engineering. No one has ever mentioned to us a similar study that made use of food in any capacity as a variable in the research. This article presents a succinct introduction to deep learning (DL), in addition to detailed descriptions of the building of a typical convolutional neural network (CNN), as well as the ways by which artificial intelligence and the internet of things convey information. We conducted a comprehensive literature review on the subject of deep learning as it relates to the identification of issues with computers that are related to food. Some of the topics that were covered in this review include, but are not limited to the following: food recognition; the calculation of calories; fruit; potato; meat; the safety of aquatic goods; the safety of the food supply chain; and food infection. Each inquiry assessed its own distinct set of problems, datasets, preparation techniques, network topologies, and system architectures to discover how well they functioned and how they stacked up against other possible solutions. This paper is an investigation into the use of big data to the issue of hunger, during which we discovered some fascinating trends. According to the findings of our research, DL is superior to more traditional methods of system analysis, such as guided attribute extractors and classical algorithms. They have the potential to become the subsequent generation of food safety regulators. © 2024, Ismail Saritas. All rights reserved.
DA  - 2024///
PY  - 2024
VL  - 12
IS  - 1s
SP  - 61
EP  - 70
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173785466&partnerID=40&md5=b50d75a99907c51dad32ca25e8dba9a8
DB  - Scopus
KW  - Deep Learning
KW  - Artificial Intelligence (AI)
KW  - convolutional neural network (CNN)
KW  - Food Safety
KW  - IOT and Big data
ER  - 

TY  - CONF
TI  - Robust Filtering of Nonlinear Stochastic Processes in Machine Learning Systems
AU  - Sokolov, S.S.
AU  - Kurinenko, M.V.
AU  - Sokolova, O.I.
T2  - Lecture Notes in Networks and Systems
AB  - One of the problems of machine learning is the criticality of algorithms for assessing the characteristics of input stochastic data to a priori uncertainty of their probability distributions. Machine learning theory is the most important area of artificial intelligence. One of the urgent problems of machine learning is to increase the accuracy and stability of the estimation of parameters of nonlinear stochastic processes handled in machine learning systems under conditions of uncertainty of their statistical characteristics. In this regard, the article considers an approach to solving the problem of robust (stable) stochastic filtration of a nonlinear stochastic process observed under conditions of interference with unknown probability distributions and generated by a stochastic nonlinear differential system. This system is perturbed by multiplicative noise with an unknown probability distribution from the class of distributions with bounded mean squares. The synthesis of the robust estimation of the considered nonlinear stochastic process was carried out on the basis of optimization of the developed criterion. This criterion is described by the sum of the integral quadratic form of the estimate and the nonlinear function of the measurement mismatch determined by the probabilistic distribution class of the measurement interference. The proposed algorithm uses a priori knowledge of the dynamic model of the stochastic process in contrast to the traditional approach to robust estimation. This makes it possible to increase the accuracy of the estimation without requiring knowledge of the type of distributions of object noise (generating differential system) and observer interference, unlike existing nonlinear filtering algorithms. At the same time, its implementation leads to significantly lower computational costs compared to both the traditional robust approach and modern non-linear filtering methods. The above advantages of the developed algorithm provide the possibility of its effective practical use when evaluating stochastic nonlinear processes handled in artificial intelligence systems in conditions of uncertainty, focused on application in a variety of technical systems - infocommunication, satellite navigation, avionics systems, etc. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-43792-2_21
VL  - 777 LNNS
SP  - 217
EP  - 224
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174446239&doi=10.1007%2f978-3-031-43792-2_21&partnerID=40&md5=9711dff24f9e94a5565ff992c00b1ca1
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Machine-learning
KW  - Condition
KW  - Robust estimation
KW  - Uncertainty analysis
KW  - Computation theory
KW  - Stochastic models
KW  - Stochastic systems
KW  - Probability distributions
KW  - robust estimation
KW  - Random processes
KW  - Class of probability distribution
KW  - class of probability distributions
KW  - Differential equations
KW  - measurement mismatch
KW  - Measurement mismatch
KW  - Nonlinear analysis
KW  - Nonlinear filtering
KW  - Nonlinear process
KW  - Nonlinear stochastic process
KW  - Number theory
KW  - Probability: distributions
KW  - stochastic nonlinear process
KW  - Stochastic nonlinear process
KW  - Stochastics
ER  - 

TY  - JOUR
TI  - Machine Learning-Based Prediction Models for Control Traffic in SDN Systems
AU  - Yoo, Y.
AU  - Yang, G.
AU  - Shin, C.
AU  - Lee, J.
AU  - Yoo, C.
T2  - IEEE Transactions on Services Computing
AB  - This paper presents <italic>Elixir</italic>, an automated prediction model formulation framework for control traffic using machine learning. Control traffic is vital in software-defined networking (SDN) systems because it determines the reliability and scalability of the entire system. Various studies have sought to design control traffic prediction models for the proper provisioning and planning of SDN systems. However, previously proposed models are based on descriptive modeling, well-suited for only specific SDN system instances. Furthermore, these models exhibit poor accuracy (errors of up to 85&#x0025;) because of the heterogeneity of SDN systems. Because descriptive modeling requires a significant amount of human contemplation, it is impossible to formulate adequate prediction models for countless SDN system instances. <italic>Elixir</italic> addresses this problem by applying machine learning. <italic>Elixir</italic> starts the model formulation through self-generated datasets. Then, <italic>Elixir</italic> searches prediction models to fit the accuracy for respective SDN systems. Also, <italic>Elixir</italic> picks robust models that exhibit reasonable accuracy even in a network topology that differs from the topology used for model training. We evaluate the <italic>Elixir</italic> framework on nine heterogeneous SDN systems. As a key outcome, <italic>Elixir</italic> significantly reduces prediction errors, achieving up to 10.6&#x00D7; improvement compared to the previous model for control traffic throughput of OpenDayLight controller. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TSC.2023.3324007
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174813284&doi=10.1109%2fTSC.2023.3324007&partnerID=40&md5=b7ec701697e20bd14d345006526bc829
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Prediction algorithms
KW  - Predictive models
KW  - Training
KW  - Machine-learning
KW  - Forecasting
KW  - Robustness (control systems)
KW  - Throughput
KW  - Software reliability
KW  - Control systems
KW  - Prediction modelling
KW  - Network topology
KW  - Topology
KW  - Control traffic
KW  - Model formulation
KW  - prediction model formulation
KW  - Prediction model formulation
KW  - prediction robustness
KW  - Prediction robustness
KW  - Software defined networking
KW  - software-defined networking
KW  - Software-defined networkings
ER  - 

TY  - JOUR
TI  - Auto-Scaling Containerized Applications in Geo-Distributed Clouds
AU  - Shi, T.
AU  - Ma, H.
AU  - Chen, G.
AU  - Hartmann, S.
T2  - IEEE Transactions on Services Computing
AB  - As a lightweight and flexible infrastructure solution, containers have increasingly been used for application deployment on a global scale. By rapidly scaling containers at different locations, the deployed applications can handle dynamic workloads from the worldwide user community. Existing studies usually focus on the (dynamic) container scaling within a single data center or the (static) container deployment across geo-distributed data centers. This article studies an increasingly important container scaling problem for application deployment in geo-distributed clouds. Reinforcement learning (RL) has been widely used in container scaling due to its high adaptability and robustness. To handle high-dimensional state spaces in geo-distributed clouds, we propose a deep RL algorithm, named <italic>DeepScale</italic>, to auto-scale containerized applications. <italic>DeepScale</italic> innovatively utilizes multi-step predicted future workloads to train a holistic scaling policy. It features several newly designed algorithmic components, including a domain-tailored state constructor and a heuristic-based action executor. These new algorithmic components are essential to meet the requirements of low deployment costs and achieve desirable application performance. We conduct extensive simulation studies using real-world datasets. The results show that <italic>DeepScale</italic> can significantly outperform an industry-leading scaling strategy and two state-of-the-art baselines in terms of both cost-effectiveness and constraint satisfaction. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TSC.2023.3317262
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173053796&doi=10.1109%2fTSC.2023.3317262&partnerID=40&md5=3a3b2b5cbfd438672ef2c09058a9c07d
DB  - Scopus
KW  - Reinforcement learning
KW  - Prediction algorithms
KW  - Time series analysis
KW  - Time-series analysis
KW  - Reinforcement learnings
KW  - Costs
KW  - Cost effectiveness
KW  - Safe reinforcement learning
KW  - Heuristic algorithms
KW  - Scalings
KW  - safe reinforcement learning
KW  - Datacenter
KW  - Heuristics algorithm
KW  - Cloud computing
KW  - Cloud-computing
KW  - Auto-scaling
KW  - containerized application
KW  - Containerized application
KW  - Containers
KW  - Data centers
KW  - Distributed cloud
KW  - Distributed clouds
KW  - Geo-distributed cloud
KW  - geo-distributed clouds
KW  - Time factors
KW  - time series analysis
KW  - workload management
KW  - Workload management
ER  - 

TY  - CONF
TI  - Towards Deep Anomaly Detection with Structured Knowledge Representations
AU  - Kirchheim, K.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Machine learning models tend to only make reliable predictions for inputs that are similar to the training data. Consequentially, anomaly detection, which can be used to detect unusual inputs, is critical for ensuring the safety of machine learning agents operating in open environments. In this work, we identify and discuss several limitations of current anomaly detection methods, such as their weak performance on tasks that require abstract reasoning, the inability to integrate background knowledge, and the opaqueness that undermines their trustworthiness in critical applications. Furthermore, we propose an architecture for anomaly detection models that aims to integrate structured knowledge representations to address these limitations. Our hypothesis is that this approach can improve performance and robustness, reduce the required resources (such as data and computation), and provide a higher degree of transparency. As a result, our work contributes to the increased safety of machine learning systems. Our code is publicly available. (https://github.com/kkirchheim/sumnist )
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-40953-0_32
VL  - 14182 LNCS
SP  - 382
EP  - 389
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172421520&doi=10.1007%2f978-3-031-40953-0_32&partnerID=40&md5=e50642e6d72d42491a1f6b39cdb01a4a
DB  - Scopus
KW  - Intelligent agents
KW  - Deep learning
KW  - Knowledge representation
KW  - Training data
KW  - Deep Learning
KW  - Learning systems
KW  - Anomaly detection
KW  - Machine-learning
KW  - Machine learning models
KW  - Anomaly Detection
KW  - Hybrid model
KW  - Hybrid Models
KW  - Knowledge-representation
KW  - Machine learning safety
KW  - Machine Learning Safety
KW  - Out-of-distribution detection
KW  - Out-of-Distribution Detection
KW  - Structured knowledge
ER  - 

TY  - JOUR
TI  - Robust Data Sampling in Machine Learning: A Game-Theoretic Framework for Training and Validation Data Selection
AU  - Mo, Z.
AU  - Di, X.
AU  - Shi, R.
T2  - Games
AB  - How to sample training/validation data is an important question for machine learning models, especially when the dataset is heterogeneous and skewed. In this paper, we propose a data sampling method that robustly selects training/validation data. We formulate the training/validation data sampling process as a two-player game: a trainer aims to sample training data so as to minimize the test error, while a validator adversarially samples validation data that can increase the test error. Robust sampling is achieved at the game equilibrium. To accelerate the searching process, we adopt reinforcement learning aided Monte Carlo trees search (MCTS). We apply our method to a car-following modeling problem, a complicated scenario with heterogeneous and random human driving behavior. Real-world data, the Next Generation SIMulation (NGSIM), is used to validate this method, and experiment results demonstrate the sampling robustness and thereby the model out-of-sample performance. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/g14010013
VL  - 14
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148599130&doi=10.3390%2fg14010013&partnerID=40&md5=1befbf74e2c83028ea4123204f7abeea
DB  - Scopus
KW  - reinforcement learning
KW  - car-following modeling
KW  - Monte Carlo tree search
KW  - two-player game
ER  - 

TY  - CONF
TI  - A Concept for Dynamic and Robust Machine Learning with Context Modeling for Heterogeneous Manufacturing Data
AU  - Kamm, S.
AU  - Sahlab, N.
AU  - Jazdi, N.
AU  - Weyrich, M.
T2  - Procedia CIRP
AB  - With the increasing amount of available and connected data sources, industrial automation applications such as condition monitoring of a production machine can be improved by considering various data. To gain insights from this data and make it useable, heterogeneous data has to be analyzed intensively. Limited machine learning approaches exist in industrial automation and manufacturing for analyzing data acquired from multiple sources. In this paper, first, a suitable concept for handling heterogeneous data from integration to analysis is presented as well as a multi-layer architecture for the concept's realization. The architecture encapsulates functionalities into the different layers and allows easy extendability and modifiability. Afterwards, a context modeling approach for managing heterogeneous data and existing approaches and algorithms for analyzing this data robustly and dynamically analyzing it are presented. © 2023 Elsevier B.V.. All rights reserved.
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.procir.2023.06.061
VL  - 118
SP  - 354
EP  - 359
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173582100&doi=10.1016%2fj.procir.2023.06.061&partnerID=40&md5=93caaf62c655e13f5089c9dd4ee26c65
DB  - Scopus
KW  - Machine learning
KW  - Machine Learning
KW  - Data handling
KW  - Context models
KW  - Machine-learning
KW  - Machine learning approaches
KW  - Memory architecture
KW  - Condition monitoring
KW  - Context Modeling
KW  - Data-source
KW  - Dynamic and robust machine learning
KW  - Dynamic and Robust Machine Learning
KW  - Gain insight
KW  - Heterogeneous data
KW  - Heterogeneous Data
KW  - Industrial automation applications
KW  - Production-machines
ER  - 

TY  - JOUR
TI  - Toward Unsupervised Test Scenario Extraction for Automated Driving Systems from Urban Naturalistic Road Traffic Data
AU  - Weber, N.
AU  - Thiem, C.
AU  - Konigorski, U.
T2  - SAE International Journal of Connected and Automated Vehicles
AB  - Scenario-based testing is a promising approach to solving the challenge of proving the safe behavior of vehicles equipped with automated driving systems (ADS). Since an infinite number of concrete scenarios can theoretically occur in real-world road traffic, the extraction of scenarios relevant in terms of the safety-related behavior of these systems is a key aspect for their successful verification and validation. Therefore, a method for extracting multimodal urban traffic scenarios from naturalistic road traffic data in an unsupervised manner, minimizing the amount of (potentially biased) prior expert knowledge, is proposed. Rather than an (elaborate) rule-based assignment by extracting concrete scenarios into predefined functional scenarios, the presented method deploys an unsupervised machine learning pipeline. The approach allows for exploring the unknown nature of the data and their interpretation as test scenarios that experts could not have anticipated. The method is evaluated for naturalistic road traffic data at urban intersections from the inD and the Silicon Valley Intersections datasets. For this purpose, it is analyzed with which clustering approach (K-means, hierarchical clustering, and DBSCAN) the scenario extraction method performs best (referring to an elaborate rule-based implementation). Subsequently, using hierarchical clustering the results show both a jump in the overall accuracy of around 20% when moving from 4 to 5 clusters and a saturation effect starting at 41 clusters with an overall accuracy of 84%. These observations can be a valuable contribution in the context of the trade-off between the number of functional scenarios (i.e., clustering accuracy) and testing effort. The possible reasons for the observed accuracy variations of different clusters, each with a fixed total number of given clusters, are discussed. The findings encourage the use of this type of data and unsupervised machine learning approaches as valuable pillars for the systematic construction of a relevant scenario database with sufficient coverage for testing ADS.  © 2023 SAE International Journal of Connected and Automated Vehicles
DA  - 2023///
PY  - 2023
DO  - 10.4271/12-06-03-0017
VL  - 6
IS  - 3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149259016&doi=10.4271%2f12-06-03-0017&partnerID=40&md5=f44a289361b77e44fae7632d04568820
DB  - Scopus
KW  - Automation
KW  - Road traffic
KW  - Data mining
KW  - Vehicles
KW  - Collision avoidance
KW  - Automated vehicles
KW  - Automated driving systems
KW  - Collisions avoidance
KW  - Economic and social effects
KW  - Roads and streets
KW  - Extraction
KW  - Unsupervised machine learning
KW  - Traffic data
KW  - Cluster analysis
KW  - K-means clustering
KW  - Relevant scenario database
KW  - Safety validation
KW  - Safety validations
KW  - Test scenario
KW  - Test scenario extraction
ER  - 

TY  - JOUR
TI  - Explaining and predicting human behavior and social dynamics in simulated virtual worlds: reproducibility, generalizability, and robustness of causal discovery methods
AU  - Volkova, S.
AU  - Arendt, D.
AU  - Saldanha, E.
AU  - Glenski, M.
AU  - Ayton, E.
AU  - Cottam, J.
AU  - Aksoy, S.
AU  - Jefferson, B.
AU  - Shrivaram, K.
T2  - Computational and Mathematical Organization Theory
AB  - Ground Truth program was designed to evaluate social science modeling approaches using simulation test beds with ground truth intentionally and systematically embedded to understand and model complex Human Domain systems and their dynamics Lazer et al. (Science 369:1060–1062, 2020). Our multidisciplinary team of data scientists, statisticians, experts in Artificial Intelligence (AI) and visual analytics had a unique role on the program to investigate accuracy, reproducibility, generalizability, and robustness of the state-of-the-art (SOTA) causal structure learning approaches applied to fully observed and sampled simulated data across virtual worlds. In addition, we analyzed the feasibility of using machine learning models to predict future social behavior with and without causal knowledge explicitly embedded. In this paper, we first present our causal modeling approach to discover the causal structure of four virtual worlds produced by the simulation teams—Urban Life, Financial Governance, Disaster and Geopolitical Conflict. Our approach adapts the state-of-the-art causal discovery (including ensemble models), machine learning, data analytics, and visualization techniques to allow a human-machine team to reverse-engineer the true causal relations from sampled and fully observed data. We next present our reproducibility analysis of two research methods team’s performance using a range of causal discovery models applied to both sampled and fully observed data, and analyze their effectiveness and limitations. We further investigate the generalizability and robustness to sampling of the SOTA causal discovery approaches on additional simulated datasets with known ground truth. Our results reveal the limitations of existing causal modeling approaches when applied to large-scale, noisy, high-dimensional data with unobserved variables and unknown relationships between them. We show that the SOTA causal models explored in our experiments are not designed to take advantage from vasts amounts of data and have difficulty recovering ground truth when latent confounders are present; they do not generalize well across simulation scenarios and are not robust to sampling; they are vulnerable to data and modeling assumptions, and therefore, the results are hard to reproduce. Finally, when we outline lessons learned and provide recommendations to improve models for causal discovery and prediction of human social behavior from observational data, we highlight the importance of learning data to knowledge representations or transformations to improve causal discovery and describe the benefit of causal feature selection for predictive and prescriptive modeling. © 2021, The Author(s).
DA  - 2023///
PY  - 2023
DO  - 10.1007/s10588-021-09351-y
VL  - 29
IS  - 1
SP  - 220
EP  - 241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119490227&doi=10.1007%2fs10588-021-09351-y&partnerID=40&md5=a2aff23960320c4dfa60a4711694a0d5
DB  - Scopus
KW  - Machine learning
KW  - Predictive models
KW  - Knowledge representation
KW  - Ground truth
KW  - Visualization
KW  - Virtual reality
KW  - Learning systems
KW  - Predictive modeling
KW  - Behavioral research
KW  - Machine-learning
KW  - Predictive analytics
KW  - State of the art
KW  - Data visualization
KW  - Robustness
KW  - Clustering algorithms
KW  - Reproducibilities
KW  - Data Analytics
KW  - Generalizability
KW  - Software testing
KW  - Causal discovery
KW  - Causal structure learning
KW  - Data science
KW  - Ensemble models
KW  - Reproducibility
ER  - 

TY  - JOUR
TI  - Development of a New Robust Stable Walking Algorithm for a Humanoid Robot Using Deep Reinforcement Learning with Multi-Sensor Data Fusion
AU  - Kaymak, Ç.
AU  - Uçar, A.
AU  - Güzeliş, C.
T2  - Electronics (Switzerland)
AB  - The difficult task of creating reliable mobility for humanoid robots has been studied for decades. Even though several different walking strategies have been put forth and walking performance has substantially increased, stability still needs to catch up to expectations. Applications for Reinforcement Learning (RL) techniques are constrained by low convergence and ineffective training. This paper develops a new robust and efficient framework based on the Robotis-OP2 humanoid robot combined with a typical trajectory-generating controller and Deep Reinforcement Learning (DRL) to overcome these limitations. This framework consists of optimizing the walking trajectory parameters and posture balancing system. Multi-sensors of the robot are used for parameter optimization. Walking parameters are optimized using the Dueling Double Deep Q Network (D3QN), one of the DRL algorithms, in the Webots simulator. The hip strategy is adopted for the posture balancing system. Experimental studies are carried out in both simulation and real environments with the proposed framework and Robotis-OP2’s walking algorithm. Experimental results show that the robot performs more stable walking with the proposed framework than Robotis-OP2’s walking algorithm. It is thought that the proposed framework will be beneficial for researchers studying in the field of humanoid robot locomotion. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/electronics12030568
VL  - 12
IS  - 3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147877640&doi=10.3390%2felectronics12030568&partnerID=40&md5=a6cc0a0ef81d32d3a2e1f686027e9ee1
DB  - Scopus
KW  - Deep Reinforcement Learning
KW  - humanoid robot
KW  - multi-sensor
KW  - parameter optimization
KW  - stable walking
ER  - 

TY  - JOUR
TI  - RAP Vol: Robust Adversary Populations With Volume Diversity Measure
AU  - Yang, J.
AU  - Zhang, J.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Deep reinforcement learning (DRL) algorithms have made remarkable achievements in various fields, but they are vulnerable to changes in environment dynamics. This vulnerability easily leads to poor generalization, low performance, and catastrophic failures in unseen environments, which severely hinders the application of DRL in real-world scenarios. The robustness via adversary populations (RAP) algorithm addresses this issue by introducing a population of adversaries that perturb the protagonist. However, the low data utilization efficiency and lack of population diversity greatly limit the generalization performance. This article proposes robust adversary populations with volume diversity measure (RAP Vol) to address these drawbacks. In the proposed joint adversarial training framework, we use the training data to update all adversaries rather than only a single adversary, leading to a higher data utilization efficiency and a fast convergence speed. In the proposed population diversity iterative improvement mechanism, the vectors representing adversaries span a high-dimensional region. The volume of this region is utilized to measure and enhance population diversity via its square. The ablation experiments have verified the effectiveness of our proposed method in improving the robustness against variations in environment dynamics. Also, the influence of various factors (such as adversary population size and diversity weight) on the robustness has been investigated. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3317145
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174805744&doi=10.1109%2fTNNLS.2023.3317145&partnerID=40&md5=096be36cfc8fd1ced6ff5c6f5ea16be6
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Task analysis
KW  - Vehicle dynamics
KW  - Sociology
KW  - Training
KW  - Job analysis
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Efficiency
KW  - Robustness
KW  - Statistics
KW  - Iterative methods
KW  - Heuristic algorithms
KW  - Vehicle's dynamics
KW  - Heuristics algorithm
KW  - Dynamics
KW  - deep reinforcement learning (DRL)
KW  - Data utilization
KW  - Data utilization efficiency
KW  - Diversity measure
KW  - Environment dynamics
KW  - population diversity
KW  - Population diversity
KW  - Population statistics
KW  - Utilization efficiency
KW  - Variation in environment dynamic
KW  - variations in environment dynamics
KW  - volume diversity measure
KW  - Volume diversity measure
ER  - 

TY  - CONF
TI  - Semi-supervised Entity Alignment via Noisy Student-Based Self Training
AU  - Liu, Y.
AU  - Dai, Y.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Knowledge graph is a structured data model that captures the relationships between entities in the real world. Entity alignment (EA) has drawn significant attention in recent years as a potential means of identifying corresponding entities across different knowledge graphs. Although knowledge graph embedding-based entity alignment methods have recently obtained significant progress, the shortage of training data remains a severe challenge. Conventional approaches have attempted to solve this issue through semi-supervised learning but still suffer from the negative impacts of entity alignment. To resolute the above issues, we propose a semi-supervised framework with Noisy Student-based self training Entity Alignment named NSEA. Our framework proposes a new noisy student self-training strategy for obtaining diverse entity alignment pairs, and we also design an adaptive alignment selector to infer reliable entity pairs. Through extensive experiments on benchmark datasets, we demonstrate that our method outperforms most existing models in terms of accuracy and efficiency, highlighting its usefulness for large-scale and diverse knowledge graphs with insufficient annotated data. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-40286-9_28
VL  - 14118 LNAI
SP  - 343
EP  - 354
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172997774&doi=10.1007%2f978-3-031-40286-9_28&partnerID=40&md5=863ef05504eb1c8ede3ce87e050c77c6
DB  - Scopus
KW  - Deep learning
KW  - Knowledge graphs
KW  - Semi-supervised learning
KW  - Computer aided instruction
KW  - Alignment
KW  - Large dataset
KW  - Semi-supervised
KW  - Entity alignment model
KW  - Knowledge graph
KW  - Noisy student training
KW  - Relationships between entities
KW  - Self-training
KW  - Structured data
KW  - Student training
KW  - Student-based
KW  - Students
ER  - 

TY  - JOUR
TI  - Uncertainty Quantification and Optimal Robust Design for Machining Operations
AU  - Wan, J.
AU  - Che, Y.
AU  - Wang, Z.
AU  - Cheng, C.
T2  - Journal of Computing and Information Science in Engineering
AB  - In this study, we carry out robust optimal design for the machining operations, one key process in wafer polishing in chip manufacturing, aiming to avoid the peculiar regenerative chatter and maximize the material removal rate (MRR) considering the inherent material and process uncertainty. More specifically, we characterize the cutting tool dynamics using a delay differential equation (DDE) and enlist the temporal finite element method (TFEM) to derive its approximate solution and stability index given process settings or design variables. To further quantify the inherent uncertainty, replications of TFEM under different realizations of random uncontrollable variables are performed, which however incurs extra computational burden. To eschew the deployment of such a crude Monte Carlo (MC) approach at each design setting, we integrate the stochastic TFEM with a stochastic surrogate model, stochastic kriging, in an active learning framework to sequentially approximate the stability boundary. The numerical result suggests that the nominal stability boundary attained from this method is on par with that from the crude MC, but only demands a fraction of the computational overhead. To further ensure the robustness of process stability, we adopt another surrogate, the Gaussian process, to predict the variance of the stability index at unexplored design points and identify the robust stability boundary per the conditional value at risk (CVaR) criterion. Therefrom, an optimal design in the robust stable region that maximizes the MRR can be identified.  Copyright © 2022 by ASME.
DA  - 2023///
PY  - 2023
DO  - 10.1115/1.4055039
VL  - 23
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144112631&doi=10.1115%2f1.4055039&partnerID=40&md5=63640f89e63eccb50644b5314f551874
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - uncertainty quantification
KW  - Machine-learning
KW  - Uncertainty analysis
KW  - Optimization
KW  - Stochastic models
KW  - Stochastic systems
KW  - Numerical methods
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Gaussian process
KW  - Gaussian Processes
KW  - Data driven
KW  - Stability
KW  - Product design
KW  - Differential equations
KW  - Stochastics
KW  - Computational foundation for engineering optimization
KW  - computational foundations for engineering optimization
KW  - conditional value-at-risk
KW  - Conditional Value-at-Risk
KW  - Cutting tools
KW  - data-driven engineering
KW  - Data-driven engineering
KW  - Engineering optimization
KW  - Kriging
KW  - Machining centers
KW  - Metal cutting
KW  - Milling (machining)
KW  - Optimal systems
KW  - robust optimal design
KW  - Robust Optimal Design
KW  - stochastic kriging
KW  - Stochastic kriging
KW  - Surface roughness
KW  - Uncertainty quantifications
KW  - Value engineering
ER  - 

TY  - JOUR
TI  - Clustering and Ensemble Based Approach For Securing Electricity Theft Detectors Against Evasion Attacks
AU  - Elgarhy, I.
AU  - Badr, M.M.
AU  - Mahmoud, M.
AU  - Fouda, M.M.
AU  - Alsabaan, M.
AU  - Kholidy, H.A.
T2  - IEEE Access
AB  - In smart power grids, electricity theft causes huge economic losses to electrical utility companies. Machine learning (ML), especially deep neural network (DNN) models hold state-of-the-art performance in detecting electricity theft cyberattacks. However, DNN models are vulnerable to adversarial attacks, i.e., evasion attacks. In this work, we, first, study the vulnerability of the DNN-based electricity theft detectors against evasion attacks and the influence of the model&#x2019;s regularization (generalization) and transferability on robustness. Then, we cluster the power consumers and train a detector for each cluster, and compare the performance and robustness of this detector to a global detector that is trained on all the consumers&#x2019; data. The results indicate that the cluster-based detector is not only more robust against evasion attacks but also enhances normal classification accuracy because its training data has more consumption pattern similarity compared to the training data of the global detector which requires higher level of regularization. Then, we develop a cluster-based parallel-ensemble electricity theft detector to achieve high robustness against evasion attacks and high detection accuracy. The proposed detector has two levels of defense, including clustering and ensemble, where clustering decreases regularization and improves robustness, and the ensemble of diverse decision models improves robustness against transferability. We evaluate the detector on different threat models, including Blackbox and Graybox with different knowledge about defense strategy, model architecture, and training dataset. The evaluation results indicate that unlike the existing solutions that sacrifice the normal accuracy of the model to improve the robustness against evasion attacks, the proposed detector outperforms the benchmark defenses in terms of robustness and normal classification accuracy. Author
DA  - 2023///
PY  - 2023
DO  - 10.1109/ACCESS.2023.3318111
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173025042&doi=10.1109%2fACCESS.2023.3318111&partnerID=40&md5=27a06b5fe13c651fd75596c2d8a8ecb1
DB  - Scopus
KW  - Security
KW  - Machine learning
KW  - Deep neural networks
KW  - Data models
KW  - Support vector machines
KW  - Machine-learning
KW  - Classification (of information)
KW  - Network security
KW  - Smart grid
KW  - Smart power grids
KW  - Crime
KW  - Ensemble
KW  - Robustness
KW  - Applied machine learning
KW  - Detectors
KW  - Cybersecurity
KW  - Support vectors machine
KW  - evasion attacks
KW  - smart grid
KW  - Losses
KW  - applied machine learning
KW  - Benchmark testing
KW  - Closed box
KW  - clustering
KW  - Clustering methods
KW  - Clusterings
KW  - electricity theft
KW  - Electricity theft
KW  - ensemble
KW  - Evasion attack
KW  - Smart grids
KW  - Threat modeling
ER  - 

TY  - CONF
TI  - An Advance Approach for Diabetes Detection by Implementing Machine Learning Algorithms
AU  - Kour, S.P.
AU  - Kumar, A.
AU  - Ahuja, S.
T2  - Proceedings - 2023 IEEE World Conference on Applied Intelligence and Computing, AIC 2023
AB  - Early identification of diabetes is vital since it's an incurable condition with no complete cure. We used data mining and machine learning strategies in our investigation to anticipate diabetes. 768 individuals and their relevant attributes are the focus of the hour. Few machine learning methods have been applied to the dataset for the goal of forecasting the occurrence of diabetes. The implemented algorithms' consistency and harshness have been investigated using methods that focused on correlating accuracy and F-1 rankings. Comparison between algorithms is done to increase the accuracy in comparison. We predicted Extra Tree Classifier gives 80% accuracy compared to support vector Machine. The goal of this study is to create a feasible strategy that will aid medical personnel with the diagnosis of diabetic complications at a tender point.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/AIC57670.2023.10263919
SP  - 136
EP  - 141
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174514041&doi=10.1109%2fAIC57670.2023.10263919&partnerID=40&md5=94b1dc60a012f6ecae145120983c9f77
DB  - Scopus
KW  - Data mining
KW  - Machine learning algorithms
KW  - Support vector machines
KW  - robustness
KW  - Learning systems
KW  - Diagnosis
KW  - Learning algorithms
KW  - Condition
KW  - accuracy
KW  - Robustness
KW  - Accuracy
KW  - Trees (mathematics)
KW  - Support vectors machine
KW  - Diabetes detection
KW  - Extra tree classifier
KW  - Extra tree Classifier
KW  - Extra-trees
KW  - F-1 score
KW  - Support vector Machine
KW  - Tree classifiers
ER  - 

TY  - JOUR
TI  - Cost-Sensitive Graph Convolutional Network With Self-Paced Learning for Hit-and-Run Analysis
AU  - Wan, J.
AU  - Zhu, S.
T2  - IEEE Transactions on Intelligent Transportation Systems
AB  - This article aims to tackle two issues in hit-and-run crash analysis: The first one is the missing label issue, as the hit-and-run label information has been ignored by many crash datasets. Another one is the class imbalance problem, as the number of hit-and-run crashes is usually much smaller than that of non-hit-and-run crashes. The semi-supervised learning by manually labelling a few hit-and-run labels and the cost-sensitive learning that assigns unequal cost values to class-imbalanced crashes are adopted in this paper. Specifically, we develop a cost-sensitive graph convolutional network with self-paced learning (CSGCN<inline-formula> <tex-math notation="LaTeX">$_{\rm sp}$</tex-math> </inline-formula>) for hit-and-run analysis, which takes the proposed <inline-formula> <tex-math notation="LaTeX">$k$</tex-math> </inline-formula>-nearest neighbour anchor graph as input to extract the local clustering structure hidden among crashes for more effective convolutions. The proposed method performs semi-supervised learning with an &#x2018;easy-to-hard&#x2019; manner, which can help infer more accurate hit-and-run labels for unsupervised crashes with imbalanced data distribution. The road traffic collision database of Victoria State of Australia is selected for hit-and-run analysis. Compared to fifteen other models, the proposed CSGCN<inline-formula> <tex-math notation="LaTeX">$_{\rm sp}$</tex-math> </inline-formula> can significantly improve the prediction performance in terms of AUC, G-mean, F-measure, and total misclassification cost. The significant contributing factors analysis shows that 53.33% of true contributing factors, which is at least 20.00% higher than that of the state-of-the-art hit-and-run models, can be found by CSGCN<inline-formula> <tex-math notation="LaTeX">$_{\rm sp}$</tex-math> </inline-formula> when only 1% of hit-and-run crashes are manually labelled. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TITS.2023.3314402
SP  - 1
EP  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173036353&doi=10.1109%2fTITS.2023.3314402&partnerID=40&md5=236d2e722486b05b515f1970bde6b552
DB  - Scopus
KW  - Safety
KW  - semi-supervised learning
KW  - Neural networks
KW  - Data models
KW  - Analytical models
KW  - Convolutional neural networks
KW  - Supervised learning
KW  - Learning algorithms
KW  - Accident prevention
KW  - Convolution
KW  - Convolutional neural network
KW  - Transportation
KW  - Highway accidents
KW  - Factor analysis
KW  - Semi-supervised learning
KW  - Cost-sensitive learning
KW  - Data structures
KW  - Semisupervised learning
KW  - Computer crashes
KW  - Convolutional networks
KW  - Cost benefit analysis
KW  - Cost-sensitive
KW  - cost-sensitive learning
KW  - graph convolutional network
KW  - Graph convolutional network
KW  - Hit-and-run analyse
KW  - Hit-and-run analysis
KW  - self-paced learning
KW  - Self-paced learning
ER  - 

TY  - JOUR
TI  - Robust estimation of shear wave velocity in a carbonate oil reservoir from conventional well logging data using machine learning algorithms
AU  - Kheirollahi, H.
AU  - Shad Manaman, N.
AU  - Leisi, A.
T2  - Journal of Applied Geophysics
AB  - In recent decades, various applications of shear wave velocity have been reported in oil and gas projects. These applications include the determination of lithology, estimation of geomechanical parameters, reservoir fluid detection, etc. The shear wave velocity is usually measured or recorded by DSI (Dipole Shear Sonic imager) instruments. This log is not usually available in all wells of a hydrocarbon field because of the high cost of running this log compared to other conventional logs. However, it is tried to estimate the shear wave velocity from other related logs. The literature contains many empirical rock physics models used to estimate shear wave velocity. Most of them were developed for sandstone lithologies and didn't applicable in carbonate reservoir because of existing some vertical and horizontally complex fracture networks in the carbonate reservoirs that cause a quite different behavior for the shear wave velocity. The main objective of this research is to concentrate on the effect of lithology in the estimation of the target log for a carbonate reservoir. At the earliest step, preprocessing is performed and 455 data points of several conventional well logs, i.g., acoustic, density, neutron porosity, resistivity, gamma-ray, calcite volume, dolomite volume, and water saturation logs have been applied to generate the synthetic shear wave velocity log in a carbonate oil reservoir. First, original data are divided into training, validation, and testing subsets. Different data-driven predictive models were built: Multiple Linear Regression (MLR), Ensemble Learning Method (ELM), and three architectures of Artificial Neural Networks (ANN). The performance of all techniques was compared with each other. Finally, the feed-forward neural network shows the highest accuracy with R-values of 0.99 and 0.96 for the training and testing datasets. Moreover, the network design and tuning parameters of the model are adjusted using the grid search optimization technique to obtain the optimal design of the artificial neural network for estimating the shear wave velocity log. Hence, a deep artificial neural network, i.e., [8–11–15-1] network with bayesian regularization training algorithm and hyperbolic tangent sigmoid transfer function, is proposed to predict the target response in other wells. © 2023 Elsevier B.V.
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.jappgeo.2023.104971
VL  - 211
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148688257&doi=10.1016%2fj.jappgeo.2023.104971&partnerID=40&md5=d5e6ac2bbcec2e46872c1113d67f8a9e
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Learning systems
KW  - Learning algorithms
KW  - algorithm
KW  - Robust estimation
KW  - regression analysis
KW  - artificial neural network
KW  - Feedforward neural networks
KW  - hydrocarbon reservoir
KW  - Parameter estimation
KW  - Gamma rays
KW  - Oil well logging
KW  - Shear flow
KW  - Shear waves
KW  - Lithology
KW  - S-wave
KW  - Ensemble learning
KW  - Acoustic wave velocity
KW  - Artificial Neural Networks
KW  - Carbonate oil reservoirs
KW  - Carbonate reservoir
KW  - carbonate rock
KW  - Carbonation
KW  - Dolomite
KW  - ensemble forecasting
KW  - Hyperbolic functions
KW  - Multiple linear regression
KW  - Neutron logging
KW  - Oil and gas projects
KW  - Petroleum reservoirs
KW  - Regression
KW  - Reservoir fluid detection
KW  - Shear wave velocity
KW  - wave velocity
KW  - well logging
KW  - Well logging data
ER  - 

TY  - JOUR
TI  - Domain Generalization: A Survey
AU  - Zhou, K.
AU  - Liu, Z.
AU  - Qiao, Y.
AU  - Xiang, T.
AU  - Loy, C.C.
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - Generalization to out-of-distribution (OOD) data is a capability natural to humans yet challenging for machines to reproduce. This is because most learning algorithms strongly rely on the i.i.d. assumption on source/target data, which is often violated in practice due to domain shift. Domain generalization (DG) aims to achieve OOD generalization by using only source data for model learning. Over the last ten years, research in DG has made great progress, leading to a broad spectrum of methodologies, e.g., those based on domain alignment, meta-learning, data augmentation, or ensemble learning, to name a few; DG has also been studied in various application areas including computer vision, speech recognition, natural language processing, medical imaging, and reinforcement learning. In this paper, for the first time a comprehensive literature review in DG is provided to summarize the developments over the past decade. Specifically, we first cover the background by formally defining DG and relating it to other relevant fields like domain adaptation and transfer learning. Then, we conduct a thorough review into existing methods and theories. Finally, we conclude this survey with insights and discussions on future research directions.  © 1979-2012 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPAMI.2022.3195549
VL  - 45
IS  - 4
SP  - 4396
EP  - 4415
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135751422&doi=10.1109%2fTPAMI.2022.3195549&partnerID=40&md5=35e0f580ba4f386b2988569b54c73ba1
DB  - Scopus
KW  - machine learning
KW  - Reinforcement learning
KW  - Speech recognition
KW  - Learning algorithms
KW  - Machine-learning
KW  - article
KW  - human
KW  - Surveys
KW  - systematic review
KW  - Natural language processing systems
KW  - Medical imaging
KW  - learning
KW  - computer vision
KW  - Adaptation models
KW  - Face recognition
KW  - Model robustness
KW  - Soft sensors
KW  - diagnostic imaging
KW  - vision
KW  - transfer of learning
KW  - reinforcement learning (machine learning)
KW  - model robustness
KW  - Biomedical imaging
KW  - Character recognition
KW  - domain shift
KW  - Domain shift
KW  - Generalisation
KW  - Handwriting recognition
KW  - natural language processing
KW  - Out-of-distribution generalization
KW  - Source data
KW  - speech
KW  - speech discrimination
ER  - 

TY  - JOUR
TI  - Robust ML model ensembles via risk-driven anti-clustering of training data
AU  - Mauri, L.
AU  - Apolloni, B.
AU  - Damiani, E.
T2  - Information Sciences
AB  - In this paper, we improve the robustness of Machine Learning (ML) classifiers against training-time attacks by linking the risk of training data being tampered with to the redundancy in the ML model's design needed to prevent it. Our defense mechanism is directly applicable to classifiers' training data, without any knowledge of the specific ML model to be hardened. First, we compute the training data proximity to class separation surfaces, identified via a reference linear model. Each data point is associated with a risk index, which is used to partition the training set by an unsupervised technique. Then, we train a learner for each partition and combine the learners' output in an ensemble. Our method treats the protected ML classifier as a black box and is inherently robust to transfer attacks. Experiments show that, for data poisoning rates between 6 and 25 percent of the training set, our method is more robust compared to benchmarks and to a monolithic version of the model trained on the whole training set. Our results make a convincing case for adopting training set partitioning and ensemble generation as a stage of ML models' development and deployment lifecycle. © 2023 The Author(s)
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.ins.2023.03.085
VL  - 633
SP  - 122
EP  - 140
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150025882&doi=10.1016%2fj.ins.2023.03.085&partnerID=40&md5=85e7c63d37ea275829e2bc1b82c9fb9f
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Classification (of information)
KW  - Life cycle
KW  - Machine learning security
KW  - Adversarial machine learning
KW  - Risk modeling
KW  - Ensemble models
KW  - Poisoning attack
KW  - Poisoning attacks
KW  - Robust ensemble model
KW  - Robust ensemble models
KW  - Set partitioning
KW  - Training set partitioning
KW  - Training sets
ER  - 

TY  - JOUR
TI  - Machine Learning Models Using Routinely Collected Clinical Data Offer Robust and Interpretable Predictions of 90-Day Unplanned Acute Care Use for Cancer Immunotherapy Patients
AU  - Lu, S.-C.
AU  - Knafl, M.
AU  - Turin, A.
AU  - Offodile, A.C.
AU  - Ravi, V.
AU  - Sidey-Gibbons, C.
T2  - JCO clinical cancer informatics
AB  - PURPOSE: Clinical management of patients receiving immune checkpoint inhibitors (ICIs) could be informed using accurate predictive tools to identify patients at risk of short-term acute care utilization (ACU). We used routinely collected data to develop and assess machine learning (ML) algorithms to predict unplanned ACU within 90 days of ICI treatment initiation. METHODS: We used aggregated electronic health record data from 7,960 patients receiving ICI treatments to train and assess eight ML algorithms. We developed the models using pre-SARS-COV-19 COVID-19 data generated between January 2016 and February 2020. We validated our algorithms using data collected between March 2020 and June 2022 (peri-COVID-19 sample). We assessed performance using area under the receiver operating characteristic curves (AUROC), sensitivity, specificity, and calibration plots. We derived intuitive explanations of predictions using variable importance and Shapley additive explanation analyses. We assessed the marginal performance of ML models compared with that of univariate and multivariate logistic regression (LR) models. RESULTS: Most algorithms significantly outperformed the univariate and multivariate LR models. The extreme gradient boosting trees (XGBT) algorithm demonstrated the best overall performance (AUROC, 0.70; sensitivity, 0.53; specificity, 0.74) on the peri-COVID-19 sample. The algorithm performance was stable across both pre- and peri-COVID-19 samples, as well as ICI regimen and cancer groups. Type of ICI agents, oxygen saturation, diastolic blood pressure, albumin level, platelet count, immature granulocytes, absolute monocyte, chloride level, red cell distribution width, and alcohol intake were the top 10 key predictors used by the XGBT algorithm. CONCLUSION: Machine learning algorithms trained using routinely collected data outperformed traditional statistical models when predicting 90-day ACU. The XGBT algorithm has the potential to identify high-ACU risk patients and enable preventive interventions to avoid ACU.
DA  - 2023///
PY  - 2023
DO  - 10.1200/CCI.22.00123
VL  - 7
SP  - e2200123
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151321431&doi=10.1200%2fCCI.22.00123&partnerID=40&md5=b47ef426ede82838422c541ae09768c7
DB  - Scopus
KW  - machine learning
KW  - Machine Learning
KW  - COVID-19
KW  - Algorithms
KW  - human
KW  - Humans
KW  - algorithm
KW  - area under the curve
KW  - Area Under Curve
KW  - epidemiology
KW  - immunotherapy
KW  - Immunotherapy
KW  - neoplasm
KW  - Neoplasms
ER  - 

TY  - JOUR
TI  - Towards Fast and Accurate Image-Text Retrieval with Self-Supervised Fine-Grained Alignment
AU  - Zhuang, J.
AU  - Yu, J.
AU  - Ding, Y.
AU  - Qu, X.
AU  - Hu, Y.
T2  - IEEE Transactions on Multimedia
AB  - Image-text retrieval requires the system to bridge the heterogenous gap between vision and language for accurate retrieval while keeping the network lightweight-enough for efficient retrieval. Existing trade-off solutions mainly study from the view of incorporating cross-modal interactions with the independent-embedding framework or leveraging stronger pre-trained encoders, which still demand time-consuming similarity measurement or heavyweight model structure in the retrieval stage. In this work, we propose an image-text alignment module SelfAlign on top of the independent-embedding framework, which improves the retrieval accuracy while maintains the retrieval efficiency without extra supervision. SelfAlign contains two collaborative sub-modules that force image-text alignment at both the concept level and context level by self-supervised contrastive learning. It doesn&#x0027;t require cross-modal embedding interactions during training while maintaining independent image and text encoders during retrieval. With comparable time cost, SelfAlign consistently boosts the accuracy of state-of-the-art non-pre-training independent-embedding models respectively by 9.1&#x0025;, 4.2&#x0025;, and 6.6&#x0025; in terms of R@sum score on Flickr30K, MS-COCO 1K and MS-COCO 5K datasets. The retrieval accuracy also outperforms most existing interactive-embedding models with orders of magnitude decrease in retrieval time. The source code is available at: https://github.com/Zjamie813/SelfAlign. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TMM.2023.3280734
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161064202&doi=10.1109%2fTMM.2023.3280734&partnerID=40&md5=eb6ada6a8a34f115f8eda458ed4a49a4
DB  - Scopus
KW  - Semantics
KW  - Computational modeling
KW  - Training
KW  - Visualization
KW  - Costs
KW  - self-supervised learning
KW  - concept-level cross-modal alignment
KW  - context-level cross-modal alignment
KW  - Encoding
KW  - Fast image-text retrieval
KW  - Image coding
ER  - 

TY  - JOUR
TI  - A Robust Mean-Field Actor-Critic Reinforcement Learning Against Adversarial Perturbations on Agent States
AU  - Zhou, Z.
AU  - Liu, G.
AU  - Zhou, M.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Multiagent deep reinforcement learning (DRL) makes optimal decisions dependent on system states observed by agents, but any uncertainty on the observations may mislead agents to take wrong actions. The mean-field actor-critic (MFAC) reinforcement learning is well-known in the multiagent field since it can effectively handle a scalability problem. However, it is sensitive to state perturbations that can significantly degrade the team rewards. This work proposes a Robust MFAC (RoMFAC) reinforcement learning that has two innovations: 1) a new objective function of training actors, composed of a policy gradient function that is related to the expected cumulative discount reward on sampled clean states and an action loss function that represents the difference between actions taken on clean and adversarial states and 2) a repetitive regularization of the action loss, ensuring the trained actors to obtain excellent performance. Furthermore, this work proposes a game model named a state-adversarial stochastic game (SASG). Despite the Nash equilibrium of SASG may not exist, adversarial perturbations to states in the RoMFAC are proven to be defensible based on SASG. Experimental results show that RoMFAC is robust against adversarial perturbations while maintaining its competitive performance in environments without perturbations. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3278715
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161516711&doi=10.1109%2fTNNLS.2023.3278715&partnerID=40&md5=a842a020dd2078511d253e34c9126787
DB  - Scopus
L1  - https://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=10143665&ref=
KW  - Deep learning
KW  - Game theory
KW  - Reinforcement learning
KW  - multiagent systems
KW  - Training
KW  - Perturbation methods
KW  - robustness
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Robustness (control systems)
KW  - Robustness
KW  - Markov processes
KW  - Multi agent systems
KW  - Stochastic models
KW  - Stochastic systems
KW  - Game
KW  - Actor-critic reinforcement learning
KW  - Scalability
KW  - Perturbation method
KW  - Perturbation techniques
KW  - Games
KW  - Mean-field
KW  - Mean-field actor-critic  reinforcement learning
KW  - Mean-field actor-critic (MFAC) reinforcement learning
KW  - State-adversarial stochastic game
KW  - state-adversarial stochastic game (SASG)
KW  - Stochastic game
ER  - 

TY  - JOUR
TI  - Sinkhorn Distance Minimization for Adaptive Semi-Supervised Social Network Alignment
AU  - Xu, J.
AU  - Li, C.
AU  - Huang, F.
AU  - Li, Z.
AU  - Xie, X.
AU  - Yu, P.S.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Social network alignment, aiming at linking identical identities across different social platforms, is a fundamental task in social graph mining. Most existing approaches are supervised models and require a large number of manually labeled data, which are infeasible in practice considering the yawning gap between social platforms. Recently, isomorphism across social networks is incorporated as complementary to link identities from the distribution level, which contributes to alleviating the dependency on sample-level annotations. Adversarial learning is adopted to learn a shared projection function by minimizing the distance between two social distributions. However, the hypothesis of isomorphism might not always hold true as social user behaviors are generally unpredictable, and thus a shared projection function is insufficient to handle the sophisticated cross-platform correlations. In addition, adversarial learning suffers from training instability and uncertainty, which may hinder model performance. In this article, we propose a novel meta-learning-based social network alignment model Meta-SNA to effectively capture the isomorphism and the unique characteristics of each identity. Our motivation lies in learning a shared meta-model to preserve the global cross-platform knowledge and an adaptor to learn a specific projection function for each identity. Sinkhorn distance is further introduced as the distribution closeness measurement to tackle the limitations of adversarial learning, which owns an explicitly optimal solution and can be efficiently computed by the matrix scaling algorithm. Empirically, we evaluate the proposed model over multiple datasets, and the experimental results demonstrate the superiority of Meta-SNA. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3267126
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161030939&doi=10.1109%2fTNNLS.2023.3267126&partnerID=40&md5=c1f06e68012753647564463c739e7f40
DB  - Scopus
KW  - Task analysis
KW  - semi-supervised learning
KW  - Data mining
KW  - Training
KW  - Supervised learning
KW  - Behavioral research
KW  - Job analysis
KW  - Machine-learning
KW  - Social networking (online)
KW  - Semi-supervised learning
KW  - Adaptation models
KW  - Adversarial machine learning
KW  - Alignment
KW  - Metalearning
KW  - Annotation
KW  - Annotations
KW  - Couplings
KW  - Meta-learning
KW  - Network alignments
KW  - Set theory
KW  - social network alignment
KW  - Social network alignment
KW  - social network analysis
KW  - Social Network Analysis
ER  - 

TY  - CHAP
TI  - Development of a Hybrid Safety System Based on a Machine Learning Approach Using Thermal and RGB Data
AU  - Jathe, N.
AU  - Stern, H.
AU  - Freitag, M.
T2  - Studies in Systems, Decision and Control
AB  - Using liquefied natural gas (LNG) as an alternative to conventional marine fuels can contribute to reaching carbon neutrality. Handling LNG requires tight safety measures due to the risk of explosion and frostbite. The present paper introduces a live monitoring approach to detect safety violations (persons in dangerous areas) and LNG leakage. The system utilizes a dual-camera system with regular RGB, and thermal vision and a machine learning approach suitable for the naval environment and movements like roll, pitch, and yaw. In lab tests, we showed a reliable detection of gas leakage and improved person detection. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
VL  - 467
SP  - 273
EP  - 282
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162242864&doi=10.1007%2f978-3-031-27540-1_24&partnerID=40&md5=61593e9aca24acc02ce0d672e4eec6f3
DB  - Scopus
ER  - 

TY  - CONF
TI  - A Comprehensive Study of Blockchain for Federated Learning Toward Safe Distributed Machine Learning Systems
T2  - 2023 International Conference on Artificial Intelligence and Smart Communication, AISC 2023
AB  - Individuals have the ability to reveal the necessary data by using federated learning (FL), which is a possible decentralized method to deep learning. FL is in the process of rewriting the industrial paradigms that are now used for mathematical modelling and analysis in order to make it possible for an expanding range of industries to construct distributed machine learning models that are secure and safeguard users' privacy. However, when put into reality, FL's core traits have led to problems such as insufficient protection of users' privacy, high communication costs, varied system architectures, and unreliable model uploads. In contrast to the widespread notion, adding Blockchain technology offers the FL the opportunity to significantly improve both its performance and its level of security, in addition to expanding the applications for which it may be used. is what we refer to as this hybrid form that combines elements of the block chain and FL. This article provides a comprehensive look into BCFL and discusses the implications that may be drawn from this innovative research paradigm. To begin, we will provide a brief overview of the FL technology and then discuss the challenges that it now confronts. After that, a brief summary of the Blockchain ecosystem is provided. After that, the platform as well as the structural design of BCFL are emphasized. We also examine the efforts being made to enhance the performance of FL by using Blockchain technology, as well as numerous implementations of FL incentive systems that have been integrated. In this section, we will summarize the BCFL industrial application scenarios.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/AISC56616.2023.10085557
SP  - 1200
EP  - 1204
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153511861&doi=10.1109%2fAISC56616.2023.10085557&partnerID=40&md5=4aaafc78015a2ccb6a10ea43e20faa1f
DB  - Scopus
KW  - Deep learning
KW  - deep learning
KW  - Reinforcement learning
KW  - reinforcement learning
KW  - Blockchain
KW  - Learning systems
KW  - Performance
KW  - Reinforcement learnings
KW  - Structural design
KW  - Machine learning systems
KW  - Block-chain
KW  - Decentralised
KW  - Distributed machine learning
KW  - Industrial paradigm
KW  - Modelling and analysis
KW  - User privacy
ER  - 

TY  - JOUR
TI  - SAFER-STUDENT for Safe Deep Semi-Supervised Learning With Unseen-Class Unlabeled Data
AU  - He, R.
AU  - Han, Z.
AU  - Lu, X.
AU  - Yin, Y.
T2  - IEEE Transactions on Knowledge and Data Engineering
AB  - Deep semi-supervised learning&#x00A0;(SSL) methods aim to utilize abundant unlabeled data to improve the seen-class classification. However, in the open-world scenario, collected unlabeled data tend to contain unseen-class data, which would degrade the generalization to seen-class classification. Formally, we define the problem as safe deep semi-supervised learning with unseen-class unlabeled data. One intuitive solution is removing these unseen-class instances after detecting them during the SSL process. Nevertheless, the performance of unseen-class identification is limited by the lack of suitable score function, the uncalibrated model, and the small number of labeled data. To this end, we propose a safe SSL method called SAFE<bold>R</bold>-STUDENT from the teacher-student view. Firstly, to enhance the ability of teacher model to identify seen and unseen classes, we propose a general scoring framework called <underline>D</underline>iscrepancy with <underline>R</underline>aw&#x00A0;(DR). Secondly, based on unseen-class data mined by teacher model from unlabeled data, we calibrate student model by newly proposed <underline>U</underline>nseen-class <underline>E</underline>nergy-bounded <underline>C</underline>alibration&#x00A0;(UEC) loss. Thirdly, based on seen-class data mined by teacher model from unlabeled data, we propose <underline>W</underline>eighted <underline>C</underline>onfirmation <underline>B</underline>ias <underline>E</underline>limination&#x00A0;(WCBE) loss to boost seen-class classification of student model. Extensive studies show that SAFE<bold>R</bold>-STUDENT remarkably outperforms the state-of-the-art, verifying the effectiveness of our method in the under-explored problem. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TKDE.2023.3279139
SP  - 1
EP  - 17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161038094&doi=10.1109%2fTKDE.2023.3279139&partnerID=40&md5=73bfbfe01019bc2c72aa9bfd083bd4a9
DB  - Scopus
KW  - Deep learning
KW  - Task analysis
KW  - semi-supervised learning
KW  - Data models
KW  - Training
KW  - Supervised learning
KW  - Job analysis
KW  - Classification (of information)
KW  - Uncertainty
KW  - Uncertainty analysis
KW  - Semi-supervised learning
KW  - Semisupervised learning
KW  - Loss measurement
KW  - Students
KW  - C (programming language)
KW  - New-class detection
KW  - safe semi-supervised learning
KW  - Safe semi-supervised learning
KW  - Unlabeled data
ER  - 

TY  - CHAP
TI  - Advances in Failure Prediction of Subsea Components Considering Complex Dependencies
AU  - Li, H.
AU  - Peng, W.
AU  - Adumene, S.
AU  - Yazdi, M.
T2  - Studies in Systems, Decision and Control
AB  - The technological advancement in subsea system design for harsh environments presents structural and functional performance complexity. This paper explores the various methodologies for failure assessment of subsea systems considering the unstable operating environment and functional dependencies among sub-components. The various failure influencing factors for harsh offshore operations were examined to establish their level of importance and impact on the failure model prediction for the subsea assets. The systematic study explores the failure methods that integrate the data-driven approaches with the physics of failure models to enhance better failure risk prediction in a dynamic offshore environment. While presenting the state of knowledge and the advances in the failure prediction approaches, the study identified the need to further integrate the data-driven machine learning model with the multi-hazard failure risk aggregation approaches for a holistic safety criteria formulation for harsh subsea operations. This could be further supported by integrating resilient design, digitalization, and IoT for remote arctic subsea operations. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
VL  - 473
SP  - 93
EP  - 105
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158109847&doi=10.1007%2f978-3-031-29962-9_6&partnerID=40&md5=a89c6f8568b55ff943eaf0f2001b718a
DB  - Scopus
KW  - Safety
KW  - Data-driven machine learning
KW  - Failure prediction
KW  - Functional dependencies
KW  - Harsh environments
KW  - Subsea systems
ER  - 

TY  - JOUR
TI  - A robust clustering-based multi-objective model for optimal instruction of pipes replacement in urban WDN based on machine learning approaches
AU  - Jafari, S.M.
AU  - Nikoo, M.R.
AU  - Bozorg-Haddad, O.
AU  - Alamdari, N.
AU  - Farmani, R.
AU  - Gandomi, A.H.
T2  - Urban Water Journal
AB  - Water distribution networks (WDNs) face serious management challenges due to the high investment necessity for pipe maintenance and high performance as well as the uncertainties of input variables. To address these challenges, this study aims to prepare and implement the optimal instructions for pipe replacement with maximum hydraulic performance, minimum cost, and minimum uncertainty. Herein, a robust clustering multi-objective (RCMO) approach is developed by combining five models, including hydraulic simulation, multi-objective optimization, pipe failure rate prediction, non-linear interval programming, and multi-criteria decision-making. In this procedure, a clustering method is implemented to reduce the uncertain scenarios of the multi-objective optimization. The new approach is applied to a WDN in Gorgan, Iran. Implementing the optimal instruction increases the network’s physical and hydraulic performance by 56% and 35%, respectively, and decreases the annual deficit of nodes’ demand between 69% and 93%. Also, the proposed methodology reduces the optimization run time by about 99%. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
DA  - 2023///
PY  - 2023
DO  - 10.1080/1573062X.2023.2209063
VL  - 20
IS  - 6
SP  - 689
EP  - 706
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159684675&doi=10.1080%2f1573062X.2023.2209063&partnerID=40&md5=a6004ff98cac635132611b247715644e
DB  - Scopus
KW  - machine learning
KW  - decision-making
KW  - methodology
KW  - decision making
KW  - optimization
KW  - Iran
KW  - water management
KW  - pipe
KW  - Golestan
KW  - Gorgan
KW  - maintenance
KW  - multi-objective optimization
KW  - pipes replacement
KW  - robust model
KW  - Water distribution network
ER  - 

TY  - JOUR
TI  - Sparse and Outlier Robust Extreme Learning Machine Based on the Alternating Direction Method of Multipliers
AU  - Zhang, Y.
AU  - Dai, Y.
AU  - Wu, Q.
T2  - Neural Processing Letters
AB  - Extreme learning machine (ELM) has been extensively researched for its fast training speed and powerful learning abilities. Entering the era of big data, large-scale learning tasks, the universality of noisy data and data with distributed storage pose considerable challenges to ELM. The outlier robust ELM (OR-ELM) is an important variant of ELM that dramatically improves the robustness of the model by introducing the ℓ1-norm in the error term. Nevertheless, the solution of OR-ELM is fully dense, which requires a large amount of storage space and computational resources for massive learning tasks. In this paper, we extended OR-ELM to the sparse and outlier robust ELM (SOR-ELM) based on the elastic-net theory that can simultaneously improve the sparsity and stability of the model. We also proposed a distributed version of SOR-ELM (DSOR-ELM) for handling data with distributed storage and large-scale learning tasks. In addition, an effective iterative algorithm, the alternating direction method of multipliers (ADMM), was employed to train our proposed models. Even though extending ADMM to multi-block issues is not straightforward, its convergence can still be ensured for training SOR-ELM and DSOR-ELM. Finally, extensive numerical experiments demonstrate the superiority of SOR-ELM and DSOR-ELM in training data with outliers and distributed learning environments. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s11063-023-11227-y
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150025074&doi=10.1007%2fs11063-023-11227-y&partnerID=40&md5=450efb5de89c842cec18a1ed954448ba
DB  - Scopus
KW  - Machine learning
KW  - Data handling
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - Robustness
KW  - Learning machines
KW  - Statistics
KW  - Computation theory
KW  - Computer aided instruction
KW  - Iterative methods
KW  - Digital storage
KW  - Convergence
KW  - Alternating directions method of multipliers
KW  - Learning tasks
KW  - Alternating direction method of multiplier
KW  - Alternating direction method of multipliers (ADMM)
KW  - Distributed algorithm
KW  - Distributed storage
KW  - Extreme learning machine (ELM)
KW  - Large-scale learning
KW  - Training speed
ER  - 

TY  - JOUR
TI  - Discriminative Identity-Feature Exploring and Differential Aware Learning for Unsupervised Person Re-Identification
AU  - Liu, Y.
AU  - Ge, H.
AU  - Wang, Z.
AU  - Hou, Y.
AU  - Zhao, M.
T2  - IEEE Transactions on Multimedia
AB  - Unsupervised person re-identification (Re-ID) aims to learn discriminative representations for person retrieval from unlabeled data. Currently, state-of-the-art techniques accomplish this task by using instance contrastive learning, which contrasts the similarities of the instances in different views. However, existing contrastive methods only focus on the positive effects of inter-instance relationships, while neglecting the negative effects of intra-instance redundancy information. This redundancy information can generate invalid or spurious intra-class relationships during the instance contrasting process, which enlarges the intra-class gaps and increases the noisy pseudo-labels. To address this issue, we propose a discriminative identity-feature exploring and differential aware learning (DiDAL) framework to learn more discriminative intra-identity representations. Specifically, the DiDAL extracts intra-instance salient features by synthetic complementary attention, and further explores the discriminative identity features by modeling the relationship among these salient features based on graph neural networks. This strategy aims to reduce the intra-instance redundancy information. Moreover, DiDAL explores hard instances by leveraging the extracted intra-instance salient features, and matches an anchor with multiple hard positive instances to enhance the robustness of the model to noisy pseudo-labels. Extensive experiment results on two widely used person re-identification datasets and a vehicle re-identification dataset demonstrate the superiority of the proposed method compared with existing state-of-the-art methods. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TMM.2023.3268369
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153486115&doi=10.1109%2fTMM.2023.3268369&partnerID=40&md5=b5a57012b5016f473e35c6164d034f90
DB  - Scopus
KW  - Feature extraction
KW  - Data models
KW  - Computer science
KW  - Learning systems
KW  - Features extraction
KW  - Robustness
KW  - Noise measurement
KW  - Contrastive learning
KW  - Noise measurements
KW  - Person re identifications
KW  - contrastive learning
KW  - differential aware learning
KW  - Differential aware learning
KW  - Germanium
KW  - Germaniums (Ge)
KW  - Identity feature
KW  - identity features
KW  - Redundancy
KW  - Redundancy information
KW  - unsupervised person re-identification
KW  - Unsupervised person re-identification
ER  - 

TY  - JOUR
TI  - MINING: Multi-Granularity Network Alignment Based on Contrastive Learning
AU  - Zhang, Z.
AU  - Gao, S.
AU  - Su, S.
AU  - Sun, L.
AU  - Chen, R.
T2  - IEEE Transactions on Knowledge and Data Engineering
AB  - Network alignment aims to discover nodes in different networks belonging to the same identity. In recent years, the network alignment problem has aroused significant attentions in both industry and academia. However, the continuous exploding of network data brings two challenges in solving the network alignment problem, i.e., large network scale and scarce labeled data. To bridge this gap, in this paper we propose a novel approach termed as <underline>M</underline>ulti-granular<underline>I</underline>ty <underline>N</underline>etwork al<underline>I</underline>gnment based on co<underline>N</underline>trastive learnin<underline>G</underline> (MINING). Specifically, in MINING, we first design multi-granularity alignment framework to solve the issue of large network scale. Then, we design intra- and inter-network contrastive learning to solve the issue of scarce labeled data. Moreover, we provide theoretical proofs to demonstrate the effectiveness of MINING. Finally, we conduct extensive experiments on the benchmark datasets of Facebook-Twitter, AMiner-LinkedIn and DBpedia<inline-formula><tex-math notation="LaTeX">$_{\rm{ZH}}$</tex-math></inline-formula>-DBpedia<inline-formula><tex-math notation="LaTeX">$_{\rm{EN}}$</tex-math></inline-formula>, and results show that MINING can averagely achieve 15.93&#x0025; higher <inline-formula><tex-math notation="LaTeX">$\operatorname{Hits@}k$</tex-math></inline-formula> and 14.82&#x0025; higher <inline-formula><tex-math notation="LaTeX">$\operatorname{MRR@}k$</tex-math></inline-formula> compared with the state-of-the-art methods. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TKDE.2023.3273782
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159816922&doi=10.1109%2fTKDE.2023.3273782&partnerID=40&md5=9f5f2a0e18a79cb193ff6aeaccc1cc9b
DB  - Scopus
KW  - machine learning
KW  - Deep learning
KW  - deep learning
KW  - Feature extraction
KW  - Data mining
KW  - Data models
KW  - Learning systems
KW  - Features extraction
KW  - Machine-learning
KW  - Social networking (online)
KW  - Alignment
KW  - Contrastive learning
KW  - Knowledge management
KW  - Network alignments
KW  - Alignment Problems
KW  - Knowledge transfer
KW  - Larger networks
KW  - Multi-granularity
KW  - network alignment
KW  - Network scale
KW  - Refining
KW  - Sun
ER  - 

TY  - CONF
TI  - Out-of-Distribution Detection as Support for Autonomous Driving Safety Lifecycle
AU  - Henriksson, J.
AU  - Ursing, S.
AU  - Erdogan, M.
AU  - Warg, F.
AU  - Thorsén, A.
AU  - Jaxing, J.
AU  - Örsmark, O.
AU  - Toftås, M.Ö.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - [Context and Motivation] The automotive industry is moving towards increased automation, where features such as automated driving systems typically include machine learning (ML), e.g. in the perception system. [Question/Problem] Ensuring safety for systems partly relying on ML is challenging. Different approaches and frameworks have been proposed, typically where the developer must define quantitative and/or qualitative acceptance criteria, and ensure the criteria are fulfilled using different methods to improve e.g., design, robustness and error detection. However, there is still a knowledge gap between quality methods and metrics employed in the ML domain and how such methods can contribute to satisfying the vehicle level safety requirements. [Principal Ideas/Results] In this paper, we argue the need for connecting available ML quality methods and metrics to the safety lifecycle and explicitly show their contribution to safety. In particular, we analyse Out-of-Distribution (OoD) detection, e.g., the frequency of novelty detection, and show its potential for multiple safety-related purposes. I.e., as (a) an acceptance criterion contributing to the decision if the software fulfills the safety requirements and hence is ready-for-release, (b) in operational design domain selection and expansion by including novelty samples into the training/development loop, and (c) as a run-time measure, e.g., if there is a sequence of novel samples, the vehicle should consider reaching a minimal risk condition. [Contribution] This paper describes the possibility to use OoD detection as a safety measure, and the potential contributions in different stages of the safety lifecycle. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-29786-1_16
VL  - 13975 LNCS
SP  - 233
EP  - 242
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152531710&doi=10.1007%2f978-3-031-29786-1_16&partnerID=40&md5=a7d664a89d78ed62ff983c2f646834a8
DB  - Scopus
KW  - Machine learning
KW  - Automation
KW  - Vehicle safety
KW  - Autonomous driving
KW  - Automated driving systems
KW  - Machine-learning
KW  - Risk assessment
KW  - Safety engineering
KW  - Life cycle
KW  - Automotive safety
KW  - Safety requirements
KW  - Out-of-distribution detection
KW  - C (programming language)
KW  - Acceptance criteria
KW  - Out-of-Distribution detection
KW  - Quality methods
KW  - Quality metrices
KW  - Safety lifecycle
ER  - 

TY  - JOUR
TI  - Hyperparameter Learning Under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization
AU  - Carnerero-Cano, J.
AU  - Munoz-Gonzalez, L.
AU  - Spencer, P.
AU  - Lupu, E.C.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Machine learning (ML) algorithms are vulnerable to poisoning attacks, where a fraction of the training data is manipulated to deliberately degrade the algorithms&#x2019; performance. Optimal attacks can be formulated as bilevel optimization problems and help to assess their robustness in worst case scenarios. We show that current approaches, which typically assume that hyperparameters remain constant, lead to an overly pessimistic view of the algorithms&#x2019; robustness and of the impact of regularization. We propose a novel optimal attack formulation that considers the effect of the attack on the hyperparameters and models the attack as a <italic>multiobjective</italic> bilevel optimization problem. This allows us to formulate optimal attacks, learn hyperparameters, and evaluate robustness under worst case conditions. We apply this attack formulation to several ML classifiers using <inline-formula> <tex-math notation="LaTeX">$L_2$</tex-math> </inline-formula> and <inline-formula> <tex-math notation="LaTeX">$L_1$</tex-math> </inline-formula> regularization. Our evaluation on multiple datasets shows that choosing an &#x201C;a priori&#x201D; constant value for the regularization hyperparameter can be detrimental to the performance of the algorithms. This confirms the limitations of previous strategies and evidences the benefits of using <inline-formula> <tex-math notation="LaTeX">$L_2$</tex-math> </inline-formula> and <inline-formula> <tex-math notation="LaTeX">$L_1$</tex-math> </inline-formula> regularization to dampen the effect of poisoning attacks, when hyperparameters are learned using a small trusted dataset. Additionally, our results show that the use of regularization plays an important robustness and stability role in complex models, such as deep neural networks (DNNs), where the attacker can have more flexibility to manipulate the decision boundary. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3291648
SP  - 1
EP  - 0
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169677840&doi=10.1109%2fTNNLS.2023.3291648&partnerID=40&md5=0916d09068e36a5755f45fa052059054
DB  - Scopus
KW  - Deep neural networks
KW  - Training
KW  - Machine learning algorithms
KW  - Training data
KW  - Learning algorithms
KW  - Machine-learning
KW  - Classification (of information)
KW  - Optimisations
KW  - Optimization
KW  - Robustness
KW  - Multiobjective optimization
KW  - Adversarial machine learning
KW  - Classification algorithm
KW  - Classification algorithms
KW  - Hyper-parameter optimizations
KW  - Poisoning attacks
KW  - Adversarial machine learning (ML)
KW  - Bi-level optimization
KW  - bilevel optimization
KW  - Data poisoning attack
KW  - data poisoning attacks
KW  - hyperparameter optimization
KW  - Regularisation
KW  - regularization
KW  - Toxicology
ER  - 

TY  - JOUR
TI  - On the Robustness of Random Forest Against Untargeted Data Poisoning: An Ensemble-Based Approach
AU  - Anisetti, M.
AU  - Ardagna, C.A.
AU  - Balestrucci, A.
AU  - Bena, N.
AU  - Damiani, E.
AU  - Yeun, C.Y.
T2  - IEEE Transactions on Sustainable Computing
AB  - Machine learning is becoming ubiquitous. From finance to medicine, machine learning models are boosting decision/making processes and even outperforming humans in some tasks. This huge progress in terms of prediction quality does not however find a counterpart in the security of such models and corresponding predictions, where perturbations of fractions of the training set (poisoning) can seriously undermine the model accuracy. Research on poisoning attacks and defenses received increasing attention in the last decade, leading to several promising solutions aiming to increase the robustness of machine learning. Among them, ensemble-based defenses, where different models are trained on portions of the training set and their predictions are then aggregated, provide strong theoretical guarantees at the price of a linear overhead. Surprisingly, ensemble-based defenses, which do not pose any restrictions on the base model, have not been applied to increase the robustness of random forest models. The work in this paper aims to fill in this gap by designing and implementing a novel hash-based ensemble approach that protects random forest against untargeted, random poisoning attacks. An extensive experimental evaluation measures the performance of our approach against a variety of attacks, as well as its sustainability in terms of resource consumption and performance, and compares it with a traditional monolithic model based on random forest. A final discussion presents our main findings and compares our approach with existing poisoning defenses targeting random forests. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TSUSC.2023.3293269
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164443886&doi=10.1109%2fTSUSC.2023.3293269&partnerID=40&md5=5a096d37ba02d8c6cd3ea6373e520297
DB  - Scopus
KW  - Machine learning
KW  - Predictive models
KW  - Random Forest
KW  - Data models
KW  - Training
KW  - Machine Learning
KW  - Machine-learning
KW  - Forecasting
KW  - Robustness (control systems)
KW  - Ensemble
KW  - Robustness
KW  - Adaptive boosting
KW  - Random forests
KW  - Sustainable development
KW  - Poisoning attacks
KW  - Training sets
KW  - Petroleum reservoir evaluation
KW  - Poisoning
KW  - Radio frequency
KW  - Radiofrequencies
KW  - Sustainability
ER  - 

TY  - CONF
TI  - Data Banzhaf: A Robust Data Valuation Framework for Machine Learning
AU  - Wang, J.T.
AU  - Jia, R.
T2  - Proceedings of Machine Learning Research
AB  - Data valuation has wide use cases in machine learning, including improving data quality and creating economic incentives for data sharing. This paper studies the robustness of data valuation to noisy model performance scores. Particularly, we find that the inherent randomness of the widely used stochastic gradient descent can cause existing data value notions (e.g., the Shapley value and the Leave-one-out error) to produce inconsistent data value rankings across different runs. To address this challenge, we introduce the concept of safety margin, which measures the robustness of a data value notion. We show that the Banzhaf value, a famous value notion that originated from cooperative game theory literature, achieves the largest safety margin among all semivalues (a class of value notions that satisfy crucial properties entailed by ML applications and include the famous Shapley value and Leave-one-out error). We propose an algorithm to efficiently estimate the Banzhaf value based on the Maximum Sample Reuse (MSR) principle. Our evaluation demonstrates that the Banzhaf value outperforms the existing semivalue-based data value notions on several ML tasks such as learning with weighted samples and noisy label detection. Overall, our study suggests that when the underlying ML algorithm is stochastic, the Banzhaf value is a promising alternative to the other semivalue-based data value schemes given its computational advantage and ability to robustly differentiate data quality. Copyright © 2023 by the author(s)
DA  - 2023///
PY  - 2023
VL  - 206
SP  - 6388
EP  - 6421
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165146592&partnerID=40&md5=a821d12295cd52facd652e9c94031f07
DB  - Scopus
KW  - Game theory
KW  - Machine learning
KW  - Machine-learning
KW  - Data quality
KW  - Computation theory
KW  - Stochastic systems
KW  - Gradient methods
KW  - Robust datum
KW  - Banzhaf value
KW  - Data values
KW  - Economic incentive
KW  - Leave one out errors
KW  - Safety margin
KW  - Semivalue
KW  - Shapley value
ER  - 

TY  - JOUR
TI  - Autonomous Driving Risk Assessment with Boundary-based Environment Model
AU  - Jiao, X.
AU  - Chen, J.
AU  - Jiang, K.
AU  - Cao, Z.
AU  - Yang, D.
T2  - IEEE Transactions on Intelligent Vehicles
AB  - Risk assessment is important for intelligent vehicles to make safe driving decisions. In some researches, the risk is modeled as the effect of each environment element on the ego vehicle. However, the overall understanding of the whole scenario is not achieved. In order to get a comprehensive understanding of the overall scenario, some researchers analyzed risk with 2D field. However, the analysis of surface-level dense risk distribution has heavy computational burden. In view of this, we proposed the boundary-based risk assessment method and corresponding decision-making mechanism, as a light-weighted way of understanding the overall risk distribution for intelligent vehicles. First, different environment elements are generally modeled as the unified environment boundary representing space occupation, semantic type and motion status. Then, the risk in different directions is analyzed according to the environment boundary in the ego-centered polar coordinate. Furthermore, considering the perception uncertainty, the safe boundary is set to serve for decision-making as boundary constraint. Experiment results proved that the proposed boundary-based risk assessment method has significantly reduced computational burden than surface-level dense risk assessment with similar decision performance. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TIV.2023.3285762
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162708298&doi=10.1109%2fTIV.2023.3285762&partnerID=40&md5=cdc316a93c9b6b76d320d503af291a3b
DB  - Scopus
KW  - Semantics
KW  - Autonomous vehicles
KW  - Safety
KW  - Machine learning
KW  - Risk management
KW  - Decision making
KW  - Computational modeling
KW  - Vehicle dynamics
KW  - Data models
KW  - Autonomous driving
KW  - Learning systems
KW  - Decisions makings
KW  - Intelligent vehicle highway systems
KW  - Machine-learning
KW  - Risk perception
KW  - Risk assessment
KW  - Computational modelling
KW  - Vehicle's dynamics
KW  - Risks assessments
KW  - Risks management
KW  - Computational burden
KW  - Risk assessment methods
KW  - Risk distribution
ER  - 

TY  - JOUR
TI  - Delicately Reinforced $k$ -Nearest Neighbor Classifier Combined With Expert Knowledge Applied to Abnormity Forecast in Electrolytic Cell
AU  - Shi, J.
AU  - Chen, X.
AU  - Xie, Y.
AU  - Zhang, H.
AU  - Sun, Y.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - As the profit and safety requirements become higher and higher, it is more and more necessary to realize an advanced intelligent analysis for abnormity forecast of the synthetical balance of material and energy (AF-SBME) on aluminum reduction cells (ARCs). Without loss of generality, AF-SBME belongs to classification problems. Its advanced intelligent analysis can be realized by high-performance data-driven classifiers. However, AF-SBME has some difficulties, including a high requirement for interpretability of data-driven classifiers, a small number, and decreasing-over-time correctness of training samples. In this article, based on a preferable data-driven classifier, which is called a reinforced <inline-formula> <tex-math notation="LaTeX">$k$</tex-math> </inline-formula>-nearest neighbor (R-KNN) classifier, a delicately R-KNN combined with expert knowledge (DR-KNN/CE) is proposed. It improves R-KNN in two ways, including using expert knowledge as external assistance and enhancing self-ability to mine and synthesize data knowledge. The related experiments on AF-SBME, where the relevant data are directly sampled from practical production, have demonstrated that the proposed DR-KNN/CE not only makes an effective improvement for R-KNN, but also has a more advanced performance compared with other existing high-performance data-driven classifiers. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3280963
SP  - 1
EP  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165935129&doi=10.1109%2fTNNLS.2023.3280963&partnerID=40&md5=7eb6e5f11b7a5f564983204ecc5bf5d3
DB  - Scopus
KW  - Safety
KW  - Training
KW  - Visualization
KW  - Learning systems
KW  - Classification (of information)
KW  - Image segmentation
KW  - Images segmentations
KW  - Medical imaging
KW  - Xmlns:mml="
KW  - Xmlns:xlink="
KW  - Xmlns:xsi="
KW  - Nearest-neighbour
KW  - Biomedical imaging
KW  - > $k$ -near neighbor (KNN) classifier
KW  - $k$ -nearest neighbor (KNN) classifier
KW  - Aluminum
KW  - Aluminum electrolysis
KW  - classification problem
KW  - Classification problem
KW  - Human-machine
KW  - human-machine hybrid intelligence
KW  - Human-machine hybrid intelligence
KW  - Hybrid intelligence
KW  - interactive learning
KW  - Interactive learning
KW  - Reinforcement
ER  - 

TY  - JOUR
TI  - Joint Adversarial Domain Adaptation With Structural Graph Alignment
AU  - Wang, M.
AU  - Chen, J.
AU  - Wang, Y.
AU  - Wang, S.
AU  - li, L.
AU  - Su, H.
AU  - Gong, Z.
AU  - Wu, K.
AU  - Chen, Z.
T2  - IEEE Transactions on Network Science and Engineering
AB  - Generative adversarial networks as a powerful technique is also used in domain adaptation (DA) problem. Existing adversarial DA methods mainly conduct domain-wise alignment to alleviate marginal distribution shift between the two domains, while it may damage latent discriminative structure hidden in data feature space and cause negative transfer accordingly. To handle this problem, we propose a joint adversarial domain adaptation method with structural graph alignment to minimize joint distribution bias by further realizing class-wise matching (conditional distribution shift) based on a simple sampling strategy except for the domain-wise alignment, and validate that simultaneously considering these two types of shift can approximately reduce the joint distribution bias. To explore transferable structural information and realize more sufficient transfer for DA problem, we propose to align structural graphs between the two domains which is also based on a simple sampling strategy. Notably, the structural graph describes the relationship between each two samples and it is computed on two domains. As such, we can learn new feature representation of the two domains which are more discriminative and transferable to benefit a cross-domain classification task desirably. Finally, we design a number of experiments to evaluate our approach on four public cross-domain benchmark datasets including standard and large-scale ones, and empirical results show that the proposed model can outperform compared state-of-the-art methods. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNSE.2023.3302574
SP  - 1
EP  - 10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167778383&doi=10.1109%2fTNSE.2023.3302574&partnerID=40&md5=b1d6a78515a4f98172a249841a67ea69
DB  - Scopus
KW  - Task analysis
KW  - Feature extraction
KW  - Training
KW  - Standards
KW  - Learning systems
KW  - Features extraction
KW  - Job analysis
KW  - Machine-learning
KW  - Adaptation models
KW  - Adversarial machine learning
KW  - Domain adaptation
KW  - Generative adversarial networks
KW  - conditional distribution
KW  - Conditional distribution
KW  - joint adversarial domain adaptation
KW  - Joint adversarial domain adaptation
KW  - joint distribution
KW  - Joint distributions
KW  - marginal distribution
KW  - Marginal distribution
KW  - Shape
KW  - Structural graph
KW  - structural graph alignment
KW  - Structural graph alignment
ER  - 

TY  - JOUR
TI  - DiscrimLoss: A Universal Loss for Hard Samples and Incorrect Samples Discrimination
AU  - Wu, T.
AU  - Ding, X.
AU  - Zhang, H.
AU  - Gao, J.
AU  - Tang, M.
AU  - Du, L.
AU  - Qin, B.
AU  - Liu, T.
T2  - IEEE Transactions on Multimedia
AB  - Given data with label noise (i.e., incorrect data), deep neural networks would gradually memorize the label noise and impair model performance. To relieve this issue, curriculum learning is proposed to improve model performance and generalization by ordering training samples in a meaningful (e.g., easy to hard) sequence. Previous work takes incorrect samples as generic hard ones without discriminating between hard samples (i.e., hard samples in correct data) and incorrect samples. Indeed, a model should learn from hard samples to promote generalization rather than overfit to incorrect ones. In this paper, we address this problem by appending a novel loss function <italic>DiscrimLoss</italic>, on top of the existing task loss. Its main effect is to automatically and stably estimate the importance of easy samples and difficult samples (including hard and incorrect samples) at the early stages of training to improve the model performance. Then, during the following stages, DiscrimLoss is dedicated to discriminating between hard and incorrect samples to improve the model generalization. Such a training strategy can be formulated dynamically in a self-supervised manner, effectively mimicking the main principle of curriculum learning. Experiments on image classification, image regression, text sequence regression, and event relation reasoning demonstrate the versatility and effectiveness of our method, particularly in the presence of diversified noise levels. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TMM.2023.3290477
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163478229&doi=10.1109%2fTMM.2023.3290477&partnerID=40&md5=304b809823e78a2e0f99c1366b6f2143
DB  - Scopus
KW  - Deep learning
KW  - Machine learning
KW  - Task analysis
KW  - Predictive models
KW  - Deep neural networks
KW  - Data models
KW  - Training
KW  - Job analysis
KW  - Machine-learning
KW  - Estimation
KW  - Text processing
KW  - Switches
KW  - Modeling performance
KW  - Noise measurement
KW  - Label noise
KW  - Noise measurements
KW  - Curricula
KW  - Model generalization
KW  - Noisy label
KW  - Noisy labels
KW  - Robust methods
ER  - 

TY  - JOUR
TI  - Model-Free Economic Dispatch for Virtual Power Plants: An Adversarial Safe Reinforcement Learning Approach
AU  - Yi, Z.
AU  - Xu, Y.
AU  - Wu, C.
T2  - IEEE Transactions on Power Systems
AB  - To address the model inaccuracy and uncertainty of virtual power plants (VPPs), a model-free economic dispatch approach for multiple VPPs is studied in this article, which does not rely on an accurate environmental model. An adversarial safe reinforcement learning approach is proposed, which promotes the safety of the actions and makes the model robust to deviations between the training and testing environments. Moreover, a two-stage reinforcement learning framework is formulated based on the proposed algorithm. The dispatch policy is pretrained in the simulator and then fine-tuned in the real-world environment. The numerical simulations illustrate that the proposed approach is adaptive to the deviation between the training and testing environments, and it provides higher robustness to the noise of the network parameters and uncertainty of the VPPs&#x0027; power outputs. The scalability and superiority of the proposed approach are verified by comparing it with existing methods. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPWRS.2023.3289334
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163461903&doi=10.1109%2fTPWRS.2023.3289334&partnerID=40&md5=c034e026736354492552f9efe180da50
DB  - Scopus
KW  - Reinforcement learning
KW  - Safety
KW  - Security
KW  - Training
KW  - Uncertainty
KW  - safe reinforcement learning
KW  - Power systems
KW  - adversarial learning
KW  - Economic dispatch
KW  - Load flow
KW  - virtual power plant
ER  - 

TY  - JOUR
TI  - Toward Improved Reliability of Deep Learning Based Systems Through Online Relabeling of Potential Adversarial Attacks
AU  - Al-Maliki, S.
AU  - Bouanani, F.E.
AU  - Ahmad, K.
AU  - Abdallah, M.
AU  - Hoang, D.T.
AU  - Niyato, D.
AU  - Al-Fuqaha, A.
T2  - IEEE Transactions on Reliability
AB  - Deep neural networks have shown vulnerability to well-designed inputs called adversarial examples. Researchers in industry and academia have proposed many adversarial example defense techniques. However, they offer partial but not full robustness. Thus, complementing them with another layer of protection is a must, especially for mission-critical applications. This article proposes a novel online selection and relabeling algorithm (OSRA) that opportunistically utilizes a limited number of crowdsourced workers to maximize the machine learning (ML) system&#x0027;s robustness. The OSRA strives to use crowdsourced workers effectively by selecting the most suspicious inputs and moving them to the crowdsourced workers to be validated and corrected. As a result, the impact of adversarial examples gets reduced, and accordingly, the ML system becomes more robust. We also proposed a heuristic threshold selection method that contributes to enhancing the prediction system&#x0027;s reliability. We empirically validated our proposed algorithm and found that it can efficiently and optimally utilize the allocated budget for crowdsourcing. It is also effectively integrated with a state-of-the-art black box defense technique, resulting in a more robust system. Simulation results show that the OSRA can outperform a random selection algorithm by 60&#x0025; and achieve comparable performance to an optimal offline selection benchmark. They also show that OSRA&#x0027;s performance has a positive correlation with system robustness. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TR.2023.3298685
SP  - 1
EP  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168260380&doi=10.1109%2fTR.2023.3298685&partnerID=40&md5=49a3ddb8a11f11d30bdb6f3d9a3c89bd
DB  - Scopus
KW  - security
KW  - Security
KW  - Task analysis
KW  - Deep neural networks
KW  - Training
KW  - Perturbation methods
KW  - Online systems
KW  - Machine-learning
KW  - Network security
KW  - Benchmarking
KW  - Optimization
KW  - Robustness
KW  - Heuristic methods
KW  - Mission critical systems
KW  - Reliability analysis
KW  - Perturbation method
KW  - Perturbation techniques
KW  - adversarial machine learning
KW  - Adversarial machine learning
KW  - Adversarial example
KW  - evasion attacks
KW  - Adversarial defense
KW  - Evasion attack
KW  - adversarial examples
KW  - Budget control
KW  - crowdsourcing
KW  - Crowdsourcing
KW  - History
KW  - online relabeling
KW  - Online relabeling
KW  - Relabelling
KW  - Reliable deep learning system
KW  - reliable deep learning systems
ER  - 

TY  - CONF
TI  - Supporting winter road maintenance procedures with the use of distributed measurements based on IoT, thermodynamic models and machine learning
AU  - Hajder, M.
AU  - Hajder, P.
AU  - Hajder, L.
AU  - Liput, M.
AU  - Kolbusz, J.
T2  - 2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events, PerCom Workshops 2023
AB  - Slippery winter roads hinder car communication and cause many accidents for at least several months a year. The main cause of this problem is the crystallization of the water on the surface, which radically decreases friction between the wheels of the car and the surface of the road and thus increases the required braking distance. The relevant services have been dealing with winter slipperiness for over 100 years. During this time, many mitigation methods were developed and verified. The most widely used methods are chemical methods that cover the road surface with a layer of reagents that melt ice by lowering the solidification temperature. Unfortunately, these chemicals are usually harmful to the environment; for example, they cause degradation of the immediate surroundings of roads, and contamination of groundwater. These phenomena are favored by imperfect procedures to determine the sectoral density of reactants, mainly their dosing. In this paper, the results of the construction of an automatic and maintenance-free reagent dosing system for winter road maintenance are presented. The system acquires measurement data during the salt spreader drive, which are used to determine the sector density of the reagents for a specific road section. These data were and may be used in the future to design two models: thermodynamical to determine the required concentration of reagents and neural network to detect anomalies in a given sector. As a result, their usage is not exceeded or underestimated.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/PerComWorkshops56833.2023.10150293
SP  - 515
EP  - 520
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164189438&doi=10.1109%2fPerComWorkshops56833.2023.10150293&partnerID=40&md5=75a2acde6780cffdae8e5634f6bb63da
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Internet of things
KW  - Internet of Things
KW  - Machine-learning
KW  - Roads and streets
KW  - Motor transportation
KW  - road safety
KW  - Digital storage
KW  - Groundwater
KW  - Groundwater pollution
KW  - Maintenance
KW  - Road safety
KW  - distributed information system
KW  - Distributed information systems
KW  - Distributed measurements
KW  - environmental pollution
KW  - Environmental pollutions
KW  - Highway maintenance
KW  - Maintenance procedures
KW  - Measurement-based
KW  - Roads and highways
KW  - winter road and highway maintenance
KW  - Winter road maintenance
ER  - 

TY  - JOUR
TI  - Distributionally Robust Safety Filter for Learning-Based Control in Active Distribution Systems
AU  - Nguyen, H.T.
AU  - Choi, D.
T2  - IEEE Transactions on Smart Grid
AB  - Operational constraint violations may occur when deep reinforcement learning (DRL) agents interact with real-world active distribution systems to learn their optimal policies during training. This letter presents a universal distributionally robust safety filter (DRSF) using which any DRL agent can reduce the constraint violations of distribution systems significantly during training while maintaining near-optimal solutions. The DRSF is formulated as a distributionally robust optimization problem with chance constraints of operational limits. This problem aims to compute near-optimal actions that are minimally modified from the optimal actions of DRL-based Volt/VAr control by leveraging the distribution system model, thereby providing constraint satisfaction guarantee with a probability level under the model uncertainty. The performance of the proposed DRSF is verified using the IEEE 33-bus and 123-bus systems. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TSG.2023.3304135
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167826144&doi=10.1109%2fTSG.2023.3304135&partnerID=40&md5=dd7a4a685943ff9d83c20d4337910a1e
DB  - Scopus
KW  - Safety
KW  - Computational modeling
KW  - Training
KW  - Uncertainty
KW  - Optimization
KW  - Distributionally robust optimization
KW  - deep reinforcement learning
KW  - safe learning
KW  - Reactive power
KW  - safety filter
KW  - Volt/VAr control
KW  - Voltage
ER  - 

TY  - JOUR
TI  - PBFL: Privacy-Preserving and Byzantine-Robust Federated Learning Empowered Industry 4.0
AU  - Li, W.
AU  - Fan, K.
AU  - Yang, K.
AU  - Yang, Y.
AU  - Li, H.
T2  - IEEE Internet of Things Journal
AB  - In Industry 4.0, Artificial Intelligence (AI) has been successfully applied in scenarios such as fault prediction, traffic analysis, and production decision-making. However, due to the sensitivity and security of data, privacy regulations prohibit the transfer and exchange of industrial data between entities, resulting in training data being fragmented into data silos that limit the accuracy of AI models. Federated learning (FL) can effectively break the data silo effect, but naive FL (FedAvg) is vulnerable to inference attacks from aggregators and Byzantine attacks from participants. To address these issues, we propose a privacy-preserving and Byzantine-robust federated learning scheme (PBFL) for Industry 4.0. Under the setting of an benign-majority participants, PBFL can always identify benign direction and magnitude of updates. Extensive experiments demonstrate that PBFL is more robust than state-of-the-art schemes, even with extreme proportion (49%) of malicious participants. Moreover, PBFL contains a series of well-optimized 2-Party computation (2PC) protocols, causing it reduces total runtime of the unoptimized implementation by around 3&#x00D7;~4&#x00D7; and 9&#x00D7;~10&#x00D7; for 32-bit and 64-bit circuits, respectively. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/JIOT.2023.3315226
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171583401&doi=10.1109%2fJIOT.2023.3315226&partnerID=40&md5=43134d6ba43b9a65faf262107ac7f6e3
DB  - Scopus
KW  - Artificial intelligence
KW  - Decision making
KW  - Computational modeling
KW  - Data models
KW  - Training
KW  - Privacy preserving
KW  - Federated learning
KW  - Computational modelling
KW  - Privacy-preserving techniques
KW  - Production
KW  - Privacy protection
KW  - Byzantine robustness
KW  - Fourth industrial revolution
KW  - Fourth Industrial Revolution
KW  - industrial artificial intelligence
KW  - Industrial artificial intelligence
KW  - Industrial revolutions
KW  - Industry 4.0
KW  - Learning schemes
KW  - privacy protection
KW  - Production facilities
KW  - Production facility
ER  - 

TY  - CONF
TI  - Comparing Parametric and Nonparametric Methods for Heterogeneous Treatment Effects
AU  - Kim, J.-S.
AU  - Liao, X.
AU  - Loh, W.W.
T2  - Springer Proceedings in Mathematics and Statistics
AB  - Efforts to estimate treatment effects and draw causal inferences based on observational data are increasingly relevant with the abundance of such data in the social and behavioral sciences. Although the average treatment effect (ATE) might be the first step in the analysis, the main goal often concerns conditional average treatment effects (CATEs) of particular subgroups or treatment effects conditioning on a (set of) covariate(s). This study examines several parametric and nonparametric methods for CATE estimation. Specifically, we apply two machine learning methods, causal forest (CF) and Bayesian additive regression trees (BART), and two doubly-robust multilevel modeling approaches to the synthetic data used for the data challenge at the 2018 Atlantic Causal Inference Conference. We conclude with a discussion on the issues and challenges of different methods in estimating and interpreting CATE. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-27781-8_3
VL  - 422
SP  - 31
EP  - 39
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164695593&doi=10.1007%2f978-3-031-27781-8_3&partnerID=40&md5=4f7e7008c1f201621d5ba8cb1c3c8c18
DB  - Scopus
KW  - Machine learning
KW  - Behavioral research
KW  - Machine-learning
KW  - Regression analysis
KW  - Parameter estimation
KW  - Observational study
KW  - Forestry
KW  - Propensity score
KW  - Additives
KW  - Average treatment effects
KW  - Bayesian additive regression tree
KW  - Bayesian additive regression trees
KW  - Bayesian Additive Regression Trees (BART)
KW  - Causal forest
KW  - Clustered data
KW  - Clustered datum
KW  - Conditional average
KW  - Conditional average treatment effect
KW  - Conditional average treatment effects
KW  - Doubly-robust estimator
KW  - Doubly-robust estimators
KW  - Hierarchical linear modeling
KW  - Hierarchical linear models
KW  - Multilevel modeling
KW  - Multilevel models
KW  - Observational studies
KW  - Propensity scores
KW  - Robust estimators
ER  - 

TY  - JOUR
TI  - Robust PAC $^m$ : Training Ensemble Models Under Misspecification and Outliers
AU  - Zecchin, M.
AU  - Park, S.
AU  - Simeone, O.
AU  - Kountouris, M.
AU  - Gesbert, D.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Standard Bayesian learning is known to have suboptimal generalization capabilities under misspecification and in the presence of outliers. Probably approximately correct (PAC)-Bayes theory demonstrates that the free energy criterion minimized by Bayesian learning is a bound on the generalization error for Gibbs predictors (i.e., for single models drawn at random from the posterior) under the assumption of sampling distributions uncontaminated by outliers. This viewpoint provides a justification for the limitations of Bayesian learning when the model is misspecified, requiring ensembling, and when data are affected by outliers. In recent work, PAC-Bayes bounds&#x2014;referred to as PAC<inline-formula> <tex-math notation="LaTeX">$^m$</tex-math> </inline-formula>&#x2014;were derived to introduce free energy metrics that account for the performance of ensemble predictors, obtaining enhanced performance under misspecification. This work presents a novel robust free energy criterion that combines the generalized logarithm score function with PAC<inline-formula> <tex-math notation="LaTeX">$^m$</tex-math> </inline-formula> ensemble bounds. The proposed free energy training criterion produces predictive distributions that are able to concurrently counteract the detrimental effects of misspecification&#x2014;with respect to both likelihood and prior distribution&#x2014;and outliers. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3295168
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165930061&doi=10.1109%2fTNNLS.2023.3295168&partnerID=40&md5=0315aab5db2191d0d1fc5435c2c03206
DB  - Scopus
KW  - machine learning
KW  - Predictive models
KW  - Bayes methods
KW  - Training
KW  - Standards
KW  - robustness
KW  - Learning systems
KW  - Machine-learning
KW  - Europe
KW  - Robustness
KW  - Statistics
KW  - outliers
KW  - Outlier
KW  - Bayes method
KW  - Bayesian learning
KW  - Latexes
KW  - Ensemble models
KW  - IEEE Standards
KW  - ensemble models
KW  - Free energy
KW  - misspecification
KW  - Misspecification
KW  - Pollution measurement
ER  - 

TY  - JOUR
TI  - Exposing the many biases in machine learning
AU  - Richardson, S.
T2  - Business Information Review
AB  - In recent years, there have been numerous articles highlighting issues with bias in machine learning algorithms underpinning the use of AI in decision making. Specifically, algorithms trained on historical real-world observations. However, less is written about the many ways bias can be introduced into the machine learning process. This article outlines 12 different types of bias that can occur during the data science process, from capture through curation to analysis and application. © The Author(s) 2022.
DA  - 2022///
PY  - 2022
DO  - 10.1177/02663821221121024
VL  - 39
IS  - 3
SP  - 82
EP  - 89
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136078566&doi=10.1177%2f02663821221121024&partnerID=40&md5=850a3af53e67fad9d528d66c1a946e60
DB  - Scopus
KW  - machine learning
KW  - artificial intelligence
KW  - big data
KW  - responsible AI
KW  - algorithms
KW  - bias
ER  - 

TY  - JOUR
TI  - TOWARD THEORETICAL UNDERSTANDINGS OF ROBUST MARKOV DECISION PROCESSES: SAMPLE COMPLEXITY AND ASYMPTOTICS
AU  - Yang, W.
AU  - Zhang, L.
AU  - Zhang, Z.
T2  - Annals of Statistics
AB  - In this paper, we study the nonasymptotic and asymptotic performances of the optimal robust policy and value function of robust Markov Decision Processes (MDPs), where the optimal robust policy and value function are estimated from a generative model. While prior work focusing on nonasymptotic performances of robust MDPs is restricted in the setting of the KL uncertainty set and (s, a)-rectangular assumption, we improve their results and also consider other uncertainty sets, including the L1 and χ2 balls. Our results show that when we assume (s, a)-rectangular on uncertainty sets, the sample complexity is about Õ(ε2ρ|S2| (21|−Aγ|)4 ). In addition, we extend our results from the (s, a)-rectangular assumption to the s-rectangular assumption. In this scenario, the sample complexity varies with the choice of uncertainty sets and is generally larger than the case under the (s, a)-rectangular assumption. Moreover, we also show that the optimal robust value function is asymptotically normal with a typical rate √n under the (s, a) and s-rectangular assumptions from both theoretical and empirical perspectives. © Institute of Mathematical Statistics, 2022.
DA  - 2022///
PY  - 2022
DO  - 10.1214/22-AOS2225
VL  - 50
IS  - 6
SP  - 3223
EP  - 3248
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146154015&doi=10.1214%2f22-AOS2225&partnerID=40&md5=723751e274cff9bb4545c4dc621e4f1b
DB  - Scopus
KW  - Model-based reinforcement learning
KW  - distributional robustness
KW  - f - divergence set
KW  - robust MDPs
ER  - 

TY  - JOUR
TI  - Improving the Reliability of Network Intrusion Detection Systems Through Dataset Integration
AU  - Magan-Carrion, R.
AU  - Urda, D.
AU  - Diaz-Cano, I.
AU  - Dorronsoro, B.
T2  - IEEE Transactions on Emerging Topics in Computing
AB  - This work presents Reliable-NIDS (R-NIDS), a novel methodology for Machine Learning (ML) based Network Intrusion Detection Systems (NIDSs) that allows ML models to work on integrated datasets, empowering the learning process with diverse information from different datasets. We also propose a new dataset, called UNK22. It is built from three of the most well-known network datasets (UGR'16, USNW-NB15 and NLS-KDD), each one gathered from its own network environment, with different features and classes, by using a data aggregation approach present in R-NIDS. Therefore, R-NIDS targets the design of more robust models that generalize better than traditional approaches. Following R-NIDS, in this work we propose to build two well-known ML models for reliable predictions thanks to the meaningful information integrated in UNK22. The results show how these models benefit from the proposed approach, being able to generalize better when using UNK22 in the training process, in comparison to individually using the datasets composing it. Furthermore, these results are carefully analyzed with statistical tools that provide high confidence on our conclusions. Finally, the proposed solution is feasible to be deployed in network production environments, not usually taken into account in the literature.  © 2013 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TETC.2022.3178283
VL  - 10
IS  - 4
SP  - 1717
EP  - 1732
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131712238&doi=10.1109%2fTETC.2022.3178283&partnerID=40&md5=c77e3baa7570a6dab0c4c2db0dc6e363
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Intrusion detection
KW  - Features extraction
KW  - Machine-learning
KW  - Machine learning models
KW  - Network security
KW  - Computer crime
KW  - Statistical tests
KW  - Robust network
KW  - data aggregation
KW  - Data aggregation
KW  - data integration
KW  - Data integration
KW  - Network intrusion detection systems
KW  - network security
KW  - Networks security
KW  - NIDS
KW  - Robust network intrusion detection system
KW  - Robust network intrusion detection systems
KW  - Statistical mechanics
ER  - 

TY  - JOUR
TI  - Adaptive Proxy-based Robust Production Optimization with Multilayer Perceptron
AU  - Ng, C.S.W.
AU  - Jahanbani Ghahfarokhi, A.
T2  - Applied Computing and Geosciences
AB  - Machine learning (ML) has been a technique employed to build data-driven models that can map the relationship between the input and output data provided. ML-based data-driven models offer an alternative path to solving optimization problems, which are conventionally resolved by applying simulation models. Higher computational cost is induced if the simulation model is computationally intensive. Such a situation aptly applies to petroleum engineering, especially when different geological realizations of numerical reservoir simulation (NRS) models are considered for production optimization. Therefore, data-driven models are suggested as a substitute for NRS. In this work, we demonstrated how multilayer perceptron could be implemented to build data-driven models based on 10 realizations of the Egg Model. These models were then coupled with two nature-inspired algorithms, viz. particle swarm optimization and grey wolf optimizer to solve waterflooding optimization. These data-driven models were adaptively re-trained by applying a training database that was updated via the addition of extra samples retrieved from optimization with the proxy models. The details of the methodology will be divulged in the paper. According to the results obtained, we could deduce that the methodology generated reliable data-driven models to solve the optimization problem, as justified by the excellent performance of the ML-based proxy model (with a coefficient of determination, R2 exceeding 0.98 in training, testing, and blind validation) and accurate optimization result (less than 1% error between the Expected Net Present Values optimized using NRS and proxy models). This study aids in an enhanced understanding of implementing adaptive training in tandem with optimization in ML-based proxy modeling. © 2022 The Authors
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.acags.2022.100103
VL  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139841622&doi=10.1016%2fj.acags.2022.100103&partnerID=40&md5=3f0905ab8d1fc4e1761b9f2f62b3f273
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Biomimetics
KW  - Multilayer perceptron
KW  - Multilayers
KW  - Multilayers perceptrons
KW  - Data-driven model
KW  - Multilayer neural networks
KW  - Particle swarm optimization (PSO)
KW  - Adaptive training
KW  - Data-driven modeling
KW  - Nature inspired algorithms
KW  - Nature-inspired algorithms
KW  - Numerical reservoir simulations
KW  - Production optimization
KW  - Proxy model
KW  - Robust production
KW  - Robust production optimization
ER  - 

TY  - CONF
TI  - Zero-Sum Game-Based Controller Design Using Reinforcement Learning for Formation Tracking of Multi-agent Systems
AU  - Shi, Y.
AU  - Dong, X.
AU  - Zhang, S.
AU  - Yu, J.
AU  - Ren, Z.
T2  - Lecture Notes in Electrical Engineering
AB  - This paper proposes a hierarchical distributed formation tracking controller for continuous multi-agent systems (MASs). Firstly, a zero-sum game-based regulation controller is designed according to a min-max game cost function with respect to the control-player and a disturbance-player using reinforcement learning (RL). The H∞ robust property against perturbations is equivalently guaranteed. Secondly, the Q-learning based iteration method is implemented to continuous system to generate a stable controller. This regulator can be obtained using operational data associated with the original system. Thirdly, the distributed formation tracking controller with feedforward terms and feasible condition is further proposed based on the previous learning results to realize time-varying formation tracking while a brief stability analysis is given. Finally, simulation results are provided to illustrate the effectiveness of the proposed learning and control frame. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-19-3998-3_139
VL  - 934 LNEE
SP  - 1487
EP  - 1497
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135863677&doi=10.1007%2f978-981-19-3998-3_139&partnerID=40&md5=bfae6d3e3601f040cd607a11328a8b62
DB  - Scopus
KW  - Game theory
KW  - Multi-agent systems
KW  - Reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Controllers
KW  - Cost functions
KW  - Hierarchical systems
KW  - Robust control
KW  - Multi agent systems
KW  - Iterative methods
KW  - Controller designs
KW  - Cost-function
KW  - Distributed formation tracking
KW  - Formation tracking
KW  - Game-Based
KW  - H ∞
KW  - Min-max
KW  - Tracking controller
KW  - Zero-sum game
ER  - 

TY  - CONF
TI  - Data Characterization for Reliable AI in Medicine
AU  - Rajaraman, S.
AU  - Zamzmi, G.
AU  - Yang, F.
AU  - Xue, Z.
AU  - Antani, S.K.
T2  - Communications in Computer and Information Science
AB  - Research in Artificial Intelligence (AI)-based medical computer vision algorithms bear promises to improve disease screening, diagnosis, and subsequently patient care. However, these algorithms are highly impacted by the characteristics of the underlying data. In this work, we discuss various data characteristics, namely Volume, Veracity, Validity, Variety, and Velocity, that impact the design, reliability, and evolution of machine learning in medical computer vision. Further, we discuss each characteristic and the recent works conducted in our research lab that informed our understanding of the impact of these characteristics on the design of medical decision-making algorithms and outcome reliability. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-23599-3_1
VL  - 1704 CCIS
SP  - 3
EP  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148690855&doi=10.1007%2f978-3-031-23599-3_1&partnerID=40&md5=65450de71c102771b43a883d5914a9f7
DB  - Scopus
KW  - Deep learning
KW  - Artificial intelligence
KW  - Machine learning
KW  - Decision making
KW  - Learning systems
KW  - Diagnosis
KW  - Machine-learning
KW  - Computer vision
KW  - Computer vision algorithms
KW  - Medical imaging
KW  - Robustness
KW  - Medical computing
KW  - Reliability
KW  - Generalizability
KW  - Artificial intelligence in medicine
KW  - Data characteristics
KW  - Data characterization
KW  - Data-driven design
KW  - Disease screening
ER  - 

TY  - JOUR
TI  - Training Demand Prediction Models by Decision Error for Two-Stage Lot-Sizing Problems
AU  - Gong, H.
AU  - Zhang, Y.
AU  - Zhang, Z.
T2  - IEEE Transactions on Automation Science and Engineering
AB  - Demand prediction to support appropriate production decisions is being actively studied. Many prediction models are designed to minimize the prediction error, which is measured by determining the difference between the predicted and ground-truth demand. However, these models ignore the effect of the prediction error on downstream production decisions. This prompted our study, which focuses on demand prediction models for two-stage uncapacitated lot-sizing problems. In this paper, we present a prediction model that minimizes the decision error, which is measured by the optimization objective of lot-sizing problems. Our model mitigates the impact of prediction errors by leveraging the structure of the lot-sizing problems. To enhance the ability to accommodate imperfect data, such as data based on inaccurate information, we subsequently extend the prediction models to distributionally robust versions. We consider the worst-case formulation in the feature space to enhance the robustness of the model to data imperfection. Numerical experiments demonstrate that the proposed prediction models are significantly superior to the traditional prediction methods when the model being trained is misspecified. In addition, the robust extension enables the models to train well on imperfect datasets while requiring less training data. <italic>Note to Practitioners</italic>&#x2014;This study is motivated by the two-stage lot-sizing problem in manufacturing systems which involves the determination of the time at which (the setup decisions) to produce before the demand is revealed, and the production quantity decisions are adjusted during production processing. Predicting the demand properly while making the set-up decisions helps to decrease the production cost. This paper proposes a novel method that aims to minimize the total production cost to train demand prediction models. Practitioners can deploy the proposed method to train popular prediction models including linear prediction, decision tree, and neural network models. It is shown that the production cost associated with the decisions based on our models is lower than that associated with the traditional prediction models. Furthermore, our method enhances the ability of the model to handle model misspecification and imperfect data. Practitioners can apply our method to overcome the problems caused by imperfect data such as those containing contaminated and inaccurate measurements. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TASE.2023.3248623
SP  - 1
EP  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149372111&doi=10.1109%2fTASE.2023.3248623&partnerID=40&md5=dd8ce124b2390cd29e93f1f2e20771ce
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Predictive models
KW  - Data models
KW  - Optimization
KW  - Costs
KW  - Production
KW  - Decision error
KW  - distributionally robust
KW  - joint prediction and optimization
KW  - lot-sizing problem
KW  - Stochastic processes
ER  - 

TY  - JOUR
TI  - Deep Multiview Adaptive Clustering With Semantic Invariance
AU  - Gao, J.
AU  - Liu, M.
AU  - Li, P.
AU  - Zhang, J.
AU  - Chen, Z.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Multiview clustering has attracted significant attention in various fields, due to the superiority in mining patterns of multiview data. However, previous methods are still confronted with two challenges. First, they do not fully consider the semantic invariance of multiview data in aggregating complementary information, degrading semantic robustness of fusion representations. Second, they rely on predefined clustering strategies to mine patterns, lacking adequate explorations of data structures. To address the challenges, deep multiview adaptive clustering via semantic invariance (DMAC-SI) is proposed, which learns an adaptive clustering strategy on semantics-robust fusion representations to fully explore structures in mining patterns. Specifically, a mirror fusion architecture is devised to explore interview invariance and intrainstance invariance hidden in multiview data, which captures invariant semantics of complementary information to learn semantics-robust fusion representations. Then, a Markov decision process of multiview data partitions is proposed within the reinforcement learning framework, which learns an adaptive clustering strategy on semantics-robust fusion representations to guarantee the structure explorations in mining patterns. The two components seamlessly collaborate in an end-to-end manner to accurately partition multiview data. Finally, extensive experiment results on five benchmark datasets demonstrate that DMAC-SI outperforms the state-of-the-art methods. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3265699
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159793828&doi=10.1109%2fTNNLS.2023.3265699&partnerID=40&md5=e243548471776613ae4c96ffb8831554
DB  - Scopus
KW  - Deep learning
KW  - Semantics
KW  - Reinforcement learning
KW  - Data mining
KW  - Reinforcement learnings
KW  - Robustness
KW  - Markov processes
KW  - Data structures
KW  - Clustering algorithms
KW  - Cluster analysis
KW  - Adaptive clustering
KW  - Deep multiview clustering
KW  - Fusion architecture
KW  - mirror fusion architecture
KW  - Mirror fusion architecture
KW  - Mirrors
KW  - Multi-view clustering
KW  - Multi-view datum
KW  - reinforcement partitioning
KW  - Reinforcement partitioning
KW  - semantic invariance
KW  - Semantic invariance
ER  - 

TY  - JOUR
TI  - Blockchain Empowered Edge Intelligence for TACS Obstacle Detection: System Design and Performance Optimization
AU  - Liang, H.
AU  - Zhu, L.
AU  - Yu, F.R.
AU  - Ma, Z.
T2  - IEEE Transactions on Industrial Informatics
AB  - With the significant advantages of system complexity and operating costs, Train Autonomous Circumambulate System (TACS) is gradually replacing the traditional Communication Based Train Control (CBTC) system as the next-generation train operation control system development direction. As train operation and control become more decentralized and autonomous, real-time and accurate obstacle detection, apart from route-level protection, is quite desirable in TACS. Most of the existing researches about obstacle detection focus on detection algorithm optimization based on the once-deployed lifelong use principle, while model re-optimization based on the actual operating environment under unexpected situations and model sharing among multi-users are largely ignored. In this paper, we design a novel obstacle detection system in TACS based on blockchain-empowered Edge Intelligence (EI). To make full use of the massive raw unannotated data collected online, we first propose an SSL-based TACS obstacle detection model. Considering the resource-hungry model training, we introduce EI into TACS and propose a MARL-based task offloading algorithm for secure and efficient computation offloading coordination. Furthermore, we propose a blockchain-based model sharing scheme to facilitate the multi-model parameter exchange and improve the obstacle detection accuracy. Extensive simulation results show that the designed obstacle detection system can effectively improve the TACS obstacle detection performance. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TII.2023.3257308
SP  - 1
EP  - 10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151372152&doi=10.1109%2fTII.2023.3257308&partnerID=40&md5=f60ac8570a9f56317ed42253eefe972a
DB  - Scopus
KW  - Safety
KW  - Task analysis
KW  - Computational modeling
KW  - Data models
KW  - Training
KW  - Real-time systems
KW  - Blockchain
KW  - Multi-agent reinforcement learning
KW  - Rails
KW  - Edge intelligence
KW  - Obstacle detection
KW  - Train Autonomous Circumambulate System
ER  - 

TY  - JOUR
TI  - Physics-informed Graphical Representation-enabled Deep Reinforcement Learning for Robust Distribution System Voltage Control
AU  - Cao, D.
AU  - Zhao, J.
AU  - Hu, J.
AU  - Pei, Y.
AU  - Huang, Q.
AU  - Chen, Z.
AU  - Hu, W.
T2  - IEEE Transactions on Smart Grid
AB  - The anomalous measurements and inaccurate distribution system physical models cause huge challenges for distribution system optimization. This paper proposes a robust voltage control method that can deal with them by systematically integrating a representation network, the deep reinforcement learning (DRL) method, and the surrogate model. The partial observation of the distribution network is first represented as a graph with tree topology that is processed by a physics-informed global graph attention network (GGAT) and a deep auto-encoder (DAE) to achieve informative and robust representation of the real-time and pseudo-measurements. The extracted features are then fed into the soft actor-critic algorithm, during the training of which a graphical-learning-based power flow surrogate model is developed to provide a reward signal for the DRL algorithm. This allows the proposed method to reduce reliance on accurate distribution system parameters. The embedding of the structural information by the GGAT and the informative features extracted by the DAE further enhances the robustness of the proposed method against anomalous measurements. The proposed method is validated using IEEE 33-node and 119-node systems. Simulation results show the robustness of the proposed method against anomalous measurements. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TSG.2023.3267069
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159804185&doi=10.1109%2fTSG.2023.3267069&partnerID=40&md5=957a20fba3535b82e66a83892de5e54b
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Training
KW  - Reinforcement learnings
KW  - Uncertainty
KW  - Robustness (control systems)
KW  - Uncertainty analysis
KW  - Electric load flow
KW  - Trees (mathematics)
KW  - Electric inverters
KW  - Distribution systems
KW  - Electric power distribution
KW  - Voltage control
KW  - Surrogate modeling
KW  - Power control
KW  - Reactive power
KW  - Inverter
KW  - Auto encoders
KW  - Distribution system voltages
KW  - Graphical representations
KW  - Inverters
KW  - Physical modelling
KW  - Static VAr compensator
KW  - Static VAr compensators
KW  - Voltage measurement
ER  - 

TY  - JOUR
TI  - A Data-driven Framework for Power System Event Type Identification via Safe Semi-supervised Techniques
AU  - Yuan, Y.
AU  - Wang, Y.
AU  - Wang, Z.
T2  - IEEE Transactions on Power Systems
AB  - This paper investigates the use of phasor measurement unit (PMU) data with deep learning techniques to construct real-time event identification models for transmission networks. Increasing penetration of distributed energy resources represents a great opportunity to achieve decarbonization, as well as challenges in systematic situational awareness. When high-resolution PMU data and sufficient manually recorded event labels are available, the power event identification problem is defined as a statistical classification problem that can be solved by numerous cutting-edge classifiers. However, in real grids, collecting tremendous high-quality event labels is quite expensive. Utilities frequently have a large number of event records without in-depth details (i.e., unlabeled events). To bridge this gap, we propose a novel semi-supervised learning-based method to improve the performance of event classifiers trained with a limited number of labeled events by exploiting the information from massive unlabeled events. In other words, compared to existing data-driven methods, our method requires only a small portion of labeled data to achieve a similar level of accuracy. Meanwhile, this work discusses and addresses the performance degradation caused by class distribution mismatch between the training set and the real applications. Specifically, this method utilizes pseudo-labeling technique to investigate the value of unlabeled events and incrementally expands the training dataset. Moreover, a safe learning mechanism is developed to mitigate the impacts of class distribution mismatch and prevent performance degradation. Based on the proposed safe learning mechanism, our model does not directly use all unlabeled events during model training, but selectively uses them through a comprehensive evaluation procedure. Numerical studies on a sizable PMU dataset have been used to validate the performance of the proposed method. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPWRS.2023.3266153
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153366084&doi=10.1109%2fTPWRS.2023.3266153&partnerID=40&md5=e1b527a08933933946e61067a9f9a11a
DB  - Scopus
KW  - Deep learning
KW  - Data models
KW  - Training
KW  - Support vector machines
KW  - Supervised learning
KW  - Learning algorithms
KW  - Performance
KW  - Classification (of information)
KW  - Electric power transmission networks
KW  - Semi-supervised learning
KW  - Power
KW  - Numerical methods
KW  - Power quality
KW  - Semisupervised learning
KW  - Electric power transmission
KW  - Support vectors machine
KW  - safe learning
KW  - Safe learning
KW  - Semi-supervised
KW  - Energy resources
KW  - Degradation
KW  - Event identification
KW  - Performance degradation
KW  - Phase measurement
KW  - phasor measurement unit
KW  - Phasor measurement units
KW  - semi-supervised model
KW  - Semi-supervised model
KW  - unlabeled event
KW  - Unlabeled event
ER  - 

TY  - CONF
TI  - Crime Data Analysis and Safety Recommendation System Using Machine Learning
AU  - Akil, R.M.
AU  - Sarathambekai, S.
AU  - Vairam, T.
AU  - Krishnan, R.S.
AU  - Dharaneesh, G.S.
AU  - Janarthanan, D.
T2  - 2023 9th International Conference on Advanced Computing and Communication Systems, ICACCS 2023
AB  - Crime is the intentional commission of an act that is often seen as risky or socially damaging, specifically prohibited by law, and punishable. [1] Judicial rulings used to be the main method of defining crimes in the common-law system. [2] Today, most common-law offenses are governed by statutes. Many people hold the opinion that a crime cannot exist without a law. Behavior and an associated state of mind are the usual elements of a crime. Criminal offences include things like arson, assault, bribery, burglary, child exploitation, counterfeiting, embezzlement, extortion, forgery, fraud, hijacking, murder, kidnapping, perjury, piracy, rape, sedition, smuggling, treason, theft, and usury. [5] The major goal of this initiative is to assist people who often visit new locations by teaching them about the region's criminal history so that they may exercise caution and avoid being a victim of any kind of crime. [7] The user may clearly comprehend the most frequent crimes in the area and how often each crime occurs in different parts of the state given the extensive analysis of the crime data. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICACCS57279.2023.10113102
SP  - 183
EP  - 188
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159756215&doi=10.1109%2fICACCS57279.2023.10113102&partnerID=40&md5=4c27c1db5fae6f4bc9a5e0f871cbde66
DB  - Scopus
KW  - Machine learning
KW  - Visualization
KW  - Machine Learning
KW  - Machine-learning
KW  - Data visualization
KW  - Crime
KW  - Common law
KW  - Crime analyse
KW  - Crime Analysis
KW  - Crime data
KW  - Criminal offences
KW  - K-means++ clustering
KW  - KMeans Clustering
KW  - NCRB
KW  - Safety recommendations
ER  - 

TY  - JOUR
TI  - Real-time Sequential Security-Constrained Optimal Power Flow: A Hybrid Knowledge-Data-Driven Reinforcement Learning Approach
AU  - Yi, Z.
AU  - Wang, X.
AU  - Yang, C.
AU  - Yang, C.
AU  - Niu, M.
AU  - Yin, W.
T2  - IEEE Transactions on Power Systems
AB  - To confront the inaccuracy and imperfection of the environmental model, this article proposes a hybrid knowledge-data-driven reinforcement learning (KDD-RL) approach to solve the sequential optimal power flow problem during real-time operation. An improved soft actor-critic algorithm is proposed to train the control policy and formulate the sequential dispatch commands to the generators. To promote the safe exploration of the reinforcement learning algorithm, a hybrid knowledge-data-driven safety layer is developed to convert the unsafe actions into the safety region. Furthermore, a security-constrained linear projection model with an inactive constraint identification process is proposed to accelerate the computation efficiency of the safety layer. Numerical simulation results verify the superiority and scalability of the proposed approach in improving the decision-making efficiency and promoting the security operation of the power systems. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPWRS.2023.3262843
SP  - 1
EP  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151558357&doi=10.1109%2fTPWRS.2023.3262843&partnerID=40&md5=25d039cabdc1736f138408cf6d4c99a3
DB  - Scopus
KW  - Reinforcement learning
KW  - Safety
KW  - Security
KW  - Decision making
KW  - reinforcement learning
KW  - Training
KW  - Learning algorithms
KW  - Accident prevention
KW  - Real time systems
KW  - Reinforcement learnings
KW  - Efficiency
KW  - Electric load flow
KW  - Power
KW  - Power system
KW  - Power systems
KW  - Safety layer
KW  - Electric load dispatching
KW  - Generators
KW  - Load flow
KW  - Acoustic generators
KW  - economic dispatch
KW  - Economic Dispatch
KW  - Generator
KW  - Optimal power flow
KW  - Optimal power flows
KW  - safety layer
ER  - 

TY  - JOUR
TI  - On the Robustness of Average Losses for Partial-Label Learning
AU  - Lv, J.
AU  - Liu, B.
AU  - Feng, L.
AU  - Xu, N.
AU  - Xu, M.
AU  - An, B.
AU  - Niu, G.
AU  - Geng, X.
AU  - Sugiyama, M.
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - <italic>Partial-label learning</italic>&#x00A0;(PLL) utilizes instances with PLs, where a PL includes several candidate labels but only one is the true label (TL). In PLL, <italic>identification-based strategy</italic>&#x00A0;(IBS) purifies each PL on the fly to select the (most likely) TL for training; <italic>average-based strategy</italic>&#x00A0;(ABS) treats all candidate labels equally for training and let trained models be able to predict TL. Although PLL research has focused on IBS for better performance, ABS is also worthy of study since <italic>modern IBS behaves like ABS in the beginning of training</italic> to prepare for PL purification and TL selection. In this paper, we analyze why ABS was unsatisfactory and propose how to improve it. Theoretically, we propose two problem settings of PLL and prove that <italic>average PL</italic> losses&#x00A0;(APLLs) with <italic>bounded</italic> multi-class losses are <italic>always</italic> robust, while APLLs with <italic>unbounded</italic> losses may be non-robust, which is the first robustness analysis for PLL. Experimentally, we have two promising findings: ABS using bounded losses can match/exceed state-of-the-art performance of IBS using unbounded losses; after using robust APLLs to warm start, IBS can further improve upon itself. Our work draws attention to ABS research, which can in turn boost IBS and push forward the whole PLL. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPAMI.2023.3275249
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159796877&doi=10.1109%2fTPAMI.2023.3275249&partnerID=40&md5=d93829adda7ecdce1f3c138695169cb5
DB  - Scopus
KW  - Deep learning
KW  - Predictive models
KW  - Training
KW  - Learning systems
KW  - Robustness
KW  - Noise measurement
KW  - weakly supervised learning
KW  - Weakly supervised learning
KW  - Reliability analysis
KW  - Noise measurements
KW  - Robustness analysis
KW  - Average loss
KW  - On-the-fly
KW  - Partial-label learning
KW  - Phase locked loops
KW  - Reliability theory
KW  - robust loss
KW  - Robust loss
KW  - robustness analysis
ER  - 

TY  - CONF
TI  - Simulation: The Great Enabler?: Synthetic Data for Supercharging AI Military Systems
AU  - Liegl, C.J.
AU  - Nickchen, T.
AU  - Strunz, E.
AU  - Horn, A.
AU  - Coppenrath, A.
AU  - Uysal, U.
AU  - Ruß, M.
AU  - Luft, F.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Autonomous systems (AxS) have successfully been employed in military tasks such as search and rescue, logistics, and reconnaissance. Whether it be on land, at sea, or in the air, diverse and representative training samples are indispensable for operationalising recent advances in artificial intelligence (AI). Applying deep learning to the task of armoured fighting vehicle (AFV) recognition, we examine the role synthetic data are capable of playing in training image classification and object detection models. To this end we implement a modular pipeline for the controlled generation of synthetic samples and their combination with real data with downstream building blocks for data augmentation and adversarial machine learning. This lets us conduct well-structured experiments (e.g., involving varying lighting conditions or adversarial perturbations) and develop hypotheses regarding the most beneficial composition of the training data set and the influence of individual pipeline building blocks on performance or robustness. In order to bridge the simulation-to-reality gap we use data augmentation techniques akin to domain randomisation. In particular, we fuse images with fractal pat-terns, which, in their structural complexity, resemble many forms of military camouflage. Anticipating adversarial attacks on our computer vision systems, we also train a set of more robust models by means of adversarial training, a well-studied defensive measure. Our experiments follow a rigorous evaluation protocol accounting for the multidimensional nature of both performance and robustness. We envision future applications of our thorough approach to training AxS beyond AFV recognition – in all dimensions of modern battlespace. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-31268-7_19
VL  - 13866 LNCS
SP  - 312
EP  - 325
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161710575&doi=10.1007%2f978-3-031-31268-7_19&partnerID=40&md5=3d78097b66f52b053b0eba359722cb27
DB  - Scopus
KW  - Deep learning
KW  - AI
KW  - Deep Learning
KW  - Learning systems
KW  - Machine-learning
KW  - Image classification
KW  - Object detection
KW  - Image Classification
KW  - Images classification
KW  - Robustness
KW  - Object recognition
KW  - Objects detection
KW  - Object Detection
KW  - Adversarial machine learning
KW  - Adversarial Machine Learning
KW  - Data augmentation
KW  - AFV
KW  - AFVs
KW  - AxS
KW  - Camouflage
KW  - Data Augmentation
KW  - Fractals
KW  - Land-based systems
KW  - Land-Based Systems
KW  - Military vehicles
KW  - Modeling simulation
KW  - Modelling & Simulation
KW  - Reality gaps
KW  - Simulation-to-reality-gap
KW  - Simulation-to-Reality-Gap
ER  - 

TY  - CONF
TI  - Magical-Decomposition: Winning Both Adversarial Robustness and Efficiency on Hardware
AU  - Cheng, X.
AU  - Wang, M.-Q.
AU  - Shi, Y.-B.
AU  - Lin, J.
AU  - Wang, Z.-F.
T2  - Proceedings - International Conference on Machine Learning and Cybernetics
AB  - Model compression is one of the most preferred techniques for efficiently deploying deep neural networks (DNNs) on resource- constrained Internet of Things (IoT) platforms. However, the simply compressed model is often vulnerable to adversarial attacks, leading to a conflict between robustness and efficiency, especially for IoT devices exposed to complex real-world scenarios. We, for the first time, address this problem by developing a novel framework dubbed Magical-Decomposition to simultaneously enhance both robustness and efficiency for hardware. By leveraging a hardware-friendly model compression method called singular value decomposition, the defending algorithm can be supported by most of the existing DNN hardware accelerators. To step further, by using a recently developed DNN interpretation tool, the underlying scheme of how the adversarial accuracy can be increased in the compressed model is highlighted clearly. Ablation studies and extensive experiments under various attacks/models/datasets consistently validate the effectiveness and scalability of the proposed framework.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICMLC56445.2022.9941335
VL  - 2022-September
SP  - 61
EP  - 66
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142519587&doi=10.1109%2fICMLC56445.2022.9941335&partnerID=40&md5=29ec8bb5adc60ef337a0f8fce8ae409c
DB  - Scopus
KW  - Machine learning
KW  - Deep neural networks
KW  - Internet of things
KW  - Machine-learning
KW  - Efficiency
KW  - Robustness
KW  - Real-world scenario
KW  - Adversarial training
KW  - Singular value decomposition
KW  - Compression methods
KW  - Decomposition
KW  - Exposed to
KW  - Hardware accelerators
KW  - Interpretation tools
KW  - Model compression
KW  - Neural network hardware
ER  - 

TY  - CONF
TI  - Research on Network Security Authentication Method Based on Data Mining Technology
AU  - Ma, X.-G.
AU  - Wang, H.-Y.
T2  - Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST
AB  - In order to solve the problems of low authentication accuracy, long authentication time and poor authentication security in traditional network security authentication methods, this paper uses data mining technology to design a new network security authentication method. First, analyze the types of attacks on the network by illegal nodes on the network and the principles of authentication, and then mine the data to be authenticated through the binary network. In order to reduce the mining error, the acquired data is punished and integrated. In this process, in order to ensure the effective iteration of the data, the neural network algorithm in the machine learning algorithm is introduced for in-depth mining. The experimental results show that the authentication accuracy of this method can reach up to 98%, and the authentication time is always less than 2 s. The above results show that: after adopting this method, the network security performance can be improved. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-94182-6_2
VL  - 415 LNICST
SP  - 19
EP  - 29
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133241950&doi=10.1007%2f978-3-030-94182-6_2&partnerID=40&md5=1d69d88df76a91abf2d7c246f6334920
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Machine learning algorithms
KW  - Learning algorithms
KW  - Network security
KW  - Iterative methods
KW  - Machine learning algorithm
KW  - Networks security
KW  - Authentication
KW  - Authentication methods
KW  - Authentication time
KW  - Data mining technology
KW  - Illegal nodes
KW  - Neural networks algorithms
KW  - Safety certification
KW  - Security authentication
KW  - Security performance
ER  - 

TY  - CONF
TI  - A System for Network Based Intrusion Avoidance Using Dedicated Machine Learning and Artificial Intelligence-Based Model for Application and Data Safety
AU  - Manjunath, H.
AU  - Saravana Kumar, S.
T2  - Communications in Computer and Information Science
AB  - The influx in usage of internet has led to decent amount of risk happening on target application systems and servers which are part of the ecosystem. Detecting the unwanted events which might be triggered by security loophole or improper deciphering the messages is the most common phenomenon in the current practice. Such unfavorable events are called intrusion and detecting such intrusions are called as Intrusion detection. Our proposed system supports dynamic facets and handles multiple events with message queues. It is an intelligent system to handle the incoming events in a better way due to proposed tagging mechanism. This also handles the categorization of the intrusion detected values such that from the next occurrence of such events will be handled gracefully without making much utilization of computation and re-iteration of the events under observation. The whole categorized event handling ensures that there is no data loss due to threshold and latency issues which are commonly observed in current systems. This system ensures faster mode to reach the conclusion by making dynamic decision system development and feedback looping, for better grouping of the detected intrusions to take appropriate actions when needed. Such grouping helps to dynamically identify the threats observed through this system without manual intervention and allows the system to take actions based on the patterns observed using brute force methodologies. This provides a dedicated space for IT management to adopt much better guidelines to keep app, app gateway, servers, etc. safe. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-21385-4_20
VL  - 1673 CCIS
SP  - 227
EP  - 240
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145009939&doi=10.1007%2f978-3-031-21385-4_20&partnerID=40&md5=870ee67733f3b71885730f4399b7d4f4
DB  - Scopus
KW  - Machine learning
KW  - Intelligent systems
KW  - Intrusion detection
KW  - Machine-learning
KW  - Categorization
KW  - Iterative methods
KW  - Classification
KW  - Network-based
KW  - Application Servers
KW  - Application systems
KW  - Data safeties
KW  - Gateways (computer networks)
KW  - Intrusion
KW  - Message queue
KW  - Message queues
KW  - Tagging
KW  - Target application
ER  - 

TY  - JOUR
TI  - Feasibility Constrained Online Calculation for Real-Time Optimal Power Flow: A Convex Constrained Deep Reinforcement Learning Approach
AU  - Sayed, A.R.
AU  - Wang, C.
AU  - Anis, H.
AU  - Bi, T.
T2  - IEEE Transactions on Power Systems
AB  - Due to the increasing uncertainties of renewable energy and stochastic demands, quick-optimal control actions are necessary to retain the system stability and economic operation. Existing optimal power flow (OPF) solution methods need to be enhanced to guarantee the solution optimality and feasibility in real-time operation under such uncertainties. This paper proposes a convex constrained soft actor-critic (CC-SAC) deep reinforcement learning (DRL) algorithm for the AC-OPF problem. First, this problem is standardized as a Markov decision process model to be solved by DRL algorithms. Second, the operational constraints are satisfied by a novel convex safety layer based on the penalty convex-concave procedure (P-CCP). Then, the control policy is updated by the state-of-the-art off-policy entropy maximization-based SAC algorithm. Therefore, the CC-SAC is a combination of data-driven and physics-driven approaches. The former speedups the solution time by predicting near-optimum control actions through a deep neural network. The latter effectively guarantees the solution feasibility. Simulation results demonstrate the computational performance of the proposed CC-SAC to effectively find AC-OPF decisions with no constraint violation, zero optimality gap and high speed up to 34 times compared to a state-of-the-art solver. The proposed approach indicates its practicability for power system real-time operation and marketing. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TPWRS.2022.3220799
SP  - 1
EP  - 13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141636794&doi=10.1109%2fTPWRS.2022.3220799&partnerID=40&md5=f19e94781f1e7e4fd69e4b436f426659
DB  - Scopus
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - Training
KW  - Real-time systems
KW  - Learning algorithms
KW  - Interactive computer systems
KW  - Online systems
KW  - Real - Time system
KW  - Real time systems
KW  - Reinforcement learnings
KW  - Electric power transmission networks
KW  - Markov processes
KW  - Stochastic systems
KW  - Electric load flow
KW  - Electric power system control
KW  - Power system stability
KW  - Power systems stability
KW  - Programming
KW  - Convergence
KW  - Convex optimization
KW  - Actor-critic algorithm
KW  - Safe exploration
KW  - Load flow
KW  - Optimal power flow
KW  - Optimal power flows
KW  - Difference of convex programming
KW  - Difference-of-convex programming
KW  - Soft actor-critic algorithm
ER  - 

TY  - JOUR
TI  - Distributed Minmax Strategy for Multiplayer Games: Stability, Robustness, and Algorithms
AU  - Lian, B.
AU  - Donge, V.S.
AU  - Xue, W.
AU  - Lewis, F.L.
AU  - Davoudi, A.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - This article studies a distributed minmax strategy for multiplayer games and develops reinforcement learning (RL) algorithms to solve it. The proposed minmax strategy is distributed, in the sense that it finds each player&#x2019;s optimal control policy without knowing all the other players&#x2019; policies. Each player obtains its distributed control policy by solving a distributed algebraic Riccati equation in a multiplayer noncooperative game. This policy is found against the worst policies of all the other players. We guarantee the existence of distributed minmax solutions and study their <inline-formula> <tex-math notation="LaTeX">$\mathcal{L}_2$</tex-math> </inline-formula> and asymptotic stabilities. Under mild conditions, the resulting minmax control policies are shown to improve robust gain and phase margins of multiplayer systems compared to the standard linear&#x2013;quadratic regulator controller. Distributed minmax solutions are found using both model-based policy iteration and data-driven off-policy RL algorithms. Simulation examples verify the proposed formulation and its computational efficiency over the nondistributed Nash solutions. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TNNLS.2022.3215629
SP  - 1
EP  - 13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141612098&doi=10.1109%2fTNNLS.2022.3215629&partnerID=40&md5=60f75bf644660eb290489484efb67111
DB  - Scopus
KW  - Reinforcement learning
KW  - Computational modeling
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Robustness (control systems)
KW  - Robustness
KW  - Costs
KW  - Iterative methods
KW  - Game
KW  - reinforcement learning (RL)
KW  - Optimal control
KW  - Optimal controls
KW  - Computational modelling
KW  - Distributed parameter control systems
KW  - Computational efficiency
KW  - Games
KW  - Asymptotic stability
KW  - Distributed solution
KW  - Distributed solutions
KW  - Min-max control
KW  - minmax control
KW  - multiplayer games
KW  - Multiplayer games
KW  - Nash equilibria
KW  - Nash equilibrium
KW  - Riccati equations
KW  - robustness margins
KW  - Robustness margins
ER  - 

TY  - JOUR
TI  - 6th International Workshop on Cyber-Security and Functional Safety in Cyber-Physical Systems, IWCFS 2022, 4th International Workshop on Machine Learning and Knowledge Graphs, MLKgraphs 2022, 2nd International Workshop on Time Ordered Data, ProTime2022, 2nd International Workshop on AI System Engineering: Math, Modelling and Software, AISys2022, 1st International Workshop on Distributed Ledgers and Related Technologies, DLRT2022 and 1st International Workshop on Applied Research, Technology Transfer and Knowledge Exchange in Software and Data Science, ARTE2022 held at 33rd International Conference on Database and Expert Systems Applications, DEXA 2022
T2  - Communications in Computer and Information Science
AB  - The proceedings contain 40 papers. The special focus in this conference is on Database and Expert Systems Applications. The topics include: Synthetic Data in Automatic Number Plate Recognition; An Untold Tale of Scientific Collaboration: SCCH and AC 2 T; on the Creation and Maintenance of a Documentation Generator in an Applied Research Context; towards the Digitalization of Additive Manufacturing; Twenty Years of Successful Translational Research: A Case Study of Three COMET Centers; data Integration, Management, and Quality: From Basic Research to Industrial Application; building a YouTube Channel for Science Communication; introduction of Visual Regression Testing in Collaboration Between Industry and Academia; vibration Analysis for Rotatory Elements Wear Detection in Paper Mill Machine; applying Time-Inhomogeneous Markov Chains to Math Performance Rating; introducing Data Science Techniques into a Company Producing Electrical Appliances; a Technology Transfer Portal to Promote Industry-Academia Collaboration in South-Tyrol; fast and Automatic Object Registration for Human-Robot Collaboration in Industrial Manufacturing; sending Spies as Insurance Against Bitcoin Pool Mining Block Withholding Attacks; risks in DeFi-Lending Protocols - An Exploratory Categorization and Analysis of Interest Rate Differences; battling the Bullwhip Effect with Cryptography; Reporting of Cross-Border Transactions for Tax Purposes via DLT; securing File System Integrity and Version History Via Directory Merkle Trees and Blockchains; taxation of Blockchain Staking Rewards: Propositions Based on a Comparative Legal Analysis; comparison Framework for Blockchain Interoperability Implementations; A Comparative Analysis of Anomaly Detection Methods for Predictive Maintenance in SME; towards Strategies for Secure Data Transfer of IoT Devices with Limited Resources; application of Validation Obligations to Security Concerns; mode Switching for Secure Edge Devices; a Lifecycle Framework for Semantic Web Machine Learning Systems; enhancing TransE to Predict Process Behavior in Temporal Knowledge Graphs; an Explainable Multimodal Fusion Approach for Mass Casualty Incidents.
DA  - 2022///
PY  - 2022
VL  - 1633 CCIS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136913737&partnerID=40&md5=474fa9d7746e948ec64070e6a1a0faf3
DB  - Scopus
ER  - 

TY  - JOUR
TI  - Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning
AU  - Huang, L.
AU  - Zhang, C.
AU  - Zhang, H.
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - We propose self-adaptive training&#x2014;a unified training algorithm that dynamically calibrates and enhances training processes by model predictions without incurring an extra computational cost&#x2014;to advance both supervised and self-supervised learning of deep neural networks. We analyze the training dynamics of deep networks on training data that are corrupted by, e.g., random noise and adversarial examples. Our analysis shows that model predictions are able to magnify useful underlying information in data and this phenomenon occurs broadly even in the absence of <italic>any</italic> label information, highlighting that model predictions could substantially benefit the training processes: self-adaptive training improves the generalization of deep networks under noise and enhances the self-supervised representation learning. The analysis also sheds light on understanding deep learning, e.g., a potential explanation of the recently-discovered double-descent phenomenon in empirical risk minimization and the collapsing issue of the state-of-the-art self-supervised learning algorithms. Experiments on the CIFAR, STL, and ImageNet datasets verify the effectiveness of our approach in three applications: classification with label noise, selective classification, and linear evaluation. To facilitate future research, the code has been made publicly available at <uri>https://github.com/LayneH/self-adaptive-training</uri>. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TPAMI.2022.3217792
SP  - 1
EP  - 17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141523455&doi=10.1109%2fTPAMI.2022.3217792&partnerID=40&md5=2981105705567c1b7c3d08de6e2921e1
DB  - Scopus
KW  - Deep learning
KW  - Predictive models
KW  - Deep neural networks
KW  - Neural networks
KW  - Data models
KW  - Training
KW  - Deep Learning
KW  - Supervised learning
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Forecasting
KW  - Risk assessment
KW  - Supervised Learning
KW  - Neural-networks
KW  - Noise measurement
KW  - Self-supervised learning
KW  - Robust learning
KW  - Generalization
KW  - Noise measurements
KW  - Generalisation
KW  - Robust learning under noise
KW  - Robust Learning under Noise
KW  - Self-Supervised Learning
ER  - 

TY  - CONF
TI  - A Predictive Analytics Method for the Avoidance of Ship Grounding in Real Operational Conditions
AU  - Taimuri, G.
AU  - Zhang, M.
AU  - Hirdaris, S.
T2  - SNAME Maritime Convention, SMC 2022
AB  - This paper presents a rapid method for the evaluation of ship grounding risk and the estimation of avoidance action in real operational conditions. The approach makes use of big data analytics from Automatic Identification System (AIS), nowcast and General Bathymetric Chart of the Oceans (GEBCO) to generate potential grounding scenarios. Following the identification of potential grounding scenarios, a Fluid Structure Interaction (FSI) model is adopted to simulate grounding avoidance actions that account for the influence of surrounding water and ship controlling devices in 6- DoF. Application for the case of a passenger ship operating under ice free conditions in the Gulf of Finland demonstrates the potential of the method for the development of improved decision support systems and operational practices. Copyright © 2022 Society of Naval Architects and Marine Engineers (SNAME)
DA  - 2022///
PY  - 2022
DO  - 10.5957/SMC-2022-012
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133540519&doi=10.5957%2fSMC-2022-012&partnerID=40&md5=a98032eca0ecb98b13316eb47f9b17ab
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Automation
KW  - Data analytics
KW  - Machine-learning
KW  - Predictive analytics
KW  - Risk perception
KW  - Decision support systems
KW  - Big data
KW  - Data Analytics
KW  - Gulf of Finland
KW  - Ship safety
KW  - Ships
KW  - Big data analytic
KW  - 6-DoF maneuvering model
KW  - big data analytics
KW  - Fluid structure interaction
KW  - Fluid-structure interaction
KW  - grounding risk
KW  - Grounding risk
KW  - Ship grounding
KW  - ship safety
KW  - Simplified fluid structure interaction
KW  - simplified FSI
ER  - 

TY  - JOUR
TI  - Automobile crash test time-series data processing and classification method based on SSI-PSO algorithm
AU  - Li, H.
AU  - Liu, Z.
AU  - Zhu, P.
T2  - Journal of Automotive Safety and Energy
AB  - This paper investigated an optimization problem transformation and construction method for heuristic optimization algorithm to realize the category identification of dummy curve dataset from automobile crash test. A method of feature selection and classification was proposed for multi-variable time-series data in crash test based on a social spider inspired particle swarm optimization (SSI-PSO) for the feature processing and for the classification process of dummy curve data. The proposed method was tested and validated by using the dummy curve data collected from automobile crash test. The result shows that the optimal feature combination and the small-scale neural network for dummy curve classification are obtained by the proposed method. The performance of dummy curve classification model improves by 17.5% and classification accuracy reaches 96.5% based on the proposed method. Therefore, the labeling information of dummy response curve from crash test is classified effectively. © 2022 Journal of Automotive Safety and Energy. All rights reserved.
DA  - 2022///
PY  - 2022
DO  - 10.3969/j.issn.1674-8484.2022.02.005
VL  - 13
IS  - 2
SP  - 259
EP  - 268
ST  - 基于SSI-PSO 的汽车碰撞试验时序数据处理与分类方法
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135046567&doi=10.3969%2fj.issn.1674-8484.2022.02.005&partnerID=40&md5=21d3625d248c545737a606096f2d6cdc
DB  - Scopus
KW  - supervised learning
KW  - automobile crash
KW  - feature engineering
KW  - heuristic optimization algorithm
KW  - multi-variable time series data
KW  - safety data
KW  - social spider inspired particle swarm optimization (SSI-PSO) algorithm
ER  - 

TY  - JOUR
TI  - RAgE: Robust Age Estimation Through Subject Anchoring with Consistency Regularisation
AU  - Akbari, A.
AU  - Awais, M.
AU  - Fatemifar, S.
AU  - Khalid, S.S.
AU  - Kittler, J.
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - Modern facial age estimation systems can achieve high accuracy when training and test datasets are identically distributed and captured under similar conditions. However, domain shifts in data, encountered in practice, lead to a sharp drop in accuracy of most existing age estimation algorithms. In this work, we propose a novel method, namely RAgE, to improve the robustness and reduce the uncertainty of age estimates by leveraging unlabelled data through a subject anchoring strategy and a novel consistency regularisation term. First, we propose an similarity-preserving pseudo-labelling algorithm by which the model generates pseudo-labels for a cohort of unlabelled images belonging to the same subject, while taking into account the similarity among age labels. In order to improve the robustness of the system, a consistency regularisation term is then used to simultaneously encourage the model to produce invariant outputs for the images in the cohort with respect to an anchor image. We propose a novel consistency regularisation term the noise-tolerant property of which effectively mitigates the so-called confirmation bias caused by incorrect pseudo-labels. Experiments on multiple benchmark ageing datasets demonstrate substantial improvements over the state-of-the-art methods and robustness to confounding external factors, including subject&#x2019;s head pose, illumination variation and appearance of expression in the face image. Crown
DA  - 2022///
PY  - 2022
DO  - 10.1109/TPAMI.2022.3187079
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133637460&doi=10.1109%2fTPAMI.2022.3187079&partnerID=40&md5=1aed30519e43658671c3d35eaf9996e2
DB  - Scopus
KW  - Predictive models
KW  - semi-supervised learning
KW  - Data models
KW  - Training
KW  - Robustness
KW  - Estimation
KW  - Semisupervised learning
KW  - domain shift
KW  - Age estimation
KW  - consistency regularisation
KW  - cross-domain recognition
KW  - Lighting
ER  - 

TY  - JOUR
TI  - A robust framework for handling health care information based on machine learning and big data engineering techniques
AU  - Praveen, S.P.
AU  - Murali Krishna, T.B.
AU  - Anuradha, C.H.
AU  - Mandalapu, S.R.
AU  - Sarala, P.
AU  - Sindhura, S.
T2  - International Journal of Healthcare Management
AB  - Confidentiality and security breaches remain significant concerns for electronic healthcare systems even though many relevant rules, principles, and compliance standards are in place to protect health information. It is now essential to use strategies revolving around big data to enhance the dependability of healthcare delivery due to the ever-increasing number of data generated within the healthcare sector. Even though big data processing methods and platforms have been incorporated into the data management designs for medical systems, these designs have trouble addressing urgent situations. Today, it is difficult to predict how big data and ML will affect the healthcare sectors. As a result, a clinical healthcare data warehouse environment utilizing big data analytics and ML is provided in this analysis. Quick digital access to all types of vital data, including patient histories, scan records, insurance claims, and payment history, is guaranteed by healthcare data warehouse systems. This clinical healthcare data warehouse environment can improve an individual's quality of care and monitor the patient's health status in real-time by using ML algorithms and Big data analytics. The effectiveness of the ML technique's performance is measured in terms of accuracy, specificity, sensitivity, precision, recall and Receiver Operating Characteristics (RoC). © 2022 Informa UK Limited, trading as Taylor & Francis Group.
DA  - 2022///
PY  - 2022
DO  - 10.1080/20479700.2022.2157071
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144111812&doi=10.1080%2f20479700.2022.2157071&partnerID=40&md5=aa5def61ff43fb486e43690727e57485
DB  - Scopus
KW  - machine learning
KW  - big data
KW  - adult
KW  - article
KW  - controlled study
KW  - human
KW  - algorithm
KW  - receiver operating characteristic
KW  - sensitivity and specificity
KW  - health status
KW  - machine learning (ML)
KW  - recall
KW  - health care delivery
KW  - Clinical healthcare data
KW  - data warehouse
KW  - data warehouse environment
KW  - health care cost
KW  - health care industry
KW  - insurance
KW  - medical history
KW  - the healthcare industry
ER  - 

TY  - JOUR
TI  - Safe Reinforcement Learning Using Robust Control Barrier Functions
AU  - Emam, Y.
AU  - Notomista, G.
AU  - Glotfelter, P.
AU  - Kira, Z.
AU  - Egerstedt, M.
T2  - IEEE Robotics and Automation Letters
AB  - Reinforcement Learning (RL) has been shown to be effective in many scenarios. However, it typically requires the exploration of a sufficiently large number of state-action pairs, some of which may be unsafe. Consequently, its application to safety-critical systems remains a challenge. An increasingly common approach to address safety involves the addition of a safety layer that projects the RL actions onto a safe set of actions. In turn, a difficulty for such frameworks is how to effectively couple RL with the safety layer to improve the learning performance. In this paper, we frame safety as a differentiable robust-control-barrier-function layer in a model-based RL framework. Moreover, we also propose an approach to modularly learn the underlying reward-driven task, independent of safety constraints. We demonstrate that this approach both ensures safety and effectively guides exploration during training in a range of experiments, including zero-shot transfer when the reward is learned in a constraint-agnostic fashion. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/LRA.2022.3216996
SP  - 1
EP  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141486331&doi=10.1109%2fLRA.2022.3216996&partnerID=40&md5=1f9d3eb63c42c01dfdd11e3204967b99
DB  - Scopus
KW  - Reinforcement learning
KW  - Safety
KW  - Task analysis
KW  - Robots
KW  - Training
KW  - Reinforcement learnings
KW  - Safety engineering
KW  - Robust control
KW  - Barriers functions
KW  - Control barriers
KW  - Dynamical systems
KW  - Control systems
KW  - Safety critical systems
KW  - Reinforcement Learning
KW  - Robot safety
KW  - Robot Safety
KW  - Robust-adaptive control
KW  - Robust/Adaptive Control
KW  - ITS applications
KW  - Number of state
ER  - 

TY  - CONF
TI  - Editorial: Machine Learning, Advances in Computing, Renewable Energy and Communication (MARC)
AU  - Tomar, A.
AU  - Malik, H.
AU  - Kumr, P.
AU  - Iqbal, A.
T2  - Lecture Notes in Electrical Engineering
AB  - Machine learning (ML) is the subcategory of artificial intelligence (AI), which has the capability to imitate human behavior intelligently as per the task performed by the human. In the modern time, any organization implements AI by using ML so that system’s behavior of interchangeably and ambiguously is updated automatically through the experience without any delay. So, current advances in AI have involved ML. The ML starts with data (i.e., any kind of data starting from primary to secondary data). These data are collected and preprocessed to be used as training and testing the ML models being utilized for different applications such as regression, prediction, forecasting, classification, clustering, management, design, optimization, security, IoTs, health care, digitization, automation, control, privacy protection and e-commerce. In this book, the applications AI, ML and its advancement for different applications have been presented into different chapters, including the state-of-the-art and implementation in the various research domains of engineering and science. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-19-2828-4_1
VL  - 915
SP  - 1
EP  - 19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138759601&doi=10.1007%2f978-981-19-2828-4_1&partnerID=40&md5=cb8aafb88a19fee8bc8ca3fe758be8e1
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Prediction
KW  - Data analytics
KW  - Diagnosis
KW  - Smart city
KW  - Behavioral research
KW  - Machine-learning
KW  - Forecasting
KW  - Communication
KW  - Electric power transmission networks
KW  - Smart grid
KW  - Smart power grids
KW  - Optimisations
KW  - Optimization
KW  - Electric vehicles
KW  - Digital storage
KW  - Fault detection
KW  - Power
KW  - Renewable energy resources
KW  - Faults detection
KW  - Data Analytics
KW  - Information management
KW  - Power system
KW  - Renewable energies
KW  - Renewable energy
KW  - Condition monitoring
KW  - Energy storage
KW  - Safety analysis
KW  - Advance computing
KW  - Condition based maintenance
KW  - Electric vehicle
KW  - Management
ER  - 

TY  - CONF
TI  - Novel Framework for Identifying Anomalies in High Volume of Data using Robust Machine Learning Algorithm
AU  - Kumar Nanda, S.
AU  - Jyoti Borah, N.
T2  - Proceedings - 2022 OITS International Conference on Information Technology, OCIT 2022
AB  - Anomaly detection in unlabelled data is very tedious task using unsupervised learning models and also to study the model validation process. Furthermore, it is also getting difficulty to get large-scale labelled data and evaluate the model performance. In real-world problem, in general, for unlabelled data set, evaluation process not only takes time but also increase the project cost. To minimize this issue, here we proposed a novel framework merging with both the unsupervised and supervised learning process. In this framework, the process will generate global label followed by a majority voting ensemble approach. With the availability of global label, the framework latter established a classifier to train and finally predict the appropriate normal or anomaly label of any unlabelled data. This framework has seven stage or seven process and takes very low computing cost. To design this frame-work, we used five unsupervised learning models including Isolation forest (IF), Local Outlier Factor (LOF), Gaussian Mixture, One Class SVM and Auto encoders, in addition to this, we used six supervised learning models like Random Forest, Logistic Regression, CART, Gaussian NB, K-nearest neighbour (KNN) and XG-Boost.All the applied model performance discussed extensively in the report. It is found the proposed framework has able to enhance the accuracy of anomaly detection rate.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/OCIT56763.2022.00067
SP  - 318
EP  - 323
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150298278&doi=10.1109%2fOCIT56763.2022.00067&partnerID=40&md5=b59d8ace107463fca8de67b304141c7f
DB  - Scopus
KW  - Ensemble methods
KW  - Random Forest
KW  - Machine Learning
KW  - CART
KW  - Fraud detection
KW  - Learning systems
KW  - Anomaly detection
KW  - Machine-learning
KW  - Big Data
KW  - Big data
KW  - Nearest neighbor search
KW  - Semi-supervised learning
KW  - Statistics
KW  - Random forests
KW  - Fraud Detection
KW  - Unsupervised learning
KW  - Gaussian-mixtures
KW  - Gaussian distribution
KW  - Signal encoding
KW  - Logistic regression
KW  - Nearest-neighbour
KW  - Logistic Regression
KW  - Logistics regressions
KW  - Gaussians
KW  - Auto encoders
KW  - Ensemble Methods
KW  - Gaussian Mixture
KW  - Gaussian NB
KW  - Isolation forest
KW  - Isolation forest (IF)
KW  - K-near neighbor  and XG-boost
KW  - K-nearest neighbour (KNN) and XG-Boost
KW  - Local Outlier Factor
KW  - Local Outlier Factor (LOF)
KW  - One Class SVM
KW  - One class-SVM
KW  - Unlabeled learning
KW  - Unlabelled Learning
ER  - 

TY  - JOUR
TI  - Cooperative optimal scheduling strategy of source and storage in microgrid based on soft actor-critic
AU  - Liu, L.
AU  - Zhu, J.
AU  - Chen, J.
AU  - Ye, H.
T2  - Dianli Zidonghua Shebei/Electric Power Automation Equipment
AB  - In recent years, the proportion of renewable energy and energy storage in microgrid is increasing, which brings new challenges to its optimal scheduling. Aiming at the difficulty in solving the cooperative optimal scheduling problem of source and storage in microgrid due to the non-convex nonlinear constraints, the deep reinforcement learning algorithm is used to construct the data-based strategy function, and the optimal strategy is found out through continuous interactive learning with the environment, so that avoiding the direct solution of the original non-convex nonlinear problem. Considering the strategy function may not meet the security constraints in the training process, furthermore, a learning method of cooperative optimal scheduling secure strategy of source and storage in microgrid based on partial model information is proposed, and the optimal strategy meeting the network security constraints is obtained. In addition, aiming at the problem of long time-consuming due to the interaction between agents and environment in the training process for reinforcement learning, the neural network is used to model the environment, so as to improve the learning efficiency.Review and prospect of robust optimization and planning research on generation and transmission systemYUAN　Yang1, ZHANG　Heng1, CHENG　Haozhong1, LIU　Lu1, ZHANG　Xiaohu2, LI　Gang2, ZHANG　Jianping2(1. Key Laboratory Control of Power Transmission and Conversion, Ministry of Education, Shanghai Jiao Tong University, Shanghai 200240, China;2. East China Branch of State Grid Corporation of China, Shanghai 200120, China)With the uncertainty of power system increasing gradually, the application of robust optimization and planning research on generation and transmission system to resist the uncertainty of extremely scenes has become a significant research method. Firstly, the robust optimization is divided into classical robust optimization and distributionally robust optimization from the perspective of whether the probability distribution characteristics of uncertain factors are considered, the mathematical models and uncertain set characteristics of these two kinds of robust optimization are sorted out. Secondly, the existing classical robust optimization and distributionally robust optimization research on generation and transmission system are divided into three aspects:considering the uncertainty of node injection power, considering the uncertainty of power capacity growth and cost, and considering the uncertainty of transmission network state, and the research framework and limitations of robust optimization planning research on generation and transmission system are refined. Finally, the problems worthy of further study in robust optimization planning on power generation and transmission system are prospected, which provides ideas and directions for the robust optimization planning follow-up research on power generation and transmission system. © 2022, Electric Power Automation Equipment Press. All right reserved.
DA  - 2022///
PY  - 2022
DO  - 10.16081/j.epae.202110036
VL  - 42
IS  - 1
SP  - 79
EP  - 85
ST  - 基于柔性策略-评价网络的微电网源储协同优化调度策略
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122516065&doi=10.16081%2fj.epae.202110036&partnerID=40&md5=9adf015579f20bab11c951457c3a8343
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Uncertainty
KW  - Network security
KW  - Optimisations
KW  - Optimization
KW  - Robust optimization
KW  - Digital storage
KW  - Microgrid
KW  - Probability distributions
KW  - Electric power transmission
KW  - Microgrids
KW  - Scheduling
KW  - Renewable energies
KW  - Renewable energy
KW  - Actor critic
KW  - Optimal systems
KW  - Soft actor-critic
KW  - Energy storage
KW  - Distributionally robust optimizationkey word:microgrid
KW  - Distributionally robust optimizationKey words:microgrid
KW  - Generation and transmission system
KW  - Generation systems
KW  - Optimization and planning
KW  - Security constraint
KW  - Transmission systems
ER  - 

TY  - JOUR
TI  - Data-driven adaptive robust optimization for energy systems in ethylene plant under demand uncertainty
AU  - Shen, F.
AU  - Zhao, L.
AU  - Wang, M.
AU  - Du, W.
AU  - Qian, F.
T2  - Applied Energy
AB  - The operational optimization of energy systems is of great significance for improving the overall efficiency of industrial processes. Facing new challenges brought by widespread uncertainties, a data-driven adaptive robust industrial multi-type energy systems optimization framework was proposed by bridging robust optimization and machine learning methods in this paper. The industrial data were used to capture the demand uncertainty of the actual process. Hybrid models of units were first developed considering the operational characteristics, and the energy system optimization model was then formed as a mixed-integer nonlinear programming problem. The uncertain parameter set of process power demands was formed by the process models using historical data of a whole operating period. Afterward, the uncertainty set was constructed by applying the robust kernel density estimation method, which can reduce conservatism by considering the distributional information. By integrating the derived data-driven uncertainty set, a two-stage adaptive robust optimization model aiming at minimizing the weighted total energy consumption was developed. The multi-level robust optimization model was reformulated as a tractable single-level model by employing the affine decision rule. A case study on a plant-wide industrial energy system in the ethylene plant was performed, and the minimum optimal energy consumption was 25,350 kg/h, whose price of robustness was only 2.18%. The robust optimization results can guide the operational optimization of energy systems under uncertainty for the operators of the ethylene plant. © 2021 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.apenergy.2021.118148
VL  - 307
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119189286&doi=10.1016%2fj.apenergy.2021.118148&partnerID=40&md5=9639c6cedc6ad1e4808e8111e0a51c88
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Uncertainty
KW  - Big data
KW  - Uncertainty analysis
KW  - Robust optimization
KW  - uncertainty analysis
KW  - Energy utilization
KW  - performance assessment
KW  - Energy systems
KW  - Data driven
KW  - Nonlinear programming
KW  - Adaptive robust optimization
KW  - Ethylene
KW  - Integer programming
KW  - Demand uncertainty
KW  - Energy system optimizations
KW  - ethylene
KW  - Ethylene plants
KW  - Industrial big data
KW  - Operational optimization
ER  - 

TY  - JOUR
TI  - A Semi-Supervised Adversarial Robust Model-Agnostic Meta-Learning Method
AU  - Hu, B.
AU  - Wang, X.
AU  - Zhang, L.
T2  - Jisuanji Gongcheng/Computer Engineering
AB  - The meta model developed by meta learning is expected to have the ability of “learning to learn”. Therefore, it can quickly adapt to new tasks based on the learned “meta knowledge”, with a small number of gradient descent steps to fine- tune the model using a few labeled training data from new tasks. However, owing to the scarcity of training sampling data, when the meta-learning algorithm overtrains the existing tasks during the meta-training phase, the decision boundary trained by the meta learner is not sufficiently accurate. The unreasonable decision boundary makes the meta model more vulnerable to adversarial perturbation, which may lead to poor robustness performance of the meta model on new tasks. Therefore, a semisupervised Adversarial Robust Model-Agnostic Meta-Learnin (semi-ARMAML) method is proposed. A semi-supervised adversarial robust regularizer and a task-agnostic regularizer based on information entropy are integrated into the objective function to optimize the decision boundary. In particular, the calculation of the adversarial robust regularizer allows the unlabeled dataset to contain the classes unseen in the labeled dataset. The developed meta model performs better on new tasks of real application scenes and is more robust on input disturbances. The experimental results indicate that the scheme has a higher accuracy rate on clean samples. Compared with current mainstream adversarial meta-learning schemes such as ADML and R-MAML-TRADES, the adversarial robustness performance of the semi-ARMAML method improved by approximately 1.8% and 2.7% on the five- way one-shot and five-way five-shot tasks of the MiniImage Net dataset, respectively, and by approximately 5.2% and 8.1% on the five-way one-shot and five-way five-shot tasks of the CIFAR-FS dataset, respectively. © 2022, Editorial Office of Computer Engineering. All rights reserved.
DA  - 2022///
PY  - 2022
DO  - 10.19678/j.issn.1000-3428.0063365
VL  - 48
IS  - 12
SP  - 112
EP  - 118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147034501&doi=10.19678%2fj.issn.1000-3428.0063365&partnerID=40&md5=2203177a06f2749d5d3c95fcc03abef3
DB  - Scopus
KW  - Semi-supervised learning
KW  - Adversarial training
KW  - Meta-learning
KW  - Adversarial robustness
KW  - Few-Shot Learnin(FSL)
ER  - 

TY  - CHAP
TI  - Advanced machine learning
AU  - Livne, O.E.
T2  - International Encyclopedia of Education: Fourth Edition
AB  - Machine learning is the branch of artificial intelligence concerned with the use and development of computer systems that can learn and improve through experience. It has become the dominant data-driven approach in a great number of fields where an enormous amount of data is available, but it is difficult or unfeasible to develop conventional algorithms to perform the task. In this entry we focus on deep learning: a family of machine learning methods for extracting patterns from data using artificial neural networks, which has had tremendous success in performing complex tasks, from image recognition and medical diagnosis to language translation and content generation. A plethora of papers, pre-trained models and software frameworks have emerged to support neural network development. Neural networks have also become increasingly important in educational assessment and learning. Automatic feature extraction from student essays, predicting student behavior and future success, automated essay scoring, and content generation, are but a few current applications. © 2023 Elsevier Ltd. All rights reserved.
DA  - 2022///
PY  - 2022
SP  - 684
EP  - 694
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150556105&doi=10.1016%2fB978-0-12-818630-5.10093-4&partnerID=40&md5=ce63eb1be5b2fdcd4a0c70b1dbd43fac
DB  - Scopus
KW  - Deep learning
KW  - Artificial intelligence
KW  - Machine learning
KW  - Deep neural networks
KW  - Hidden layers
KW  - Training algorithms
KW  - Automatic feature extraction
KW  - Robust classifiers
KW  - Stochastic gradient descent
ER  - 

TY  - JOUR
TI  - Towards Robust Adversarial Training via Dual-label Supervised and Geometry Constraint
AU  - Cao, L.-J.
AU  - Kuang, H.-F.
AU  - Liu, H.
AU  - Wang, Y.
AU  - Zhang, B.-C.
AU  - Huang, F.-Y.
AU  - Wu, Y.-J.
AU  - Ji, R.-R.
T2  - Ruan Jian Xue Bao/Journal of Software
AB  - Recent studies have shown that adversarial training is an effective method to defend against adversarial example attacks. However, such robustness comes with a price of a larger generalization gap. To this end, existing endeavors mainly treat each training example independently, which ignores the geometry relationship between inter-samples and does not take the defending capability to the full potential. Different from existing works, this study focuses on improving the robustness of the neural network model by aligning the geometric information of inter-samples to make the feature spatial distribution structure between the natural and adversarial samples is consistent. Furthermore, a dual-label supervised method is proposed to leverage true and wrong labels of adversarial example to jointly supervise the adversarial learning process. The characteristics of the dual-label supervised learning method are analyzed and it is tried to explain the working mechanism of the adversarial example theoretically. The extensive experiments have been conducted on benchmark datasets, which well demonstrates that the proposed approach effectively improves the robustness of the model and still keeps the generalization accuracy. Code is available: https://github.com/SkyKuang/DGCAT. © Copyright 2022, Institute of Software, the Chinese Academy of Sciences. All rights reserved.
DA  - 2022///
PY  - 2022
DO  - 10.13328/j.cnki.jos.006477
VL  - 33
IS  - 4
SP  - 1218
EP  - 1230
ST  - 双标签监督的几何约束对抗训练
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128433821&doi=10.13328%2fj.cnki.jos.006477&partnerID=40&md5=4775ad9765c9567d81f9cbfd318075d4
DB  - Scopus
KW  - Deep learning
KW  - Supervised learning
KW  - Neural network model
KW  - Model robustness
KW  - Generalisation
KW  - Adversarial training
KW  - Dual label supervised
KW  - Dual labels
KW  - Geometry
KW  - Geometry constraint
KW  - Geometry constraints
KW  - Geometry relationships
KW  - Training example
ER  - 

TY  - JOUR
TI  - Semiclosed Greenhouse Climate Control Under Uncertainty via Machine Learning and Data-Driven Robust Model Predictive Control
AU  - Chen, W.-H.
AU  - You, F.
T2  - IEEE Transactions on Control Systems Technology
AB  - This work proposes a novel data-driven robust model predictive control (DDRMPC) framework for automatic control of greenhouse in-door climate. The framework integrates dynamic control models of greenhouse temperature, humidity, and CO2 concentration level with data-driven robust optimization models that accurately and rigorously capture uncertainty in weather forecast error. Data-driven uncertainty sets for ambient temperature, solar radiation, and humidity are constructed from historical data by leveraging a machine learning approach, namely, support vector clustering with weighted generalized intersection kernel. A training-calibration procedure that tunes the size of uncertainty sets is implemented to ensure that data-driven uncertainty sets attain an appropriate performance guarantee. In order to solve the optimization problem in DDRMPC, an affine disturbance feedback policy is utilized to obtain tractable approximations of optimal control. A case study of controlling temperature, humidity, and CO2 concentration of a semiclosed greenhouse in New York City is presented. The results show that the DDRMPC approach ends up with 14% and 4% lower total cost than rule-based control and robust model predictive control with L1-norm-based uncertainty set, respectively. The constraint violation probability, which is the percentage of time that the greenhouse system states violate the constraint throughout the whole growing period, for DDRMPC is only 0.39%. Hence, the proposed DDRMPC framework can prevent the greenhouse climate from becoming harmful to plants and fruits. In conclusion, the proposed DDRMPC approach can improve the greenhouse climate control performance and reduce cost compared with other control strategies.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TCST.2021.3094999
VL  - 30
IS  - 3
SP  - 1186
EP  - 1197
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112643547&doi=10.1109%2fTCST.2021.3094999&partnerID=40&md5=43bcc998682a46e423e6ec958185dffa
DB  - Scopus
KW  - Machine learning
KW  - Automation
KW  - uncertainty
KW  - Predictive analytics
KW  - Optimization
KW  - Machine learning approaches
KW  - Model predictive control
KW  - Robust control
KW  - Turing machines
KW  - Humidity control
KW  - Robust model predictive control
KW  - Weather forecasting
KW  - Climate control
KW  - Climate models
KW  - Controlled environment agriculture
KW  - data-driven robust optimization
KW  - Generalized intersection
KW  - greenhouse climate control
KW  - Greenhouse climate control
KW  - Greenhouse temperature
KW  - Greenhouses
KW  - robust model predictive control (RMPC)
KW  - Robust optimization models
KW  - Support vector clustering
KW  - Weather forecast errors
ER  - 

TY  - JOUR
TI  - Hierarchical confounder discovery in the experiment-machine learning cycle
AU  - Rogozhnikov, A.
AU  - Ramkumar, P.
AU  - Bedi, R.
AU  - Kato, S.
AU  - Escola, G.S.
T2  - Patterns
AB  - The promise of machine learning (ML) to extract insights from high-dimensional datasets is tempered by confounding variables. It behooves scientists to determine if a model has extracted the desired information or instead fallen prey to bias. Due to features of natural phenomena and experimental design constraints, bioscience datasets are often organized in nested hierarchies that obfuscate the origins of confounding effects and render confounder amelioration methods ineffective. We propose a non-parametric statistical method called the rank-to-group (RTG) score that identifies hierarchical confounder effects in raw data and ML-derived embeddings. We show that RTG scores correctly assign the effects of hierarchical confounders when linear methods fail. In a public biomedical image dataset, we discover unreported effects of experimental design. We then use RTG scores to discover crossmodal correlated variability in a multi-phenotypic biological dataset. This approach should be generally useful in experiment-analysis cycles and to ensure confounder robustness in ML models. © 2022 The Author(s)
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.patter.2022.100451
VL  - 3
IS  - 4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127707800&doi=10.1016%2fj.patter.2022.100451&partnerID=40&md5=5ade91e6b6d7fb9affc495bed4c8605a
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - robustness
KW  - Statistical tests
KW  - Robustness
KW  - Statistics
KW  - Design of experiments
KW  - bias
KW  - Cytology
KW  - Bias
KW  - Confounder
KW  - confounders
KW  - De-biasing
KW  - debiasing
KW  - Domain problems
KW  - DSML 3: Development/Pre-production: Data science output has been rolled out/validated across multiple domains/problems
KW  - DSML 3: development/pre-production: data science output have been rolled out/validated across multiple domain/problem
KW  - experimental design
KW  - Experimental design
KW  - Hierarchical confounder
KW  - hierarchical confounders
KW  - Mann-Whitney U test
KW  - Mann-Whitney U-test
KW  - Multiple domains
KW  - Pre-production
KW  - Production data
KW  - stem cell biology
KW  - Stem cell biology
KW  - Stem cells
ER  - 

TY  - JOUR
TI  - Building robust machine learning models for small chemical science data: the case of shear viscosity of fluids
AU  - Avula, N.V.S.
AU  - Veesam, S.K.
AU  - Behera, S.
AU  - Balasubramanian, S.
T2  - Machine Learning: Science and Technology
AB  - Shear viscosity, though being a fundamental property of all fluids, is computationally expensive to calculate from equilibrium molecular dynamics simulations. Recently, machine learning (ML) methods have been used to augment molecular simulations in many contexts, thus showing promise to estimate viscosity too in a relatively inexpensive manner. However, ML methods face significant challenges—such as overfitting, when the size of the data set is small, as is the case with viscosity. In this work, we train seven ML models to predict the shear viscosity of a Lennard-Jones fluid, with particular emphasis on addressing issues arising from a small data set. Specifically, the issues related to model selection, performance estimation and uncertainty quantification were investigated. First, we show that the widely used performance estimation procedure of using a single unseen data set shows a wide variability—in estimating the errors on—small data sets. In this context, the common practice of using cross validation (CV) to select the hyperparameters (model selection) can be adapted to estimate the generalization error (performance estimation) as well. We compare two simple CV procedures for their ability to do both model selection and performance estimation, and find that k-fold CV based procedure shows a lower variance of error estimates. Also, these CV procedures naturally lead to an ensemble of trained ML models. We discuss the role of performance metrics in training and evaluation and propose a method to rank the ML models based on multiple metrics. Finally, two methods for uncertainty quantification—Gaussian process regression (GPR) and ensemble method—were used to estimate the uncertainty on individual predictions. The uncertainty estimates from GPR were also used to construct an applicability domain using which the ML models provided even more reliable predictions on an independent viscosity data set generated in this work. Overall, the procedures prescribed in this work, together, lead to robust ML models for small data sets. © 2022 The Author(s). Published by IOP Publishing Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1088/2632-2153/acac01
VL  - 3
IS  - 4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145668346&doi=10.1088%2f2632-2153%2facac01&partnerID=40&md5=85c480b125a3a4615e2a5ed437cf245f
DB  - Scopus
KW  - Machine learning
KW  - uncertainty quantification
KW  - Forecasting
KW  - Machine learning models
KW  - Machine learning methods
KW  - Uncertainty analysis
KW  - Errors
KW  - Molecular dynamics
KW  - Data set
KW  - Uncertainty quantifications
KW  - applicability domain
KW  - Applicability domain
KW  - Cross validation
KW  - model selection
KW  - Model Selection
KW  - performance estimation
KW  - Performance estimation
KW  - shear viscosity
KW  - Shear viscosity
KW  - small data
KW  - Small data
KW  - Small data set
ER  - 

TY  - JOUR
TI  - Liquefaction prediction with robust machine learning algorithms (SVM, RF, and XGBoost) supported by genetic algorithm-based feature selection and parameter optimization from the perspective of data processing
AU  - Demir, S.
AU  - Şahin, E.K.
T2  - Environmental Earth Sciences
AB  - Liquefaction prediction is an important issue in the seismic design of engineering structures, and research on this topic has been continuing in current literature using different methods, including experimental, numerical, or soft computing. In this paper, three robust machine learning (ML) algorithms are applied to predict soil liquefaction using a set of 411 shear wave velocity case records. The Genetic Algorithm (GA) based feature selection (FS) and parameter optimization of Random Forest (RF), Support Vector Machines (SVM), and eXtreme Gradient Boosting (XGBoost) algorithms are utilized to improve the accuracy of the liquefaction prediction models. Simple Random Sampling (SRS) and Stratified Random Sampling (StrRS) are used for data sampling, and also SMOTE algorithm are applied to prepare the balanced training sets. The results of robust ML algorithms are assessed based on well-known five performance matrices, namely Accuracy (Acc), Kappa, Precision, Recall, and F-Measure. Evaluation of the results is made separately for each ML algorithm considering sampling data generated from SRS, StrRS, and SMOTE. As a result, the XGBoost model is more accurate (Acc = 96%) than RF (Acc = 93%) and SVM (Acc = 91%) in the case of the SMOTE algorithm. This study reveals the superiority of the XGBoost algorithm in the liquefaction prediction and shows how the accuracy measures tend to improve when the predictive models are trained using balanced samples with StrRS and SMOTE sampling strategies. © 2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
DA  - 2022///
PY  - 2022
DO  - 10.1007/s12665-022-10578-4
VL  - 81
IS  - 18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138466566&doi=10.1007%2fs12665-022-10578-4&partnerID=40&md5=405dfe2aa5efe3e482e7503604ba9a88
DB  - Scopus
KW  - machine learning
KW  - Decision trees
KW  - Machine learning algorithms
KW  - Support vector machines
KW  - Learning systems
KW  - XGBoost
KW  - Data handling
KW  - Forecasting
KW  - data processing
KW  - Adaptive boosting
KW  - Parameter estimation
KW  - Random forests
KW  - Shear flow
KW  - Shear waves
KW  - Numerical methods
KW  - Support vectors machine
KW  - Genetic algorithms
KW  - Genetic algorithm
KW  - Feature Selection
KW  - Imbalanced data
KW  - Wave propagation
KW  - Soft computing
KW  - Feature parameters
KW  - Liquefaction prediction
KW  - Parameter optimization
KW  - Seismic design
KW  - SMOTE
KW  - Stratified random sampling
KW  - Xgboost
ER  - 

TY  - JOUR
TI  - Simultaneously Transmitting and Reflecting Reconfigurable Intelligent Surface (STAR-RIS) Assisted UAV Communications
AU  - Zhao, J.
AU  - Zhu, Y.
AU  - Mu, X.
AU  - Cai, K.
AU  - Liu, Y.
AU  - Hanzo, L.
T2  - IEEE Journal on Selected Areas in Communications
AB  - A novel air-to-ground communication paradigm is conceived, where an unmanned aerial vehicle (UAV)-mounted base station (BS) equipped with multiple antennas sends information to multiple ground users (GUs) with the aid of a simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). In contrast to the conventional RIS whose main function is to reflect incident signals, the STAR-RIS is capable of both transmitting and reflecting the impinging signals from either side of the surface, thereby leading to full-space 360 degree coverage. However, the transmissive and reflective capabilities of the STAR-RIS require more complex transmission/reflection coefficient design. Therefore, in this work, a sum-rate maximization problem is formulated for the joint optimization of the UAV's trajectory, the active beamforming at the UAV, and the passive transmission/reflection beamforming at the STAR-RIS. This cutting-edge optimization problem is also subject to the UAV's flight safety, to the maximum flight duration constraint, as well as to the GUs' minimum data rate requirements. Given the unknown locations of obstacles prior to the UAV's flight, we provide an online decision making framework employing reinforcement learning (RL) to simultaneously adjust both the UAV's trajectory as well as the active and passive beamformer. To enhance the system's robustness against the associated uncertainties caused by limited sampling of the environment, a novel 'distributionally-robust' RL (DRRL) algorithm is proposed for offering an adequate worst-case performance guarantee. Our numerical results unveil that: 1) the STAR-RIS assisted UAV communications benefit from significant sum-rate gain over the conventional reflecting-only RIS; and 2) the proposed DRRL algorithm achieves both more stable and more robust performance than the state-of-the-art RL algorithms.  © 1983-2012 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/JSAC.2022.3196102
VL  - 40
IS  - 10
SP  - 3041
EP  - 3056
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135734435&doi=10.1109%2fJSAC.2022.3196102&partnerID=40&md5=366c13f85692d288309f5dc606342c96
DB  - Scopus
KW  - Reinforcement learning
KW  - Decision making
KW  - Collisions avoidance
KW  - Reinforcement learnings
KW  - Unmanned aerial vehicles (UAV)
KW  - Antennas
KW  - Aerial vehicle
KW  - Stars
KW  - collision avoidance
KW  - Beamforming
KW  - Reconfigurable
KW  - Air-to-ground communications
KW  - distributionally-robust reinforcement learning
KW  - Distributionally-robust reinforcement learning
KW  - Joint beamforming
KW  - joint beamforming design
KW  - Joint beamforming design
KW  - simultaneously transmitting and reflecting reconfigurable intelligent surface
KW  - Simultaneously transmitting and reflecting reconfigurable intelligent surface
KW  - Vehicle communications
ER  - 

TY  - JOUR
TI  - A Robust and Fast Data Management System for Machine-Learning Research of Tokamaks
AU  - Wan, C.
AU  - Yu, Z.
AU  - Liu, X.
AU  - Wen, X.
AU  - Deng, X.
AU  - Li, J.
T2  - IEEE Transactions on Plasma Science
AB  - In recent years, machine-learning (ML) research methods have received increasing attention in the tokamak community. The conventional database (i.e., MDSplus for tokamak) of experimental data has been designed for small group consumption and is mainly aimed at simultaneous visualization of a small amount of data. The ML data access patterns fundamentally differ from traditional data access patterns. The typical MDSplus database is increasingly showing its limitations. We developed a new data management system suitable for tokamak ML research based on experimental advanced superconducting tokamak (EAST) data. The data management system is based on MongoDB and hierarchical data format version 5 (HDF5). Currently, the entire data management has more than 3000 channels of data. The system can provide highly reliable concurrent access. The system includes error correction, MDSplus original data conversion, and high-performance sequence data output. Furthermore, some valuable functions are implemented to accelerate ML model training of fusion, such as a bucketing generator, the concatenating buffer, and distributed sequence generation. This data management system is more suitable for fusion ML model research and development than MDSplus, but it cannot replace the MDSplus database. The MDSplus database is still the backend for EAST tokamak data acquisition and storage.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TPS.2022.3223732
VL  - 50
IS  - 12
SP  - 4980
EP  - 4986
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144776089&doi=10.1109%2fTPS.2022.3223732&partnerID=40&md5=4ed763f599188df1d83435262ba652ad
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Learning systems
KW  - Data handling
KW  - Machine-learning
KW  - Data visualization
KW  - Digital storage
KW  - Information management
KW  - machine learning (ML)
KW  - Error correction
KW  - Data acquisition
KW  - Generator
KW  - Data management
KW  - Data management system
KW  - Distributed database
KW  - Distributed database systems
KW  - Experimental advanced superconducting tokamak
KW  - experimental advanced superconducting tokamak (EAST)
KW  - Experimental advanced superconducting tokamaks
KW  - Machine learning research
KW  - Superconducting magnets
KW  - tokamak
KW  - Tokamak
KW  - Tokamaks
ER  - 

TY  - JOUR
TI  - Robustness Verification for Machine-Learning-Based Power System Dynamic Security Assessment Models Under Adversarial Examples
AU  - Ren, C.
AU  - Xu, Y.
T2  - IEEE Transactions on Control of Network Systems
AB  - Based on machine learning (ML) technique, the data-driven power system dynamic security assessment (DSA) has received significant research interest. Yet, the well-trained ML-based models with high training and testing accuracy may be vulnerable to the adversarial example, which is a modified version of the original sample that is intentionally perturbed but retains being very close to the original one. Such adversarial examples can mislead the DSA results and lead to catastrophic consequences. Thus, the accuracy index alone is not enough to represent the performance of the ML-based DSA models. To evaluate the ML-based DSA models and provide formal robustness guarantee for real-time DSA, this article proposes an adversarial robustness verification method to quantify the ability of ML-based DSA models against all kinds of adversarial examples. A model-free and attack-independent robust index is defined for both differentiable and nondifferentiable attack scenarios. Simulation results have verified the effectiveness of the proposed adversarial robustness verification method and the superiority of robust index compared with the upper bound of the adversarial perturbations computed by existing adversarial attack methods.  © 2014 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TCNS.2022.3145285
VL  - 9
IS  - 4
SP  - 1645
EP  - 1654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123679176&doi=10.1109%2fTCNS.2022.3145285&partnerID=40&md5=11691a5b44ba32e24ca73411ddfaa9ca
DB  - Scopus
KW  - Security
KW  - Machine learning
KW  - Machine-learning
KW  - Robustness
KW  - machine learning (ML)
KW  - Power systems stability
KW  - Stability criteria
KW  - Perturbation method
KW  - Perturbation techniques
KW  - Data driven
KW  - Index
KW  - Well testing
KW  - Adversarial example
KW  - Stability criterions
KW  - Transient analysis
KW  - adversarial robustness verification
KW  - Adversarial robustness verification
KW  - data-driven
KW  - Dynamic security assessment
KW  - Power system dynamic securities
KW  - Power system dynamic security assessment
KW  - power system dynamic security assessment (DSA)
KW  - robust index
KW  - Robust index
ER  - 

TY  - JOUR
TI  - Homeostasis phenomenon in conformal prediction and predictive distribution functions
AU  - Xie, M.-G.
AU  - Zheng, Z.
T2  - International Journal of Approximate Reasoning
AB  - Conformal prediction is an attractive framework for prediction that is distribution free. In this article, we study in details its homeostasis property under a general regression setup and also introduce the concepts of upper and lower predictive distributions and predictive curve to establish connections to left-, right- and two-tailed hypothesis testing problems as well as the developments in confidence distributions. The homeostasis property is very attractive, since it states that under some conditions the prediction results remain valid even if the model used for learning is completely wrong. We show explicitly why the property holds in a model-based setup and also explore the boundary when the property breaks down. Beside the typical assumption used in conformal prediction that the response and covariate pairs (y,x) of all subjects are iid distributed, we also study the classical regression setting in which the design is fixed with given (non-random) covariates x. The trade-offs among learning model accuracy, prediction valid and prediction efficiency are discussed, leading to an emphasis of more efforts on developing better learning models. © 2021 Elsevier Inc.
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.ijar.2021.09.001
VL  - 141
SP  - 131
EP  - 145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116745575&doi=10.1016%2fj.ijar.2021.09.001&partnerID=40&md5=3df66cf06ef9ebf176704ac659a8ebf3
DB  - Scopus
KW  - Machine learning
KW  - Economic and social effects
KW  - Forecasting
KW  - Learning models
KW  - Robustness
KW  - Well testing
KW  - Property
KW  - Distribution functions
KW  - Distribution-functions
KW  - Confidence
KW  - Conformal predictions
KW  - Covariates
KW  - Homoeostasis
KW  - Model mis-specification
KW  - Predictive distribution
KW  - Predictive distributions
ER  - 

TY  - CONF
TI  - Object Detection and Tracking: Deep Learning based Novel Tools to Generate Robust Human and Machine-Annotated Ground Truth Data for Training AI Models
AU  - Hossain Faruk, M.J.
AU  - Asadur Rahman, M.
T2  - 2022 4th International Conference on Sustainable Technologies for Industry 4.0, STI 2022
AB  - Object detection and tracking is one of the most emerging fields of computer vision that facilitates various fields including robotics, healthcare, security, autonomous vehicle systems, machine inspection, surveillance, and logistics. In object detection, many factors need to be considered including intrinsic and extrinsic factors, camera motion, deformation, occlusion, and motion blur. Machine learning (ML) and deep learning (DL) approaches are being adopted in object detection and tracking, and training these models is the key challenge achieving robust accuracy in the automated detection and tracking of objects. Data annotation paves the way to training ML and DL models; however, training models with inaccurate data jeopardizes the robustness of actual object detection and tracking. Towards generating 100% accurate datasets, human intervention is crucial for assigning identities to the correspondent objects throughout frames. In this paper, we utilize the OpenCV-based deep learning technique and introduce a framework that allows users to assign identities to detected objects towards generating flawless human-annotated ground truth data. The proposed framework allows the users to assign correspondence ids for bounding boxes on Tkinter GUI to help organizations prepare robust annotated datasets to train large-scale object-tracking models for object detection. In an extension of our study, we introduce a novel tool that will learn from human-annotated datasets and generate identities for the detected objects accurately. We evaluate our models on roughly 100 and 1000 human-annotated ground-truth datasets and later 5000 machine-generated ground-truth datasets. According to our demonstration, we achieved an accuracy of 97.55% and 96.68% respectively for human-annotated ground truth datasets. We also achieved an accuracy of 96.33% using a machine-automated ground truth dataset which indicates the robustness of our model. In future studies, we will extend our research to optimize proposed models to achieve an ultimate accuracy of 100%.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/STI56238.2022.10103294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159111361&doi=10.1109%2fSTI56238.2022.10103294&partnerID=40&md5=c2de3da6f9b532ac736ffd97d302adf1
DB  - Scopus
KW  - Deep learning
KW  - Deep Learning
KW  - Learning systems
KW  - Machine-learning
KW  - Object detection
KW  - Computer vision
KW  - Ground truth data
KW  - Object recognition
KW  - Objects detection
KW  - Security systems
KW  - Opencv
KW  - OpenCV
KW  - Large dataset
KW  - Data annotation
KW  - Data Annotation
KW  - Ground truth data annotation
KW  - Ground Truth Data Annotation
KW  - Ground-truth dataset
KW  - Object detection and tracking
KW  - Object Detection and Tracking
ER  - 

TY  - CONF
TI  - Research on Sentence Alignment of Ancient and Modern Chinese based on Reinforcement Learning
AU  - Yu, K.
AU  - Shao, Y.
AU  - Li, W.
T2  - 21st Chinese National Conference on Computational Linguistic, CCL 2022
AB  - Supervised machine translation based on deep learning has achieved good results, but high-quality aligned corpora are needed in training process. There hasn't been a lot of parallel corpora of high quality for ancient and modern Chinese translation scenes, while coarsely aligned discourse and paragraph corpora are relatively easy to obtain. Therefore corpus alignment is quite valuable and necessary for research. In the study of sentence alignment in traditional bilingual parallel corpus, a comprehensive evaluation criterion is established to measure the similarity between two sentence pairs according to the grammatical information of bilingual text, such as length, vocabulary and context. Although it has achieved good results in single sentence alignment, it has limited ability in sentence matching and poor performance in some many-to-many alignment patterns. We attempt to consider bilingual semantic information by using the rapidly developing pre-trained language model with strong semantic representation capabilities. However, the pre-trained language model itself can only cover relatively local information, so we propose reinforcement learning training objectives based on dynamic programming algorithm to integrate global information of paragraphs, and then carry out unsupervised training. Experimental results show that the performance of the model trained by our proposed method is better than that of previous baseline model with best performance, especially compared with many-to-many alignment model, which is difficult to deal with by traditional models. © 2022 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License.
DA  - 2022///
PY  - 2022
SP  - 704
EP  - 715
ST  - 基于强化学习的古今汉语句子对齐研究
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146368153&partnerID=40&md5=77c14215c03ebedce96f2401687692c0
DB  - Scopus
KW  - Deep learning
KW  - Semantics
KW  - Reinforcement learning
KW  - Performance
KW  - Reinforcement learnings
KW  - Dynamic programming
KW  - Reinforcement Learning
KW  - Computational linguistics
KW  - Language model
KW  - High quality
KW  - Bilingual alignment
KW  - Bilingual Alignment
KW  - Bilinguals
KW  - Dynamic Programming
KW  - Machine translation
KW  - Many to many
KW  - Parallel corpora
KW  - Pre-trained language model
KW  - Pre-trained Language Model
KW  - Sentence alignment
ER  - 

TY  - CONF
TI  - Machine learning technology in safety production and maintenance of power plant
AU  - Wang, S.
AU  - Liu, Z.
AU  - Zhang, P.
AU  - Zhang, L.
AU  - Chen, S.
AU  - Qi, N.
AU  - Wu, J.
T2  - Proceedings of SPIE - The International Society for Optical Engineering
AB  - Many safety accidents occur in electric power enterprises every year, more than 50% of which are caused by the lack of safety supervision, disregard for safety regulations and non-standard operation when operators are maintaining electric power equipment. In order to improve the professional quality of operators, we developed the power equipment maintenance training system based on virtual reality, which allows operators to operate in a 360-degree immersive virtual environment. In this system, we also developed an automatic online evaluation algorithm based on YOLOv3, and the experiment results shows that this method has good accuracy, intelligence and high reliability. © 2022 SPIE.
DA  - 2022///
PY  - 2022
DO  - 10.1117/12.2662237
VL  - 12506
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146702026&doi=10.1117%2f12.2662237&partnerID=40&md5=710f01929d32d804886b3b7c4cc6eea0
DB  - Scopus
KW  - artificial intelligence
KW  - Machine learning
KW  - virtual reality
KW  - Virtual reality
KW  - E-learning
KW  - Machine-learning
KW  - Personnel training
KW  - Engineering education
KW  - Training Systems
KW  - Safety regulations
KW  - Machine learning technology
KW  - Safety standard
KW  - Safety accidents
KW  - Electric power enterprise
KW  - safety production
KW  - Safety production
KW  - Safety supervision
KW  - target identification
KW  - Target's identifications
KW  - training system
ER  - 

TY  - CONF
TI  - An Industrial Experience Report about Challenges from Continuous Monitoring, Improvement, and Deployment for Autonomous Driving Features
AU  - Nouri, A.
AU  - Berger, C.
AU  - Torner, F.
T2  - Proceedings - 48th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2022
AB  - Using continuous development, deployment, and monitoring (CDDM) to understand and improve applications in a customer's context is widely used for non-safety applications such as smartphone apps or web applications to enable rapid and innovative feature improvements. Having demonstrated its potential in such domains, it may have the potential to also improve the software development for automotive functions as some OEMs described on a high level in their financial company communiqués. However, the application of a CDDM strategy also faces challenges from a process adherence and documentation perspective as required by safety-related products such as autonomous driving systems (ADS) and guided by industry standards such as ISO-26262 [1] and ISO21448 [2]. There are publications on CDDM in safety-relevant contexts that focus on safety-critical functions on a rather generic level and thus, not specifically ADS or automotive, or that are concentrating only on software and hence, missing out the particular context of an automotive OEM: Well-established legacy processes and the need of their adaptations, and aspects originating from the role of being a system integrator for software/software, hardware/hardware, and hardware/software. In this paper, particular challenges from the automotive domain to better adopt CDDM are identified and discussed to shed light on research gaps to enhance CDDM, especially for the software development of safe ADS. The challenges are identified from today's industrial well-established ways of working by conducting interviews with domain experts and complemented by a literature study. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/SEAA56994.2022.00063
SP  - 358
EP  - 365
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147655692&doi=10.1109%2fSEAA56994.2022.00063&partnerID=40&md5=caab0e8b8889c856348574c0f6aa89e9
DB  - Scopus
KW  - Autonomous vehicles
KW  - Machine learning
KW  - Autonomous driving
KW  - Learning systems
KW  - autonomous driving
KW  - Accident prevention
KW  - Machine-learning
KW  - Driving systems
KW  - Functional Safety
KW  - Software design
KW  - software development
KW  - continuous deployment
KW  - Continuous deployment
KW  - continuous development
KW  - Continuous development
KW  - continuous monitoring
KW  - Continuous monitoring
KW  - functional safety (FUSA)
KW  - machine Learning
KW  - Safety of the intended function
KW  - safety of the intended function (SOTIF)
KW  - Safety related functions
KW  - safety-related function
ER  - 

TY  - CHAP
TI  - Applications of AI and possibilities for process control
AU  - Mylvaganam, S.
T2  - Industrial Tomography: Systems and Applications, Second Edition
AB  - Multiphase flows occur in the oil and gas industries, e.g., gas/oil/water/sand (g/o/w/s) in all possible combinations, drilling mud with cuttings and g/o/w/s, in the storage and transport of wet or dry particulates, e.g., fluidized beds, slurries and sedimentation, e.g., as in dredging, in the nuclear power industries, e.g., entrained air, and steam at supercritical temperatures in cooling water in pressurized water reactors. Most of these processes have different flow regimes with varying distributions of the different materials/phases, flowing at different speeds and spread over the cross-section of the conduit supporting the flow, an important topic in CFD studies and software development. These processes are monitored with a plethora of sensors, continuously gathering vast amount of valuable data from various locations with many control loops distributed in the processes with a dedicated overall process control using different strategies, which recently have AI and machine learning techniques in their portfolio. The data from the sensors are valuable in data fusion not only for deterministic mechanistic modeling but also for exploratory data analysis (EDA), a growing branch of AI-based industrial machine learning. Data from process tomography/tomometry using nonintrusive and noninvasive sensing provide big data in real time, useful in identifying various flow phenomena, such as flow regimes, tunneling flow in silos, infiltration of sand in pipes, unusually high presence of gas bubbles in cooling water, etc. In this chapter, some applications of ECT and EIT in the above three process industries are presented. This chapter focuses on the sensor arrays and protocols used along with excitation and sensing methods used in the ECT/EIT modules and then presents some results from EDA as applied in the growing field of industrial machine learning. In all the three branches of process industries mentioned above, interesting results are presented showing possibilities of flow regime identification based on the distribution of the phases involved with the possibilities of integrating ECT/EIT in model free adaptive control of these processes. © 2022 Elsevier Ltd. All rights reserved.
DA  - 2022///
PY  - 2022
SP  - 823
EP  - 852
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159499951&doi=10.1016%2fB978-0-12-823015-2.00014-5&partnerID=40&md5=bf5cc74ccca0ce7fb9fe5d61551a2880
DB  - Scopus
KW  - Machine learning
KW  - Neural networks
KW  - Multiphase flow
KW  - Process industries
KW  - Process safety
KW  - Electrical capacitance/impedance tomography (ECT/EIT)
KW  - Flow regime
KW  - Fluidized bed column (FBC)
KW  - Model free adaptive control (MFAC)
KW  - Pressurized water reactors
KW  - Process tomography
KW  - Sensor data fusion
ER  - 

TY  - CONF
TI  - Data Efficient Safe Reinforcement Learning Algorithm
AU  - Padakandla, S.
T2  - ALA 2022 - Adaptive and Learning Agents Workshop at AAMAS 2022
AB  - Applying reinforcement learning (RL) methods for real world applications poses multiple challenges - the foremost being safety of the physical system controlled by the learning agent and the learning efficiency. A RL agent learns to control a system by exploring available actions. In some operating states, when the RL agent exercises an exploratory action, the system may enter unsafe operation, which can lead to safety hazards both for the system as well as for humans supervising the system. RL algorithms thus need to respect these safety constraints and must do so with limited available information. In our work, we formulate this problem in the constrained off-policy setting that facilitates safe exploration by the RL agent. Further, we develop a sample efficient algorithm by adapting the cross-entropy method. The proposed algorithm’s safety performance is evaluated numerically on benchmark RL problems. © 2022 ALA 2022 - Adaptive and Learning Agents Workshop at AAMAS 2022. All rights reserved.
DA  - 2022///
PY  - 2022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173586002&partnerID=40&md5=360c0b6fe4e7ad5c29d0651567b520d8
DB  - Scopus
KW  - Intelligent agents
KW  - Reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Physical systems
KW  - Real-world
KW  - Benchmarking
KW  - Learning agents
KW  - Safe Reinforcement Learning
KW  - Safe reinforcement learning
KW  - Reinforcement learning method
KW  - Reinforcement learning algorithms
KW  - Cross-entropy method
KW  - Cross-Entropy Method
KW  - Off-policy
ER  - 

TY  - CONF
TI  - Prediction of Shear Wave Velocity in the Williston Basin Using Big Data Analysis and Robust Machine Learning Algorithms
AU  - Laalam, A.
AU  - Mouedden, N.
AU  - Ouadi, H.
AU  - Chemmakh, A.
AU  - Merzoug, A.
AU  - Boualam, A.
AU  - Djezzar, S.
AU  - Aihar, A.
AU  - Berrehal, B.E.
T2  - 56th U.S. Rock Mechanics/Geomechanics Symposium
AB  - The shear velocity is one of the most critical parameters in determining the mechanical rock elastic properties, which serve as inputs for different studies such as wellbore stability, mechanical earth modeling, hydraulic fracturing, and reservoir characterization. However, the sonic log is not acquired in every drilled well. We analyzed the log data of more than 35000 wells in the Williston Basin, and we found that only very few wells had sonic logs. For this reason, several studies attempted to correlate the shear velocity (or slowness) to other easily accessible properties; these will be presented in the literature review, with their pros and cons. The focus of this paper is to apply machine learning algorithms to synthesize the shear slowness log. Our models are trained and tested with log data from 27 wells drilled in the Bakken petroleum system, Williston Basin. Logging data include Gamma Ray, Deep Resistivity, Density, Neutron Porosity, and Shear Slowness. Five different algorithms were developed and tested against blind data including Xtreme Gradient Booster, Random Forest Regressor, Linear Regression, Ada Boost Regression, and Bayesian Ridge Regression. Overall, the R2-score varied from 0.55 to 0.92, with the XGBoost outperforming the other algorithms. © 2022 ARMA, American Rock Mechanics Association.
DA  - 2022///
PY  - 2022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149234841&partnerID=40&md5=3630b17a53842a69fced765c5ce5cba2
DB  - Scopus
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Learning algorithms
KW  - Regression analysis
KW  - Big data
KW  - Infill drilling
KW  - Gamma rays
KW  - Shear flow
KW  - Shear waves
KW  - Forestry
KW  - Neutron logging
KW  - Shear wave velocity
KW  - Rock mechanics
KW  - Wave propagation
KW  - Acoustic logging
KW  - Elastic properties
KW  - Hydraulic fracturing
KW  - Log data
KW  - Mechanical
KW  - Shear velocities
KW  - Shear-velocity
KW  - Sonic logs
KW  - Wellbore stability
KW  - Williston basin
ER  - 

TY  - JOUR
TI  - Sustainable power systems operations under renewable energy induced disjunctive uncertainties via machine learning-based robust optimization
AU  - Zhao, N.
AU  - You, F.
T2  - Renewable and Sustainable Energy Reviews
AB  - For sustainable and reliable power systems operations integrating variable renewable energy, it is essential to incorporate the uncertain intermittent power outputs. A novel robust unit commitment framework with data-driven disjunctive uncertainty sets is proposed for sustainable energy systems with volatile renewable wind power, assisted by machine learning. The approach can flexibly identify the uncertainty space based on renewable power forecast error data with disjunctive structures. Specifically, the uncertainty data are grouped using K-means and density-based spatial clustering of applications with noise (DBSCAN) following the optimal cluster number determined by the Calinski-Harabasz index. Disjunctive uncertainty sets are constructed accordingly as the union of multiple basic uncertainty sets, including conventional box and budget uncertainty sets, and data-driven uncertainty sets using Dirichlet process mixture model, principal component analysis coupled with kernel density estimation, and support vector clustering. Subsequently, the problem is formulated into a two-stage adaptive robust unit commitment model with data-driven disjunctive uncertainty sets and with a multi-level optimization structure. To facilitate the solution process, a tailored decomposition-based optimization algorithm is developed. The effectiveness and scalability of the proposed framework are illustrated with two case studies investigating sustainable operations scheduling based on IEEE 39-bus and 118-bus systems, considering the integration of intermittent renewable energy. Results show that the proposed framework can reduce the price of robustness by 8–48% compared to the conventional “one-set-fits-all” robust optimization approaches. Benchmarking with stochastic programming indicates that the proposed framework can achieve the same or better economic performance for sustainable operations with over 75% less computational time. © 2022 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.rser.2022.112428
VL  - 161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127846772&doi=10.1016%2fj.rser.2022.112428&partnerID=40&md5=5291fb830850e06e6fc7e7e17007c123
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Uncertainty
KW  - Uncertainty analysis
KW  - Benchmarking
KW  - Wind power
KW  - Robust optimization
KW  - Data-driven approach
KW  - Principal component analysis
KW  - Stochastic systems
KW  - Stochastic programming
KW  - Data driven
KW  - Power system operations
KW  - Renewable energies
KW  - K-means clustering
KW  - Budget control
KW  - Disjunction
KW  - Sustainable operations
KW  - Unit commitment
KW  - Unit Commitment
ER  - 

TY  - CONF
TI  - Algorithmic Fairness and Structural Injustice: Insights from Feminist Political Philosophy
AU  - Kasirzadeh, A.
T2  - AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society
AB  - Data-driven predictive algorithms are widely used to automate and guide high-stake decision making such as bail and parole recommendation, medical resource distribution, and mortgage allocation. Nevertheless, harmful outcomes biased against vulnerable groups have been reported. The growing research field known as 'algorithmic fairness' aims to mitigate these harmful biases. Its primary methodology consists in proposing mathematical metrics to address the social harms resulting from an algorithm's biased outputs. The metrics are typically motivated by-or substantively rooted in-ideals of distributive justice, as formulated by political and legal philosophers. The perspectives of feminist political philosophers on social justice, by contrast, have been largely neglected. Some feminist philosophers have criticized the local scope of the paradigm of distributive justice and have proposed corrective amendments to surmount its limitations. The present paper brings some key insights of feminist political philosophy to algorithmic fairness. The paper has three goals. First, I show that algorithmic fairness does not accommodate structural injustices in its current scope. Second, I defend the relevance of structural injustices-as pioneered in the contemporary philosophical literature by Iris Marion Young-to algorithmic fairness. Third, I take some steps in developing the paradigm of 'responsible algorithmic fairness' to correct for errors in the current scope and implementation of algorithmic fairness. I close by some reflections of directions for future research.  © 2022 Owner/Author.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3514094.3534188
SP  - 349
EP  - 356
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157991&doi=10.1145%2f3514094.3534188&partnerID=40&md5=4c177887c656c6316d29bfb7a873f73f
DB  - Scopus
KW  - Machine learning
KW  - Decision making
KW  - responsibility
KW  - Algorithmic fairness
KW  - Responsibility
KW  - Machine-learning
KW  - Algorithmics
KW  - algorithmic bias
KW  - Algorithmic bias
KW  - algorithmic fairness
KW  - Ethical technology
KW  - algorithmic justice
KW  - Algorithmic justice
KW  - distributive justice
KW  - Distributive justice
KW  - Ethic of artificial intelligence
KW  - ethical machine learning
KW  - Ethical machine learning
KW  - ethics of artificial intelligence
KW  - feminist philosophy
KW  - Feminist philosophy
KW  - political philosophy
KW  - Political philosophy
KW  - structural injustice
KW  - Structural injustice
ER  - 

TY  - JOUR
TI  - Robust Data-Driven Framework for Driver Behavior Profiling Using Supervised Machine Learning
AU  - Abdelrahman, A.E.
AU  - Hassanein, H.S.
AU  - Abu-Ali, N.
T2  - IEEE Transactions on Intelligent Transportation Systems
AB  - Driver behavior profiling has been gaining increased attention due to its relevance in many applications. For instance, car insurance telematics and fleet management entities have been recently using smartphones' embedded sensors, On-Board Diagnostics II (OBDII) units and other on-board IoT devices to collect data on vehicles' behavior and evaluate the risk profile of drivers. In this context, this paper presents a robust data-driven framework for calculating drivers' risk profile measured in terms of the additive inverse of the predicted risk probability. The Strategic Highway Research Program 2 (SHRP2) naturalistic driving study (NDS) dataset, which is the largest dataset of its kind to date, is utilized to build the risk prediction models. Crash and near-crash events are used to quantify riskiness whereas balanced baseline driving events (i.e., events captured during normal day to day driving episodes) are used to reflect total exposure or driving time per driver. Thirteen mutually exclusive behavioral risk predictors are identified, and the feature matrix is formulated. A sensitivity analysis is then performed to find the best number of balanced baseline events below which drivers are filtered out. Different machine learning models are selected, customized, and compared to achieve best risk prediction performance. Finally, the utilization of the proposed prediction model within an envisioned driver profiling cloud-based framework is briefly discussed.  © 2000-2011 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TITS.2020.3035700
VL  - 23
IS  - 4
SP  - 3336
EP  - 3350
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097142238&doi=10.1109%2fTITS.2020.3035700&partnerID=40&md5=7eb7b661cbe5492cd179ea7a88e95b8b
DB  - Scopus
KW  - Learning systems
KW  - Supervised learning
KW  - Fleet operations
KW  - Predictive analytics
KW  - Forecasting
KW  - Machine learning models
KW  - Risk assessment
KW  - Inverse problems
KW  - Supervised machine learning
KW  - Sensitivity analysis
KW  - Risk prediction models
KW  - Data-driven applications
KW  - Driving behavior profiling
KW  - Feature matrices
KW  - Intelligent transportation systems (its)
KW  - Internet of intelligent vehicles (ioiv)
KW  - Naturalistic driving studies
KW  - On board diagnostics
KW  - Prediction models
KW  - Risk probabilities
KW  - Strategic highway research programs
KW  - Vehicle-to-cloud (v2c) applications
ER  - 

TY  - JOUR
TI  - Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective
AU  - Meng, M.H.
AU  - Bai, G.
AU  - Teo, S.G.
AU  - Hou, Z.
AU  - Xiao, Y.
AU  - Lin, Y.
AU  - Dong, J.S.
T2  - IEEE Transactions on Dependable and Secure Computing
AB  - Neural networks have been widely applied in security applications such as spam and phishing detection, intrusion prevention, and malware detection. This black-box method, however, often has uncertainty and poor explainability in applications. Furthermore, neural networks themselves are often vulnerable to adversarial attacks. For those reasons, there is a high demand for trustworthy and rigorous methods to verify the robustness of neural network models. Adversarial robustness, which concerns the reliability of a neural network when dealing with maliciously manipulated inputs, is one of the hottest topics in cybersecurity and machine learning. In this work, we survey existing literature in adversarial robustness verification for neural networks and collect 39 diversified research works across machine learning, security, and software engineering domains. We systematically analyze their approaches, including how robustness is formulated, what verification techniques are used, and the strengths and limitations of each technique. We provide a taxonomy from a formal verification perspective for a comprehensive understanding of this topic. We classify the existing techniques based on property specification, problem reduction, and reasoning strategies. We also demonstrate representative techniques that have been applied in existing studies with a sample model. Finally, we discuss open questions for future research. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TDSC.2022.3179131
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131769523&doi=10.1109%2fTDSC.2022.3179131&partnerID=40&md5=7457c1157e46214629cdc321c1b9d126
DB  - Scopus
KW  - Cognition
KW  - Deep learning
KW  - deep learning
KW  - security
KW  - Security
KW  - verification
KW  - Biological neural networks
KW  - Deep neural networks
KW  - Intrusion detection
KW  - Taxonomy
KW  - Training
KW  - neural networks
KW  - Surveys
KW  - Network security
KW  - Robustness
KW  - Neural-networks
KW  - adversarial machine learning
KW  - Adversarial machine learning
KW  - Malware
KW  - Cybersecurity
KW  - Model checking
KW  - Formal verification
KW  - Models checking
KW  - Taxonomies
ER  - 

TY  - JOUR
TI  - Prioritized Experience-Based Reinforcement Learning With Human Guidance for Autonomous Driving
AU  - Wu, J.
AU  - Huang, Z.
AU  - Huang, W.
AU  - Lv, C.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Reinforcement learning (RL) requires skillful definition and remarkable computational efforts to solve optimization and control problems, which could impair its prospect. Introducing human guidance into RL is a promising way to improve learning performance. In this article, a comprehensive human guidance-based RL framework is established. A novel prioritized experience replay mechanism that adapts to human guidance in the RL process is proposed to boost the efficiency and performance of the RL algorithm. To relieve the heavy workload on human participants, a behavior model is established based on an incremental online learning method to mimic human actions. We design two challenging autonomous driving tasks for evaluating the proposed algorithm. Experiments are conducted to access the training and testing performance and learning mechanism of the proposed algorithm. Comparative results against the state-of-the-art methods suggest the advantages of our algorithm in terms of learning efficiency, performance, and robustness. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TNNLS.2022.3177685
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132726832&doi=10.1109%2fTNNLS.2022.3177685&partnerID=40&md5=e6287fa91f83f824f3ff8133de781552
DB  - Scopus
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Task analysis
KW  - Training
KW  - Testing
KW  - Behavioral science
KW  - Behavioral sciences
KW  - Autonomous driving
KW  - Learning systems
KW  - Autonomous Vehicles
KW  - Behavioral research
KW  - Job analysis
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Efficiency
KW  - Robustness (control systems)
KW  - Robustness
KW  - reinforcement learning (RL)
KW  - Experience replay
KW  - human demonstration
KW  - Human demonstrations
KW  - priority experience replay
KW  - Priority experience replay
ER  - 

TY  - CHAP
TI  - Monitoring Employees Entering and Leaving the Office with Deep Learning Algorithms
AU  - Hoang, V.T.
AU  - Minh, K.T.
AU  - Hieu, N.D.
AU  - Hoang, V.N.
T2  - Lecture Notes on Data Engineering and Communications Technologies
AB  - This study attempts to create a system to monitor employees entering and leaving the office using face recognition. In addition, the system also signals by LED when recognizing a staff who has clearance to enter or notifies those who do not in the area. Events of entering and leaving from staff are written into a log file for management purposes. The face-detection and image processing utilize Multi-task Cascaded Convolutional Network. Feature data is then extracted from the processed images by FaceNet, which is classified by the Support Vector Machine algorithm into a model. Information of employees and logs are saved in MySQL database, which is also used in a web application using Python and Django web framework. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
VL  - 124
SP  - 641
EP  - 658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130976855&doi=10.1007%2f978-3-030-97610-1_51&partnerID=40&md5=781e53a9f21728ce6ee70321c8cd62a9
DB  - Scopus
KW  - Deep learning
KW  - Feature extraction
KW  - Training
KW  - Real-time systems
KW  - Support vector machines
KW  - Convolutional neural networks
KW  - Features extraction
KW  - Learning algorithms
KW  - Human resource management
KW  - Interactive computer systems
KW  - Real - Time system
KW  - Real time systems
KW  - Convolutional neural nets
KW  - Convolution
KW  - Convolutional neural network
KW  - Personnel training
KW  - Cameras
KW  - Learning (artificial intelligence)
KW  - High level languages
KW  - Python
KW  - Detectors
KW  - Face recognition
KW  - Faces detection
KW  - Raspberry pi
KW  - Support vectors machine
KW  - Support vector machine
KW  - Face alignment
KW  - Cascaded convolutional neural network
KW  - Convolutional neural net
KW  - Databases
KW  - Django
KW  - Face
KW  - Face detection
KW  - Facenet
KW  - Mysql
ER  - 

TY  - JOUR
TI  - Learning Adaptive Patch Generators for Mask-Robust Image Inpainting
AU  - Sun, H.
AU  - Li, W.
AU  - Duan, Y.
AU  - Zhou, J.
AU  - Lu, J.
T2  - IEEE Transactions on Multimedia
AB  - In this paper, we propose a Mask-Robust Inpainting Network (MRIN) method to recover the masked areas of an image. Most existing methods learn a single model for image inpainting, under a basic assumption that all the masks belong to the same type. However, we discover that the masks are usually complex and exhibit various shapes and sizes at different locations of an image, where a single model cannot fully capture the large domain gap across different masks. To address this, we learn to decompose a complex mask area into several basic mask types and inpaint the damaged image in a patch-wise manner with a type-specific generator. More specifically, our MRIN consists of a mask-robust agent and an adaptive patch generative network. The mask-robust agent contains a mask selector and a patch locator, which generates mask attention maps to select a patch at each step. We train our mask-robust agent to learn the optimal inpainting patch route in a reinforcement learning manner by formulating the process of inpainting sequentially as a Markov decision process. Then, based on the predicted mask attention maps, the adaptive patch generative network inpaints the selected patch with the generators bank, so that it sequentially inpaints each patch with different patch generators according to its mask type. Extensive experiments demonstrate that our approach outperforms most state-of-the-art approaches on the Place2, CelebA, and Paris Street View datasets. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TMM.2022.3174413
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132537497&doi=10.1109%2fTMM.2022.3174413&partnerID=40&md5=c6684939bde01526e4494f3fd1a96bfe
DB  - Scopus
KW  - Semantics
KW  - Reinforcement learning
KW  - Adaptive systems
KW  - Training
KW  - Computer vision
KW  - Complex networks
KW  - Markov processes
KW  - Learn+
KW  - Adaptation models
KW  - Generators
KW  - Shape
KW  - Generator
KW  - Adaptive patch generator
KW  - adaptive patch generators
KW  - Image inpainting
KW  - Image Inpainting
KW  - Inpainting
KW  - mask-robust agent
KW  - Mask-robust agent
KW  - Network methods
KW  - Single models
ER  - 

TY  - CONF
TI  - Robust Intent Classification Using Bayesian LSTM for Clinical Conversational Agents (CAs)
AU  - Aftab, H.
AU  - Gautam, V.
AU  - Hawkins, R.
AU  - Alexander, R.
AU  - Habli, I.
T2  - Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST
AB  - Conversational Agents (CAs) are software programs that replicate human conversations using machine learning (ML) and natural language processing (NLP). CAs are currently being utilised for diverse clinical applications such as symptom checking, health monitoring, medical triage and diagnosis. Intent classification (IC) is an essential task of understanding user utterance in CAs which makes use of modern deep learning (DL) methods. Because of the inherent model uncertainty associated with those methods, accuracy alone cannot be relied upon in clinical applications where certain errors may compromise patient safety. In this work, we employ Bayesian Long Short-Term Memory Networks (LSTMs) to calculate model uncertainty for IC, with a specific emphasis on symptom checker CAs. This method provides a certainty measure with IC prediction that can be utilised in assuring safe response from CAs. We evaluated our method on in-distribution (ID) and out-of-distribution (OOD) data and found mean uncertainty to be much higher for OOD data. These findings suggest that our method is robust to OOD utterances and can detect non-understanding errors in CAs. © 2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-06368-8_8
VL  - 440 LNICST
SP  - 106
EP  - 118
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133012008&doi=10.1007%2f978-3-031-06368-8_8&partnerID=40&md5=63ee1c8d0b61a59f295f878eb7bdfd57
DB  - Scopus
KW  - Machine Learning
KW  - Learning algorithms
KW  - Machine-learning
KW  - Bayesian networks
KW  - Conversational agents
KW  - Safety engineering
KW  - Uncertainty analysis
KW  - Long short-term memory
KW  - Natural language processing systems
KW  - Patient safety
KW  - Modeling uncertainties
KW  - Integrated circuits
KW  - Model uncertainty
KW  - Software agents
KW  - Healthcare
KW  - Bayesian
KW  - Clinical application
KW  - Conversational agent
KW  - Conversational Agents (CAs)
KW  - Memory network
KW  - Out-of-distribution
KW  - Out-of-distribution (OOD)
ER  - 

TY  - CONF
TI  - Influence of Transfer Learning on Machine Learning Systems Robustness to Data Quality Degradation
AU  - Chuprov, S.
AU  - Khokhlov, I.
AU  - Reznik, L.
AU  - Shetty, S.
T2  - Proceedings of the International Joint Conference on Neural Networks
AB  - The evolution of the Machine Learning (ML) has led to the emergence of Transfer Learning (TL) approach, which allows reusing pretrained industrial ML systems after their input data values or even an application domain has changed. In this paper, we investigate the TL process and its impact on the performance of ML-end systems with integrated network facilities. Especially, we focus on ML-systems designed for the classification of image media-files, transmitted over a network. Packet loss in a network is considered as a major input Data Quality (DQ) deterioration factor that can result in ML system classification performance degradation after pretraining on good inputs. To investigate the typical industrial TL process, we study the relationships between the ML model's last layer weights, hyperparameters, and classification performance throughout the retraining process. In addition, we conduct an empirical study to evaluate how the TL affects ML model performance in real application scenarios. For our experiments, we employ real image media-files, and transmit them over a real wireless network with inherent data losses for a classification on a remote ML-end system. According to our results, retraining ML models on corrupted data allows to enhance their robustness to a DQ degradation in the considered image classification scenarios. However, DQ influence on the ML system performance may vary depending on the data and system types. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/IJCNN55064.2022.9892247
VL  - 2022-July
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140747226&doi=10.1109%2fIJCNN55064.2022.9892247&partnerID=40&md5=aa583b00ac07e37019ece15ff066191c
DB  - Scopus
KW  - machine learning
KW  - Convolutional neural networks
KW  - Learning systems
KW  - convolutional neural networks
KW  - Transfer learning
KW  - Machine-learning
KW  - Image classification
KW  - Classification (of information)
KW  - Convolutional neural network
KW  - Machine learning models
KW  - Image enhancement
KW  - Data quality
KW  - transfer learning
KW  - Machine learning systems
KW  - On-machines
KW  - Deterioration
KW  - Input output programs
KW  - Input datas
KW  - Industrial classifier
KW  - industrial classifiers
KW  - Quality degradation
ER  - 

TY  - CHAP
TI  - Partnering with technology firms to train smart city workforces
AU  - Pahuja, N.
T2  - Smart Cities Policies and Financing: Approaches and Solutions
AB  - Globally, all Smart Cities require strong infrastructure, ways of sustainable development, and importantly Smart Workforces to handle and implement the processes required to keep the city “Smart.” With technology impacting almost all areas of work, also changing very frequently, and impacting the grassroot process, training and reskilling have become especially important. With tools for self-learning and personalized learning, the skill gaps can be manageably handled. The Technology Firms can effectively partner and provide the newer technology tools, which can be very effectively used for training, skilling, reskilling, and upskilling. With Natural Language Processes (NLP) facilities becoming better, these companies can also provide support in training in local languages. This chapter attempts to first bring in need for training by collating some of the new skilling requirements of Smart Cities. It then gets in detail of new methodologies that can be used for skilling and how some of the technology companies can partner in handling this. Even at early stage of conceptualization of “Smart Cities,” some of the technology companies helped in creating “Model Conceptual Smart Cities,” which were then expanded to include the “Smart City” implementations of today. The chapter also brings in some new thoughts to encourage the companies to spend and partner for reskilling in Public–Private Partnership (PPP) mode, to ensure continuity in this activity. The chapter also suggests the possibility of creating a “Resource Pool” for a city for getting a better return on investment required for creating this Smarter Workforce. It also goes into some suggestions on how this smarter workforce can lead to “Community Led Innovation” environment. © 2022 Elsevier Inc. All rights reserved.
DA  - 2022///
PY  - 2022
SP  - 169
EP  - 180
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137931456&doi=10.1016%2fB978-0-12-819130-9.00012-7&partnerID=40&md5=8f03586c5aff1b914f8d7f975d3b21dc
DB  - Scopus
KW  - Blockchain
KW  - Governance
KW  - Natural language processing (NLP)
KW  - Crowdsourcing
KW  - Industry 4.0
KW  - Artificial intelligence (AI)
KW  - Smart homes
KW  - Augmented reality (AR)
KW  - Change management
KW  - City assets management
KW  - Community engagement
KW  - Community-led innovations
KW  - Connectivity
KW  - Corporate social responsibilities or CSR
KW  - Data democracy
KW  - Digital learning
KW  - Disaster management
KW  - Idle resource monetization
KW  - IOT
KW  - Meta-data
KW  - Personalized learning vocational studies
KW  - Persons with special needs
KW  - Processes
KW  - Public–private partnership (PPP)
KW  - Resource reusability
KW  - Smart cclasses
KW  - Smart city framework
KW  - Smart health
KW  - Smart lights
KW  - Smart tourism
KW  - Smart water
KW  - Smarter workforce
KW  - Stakeholder consultation
KW  - Things enabled services
KW  - Virtual laboratory
KW  - Virtual reality (VR)
KW  - Water harvesting
ER  - 

TY  - JOUR
TI  - The Robustness of Counterfactual Explanations Over Time
AU  - Ferrario, A.
AU  - Loi, M.
T2  - IEEE Access
AB  - Counterfactual explanations are a prominent example of post-hoc interpretability methods in the explainable Artificial Intelligence (AI) research domain. Differently from other explanation methods, they offer the possibility to have recourse against unfavourable outcomes computed by machine learning models. However, in this paper we show that retraining machine learning models over time may invalidate the counterfactual explanations of their outcomes. We provide a formal definition of this phenomenon and we introduce a method, namely counterfactual data augmentation, to help improving the robustness of counterfactual explanations over time. We test our method in an empirical study where we simulate different model retraining scenarios. Our results show that counterfactual data augmentation improves the robustness of counterfactual explanations over time, therefore contributing to their use in real-world machine learning applications.  © 2013 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3196917
VL  - 10
SP  - 82736
EP  - 82750
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135767340&doi=10.1109%2fACCESS.2022.3196917&partnerID=40&md5=9583791ea9841f5e083261882f0fdcd7
DB  - Scopus
KW  - Explainable artificial intelligence
KW  - Artificial intelligence
KW  - Machine learning
KW  - explainable artificial intelligence
KW  - counterfactual explanations
KW  - robustness
KW  - Learning systems
KW  - Machine-learning
KW  - Counterfactuals
KW  - Robustness
KW  - Algorithmics
KW  - Data augmentation
KW  - algorithmic recourse
KW  - Algorithmic recourse
KW  - counterfactual data augmentation
KW  - Counterfactual data augmentation
KW  - Counterfactual explanation
ER  - 

TY  - JOUR
TI  - A data-driven robust optimization algorithm for black-box cases: An application to hyper-parameter optimization of machine learning algorithms
AU  - Seifi, F.
AU  - Azizi, M.J.
AU  - Akhavan Niaki, S.T.
T2  - Computers and Industrial Engineering
AB  - The huge availability of data in the last decade has raised the opportunity for the better use of data in decision-making processes. The idea of using the existing data to achieve a more coherent reality solution has led to a branch of optimization called data-driven optimization. On the one hand, the presence of uncertain variables in these datasets makes it crucial to design robust optimization methods in this area. On the other hand, in many real-world problems, the closed-form of the objective function is not available and a meta-model based framework is necessary. Motivated by the above points, in this paper a Gaussian process is used in a Bayesian optimization framework to design a method that is consistent with the data in a predefined confidence level. The advantage of the proposed method is that it is computationally tractable in addition to being robust and independent of the objective function's form. As one of the applications of the proposed algorithm, hyper-parameter optimization for deep learning is investigated. The proposed method can help find the optimal hyper-parameters that are robust with respect to noise. © 2021 Elsevier Ltd
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.cie.2021.107581
VL  - 160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112307597&doi=10.1016%2fj.cie.2021.107581&partnerID=40&md5=a6ef9ee5ae1cddf885674810e44be2c2
DB  - Scopus
KW  - Deep learning
KW  - Decision making
KW  - Learning algorithms
KW  - Optimization
KW  - Robust optimization
KW  - Parameter estimation
KW  - Bayesian optimization
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Gaussian process
KW  - Gaussian Processes
KW  - Data driven
KW  - Hyper-parameter optimizations
KW  - Objective functions
KW  - Black-box optimization
KW  - Data-driven optimization
KW  - Hyper-parameter tuning
ER  - 

TY  - JOUR
TI  - Robust ecological analysis of camera trap data labelled by a machine learning model
AU  - Whytock, R.C.
AU  - Świeżewski, J.
AU  - Zwerts, J.A.
AU  - Bara-Słupski, T.
AU  - Koumba Pambo, A.F.
AU  - Rogala, M.
AU  - Bahaa-el-din, L.
AU  - Boekee, K.
AU  - Brittain, S.
AU  - Cardoso, A.W.
AU  - Henschel, P.
AU  - Lehmann, D.
AU  - Momboua, B.
AU  - Kiebou Opepa, C.
AU  - Orbell, C.
AU  - Pitman, R.T.
AU  - Robinson, H.S.
AU  - Abernethy, K.A.
T2  - Methods in Ecology and Evolution
AB  - Ecological data are collected over vast geographic areas using digital sensors such as camera traps and bioacoustic recorders. Camera traps have become the standard method for surveying many terrestrial mammals and birds, but camera trap arrays often generate millions of images that are time-consuming to label. This causes significant latency between data collection and subsequent inference, which impedes conservation at a time of ecological crisis. Machine learning algorithms have been developed to improve the speed of labelling camera trap data, but it is uncertain how the outputs of these models can be used in ecological analyses without secondary validation by a human. Here, we present our approach to developing, testing and applying a machine learning model to camera trap data for the purpose of achieving fully automated ecological analyses. As a case-study, we built a model to classify 26 Central African forest mammal and bird species (or groups). The model generalizes to new spatially and temporally independent data (n = 227 camera stations, n = 23,868 images), and outperforms humans in several respects (e.g. detecting ‘invisible’ animals). We demonstrate how ecologists can evaluate a machine learning model's precision and accuracy in an ecological context by comparing species richness, activity patterns (n = 4 species tested) and occupancy (n = 4 species tested) derived from machine learning labels with the same estimates derived from expert labels. Results show that fully automated species labels can be equivalent to expert labels when calculating species richness, activity patterns (n = 4 species tested) and estimating occupancy (n = 3 of 4 species tested) in a large, completely out-of-sample test dataset. Simple thresholding using the Softmax values (i.e. excluding ‘uncertain’ labels) improved the model's performance when calculating activity patterns and estimating occupancy but did not improve estimates of species richness. We conclude that, with adequate testing and evaluation in an ecological context, a machine learning model can generate labels for direct use in ecological analyses without the need for manual validation. We provide the user-community with a multi-platform, multi-language graphical user interface that can be used to run our model offline. © 2021 The Authors. Methods in Ecology and Evolution published by John Wiley & Sons Ltd on behalf of British Ecological Society
DA  - 2021///
PY  - 2021
DO  - 10.1111/2041-210X.13576
VL  - 12
IS  - 6
SP  - 1080
EP  - 1092
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102314419&doi=10.1111%2f2041-210X.13576&partnerID=40&md5=de9270aa5edc290b74cf962b5a9ce470
DB  - Scopus
KW  - artificial intelligence
KW  - biodiversity
KW  - birds
KW  - Central Africa
KW  - mammals
ER  - 

TY  - JOUR
TI  - Capture the high-efficiency non-fullerene ternary organic solar cells formula by machine-learning-assisted energy-level alignment optimization
AU  - Hao, T.
AU  - Leng, S.
AU  - Yang, Y.
AU  - Zhong, W.
AU  - Zhang, M.
AU  - Zhu, L.
AU  - Song, J.
AU  - Xu, J.
AU  - Zhou, G.
AU  - Zou, Y.
AU  - Zhang, Y.
AU  - Liu, F.
T2  - Patterns
AB  - Appropriate energy-level alignment in non-fullerene ternary organic solar cells (OSCs) can enhance the power conversion efficiencies (PCEs), due to the simultaneous improvement in charge generation/transportation and reduction in voltage loss. Seven machine-learning (ML) algorithms were used to build the regression and classification models based on energy-level parameters to predict PCE and capture high-performance material combinations, and random forest showed the best predictive capability. Furthermore, two sets of verification experiments were designed to compare the experimental and predicted results. The outcome elucidated that a deep lowest unoccupied molecular orbital (LUMO) of the non-fullerene acceptors can slightly reduce the open-circuit voltage (VOC) but significantly improve short-circuit current density (JSC), and, to a certain extent, the VOC could be optimized by the slightly up-shifted LUMO of the third component in non-fullerene ternary OSCs. Consequently, random forest can provide an effective global optimization scheme and capture multi-component combinations for high-efficiency ternary OSCs. © 2021 The Authors
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.patter.2021.100333
VL  - 2
IS  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123628138&doi=10.1016%2fj.patter.2021.100333&partnerID=40&md5=f16d4b7e99abb447225e453282b2c73a
DB  - Scopus
KW  - machine learning
KW  - Decision trees
KW  - Machine learning
KW  - Random forests
KW  - Global optimization
KW  - Alignment
KW  - Domain problems
KW  - DSML 3: Development/Pre-production: Data science output has been rolled out/validated across multiple domains/problems
KW  - DSML 3: development/pre-production: data science output have been rolled out/validated across multiple domain/problem
KW  - Multiple domains
KW  - Pre-production
KW  - Production data
KW  - Energy level alignment
KW  - energy-level alignment
KW  - Fullerenes
KW  - Higher efficiency
KW  - Molecular orbitals
KW  - Open circuit voltage
KW  - organic solar cells
KW  - Organic solar cells
KW  - Power conversion efficiencies
KW  - regression and classification models
KW  - Regression and classification models
ER  - 

TY  - JOUR
TI  - A study of real-world micrograph data quality and machine learning model robustness
AU  - Zhong, X.
AU  - Gallagher, B.
AU  - Eves, K.
AU  - Robertson, E.
AU  - Mundhenk, T.N.
AU  - Han, T.Y.-J.
T2  - npj Computational Materials
AB  - Machine-learning (ML) techniques hold the potential of enabling efficient quantitative micrograph analysis, but the robustness of ML models with respect to real-world micrograph quality variations has not been carefully evaluated. We collected thousands of scanning electron microscopy (SEM) micrographs for molecular solid materials, in which image pixel intensities vary due to both the microstructure content and microscope instrument conditions. We then built ML models to predict the ultimate compressive strength (UCS) of consolidated molecular solids, by encoding micrographs with different image feature descriptors and training a random forest regressor, and by training an end-to-end deep-learning (DL) model. Results show that instrument-induced pixel intensity signals can affect ML model predictions in a consistently negative way. As a remedy, we explored intensity normalization techniques. It is seen that intensity normalization helps to improve micrograph data quality and ML model robustness, but microscope-induced intensity variations can be difficult to eliminate. © 2021, The Author(s).
DA  - 2021///
PY  - 2021
DO  - 10.1038/s41524-021-00616-3
VL  - 7
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116385242&doi=10.1038%2fs41524-021-00616-3&partnerID=40&md5=990bd2221b06446a3619d73aa94f9672
DB  - Scopus
KW  - Decision trees
KW  - Deep learning
KW  - Machine learning models
KW  - Real-world
KW  - Quality control
KW  - Data quality
KW  - Machine learning techniques
KW  - Model robustness
KW  - Pixels
KW  - Scanning electron microscopy
KW  - Compressive strength
KW  - Image pixel intensities
KW  - Molecular solid
KW  - Normalisation
KW  - Quality variation
KW  - Solid material
ER  - 

TY  - JOUR
TI  - Robust Network Intrusion Detection System Based on Machine-Learning With Early Classification
AU  - Kim, T.
AU  - Pak, W.
T2  - IEEE Access
AB  - Network Intrusion Detection Systems (NIDSs) using pattern matching have a fatal weakness in that they cannot detect new attacks because they only learn existing patterns and use them to detect those attacks. To solve this problem, a machine learning-based NIDS (ML-NIDS) that detects anomalies through ML algorithms by analyzing behaviors of protocols. However, the ML-NIDS learns the characteristics of attack traffic based on training data, so it, too, is inevitably vulnerable to attacks that have not been learned, just like pattern-matching machine learning. Therefore, in this study, by analyzing the characteristics of learning using representative features, we show that network intrusion outside the scope of the learned data in the feature space can bypass the ML-NIDS. To prevent this, designing the active session to be classified early, before it goes outside the detection range of the training dataset of the ML-NIDS, can effectively prevent bypassing the ML-NIDS. Various experiments confirmed that the proposed method can detect intrusion sessions early (before sessions terminate) significantly improving the robustness of the existing ML-NIDS. The proposed approach can provide more robust and more accurate classification with the same classification datasets compared to existing approaches, so we expect it will be used as one of feasible solutions to overcome weakness and limitation of existing ML-NIDSs. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3145002
VL  - 10
SP  - 10754
EP  - 10767
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123729139&doi=10.1109%2fACCESS.2022.3145002&partnerID=40&md5=6cea1c6c2db1b4f637cad16df3021047
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Feature extraction
KW  - Intrusion detection
KW  - Data models
KW  - Training
KW  - Training data
KW  - Learning systems
KW  - Features extraction
KW  - Classification (of information)
KW  - Computer crime
KW  - Robustness
KW  - Adversarial attack
KW  - Robust classification
KW  - Network intrusion detection systems
KW  - Payload
KW  - Network intrusion detection
KW  - Early classification
KW  - Pattern matching
KW  - Pattern-matching
KW  - Payloads
ER  - 

TY  - CONF
TI  - A NOISE-ROBUST SELF-SUPERVISED PRE-TRAINING MODEL BASED SPEECH REPRESENTATION LEARNING FOR AUTOMATIC SPEECH RECOGNITION
AU  - Zhu, Q.-S.
AU  - Zhang, J.
AU  - Zhang, Z.-Q.
AU  - Wu, M.-H.
AU  - Fang, X.
AU  - Dai, L.-R.
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
AB  - Wav2vec2.0 is a popular self-supervised pre-training framework for learning speech representations in the context of automatic speech recognition (ASR). It was shown that wav2vec2.0 has a good robustness against the domain shift, while the noise robustness is still unclear. In this work, we therefore first analyze the noise robustness of wav2vec2.0 via experiments. We observe that wav2vec2.0 pre-trained on noisy data can obtain good representations and thus improve the ASR performance on the noisy test set, which however brings a performance degradation on the clean test set. To avoid this issue, in this work we propose an enhanced wav2vec2.0 model. Specifically, the noisy speech and the corresponding clean version are fed into the same feature encoder, where the clean speech provides training targets for the model. Experimental results reveal that the proposed method can not only improve the ASR performance on the noisy test set which surpasses the original wav2vec2.0, but also ensure a tiny performance decrease on the clean test set. In addition, the effectiveness of the proposed method is demonstrated under different types of noise conditions. © 2022 IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICASSP43922.2022.9747379
VL  - 2022-May
SP  - 3174
EP  - 3178
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131259464&doi=10.1109%2fICASSP43922.2022.9747379&partnerID=40&md5=320c4904c2240b2ed27d99b3a7ef5c88
DB  - Scopus
KW  - Speech recognition
KW  - Testing
KW  - Noise robust
KW  - noise robustness
KW  - Noise robustness
KW  - Pre-training
KW  - Automatic speech recognition
KW  - self-supervised pre-training
KW  - Self-supervised pre-training
KW  - speech recognition
KW  - Wav2vec2.0
KW  - Test sets
KW  - Speech recognition performance
KW  - speech representation
KW  - Speech representation
KW  - Training model
ER  - 

TY  - JOUR
TI  - Employing Co-Learning to Evaluate the Explainability of Multimodal Sentiment Analysis
AU  - Jain, D.K.
AU  - Rahate, A.
AU  - Joshi, G.
AU  - Walambe, R.
AU  - Kotecha, K.
T2  - IEEE Transactions on Computational Social Systems
AB  - Deep neural nets are opaque black-box models with little to no understanding of underlying model dynamics. This issue is more prevalent in the case of multimodal artificial intelligence (AI) systems, where model explainability and interpretability are prime concerns due to data integration from heterogeneous data streams and complex inter and intramodal interactions. However, the traditional explainable models are challenging to apply in the multimodal scenario. We propose a co-learning-based solution for fostering model explainability for the natural language processing (NLP)-based multimodal sentiment analysis application to address this issue. The proposed approach employs explainability by obeying the co-learning principles of dealing with noisy and missing modality either at train or test time to find the modality dominance by extracting the local and global model explanations. The proposed approach is validated with post hoc explainability methods such as local interpretable model-agnostic explanations (LIME) and SHapley Additive exPlanations (SHAP) gradient-based explanations to model the modality contributions and interactions at the fusion level. The co-learning-based system ensures trust and robustness in the model by providing some degree of model explainability along with robustness. The kind of explanations provided is multifaceted and is obtained through a peek inside the black box, hence is specifically helpful for the system designers and model developers to understand the complex model dynamics that are far more challenging in the case of multimodal applications. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TCSS.2022.3176403
SP  - 1
EP  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132523429&doi=10.1109%2fTCSS.2022.3176403&partnerID=40&md5=e62f2275221fc468da261e074eab30fd
DB  - Scopus
KW  - Artificial intelligence
KW  - Predictive models
KW  - Explainable artificial intelligence (XAI)
KW  - Deep neural networks
KW  - Data models
KW  - Training
KW  - Analytical models
KW  - Natural language processing
KW  - multimodal deep learning
KW  - Multi-modal
KW  - Robustness
KW  - Language processing
KW  - Natural languages
KW  - Data fusion
KW  - interpretable AI
KW  - Data integration
KW  - Lime
KW  - Co-learning
KW  - Interpretable artificial intelligence
KW  - Modal analysis
KW  - multimodal co-learning
KW  - Multimodal co-learning
KW  - multimodal data fusion
KW  - Multimodal data fusion
KW  - Multimodal deep learning
KW  - Multimodal sentiment analyse
KW  - multimodal sentiment analysis
KW  - natural language processing (NLP)
KW  - Sentiment analysis
ER  - 

TY  - JOUR
TI  - Adversarial smoothing tri-regression for robust semi-supervised industrial soft sensor
AU  - Feng, L.
AU  - Zhao, C.
AU  - Huang, B.
T2  - Journal of Process Control
AB  - In industrial processes, soft sensor techniques are used to predict the hard-to-measure quality variables under the classic supervised learning paradigm. However, the data challenges, i.e., the widespread noises and inadequate labeled samples, usually make the data-driven sensors weak for application. In this paper, a simple but effective regularization method termed as adversarial smoothing regularization (ASR) is proposed, which measures the local smoothness of prediction around each input sample. By minimizing the divergence between the predictions for noisy and clean inputs, the proposed ASR regulates the learning model to be robust against local perturbation in a semi-supervised manner. Theoretical analysis explains the smoothing capability of ASR, and shows that it is helpful for the improvement of generalization performance. We also design a tri-regression framework to further use the information of unlabeled samples with pseudo labels and present the adversarial smoothing tri-regression (ASTR) model for soft sensor. Based on two industrial processes, comprehensive soft sensor experiments and noise tests are performed to show the robust semi-supervised learning capability of the proposed ASR and ASTR. © 2021 Elsevier Ltd
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.jprocont.2021.11.001
VL  - 108
SP  - 86
EP  - 97
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119616902&doi=10.1016%2fj.jprocont.2021.11.001&partnerID=40&md5=2b2eeb791276200e6481cd863a320f40
DB  - Scopus
KW  - Supervised learning
KW  - Forecasting
KW  - Regression analysis
KW  - Semi-supervised learning
KW  - Soft sensors
KW  - Semi-supervised
KW  - Robust modeling
KW  - Regularisation
KW  - Industrial application
KW  - Industrial processs
KW  - Sensors technique
KW  - Smoothing regularization
KW  - Soft sensor
KW  - Training strategy
KW  - Tri-training
KW  - Tri-training strategy
ER  - 

TY  - JOUR
TI  - A robust procedure for machine learning algorithms using gene expression data
AU  - Auwul, M.R.
AU  - Zhang, C.
AU  - Shahjaman, M.
T2  - Biointerface Research in Applied Chemistry
AB  - Cancer classification is one of the main objectives for analyzing big biological datasets. Machine learning algorithms (MLAs) have been extensively used to accomplish this task. Several popular MLAs are available in the literature to classify new samples into normal or cancer populations. Nevertheless, most of them often yield lower accuracies in the presence of outliers, which leads to incorrect classification of samples. Hence, in this study, we present a robust approach for the efficient and precise classification of samples using noisy GEDs. We examine the performance of the proposed procedure in a comparison of the five popular traditional MLAs (SVM, LDA, KNN, Naïve Bayes, Random forest) using both simulated and real gene expression data analysis. We also considered several rates of outliers (10%, 20%, and 50%). The results obtained from simulated data confirm that the traditional MLAs produce better results through our proposed procedure in the presence of outliers using the proposed modified datasets. The further transcriptome analysis found the significant involvement of these extra features in cancer diseases. The results indicated the performance improvement of the traditional MLAs with our proposed procedure. Hence, we propose to apply the proposed procedure instead of the traditional procedure for cancer classification. © 2021 by the authors.
DA  - 2022///
PY  - 2022
DO  - 10.33263/BRIAC122.24222439
VL  - 12
IS  - 2
SP  - 2422
EP  - 2439
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110178354&doi=10.33263%2fBRIAC122.24222439&partnerID=40&md5=0b25d8af7613294b8637750b03c1ab7c
DB  - Scopus
KW  - Classification
KW  - DE gene
KW  - Gene expression data
KW  - MAD and Robustness
KW  - Outlier detection and modification
ER  - 

TY  - CHAP
TI  - Doubly robust data-driven distributionally robust optimization
AU  - Blanchet, J.
AU  - Kang, Y.
AU  - Zhang, F.
AU  - He, F.
AU  - Hu, Z.
T2  - Applied Modeling Techniques and Data Analysis 1: Computational Data Analysis Methods and Tools
AB  - Data-driven distributionally robust optimization (DD-DRO) via optimal transport has been shown to encompass a wide range of popular machine learning algorithms. In this chapter, the authors propose a data-driven robust optimization methodology to inform the transportation cost underlying the definition of the distributional uncertainty. Empirically, they show that this additional layer of robustification, which produces a method we call doubly robust data-driven distributionally robust optimization (DD-R-DRO), allows the generalization properties of regularized estimators to be enhanced while reducing testing error relative to state-of-the-art classifiers in a wide range of datasets. The authors review a robust optimization method to a metric learning optimization problem in order to learn a robust data-driven cost function. They then proceed to numerical experiments to verify the performance of DD-R-DRO method empirically, using binary classification real datasets from the UCI machine learning database. © ISTE Ltd 2021. Published by ISTE Ltd and John Wiley & Sons, Inc.
DA  - 2021///
PY  - 2021
SP  - 75
EP  - 90
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107777542&doi=10.1002%2f9781119821588.ch4&partnerID=40&md5=4c2f1d98ad9a248b1bc61d63c885fb8e
DB  - Scopus
KW  - Machine learning algorithms
KW  - Binary classification real datasets
KW  - Distributional uncertainty
KW  - Doubly robust data-driven distributionally robust optimization
KW  - Metric learning optimization problem
KW  - Numerical experiments
KW  - Robust data-driven cost function
KW  - Transportation cost
KW  - UCI machine learning database
ER  - 

TY  - CHAP
TI  - Data-driven optimization technologies for MaaS
AU  - Xi, H.
T2  - Big Data and Mobility as a Service
AB  - In this chapter, we introduce the data-driven optimization technologies that can be applied in the Mobility as a Service (MaaS) systems in the context of operational research and management science, emphasizing both theoretical and applicable perspectives. Specifically, we give a detailed overview of data-driven optimization technologies which have been widely used in the existing urban mobility system, such as data-driven dispatching methods for on-demand ridesharing services, data-driven scheduling methods for public transit, and data-driven rebalancing methods for bicycle-sharing in Section 1. We divided the characteristics of MaaS system in the existing literature into eight groups and provide different types of data generated from MaaS system and MaaS ecosystem in Section 2. Since resource allocation relies on optimization problems generating unsolved challenges in smart mobility, we provide a general MaaS framework via resource allocation and introduce both deterministic online mobility resource allocation problems and stochastic online mobility resource allocation problems in Section 3. Further, we introduce more data-driven optimization technologies which are applicable for the mobility resource allocation problems in MaaS systems in Section 4. Finally, we present a real-world case study conducted in in Tokyo, Japan, using data derived from mobile phone records in Section 5. This chapter aims to disseminate the latest findings, research achievements, and ideas on MaaS through the lens of data-driven optimization, to balance theoretical research ideas and their practicability as well as industrial applicability. © 2022 Elsevier Inc. All rights reserved.
DA  - 2021///
PY  - 2021
SP  - 143
EP  - 176
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129803638&doi=10.1016%2fB978-0-323-90169-7.00006-3&partnerID=40&md5=769f17f9beb48fdeb764888c20f8c6f1
DB  - Scopus
KW  - Data-driven optimization
KW  - Data-driven decision-making
KW  - Machine learning-based robust optimization
KW  - Mobility as a Service
KW  - Online mobility resource allocation in MaaS system
ER  - 

TY  - CONF
TI  - A Robust Method to Predict Fluid Properties Based on Big Data and Machine Learning Algorithms
AU  - Liu, Y.
AU  - Chen, C.
AU  - Zhao, H.
AU  - Wang, Y.
AU  - Han, X.
T2  - International Petroleum Technology Conference, IPTC 2021
AB  - Fluid properties are key factors for predicting single well productivity, well test interpretation and oilfield recovery prediction, which directly affect the success of ODP program design. The most accurate and direct method of acquisition is underground sampling. However, not every well has samples due to technical reasons such as excessive well deviation or high cost during the exploration stage. Therefore, analogies or empirical formulas have to be adopted to carry out research in many cases. But a large number of oilfield developments have shown that the errors caused by these methods are very large. Therefore, how to quickly and accurately obtain fluid physical properties is of great significance. In recent years, with the development and improvement of artificial intelligence or machine learning algorithms, their applications in the oilfield have become more and more extensive. This paper proposed a method for predicting crude oil physical properties based on machine learning algorithms. This method uses PVT data from nearly 100 wells in Bohai Oilfield. 75% of the data is used for training and learning to obtain the prediction model, and the remaining 25% is used for testing. Practice shows that the prediction results of the machine learning algorithm are very close to the actual data, with a very small error. Finally, this method was used to apply the preliminary plan design of the BZ29 oilfield which is a new oilfield. Especially for the unsampled sand bodies, the fluid physical properties prediction was carried out. It also compares the influence of the analogy method on the scheme, which provides potential and risk analysis for scheme design. This method will be applied in more oil fields in the Bohai Sea in the future and has important promotion value. Copyright © 2021, International Petroleum Technology Conference.
DA  - 2021///
PY  - 2021
DO  - 10.2523/IPTC-21356-MS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129783594&doi=10.2523%2fIPTC-21356-MS&partnerID=40&md5=42dc61bc73f6c244d5e6f31db0bc6646
DB  - Scopus
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Learning systems
KW  - Learning algorithms
KW  - Gasoline
KW  - Forecasting
KW  - Risk assessment
KW  - Big data
KW  - Well testing
KW  - Software testing
KW  - Risk analysis
KW  - Robust methods
KW  - Oil wells
KW  - Direct method
KW  - Fluid property
KW  - Key factors
KW  - Physical properties
KW  - Program design
KW  - Property-based
KW  - Single well
KW  - Well productivity
KW  - Well test interpretation
ER  - 

TY  - JOUR
TI  - Resilient Predictive Control Coupled with a Worst-Case Scenario Approach for a Distributed-Generation-Rich Power Distribution Grid
AU  - Dkhili, N.
AU  - Eynard, J.
AU  - Thil, S.
AU  - Grieu, S.
T2  - Clean Technologies
AB  - In a context of accelerating deployment of distributed generation in power distribution grid, this work proposes an answer to an important and urgent need for better management tools in order to ‘intelligently’ operate these grids and maintain quality of service. To this aim, a model-based predictive control (MPC) strategy is proposed, allowing efficient re-routing of power flows using flexible assets, while respecting operational constraints as well as the voltage constraints prescribed by ENEDIS, the French distribution grid operator. The flexible assets used in the case study—a low-voltage power distribution grid in southern France—are a biogas plant and a water tower. Non-parametric machine-learning-based models, i.e., Gaussian process regression (GPR) models, are developed for intraday forecasting of global horizontal irradiance (GHI), grid load, and water demand, to better anticipate emerging constraints. The forecasts’ quality decreases as the forecast horizon grows longer, but quickly stabilizes around a constant error value. Then, the impact of forecasting errors on the performance of the control strategy is evaluated, revealing a resilient behaviour where little degradation is observed in terms of performance and computation cost. To enhance the strategy’s resilience and minimise voltage overflow, a worst-case scenario approach is proposed for the next time step and its contribution is examined. This is the main contribution of the paper. The purpose of the min–max problem added upstream of the main optimisation problem is to both anticipate and minimise the voltage overshooting resulting from forecasting errors. In this min–max problem, the feasible space defined by the confidence intervals of the forecasts is searched, in order to determine the worst-case scenario in terms of constraint violation, over the next time step. Then, such information is incorporated into the decision-making process of the main optimisation problem. Results show that these incidents are indeed reduced thanks to the min–max problem, both in terms of frequency of their occurrence and the total surface area of overshooting. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2021///
PY  - 2021
DO  - 10.3390/cleantechnol3030038
VL  - 3
IS  - 3
SP  - 629
EP  - 655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129751284&doi=10.3390%2fcleantechnol3030038&partnerID=40&md5=91da7e9785230434e612dddbd58cc979
DB  - Scopus
KW  - machine learning
KW  - Gaussian process regression
KW  - distributed generation
KW  - intraday forecasting
KW  - min–max optimisation
KW  - model-based predictive control
KW  - robust-ness
KW  - smart grid paradigm
KW  - worst-case scenario
ER  - 

TY  - CONF
TI  - CatchAll: A Robust Multivariate Intrusion Detection System for Cyber-Physical Systems using Low Rank Matrix
AU  - Dutta, A.K.
AU  - Mukhoty, B.
AU  - Shukla, S.K.
T2  - CPSIoTSec 2021 - Proceedings of the 2nd Workshop on CPS and IoT Security and Privacy, co-located with CCS 2021
AB  - Critical infrastructures often depend upon cyber-physical systems (CPS), as seen in the smart grid, autonomous vehicle monitoring, industrial monitoring systems, etc. With the IT/OT convergence, cyber-physical systems became connected to the Internet through firewalls and De-militarized Zones (DMZs). Therefore, cyber-attacks disrupting critical infrastructure services are not uncommon. Advanced attackers often use techniques to subvert standard defenses such as network intrusion detection, firewall, etc., by using packet fragmentation, overlapping fragments, checksum manipulation, sequence number manipulation, etc. Therefore, attacks often go through perimeter defenses and start affecting the physical dynamics of the CPS. This paper proposes a robust intrusion detection system dubbed CatchAll for detecting attacks by finding anomalies in the dynamics of the cyber-physical systems. The proposed Intrusion Detection System(IDS) uses unsupervised learning, as the availability of labeled data is often a problem. We further assume that some fraction of the training data might get corrupted, possibly by network noise or data poisoning attacks. Such assumptions make our method applicable to real-world scenarios, where clean and trusted training data may not be available. The proposed IDS works in $O(d)$ space and time complexity at the deployment and outperforms existing anomaly detection techniques in several real-world data sets and attack scenarios.  © 2021 ACM.
DA  - 2021///
PY  - 2021
DO  - 10.1145/3462633.3483978
SP  - 47
EP  - 56
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120920707&doi=10.1145%2f3462633.3483978&partnerID=40&md5=0e1c7a6a00a380c93cb767d845dc3ff8
DB  - Scopus
KW  - Intrusion detection
KW  - Anomaly detection
KW  - Network security
KW  - Computer crime
KW  - Embedded systems
KW  - Principal component analysis
KW  - Unsupervised learning
KW  - Cyber Physical System
KW  - unsupervised learning
KW  - Intrusion Detection Systems
KW  - Robust principal component analysis
KW  - Poisoning attacks
KW  - Data poisoning attack
KW  - data poisoning attacks
KW  - Computer system firewalls
KW  - critical infrastructures
KW  - Critical infrastructures
KW  - intrusion detection system
KW  - modbus
KW  - Modbus
KW  - Outlier Detection
KW  - plc
KW  - Plc
KW  - Public works
KW  - robust anomaly detection
KW  - Robust anomaly detection
KW  - robust outlier detection
KW  - Robust outlier detection
KW  - robust principal component analysis
KW  - scada
KW  - SCADA systems
KW  - Scadum
ER  - 

TY  - JOUR
TI  - Transition to sustainable chemistry through digitalization
AU  - Fantke, P.
AU  - Cinquemani, C.
AU  - Yaseneva, P.
AU  - De Mello, J.
AU  - Schwabe, H.
AU  - Ebeling, B.
AU  - Lapkin, A.A.
T2  - Chem
AB  - Modern chemistry is the backbone of our society, but it is also a major contributor to global environmental pollution and the ongoing climate crisis. The transition toward a sustainable future requires a radical transformation of how chemistry is designed, developed, and used. This represents a “break it or make it” challenge for the chemical industry with significant technology lock-in and high entry barriers to radical innovations. We propose that urgently required systemic changes in chemical industry, research and development (R&D), chemicals assessment and management, and education to advance sustainable chemistry are attainable through increased and more rapid adoption of digitalization and new digital tools. This will enable flexible data exchange, increased transparency of information flows along cross-country chemical, material, and product life cycles, and chemistries that are safe and sustainable by design, addressing the complexity of chemicals-environment-health interactions and lowering the costs of entry into chemical R&D and manufacture, and new, more sustainable and collaborative business models. © 2021 Elsevier Inc.
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.chempr.2021.09.012
VL  - 7
IS  - 11
SP  - 2866
EP  - 2882
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118840126&doi=10.1016%2fj.chempr.2021.09.012&partnerID=40&md5=d473ef61d823accf79b744d46c6a0f98
DB  - Scopus
KW  - machine learning
KW  - artificial intelligence
KW  - big data
KW  - safe and sustainable by design
KW  - sustainable development
KW  - green transition
KW  - SDG12: Responsible consumption and production
KW  - SDG13: Climate action
KW  - SDG3: Good health and well-being
KW  - SDG9: Industry innovation and infrastructure
ER  - 

TY  - JOUR
TI  - Malbert: A novel pre-training method for malware detection
AU  - Xu, Z.
AU  - Fang, X.
AU  - Yang, G.
T2  - Computers and Security
AB  - Microsoft's Windows desktop operating system has been the most popular operating system in the domain of personal computers in recent years. The popularity of this system has also led to a large amount of malware on the Windows platform. With the continuous exploration of malware authors, the methods of malicious software for attacking the operating system and code obfuscation anti-detection technologies are constantly updated, making malware detection increasingly difficult. In this paper, we proposed Malbert, a pre-trained deep learning model-based method to detect malicious Windows software through dynamic analysis. Experiments were implemented on two different datasets with more than 40000 samples. We compared Malbert with some existing malware detection models, including traditional machine learning-based and deep learning-based models. The experiment also deployed a robustness test to judge whether the models can resist perturbed test samples. The results show that Malbert reaches a 99.9% detection rate on both datasets and a detection rate exceeding 98% under different robustness tests. The results also highlight the importance of pre-training in deep learning-based malware detection models as Malbert outperforms the existing state-of-the-art approaches. © 2021 Elsevier Ltd
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.cose.2021.102458
VL  - 111
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114787102&doi=10.1016%2fj.cose.2021.102458&partnerID=40&md5=716104f0fe73dc99105f35ba2c15fea3
DB  - Scopus
KW  - Deep learning
KW  - Machine Learning
KW  - Machine-learning
KW  - Robustness
KW  - Malware
KW  - Self-supervised learning
KW  - Pre-training
KW  - Detection models
KW  - Detection rates
KW  - Malware detection
KW  - Dynamics analysis
KW  - Robustness tests
KW  - Dynamic Analysis
KW  - Malware Detection
KW  - Personal computers
KW  - Pre-trained model
KW  - Pre-trained Models
KW  - Self-supervised Learning
KW  - Windows
KW  - Windows operating system
ER  - 

TY  - BOOK
TI  - Frontiers in hardware security and trust: Theory, design and practice
AU  - Chang, C.H.
AU  - Cao, Y.
T2  - Frontiers in Hardware Security and Trust
AB  - Frontiers in Hardware Security and Trust provides a comprehensive review of emerging ecurity threats and privacy protection issues, and the versatile state-of-the-art hardwarebased security countermeasures and applications proposed by the hardware security community. The footprint and power constraints imposed on internet-of-things end-points, smart sensors, mobile and ad hoc network devices make traditional and software based cryptographic solutions that require a general-purpose processor increasingly unfeasible. The fact that security is not the primary functionality of these devices means that only a small portion of their limited processing power and storage is available for security, driving the need for alternative security solutions. Hardware security - including hardware obfuscation, hardware security primitives, side-channel attacks and so on - is therefore becoming an increasingly active research area in both academia and industry. This book discusses the fundamentals of reversible logics, hardware obfuscations, SAT resistant logic obfuscation, and design-for-security. Novel security primitives such as state-of-the-art true random number generators are also explored. Modern micro-architectural attacks enabled with the superscalar microprocessors and its countermeasures are analysed to shed light on how existing architectures can be fortified or made more robust against attack. The introduction of hardware security into cognitive radio networks, 5G networks and machine learning, which are widely considered to be the most promising major contributors to next wave of technological growth, are also discussed. The book serves as an advanced reference for researchers on current hardware security problems, challenges and solutions. © The Institution of Engineering and Technology 2021.
DA  - 2021///
PY  - 2021
SP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118067571&doi=10.1049%2fPBCS066E&partnerID=40&md5=0d818687b60ddc43c8977bae09733b63
DB  - Scopus
KW  - Security
KW  - Learning (artificial intelligence)
KW  - Data security
KW  - Neural computing techniques
KW  - Neural nets
KW  - Integrated circuits
KW  - Formal verification
KW  - Homomorphic encryption
KW  - 5G mobile communication
KW  - Hardware security
KW  - 5G networks
KW  - Block ciphers
KW  - CACHEKIT attack mitigation
KW  - Cognitive radio
KW  - Confidential cognitive communications
KW  - Controller area networks
KW  - Cryptographic primitive protection
KW  - Deep learning network security
KW  - Digital arithmetic methods
KW  - EMC techniques
KW  - Energy-efficient cognitive communications
KW  - General and management topics
KW  - General electrical engineering topics
KW  - Hardware obfuscation
KW  - Hardware trust
KW  - IC chip design
KW  - IC piracy threats
KW  - In-vehicle controller area network
KW  - Industrial property
KW  - Information leakage
KW  - IP piracy threats
KW  - IP protection
KW  - Local area networks
KW  - Microarchitectural attacks
KW  - Mimo communication
KW  - Mm-wave massive MIMO communications
KW  - Nondigital components
KW  - Persistent fault analysis
KW  - Physical-layer security
KW  - Public-key cryptography
KW  - Radio links and equipment
KW  - Random number generation
KW  - Reversible circuits
KW  - Robust codes
KW  - Semiconductor integrated circuits
KW  - Silicon-based true random number generators
KW  - SoC security
KW  - Trusted computing
ER  - 

TY  - CONF
TI  - Towards a Distributed Learning Architecture for Securing ISP Home Customers
AU  - Santos, P.M.
AU  - Sousa, J.
AU  - Morla, R.
AU  - Martins, N.
AU  - Tagaio, J.
AU  - Serra, J.
AU  - Silva, C.
AU  - Sousa, M.
AU  - Souto, P.
AU  - Ferreira, L.L.
AU  - Ferreira, J.
AU  - Almeida, L.
T2  - IFIP Advances in Information and Communication Technology
AB  - Networking equipment that connects households to an operator network, such as home gateways and routers, are major victims of cyber-attacks, being exposed to a number of threats, from misappropriation of user accounts by malicious agents to access to personal information and data, threatening users’ privacy and security. The exposure surface to threats is even wider when the growing ecosystem of Internet-of-Things devices is considered. Thus, it is beneficial for the operator and customer that a security service is provided to protect this ecosystem. The service should be tailored to the particular needs and Internet usage profile of the customer network. For this purpose, Machine Learning methods can be explored to learn typical behaviours and identify anomalies. In this paper, we present preliminary insights into the architecture and mechanisms of a security service offered by an Internet Service Provider. We focus on Distributed Denial-of-Service kind of attacks and define the system requirements. Finally, we analyse the trade-offs of distributing the service between operator equipment deployed at the customer premises and cloud-hosted servers. © 2021, IFIP International Federation for Information Processing.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-79157-5_26
VL  - 628
SP  - 311
EP  - 322
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112600784&doi=10.1007%2f978-3-030-79157-5_26&partnerID=40&md5=d8daf29e7eccfcaad5fb29669223ab18
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Learning systems
KW  - Anomaly detection
KW  - Economic and social effects
KW  - Energy efficiency
KW  - Privacy by design
KW  - Network security
KW  - Crime
KW  - Machine learning methods
KW  - Network architecture
KW  - Denial-of-service attack
KW  - Ecosystems
KW  - Sales
KW  - Biomedical engineering
KW  - Cyber-security
KW  - Distributed denial of service
KW  - Distributed learning
KW  - Distributed systems
KW  - Hybrid environment
KW  - Internet service providers
KW  - Networking equipment
KW  - Operator networks
KW  - Personal information
KW  - Privacy and security
KW  - Safe home
KW  - System requirements
ER  - 

TY  - CONF
TI  - Relearn: A robust machine learning framework in presence of missing data for multimodal stress detection from physiological signals
AU  - Iranfar, A.
AU  - Arza, A.
AU  - Atienza, D.
T2  - Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS
AB  - Continuous and multimodal stress detection has been performed recently through wearable devices and machine learning algorithms. However, a well-known and important challenge of working on physiological signals recorded by conventional monitoring devices is missing data due to sensors insufficient contact and interference by other equipment. This challenge becomes more problematic when the user/patient is mentally or physically active or stressed because of more frequent conscious or subconscious movements. In this paper, we propose ReLearn, a robust machine learning framework for stress detection from biomarkers extracted from multimodal physiological signals. ReLearn effectively copes with missing data and outliers both at training and inference phases. ReLearn, composed of machine learning models for feature selection, outlier detection, data imputation, and classification, allows us to classify all samples, including those with missing values at inference. In particular, according to our experiments and stress database, while by discarding all missing data, as a simplistic yet common approach, no prediction can be made for 34% of the data at inference, our approach can achieve accurate predictions, as high as 78%, for missing samples. Also, our experiments show that the proposed framework obtains a cross-validation accuracy of 86.8% even if more than 50% of samples within the features are missing. © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/EMBC46164.2021.9630040
VL  - 2021-January
SP  - 535
EP  - 541
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122549417&doi=10.1109%2fEMBC46164.2021.9630040&partnerID=40&md5=f43f73c2801474d2d61c79c8fe00c0e3
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Machine Learning
KW  - Algorithms
KW  - Learning algorithms
KW  - human
KW  - Humans
KW  - algorithm
KW  - Machine learning models
KW  - Multi-modal
KW  - Statistics
KW  - Movement
KW  - movement (physiology)
KW  - Signal detection
KW  - electronic device
KW  - Physiology
KW  - Wearable Electronic Devices
KW  - Physiological signals
KW  - Features selection
KW  - Stresses
KW  - Stress detection
KW  - Wearable devices
KW  - Missing data
KW  - Conventional monitoring
KW  - Monitoring device
ER  - 

TY  - CONF
TI  - Agile Project Management Based on Data Analysis for Information Management Systems
AU  - Haidabrus, B.
AU  - Grabis, J.
AU  - Protsenko, S.
T2  - Lecture Notes in Mechanical Engineering
AB  - Nowadays, many projects and product managers, industry, and portfolio leads understand that data from the project or portfolio can be valuable for increasing their activities. There are many different types of project and portfolio lifecycle processes of managers daily duties: pre-sales and sales, mobilization, delivery, and closure phases. Definitely, in research, we focus on the processes, staffing, governance, and reporting activities. The day-by-day tasks are quite regulated and clearly described using templates and techniques as a company standard. Our literature review shows that Data Science methods can increase the level of project management and project success in several business problems. This study gives new opportunities to improve project management evaluation and results for managers, industry, and delivery leads. The proposed approach allows doing a project, portfolio management, and agile development more accurately, considering best practices and project performance data. Moreover, our results can provide more efficient benefits for different internal and external stakeholders. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-77719-7_18
SP  - 174
EP  - 182
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110642204&doi=10.1007%2f978-3-030-77719-7_18&partnerID=40&md5=472c3196cd9d5f4a82bb0f612cbf7a63
DB  - Scopus
KW  - Machine learning
KW  - Data analysis
KW  - Machine-learning
KW  - Data reduction
KW  - Life cycle
KW  - Information management
KW  - Investments
KW  - Project management
KW  - Data science
KW  - Data Science
KW  - Managers
KW  - Financial data processing
KW  - Agile development
KW  - Agile manufacturing systems
KW  - Agile project management
KW  - Information management systems
KW  - Lean
KW  - Product manager
KW  - Product portfolios
KW  - Project managers
KW  - Safe
KW  - Scra
KW  - Scrum
ER  - 

TY  - CONF
TI  - BDI-Dojo: Developing robust BDI agents in evolving adversarial environments
AU  - Pulawski, S.
AU  - Dam, H.K.
AU  - Ghose, A.
T2  - Proceedings - 2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion, ACSOS-C 2021
AB  - The Belief-Desire-Intention (BDI) architecture is a widely-used model for developing multi-agent systems. BDI agents pursue their goals over time using a collection of plan recipes that are programmed by the developers. Thus, traditional BDI agents are limited in dealing with dynamic environments where uncertainties are not known beforehand, such as those introduced by adversarial forces. In this paper, we present the BDI-Dojo framework for developing robust BDI agents by training them using reinforcement learning against similarly learning-equipped adversarial agents. This adversarial training approach empowers BDI agents to become more resilient in uncertain, dynamic environments. © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACSOS-C52956.2021.00066
SP  - 257
EP  - 262
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123394011&doi=10.1109%2fACSOS-C52956.2021.00066&partnerID=40&md5=1d727ac9b754c915d09d08c9493bfe5e
DB  - Scopus
KW  - Intelligent agents
KW  - Reinforcement learning
KW  - Multi-Agent Systems
KW  - Dynamic environments
KW  - Uncertainty
KW  - Robustness
KW  - Multi agent systems
KW  - Resilience
KW  - Adversarial training
KW  - Adversarial environments
KW  - Adversarial agent
KW  - Belief-desire-intentions
KW  - Beliefs-desires-intentions agents
KW  - Uncertain dynamic environment
ER  - 

TY  - JOUR
TI  - Robust data predictive control framework for smart multi-microgrid energy dispatch considering electricity market uncertainty
AU  - Brahmia, I.
AU  - Wang, J.
AU  - Xu, H.
AU  - Wang, H.
AU  - de Oliveira Turci, L.
T2  - IEEE Access
AB  - With the emerging technologies for Energy Intent (EI) and data-driven applications, the conventional power grid network is undergoing a radical modernization. An efficient energy management and electricity price forecasting remains a challenging task. In this paper, a new Robust Data Predictive Control framework for Energy Management System (RDPC-EMS) is developed to overcome the uncertainty of the electricity retail price market and minimize the total operating costs for the multi-microgrids (MMG) system. The proposed framework solves the economic energy dispatch based on an accurate Electricity Price Forecasting (EPF) by an Outlier-Robust Extreme Learning Machine (OR-ELM) algorithm and a two layers cooperative Distributed Model Predictive Control (DMPC). The First level provides an optimal energy scheduling between the Distribution System Operator (DSO) and cooperative microgrids systems to minimize the operating cost based on the forecasted electricity price. In contrast, second level maintains the supply-demand balance by applying the optimal energy scheduling from the first layer through an adjustment of the distributed energy resources (DER). The electricity retail price prediction is assessed using real dataset from the Iso New England electricity market. The OR-ELM regression method shows a significant forecasting performance in terms of error metrics. For instance, the mean absolute error in the training stage 2.05% for OR-ELM with a comparison of 4.17% and 6.29% for Support Vector Regression (SVR), and Artificial Neural Network (ANN) models respectively. Finally, simulation results demonstrate the efficiency RDPC-EMS for daily operating cost reduction, with decrease of 15% for MG 1 and 16% for MG 2. © 2021 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ACCESS.2021.3060315
VL  - 9
SP  - 32390
EP  - 32404
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111947162&doi=10.1109%2fACCESS.2021.3060315&partnerID=40&md5=030f2680f99e100e8664c9b158d5648f
DB  - Scopus
KW  - Machine learning
KW  - Neural networks
KW  - Forecasting
KW  - Energy efficiency
KW  - Electric power transmission networks
KW  - Extreme learning machine
KW  - Model predictive control
KW  - Energy management
KW  - Outlier robust extreme learning machine
KW  - Information management
KW  - Cost reduction
KW  - Energy management systems
KW  - Microgrids
KW  - Support vector regression
KW  - Energy resources
KW  - Scheduling
KW  - Electric load dispatching
KW  - Data-driven applications
KW  - Support vector regression (SVR)
KW  - Power markets
KW  - Artificial neural network models
KW  - Distributed energy resource
KW  - Distributed model predictive control
KW  - Distributed Model predictive Control
KW  - Electric industry
KW  - Electricity price forecasting
KW  - Forecasting performance
KW  - Operating costs
KW  - Renewable energy sources
KW  - Retail electricity price market
ER  - 

TY  - CONF
TI  - Pedestrian Detection and Classification for Autonomous Train
AU  - Mahtani, A.
AU  - Ben-Messaoud, W.
AU  - Taleb-Ahmed, A.
AU  - Niar, S.
AU  - Strauss, C.
T2  - 4th International Conference on Image Processing, Applications and Systems, IPAS 2020
AB  - In this paper, we present a combined approach for human localization and classification in Autonomous Train application. Our contribution is threefold. (a) The creation of a new dataset for workers wearing orange vests in a railway environment context. (b) A deep learning supervised YOLO object detector for persons detection combined with a linear SVM (Support Vector Machine) classifier for persons classification into workers wearing orange vests or travelers. (c) A realtime vision-based technique for the environment monitoring in a driverless train application. Experimental results evaluate the parameters of our two stages detection approach and show that our algorithm is robust in detecting and classifying railway workers for a real-Time implementation on an embedded system. Our implementation on an embedded system allows a detection with a correct classification rate of 98.5 % of accuracy and a classification time of 1 ms per frame. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/IPAS50080.2020.9334938
SP  - 52
EP  - 57
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100744850&doi=10.1109%2fIPAS50080.2020.9334938&partnerID=40&md5=18c810eea75c5386b752c4237d3cb61d
DB  - Scopus
KW  - Deep learning
KW  - Support vector machines
KW  - Object detection
KW  - Computer vision
KW  - Railroads
KW  - Image processing
KW  - Embedded systems
KW  - Real time control
KW  - Real-time implementations
KW  - Autonomous Train
KW  - Citrus fruits
KW  - Classification rates
KW  - Classification time
KW  - Deep learning model
KW  - Detection approach
KW  - Environment monitoring
KW  - Human detection and classification
KW  - Human localizations
KW  - Pedestrian detection and classifications
KW  - Real time vision
KW  - Supervised algorithm
KW  - Train safety
KW  - Wear of materials
ER  - 

TY  - CONF
TI  - Application Research of Ship Maritime Safety Decision System Based on Big Data and Artificial Intelligence
AU  - Deng, H.
AU  - Yang, Y.
AU  - Li, Q.
T2  - Lecture Notes in Electrical Engineering
AB  - With the continuous development of global economic integration, international shipping, as a cheap and large-capacity transportation method, has also developed rapidly. However, marine safety accidents occur from time to time. In the current economic situation, ship safety issues are particularly important. The purpose of this article is to study the application of marine safety decision-making system based on big data and artificial intelligence. This article first analyzes the concepts of big data Hadoop platform and artificial intelligence, and then this article analyzes the current safety problems in marine shipping. In the experimental part, this paper designs a maritime safety decision system. The goal of the system is to analyze the ship’s navigation status, and use artificial intelligence, machine learning and other advanced technical methods to replace the original artificial experience prediction method to predict the ship’s operating data. In terms of the specific model selection of the system, this paper selects the multi-layer perceptron which is more suitable for ship navigation data with greater volatility as the core model for predictive model training. Experimental results show that the performance of the system can meet the application requirements. In this paper, by analyzing the forecast error of the system, the error is controlled within 15%. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-981-16-0115-6_109
VL  - 747
SP  - 963
EP  - 971
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122431146&doi=10.1007%2f978-981-16-0115-6_109&partnerID=40&md5=9fea27c9d528ade7452471a5df16ed9c
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Decision making
KW  - Forecasting
KW  - Big data
KW  - Ships
KW  - Safety accidents
KW  - Continuous development
KW  - Maritime safety
KW  - Application research
KW  - Decision systems
KW  - Global economics
KW  - International shippings
KW  - Marine safety
KW  - Safety decision system
KW  - Shipping safety
KW  - Transportation method
ER  - 

TY  - JOUR
TI  - Real Elliptically Skewed Distributions and Their Application to Robust Cluster Analysis
AU  - Schroth, C.
AU  - Muma, M.
T2  - IEEE Transactions on Signal Processing
AB  - This article proposes a new class of Real Elliptically Skewed (RESK) distributions and associated clustering algorithms that integrate robustness and skewness into a single unified cluster analysis framework. Non-symmetrically distributed and heavy-tailed data clusters have been reported in a variety of real-world applications. Robustness is essential because a few outlying observations can severely obscure the cluster structure. The RESK distributions are a generalization of the Real Elliptically Symmetric (RES) distributions. To estimate the cluster parameters and memberships, we derive an expectation maximization (EM) algorithm for arbitrary RESK distributions. Special attention is given to a new robust skew-Huber M-estimator, which is also the approximate maximum likelihood estimator (MLE) for the skew-Huber distribution, that belongs to the RESK class. Numerical experiments on simulated and real-world data confirm the usefulness of the proposed methods for skewed and heavy-tailed data sets. © 1991-2012 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/TSP.2021.3092373
VL  - 69
SP  - 3947
EP  - 3962
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111967283&doi=10.1109%2fTSP.2021.3092373&partnerID=40&md5=a24515aff8ba5443916b90512c102e2e
DB  - Scopus
KW  - Analysis frameworks
KW  - M-estimator
KW  - Clustering algorithms
KW  - Numerical methods
KW  - unsupervised learning
KW  - Maximum principle
KW  - Cluster analysis
KW  - Numerical experiments
KW  - Approximate maximum likelihood estimators
KW  - Cluster parameters
KW  - EM algorithm
KW  - Expectation-maximization algorithms
KW  - heavy-tailed mixture models
KW  - Huber M-estimator
KW  - Maximum likelihood estimation
KW  - multivariate RES distributions
KW  - Outlying observation
KW  - real elliptically skewed distributions
KW  - Robust cluster analysis
KW  - robust data science
KW  - skew-Gaussian
KW  - skew-Huber
KW  - skew-t
KW  - Skewed distribution
ER  - 

TY  - CONF
TI  - Framework for safety assessment of autonomous driving functions up to SAE level 5 by self-learning iteratively improving control loops between development, safety and field life cycle phases
AU  - Häring, I.
AU  - Lüttner, F.
AU  - Frorath, A.
AU  - Fehling-Kaschek, M.
AU  - Ross, K.
AU  - Schamm, T.
AU  - Knoop, S.
AU  - Schmidt, D.
AU  - Schmidt, A.
AU  - Ji, Y.
AU  - Yang, Z.
AU  - Rupalla, A.
AU  - Hantschel, F.
AU  - Frey, M.
AU  - Wiechowski, N.
AU  - Schyr, C.
AU  - Grimm, D.
AU  - Zofka, M.R.
AU  - Viehl, A.
T2  - Proceedings - 2021 IEEE 17th International Conference on Intelligent Computer Communication and Processing, ICCP 2021
AB  - Safety verification and validation of autonomous driving functions up to SAE level 5 pose enormous challenges for car manufacturers. The paper argues that efficient improvement opportunities arise by suitably combining iterative development and verification processes that use self-learning approaches and well-defined quality and convergence criteria within a conceptual framework. The following cycles are used: development cycle, safety life cycle and field life cycle. For these cycles, suitable phases are first identified and defined. Then linkages are given that enable criteria-based iterative execution and improvement of selected combined phases. For this purpose, the selected phases are further resolved. It is distinguished between local loops within one cycle and loops between several cycles as well as with respect to the time horizon they cover. Suitable sample machine learning (ML) and artificial intelligence (AI) methods for the improvement loops are proposed in order to improve safety assessment of autonomous driving (AD) functions. The article presents three different types of ML/AI approaches regarding their usage within the development process of AD functions as well as identifies further improvement potentials. The approach is illustrated by ML/AI approach examples for the efficient provision of relevant and critical scenarios for the training and assessment of AD functions. © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICCP53602.2021.9733699
SP  - 33
EP  - 40
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127404718&doi=10.1109%2fICCP53602.2021.9733699&partnerID=40&md5=3e3c3ffb211d01f6fd23ac7571725147
DB  - Scopus
KW  - Autonomous vehicles
KW  - Machine learning
KW  - Training data
KW  - Autonomous driving
KW  - Automotive industry
KW  - Self-learning
KW  - Safety engineering
KW  - Life cycle
KW  - Iterative methods
KW  - development
KW  - Development
KW  - iterative self-learning improvement loop
KW  - Iterative self-learning improvement loop
KW  - machine learning and artificial intelligence
KW  - Machine learning and artificial intelligence
KW  - safety and life cycle
KW  - Safety and life cycle
KW  - selection of training data
KW  - Selection of training data
KW  - Verification and validation of autonomous driving
KW  - Verification-and-validation
ER  - 

TY  - JOUR
TI  - The Application of Data-Driven Methods and Physics-Based Learning for Improving Battery Safety
AU  - Finegan, D.P.
AU  - Zhu, J.
AU  - Feng, X.
AU  - Keyser, M.
AU  - Ulmefors, M.
AU  - Li, W.
AU  - Bazant, M.Z.
AU  - Cooper, S.J.
T2  - Joule
AB  - Although the hazardous failure of lithium-ion batteries is rare, the fallout can be severe. The safety and reliability of lithium-ion batteries are more important now than ever because of their widespread adoption, yet our ability to predict failure through online and offline diagnostics is still very limited. Lithium-ion batteries are highly complex, nonlinear systems. To make matters worse, two cells of identical geometry, chemistry, and history might respond differently when exposed to identical mechanical, thermal, or electrical stimuli. This limits the value of classical deterministic modeling techniques. Applying a probabilistic approach allows for quantification of uncertainty to support decisions in design and control. Machine-learning algorithms are well suited for predicting nonlinear systems like lithium-ion cells, but training and validation of algorithms are challenging for safety applications because large amounts of failure data are needed. Even if the algorithms predict accurately, machine learning is typically agnostic to underlying physics and thus presents limited value in informing researchers and engineers on design opportunities to improve the cells’ performance. There is much interest within the battery research community in tackling these challenges, and this perspective aims to offer suggestions on promising avenues of investigation to achieve accurate predictions of the risk of cell failure while gaining some physical insights into the predicted behaviors. © 2020; Enabling accurate prediction of battery failure will lead to safer battery systems, as well as accelerating cell design and manufacturing processes for increased consistency and reliability. Data-driven prediction methods have shown promise for accurately predicting cell behaviors with low computational cost, but they are expensive to train. Furthermore, given that the risk of battery failure is already very low, gathering enough relevant data to facilitate data-driven predictions is extremely challenging. Here, a perspective for designing experiments to facilitate a relatively low number of tests, handling the data, applying data-driven methods, and improving our understanding of behavior-dictating physics is outlined. This perspective starts with effective strategies for experimentally replicating rare failure scenarios and thus reducing the number of experiments, and proceeds to describe means to acquire high-quality datasets, apply data-driven prediction techniques, and to extract physical insights into the events that lead to failure by incorporating physics into data-driven approaches. © 2020; Being able to predict the risk of battery failure is expected to greatly improve the safety of battery systems where defective cells could be identified and removed before a dangerous failure event occurs. Acquiring enough high-quality data for training prediction models is extremely challenging, particularly given that catastrophic failure is rare. This perspective focuses on describing experiments, modeling, and machine-learning techniques that might lead to improving capabilities of predicting battery failure. © 2020
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.joule.2020.11.018
VL  - 5
IS  - 2
SP  - 316
EP  - 329
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099700596&doi=10.1016%2fj.joule.2020.11.018&partnerID=40&md5=54b526657ff8493ac4abdef9f3baf7f9
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - modeling
KW  - Learning algorithms
KW  - experimental study
KW  - Predictive analytics
KW  - safety
KW  - Forecasting
KW  - Safety engineering
KW  - Data-driven approach
KW  - Nonlinear systems
KW  - Machine learning techniques
KW  - Lithium-ion batteries
KW  - Ions
KW  - research work
KW  - Catastrophic failures
KW  - manufacturing
KW  - Research communities
KW  - Manufacturing process
KW  - battery failure
KW  - data-driven methods
KW  - Deterministic modeling
KW  - diagnostics
KW  - fuel cell
KW  - lithium
KW  - lithium-ion batteries
KW  - Prediction techniques
KW  - Probabilistic approaches
KW  - service quality
ER  - 

TY  - CONF
TI  - Robust Advanced Sensor System for Determination of Volatile Organic Compounds (VOC)
AU  - Mangler, A.
AU  - Eise, J.
AU  - Zhang, Q.
T2  - Proceedings of International Workshop on Impedance Spectroscopy, IWIS 2021
AB  - Nowadays more and more health risks are increasing. Beside the viruses, there are also other particles which have an impact on the human well-being. The so called volatile organic compounds (VOCs) are substances in the air and can be harmful in high concentrations. Therefore, the detection of VOC value is particularly important.  © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/IWIS54661.2021.9711830
SP  - 89
EP  - 93
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126879863&doi=10.1109%2fIWIS54661.2021.9711830&partnerID=40&md5=753a05ff2af0b72483e15a7a4e4f3785
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Machine Learning
KW  - E-learning
KW  - Machine-learning
KW  - Sensor fusion
KW  - Advanced sensors
KW  - Robust datum
KW  - Embedded-system
KW  - Viruses
KW  - Health risks
KW  - Sensor systems
KW  - Photocatalysis
KW  - Data mining algorithm
KW  - Electronic nose
KW  - Electronic Nose
KW  - Embedded System
KW  - Excitation
KW  - Ionization
KW  - Robust data mining algorithm
KW  - Robust Data Mining Algorithm
KW  - Sensor Fusion
KW  - VOC Characterization
KW  - Volatile organic compound characterization
KW  - Volatile organic compounds
KW  - Volatile Organic Compounds
ER  - 

TY  - CONF
TI  - Evaluation and Comparison of the Performance of Artificial Intelligence Algorithms in Predicting Construction Safety Incidents
AU  - Alsakka, F.
AU  - Mohamed, Y.
AU  - Al-Hussein, M.
T2  - Proceedings of the International Symposium on Automation and Robotics in Construction
AB  - Predicting the outcomes of safety incidents on construction projects is of a great value to various project stakeholders. Accurate estimates allow construction managers to take appropriate preventive measures based on the severity of the outcomes. Such estimates can be predicted using machine learning algorithms, although the quality of these estimates is dictated by factors including the types of algorithms employed and the dataset used to train them. Moreover, the metrics used to evaluate the algorithms can be misleading, indicating satisfactory performance when this may not be the case. In light of these considerations, this study trains a set of machine learning algorithms to predict the severity of safety incidents, highlighting the importance of confirming the credibility of performance evaluation results, and compares the performance of the algorithms. The results show that the support vector machine and k-nearest neighbors prediction models exhibit the best overall performance, with support vector machine achieving a mean absolute percentage error value of 18.78% and k-nearest neighbors an accuracy of 64.84%. On the other hand, the results also reveal that the models performed poorly in predicting some classes as a result of a high degree of imbalance identified in the dataset used for training and testing the models. The study’s main contribution is to highlight the possibility of making biased performance evaluations of machine learning algorithms, depending on the performance measures used for the evaluation. © 2021 Proceedings of the International Symposium on Automation and Robotics in Construction. All rights reserved.
DA  - 2021///
PY  - 2021
VL  - 2021-November
SP  - 568
EP  - 575
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127545660&partnerID=40&md5=ccbb2034115f6a22c92701a80b612df9
DB  - Scopus
KW  - Safety
KW  - Machine learning algorithms
KW  - Support vector machines
KW  - Robotics
KW  - Prediction
KW  - Learning algorithms
KW  - Performance
KW  - Forecasting
KW  - Personnel training
KW  - Statistical tests
KW  - Nearest neighbor search
KW  - Performances evaluation
KW  - Support vectors machine
KW  - Construction projects
KW  - Construction safety
KW  - Motion compensation
KW  - Construction
KW  - Artificial intelligence algorithms
KW  - Data imbalance
KW  - Data Imbalance
KW  - k-nearest neighbors
KW  - Machine Learning Algorithms
KW  - Project stakeholders
KW  - Safety incidents
ER  - 

TY  - JOUR
TI  - Beam data modeling of linear accelerators (linacs) through machine learning and its potential applications in fast and robust linac commissioning and quality assurance
AU  - Zhao, W.
AU  - Patil, I.
AU  - Han, B.
AU  - Yang, Y.
AU  - Xing, L.
AU  - Schüler, E.
T2  - Radiotherapy and Oncology
AB  - Background and purpose: To propose a novel machine learning-based method for reliable and accurate modeling of linac beam data applicable to the processes of linac commissioning and QA. Materials and methods: We hypothesize that the beam data is a function of inherent linac features and percentage depth doses (PDDs) and profiles of different field sizes are correlated with each other. The correlation is formulated as a multivariable regression problem using a machine learning framework. Varian TrueBeam beam data sets (n = 43) acquired from multiple institutions were used to evaluate the framework. The data sets included PDDs and profiles across different energies and field sizes. A multivariate regression model was trained for prediction of beam specific PDDs and profiles of different field sizes using a 10 × 10 cm2 field as input. Results: Predictions of PDDs were achieved with a mean absolute percent relative error (%RE) of 0.19–0.35% across the different beam energies investigated. The maximum mean absolute %RE was 0.93%. For profile prediction, the mean absolute %RE was 0.66–0.93% with a maximum absolute %RE of 3.76%. The largest uncertainties in the PDD and profile predictions were found at the build-up region and at the field penumbra, respectively. The prediction accuracy increased with the number of training sets up to around 20 training sets. Conclusions: Through this novel machine learning-based method we have shown accurate and reproducible generation of beam data for linac commissioning for routine radiation therapy. This method has the potential to simplify the linac commissioning procedure, save time and manpower while increasing the accuracy of the commissioning process. © 2020 Elsevier B.V.
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.radonc.2020.09.057
VL  - 153
SP  - 122
EP  - 129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093922052&doi=10.1016%2fj.radonc.2020.09.057&partnerID=40&md5=66ae9731ec2ae168a848903c2f81ab5b
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Machine Learning
KW  - prediction
KW  - uncertainty
KW  - controlled study
KW  - human
KW  - Humans
KW  - Uncertainty
KW  - Article
KW  - priority journal
KW  - quality control
KW  - Photons
KW  - Quality assurance
KW  - calibration
KW  - Radiotherapy
KW  - least square analysis
KW  - Beam data modeling
KW  - dosimetry
KW  - Linac commissioning
KW  - magnetic and electromagnetic equipment
KW  - Particle Accelerators
KW  - photon
KW  - radiation beam
KW  - radiation dose distribution
KW  - radiation field
KW  - radiotherapy dosage
KW  - radiotherapy planning system
KW  - Radiotherapy Planning, Computer-Assisted
ER  - 

TY  - BOOK
TI  - Human factors in intelligent vehicles
AU  - Olaverri-Monreal, C.
AU  - Garćia-Ferńandez, F.
AU  - Rossetti, R.J.F.
T2  - Human Factors in Intelligent Vehicles
AB  - Human Factors in Intelligent Vehicles addresses issues related to the analysis of human factors in the design and evaluation of intelligent vehicles for a wide spectrum of applications and over different dimensions. To commemorate the 8th anniversary of the IEEE ITS Workshop on Human Factors (http://hfiv.net) some recent works of authors active in the automotive human factors community have been collected in this book. Enclosed here are extended versions of papers and tutorials that were presented at the IEEE ITSS Workshop on “Human Factors in Intelligent Vehicles” and also included is additional deeper analysis along with detailed experimental and simulation results. The contributors cover autonomous vehicles as well as the frameworks for analyzing automation, modelling and methods for road users’ interaction such as intelligent user interfaces, including brain-computer interfaces and simulation and analysis tools related to human factors. © 2020 River Publishers.
DA  - 2020///
PY  - 2020
SP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106555019&partnerID=40&md5=037695186b38a510a6106ca8825df0c8
DB  - Scopus
KW  - Game theory
KW  - Autonomous vehicles
KW  - Machine learning
KW  - Human factors
KW  - Intelligent vehicles
KW  - Technology acceptance
KW  - Responsibility
KW  - Driving simulator
KW  - Ergonomics
KW  - Human-machine interaction
KW  - Brain-computer interfaces
KW  - Age-related limitations
KW  - Allocation of functions and tasks
KW  - Authority
KW  - Automation design and assessment
KW  - Brain waves
KW  - Driver behavior
KW  - Effectiveness data fusion model
KW  - Electroencephalography
KW  - Field test
KW  - Integration patterns
KW  - Interactions
KW  - Older driver
KW  - Pedestrian crossing
KW  - Pedestrians behavior
ER  - 

TY  - JOUR
TI  - A machine learning and distributionally robust optimization framework for strategic energy planning under uncertainty
AU  - Guevara, E.
AU  - Babonneau, F.
AU  - Homem-de-Mello, T.
AU  - Moret, S.
T2  - Applied Energy
AB  - This paper investigates how the choice of stochastic approaches and distribution assumptions impacts strategic investment decisions in energy planning problems. We formulate a two-stage stochastic programming model assuming different distributions for the input parameters and show that there is significant discrepancy among the associated stochastic solutions and other robust solutions published in the literature. To remedy this sensitivity issue, we propose a combined machine learning and distributionally robust optimization (DRO) approach which produces more robust and stable strategic investment decisions with respect to uncertainty assumptions. DRO is applied to deal with ambiguous probability distributions and Machine Learning is used to restrict the DRO model to a subset of important uncertain parameters ensuring computational tractability. Finally, we perform an out-of-sample simulation process to evaluate solutions performances. The Swiss energy system is used as a case study all along the paper to validate the approach. © 2020 Elsevier Ltd
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.apenergy.2020.115005
VL  - 271
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085772465&doi=10.1016%2fj.apenergy.2020.115005&partnerID=40&md5=b13ec37099b7f34dcafbc507871a5300
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Uncertainty
KW  - Uncertainty analysis
KW  - optimization
KW  - Robust optimization
KW  - uncertainty analysis
KW  - strategic approach
KW  - Stochastic models
KW  - Stochastic systems
KW  - Distributionally robust optimization
KW  - Probability distributions
KW  - Stochastic programming
KW  - Investments
KW  - Uncertain parameters
KW  - Computational tractability
KW  - Different distributions
KW  - Electricity generation
KW  - energy planning
KW  - Stochastic approach
KW  - Strategic energy planning
KW  - Strategic investments
KW  - Two-stage stochastic programming
ER  - 

TY  - CONF
TI  - Adversarial Training with Orthogonal Regularization
AU  - Yuksel, O.K.
AU  - Baytas, I.M.
T2  - 2020 28th Signal Processing and Communications Applications Conference, SIU 2020 - Proceedings
AB  - Deep neural networks have been successful in various domains, such as computer vision and natural language processing. On the other hand, researchers have discovered a vulnerability of convolutional neural networks to the samples with imperceptible perturbations, also known as, adversarial perturbations. It has been observed that adversarial perturbations can alter the predictions of a deep model. One of the most common approaches to increase the robustness of deep models is adversarial training. However, adversarial training often suffers from a degradation in generalization performance. In this study, orthogonal regularization is used along with adversarial training to facilitate both generalizability and adversarial robustness in deep models. According to the experiments on MNIST and CIFAR10 datasets, imposing orthogonality in weights improves both the generalization performance and adversarial robustness.  © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/SIU49456.2020.9302247
ST  - Dikey Duzenlestirme ile Hasmane Egitim
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100302209&doi=10.1109%2fSIU49456.2020.9302247&partnerID=40&md5=91242a4f99326d61cbe2c260ca8af4f3
DB  - Scopus
L1  - https://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=9302247&ref=
KW  - Deep learning
KW  - Signal processing
KW  - Deep neural networks
KW  - Convolutional neural networks
KW  - Natural language processing systems
KW  - NAtural language processing
KW  - adversarial machine learning
KW  - Generalization performance
KW  - orthogonality
KW  - Orthogonality
KW  - robust model training
ER  - 

TY  - CONF
TI  - Towards Robust Production Machine Learning Systems: Managing Dataset Shift
AU  - Abdelkader, H.
T2  - Proceedings - 2020 35th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020
AB  - The advances in machine learning (ML) have stimulated the integration of their capabilities into software systems. However, there is a tangible gap between software engineering and machine learning practices, that is delaying the progress of intelligent services development. Software organisations are devoting effort to adjust the software engineering processes and practices to facilitate the integration of machine learning models. Machine learning researchers as well are focusing on improving the interpretability of machine learning models to support overall system robustness. Our research focuses on bridging this gap through a methodology that evaluates the robustness of machine learning-enabled software engineering systems. In particular, this methodology will automate the evaluation of the robustness properties of software systems against dataset shift problems in ML. It will also feature a notification mechanism that facilitates the debugging of ML components. © 2020 ACM.
DA  - 2020///
PY  - 2020
DO  - 10.1145/3324884.3415281
SP  - 1164
EP  - 1166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099251225&doi=10.1145%2f3324884.3415281&partnerID=40&md5=b7f18b590ee0b52cf8df446932f366cc
DB  - Scopus
KW  - Machine learning
KW  - Machine learning models
KW  - Computer software
KW  - System robustness
KW  - Robust production
KW  - Software engineering process
KW  - Intelligent Services
KW  - n/a
KW  - Notification mechanism
KW  - Robustness properties
KW  - Software organisations
ER  - 

TY  - JOUR
TI  - A Synchrophasor Data-Driven Method for Forced Oscillation Localization under Resonance Conditions
AU  - Huang, T.
AU  - Freris, N.M.
AU  - Kumar, P.R.
AU  - Xie, L.
T2  - IEEE Transactions on Power Systems
AB  - This paper proposes a data-driven algorithm for locating the source of forced oscillations and suggests a physical interpretation for the method. By leveraging the sparsity of forced oscillations along with the low-rank nature of synchrophasor data, the problem of source localization under resonance conditions is cast as computing the sparse and low-rank components using Robust Principal Component Analysis (RPCA), which can be efficiently solved by the exact Augmented Lagrange Multiplier method. Based on this problem formulation, an efficient and practically implementable algorithm is proposed to pinpoint the forced oscillation source during real-time operation. Furthermore, theoretical insights are provided for the efficacy of the proposed approach, by use of physical model-based analysis, specifically by highlighting the low-rank nature of the resonance component matrix. Without the availability of system topology information, the proposed method can achieve high localization accuracy in synthetic cases based on benchmark systems and real-world forced oscillations in the power grid of Texas.  © 1969-2012 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/TPWRS.2020.2982267
VL  - 35
IS  - 5
SP  - 3927
EP  - 3939
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089309858&doi=10.1109%2fTPWRS.2020.2982267&partnerID=40&md5=2a8089aac6c0579a5f186d100fdb6400
DB  - Scopus
KW  - big data
KW  - Electric power transmission networks
KW  - Lagrange multipliers
KW  - unsupervised learning
KW  - Data-driven algorithm
KW  - Robust principal component analysis
KW  - Augmented lagrange multiplier methods
KW  - Forced oscillations (FOs)
KW  - Localization accuracy
KW  - phasor measurement unit (PMU)
KW  - Physical interpretation
KW  - Resonance
KW  - Resonance components
KW  - Resonance condition
KW  - resonant systems
KW  - robust principal component analysis (RPCA)
KW  - Sparse and low ranks
ER  - 

TY  - JOUR
TI  - Robust Identification of Thermal Models for In-Production High-Performance-Computing Clusters with Machine Learning-Based Data Selection
AU  - Pittino, F.
AU  - Diversi, R.
AU  - Benini, L.
AU  - Bartolini, A.
T2  - IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems
AB  - Power and thermal management are critical components of high-performance-computing (HPC) systems, due to their high-power density and large total power consumption. The assessment of thermal dissipation by means of compact models directly from the thermal response of the final device enables more robust and precise thermal control strategies as well as automated diagnosis. However, when dealing with large-scale systems 'in production,' the accuracy of learned thermal models depends on the dynamics of the power excitation, which depends also on the executed workload, and measurement nonidealities such as quantization. In this article we show that, using an advanced system identification algorithm, we are able to generate very accurate thermal models (average error lower than our sensors quantization step of 1 °C) for a large-scale HPC system on real workloads for very long time periods. However, we also show that: 1) not all real workloads allow for the identification of a good model and 2) starting from the theory of system identification it is very difficult to evaluate if a trace of data leads to a good estimated model. We then propose and validate a set of techniques based on machine learning and deep learning algorithms for the choice of data traces to be used for model identification. We also show that deep learning techniques are absolutely necessary to correctly choose such traces up to 96% of the times. © 1982-2012 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/TCAD.2019.2950378
VL  - 39
IS  - 10
SP  - 2042
EP  - 2054
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074564641&doi=10.1109%2fTCAD.2019.2950378&partnerID=40&md5=21c48cd719432c024b46745c290e8491
DB  - Scopus
KW  - Deep learning
KW  - Machine learning
KW  - Predictive models
KW  - Learning systems
KW  - modeling
KW  - Learning algorithms
KW  - Predictive analytics
KW  - Data structures
KW  - Computation theory
KW  - Electric power utilization
KW  - Integrated circuit modeling
KW  - Green computing
KW  - predictive models
KW  - Large scale systems
KW  - Noise measurements
KW  - Power demands
KW  - Computational model
KW  - power system modeling
KW  - Religious buildings
KW  - system analysis and design
KW  - Thermal sensors
KW  - Thermal variables control
KW  - Thermography (temperature measurement)
ER  - 

TY  - CONF
TI  - MACHINE LEARNING ENABLED TURBULENCE PREDICTION USING FLIGHT DATA FOR SAFETY ANALYSIS
AU  - Emara, M.
AU  - dos Santos, M.
AU  - Chartier, N.
AU  - Ackley, J.
AU  - Puranik, T.G.
AU  - Payan, A.
AU  - Kirby, M.
AU  - Pinon, O.J.
AU  - Mavris, D.N.
T2  - 32nd Congress of the International Council of the Aeronautical Sciences, ICAS 2021
AB  - The hazards posed by turbulence remain an important issue in commercial aviation safety analysis. Turbulence is among the leading cause of in-flight injury to passengers and flight attendants. Current methods of turbulence detection may suffer from sparse or inaccurate forecast data sets, low spatial and temporal resolution, and lack of in-situ reports. The increased availability of flight data records offers an opportunity to improve the state-of-the-art in turbulence detection. The Eddy Dissipation Rate (EDR) is consistently recognized as a reliable measure of turbulence and is widely used in the aviation industry. In this paper, both classification and regression supervised machine learning models are used in conjunction with flight operations quality assurance (FOQA) data collected from 6,000 routine flights to estimate the EDR (and thereby turbulence severity) in future time horizons. Data from routine airline operations that encountered different levels of turbulence is collected and analyzed for this purpose. Results indicate that the models are able to perform reasonably well in predicting the EDR and turbulence severity around 10 seconds prior to encountering a turbulence event. Continuous deployment of the model enables obtaining a near-continuous prediction of possible future turbulence events and builds the capability towards an early warning system for pilots and flight attendants. © 2021 32nd Congress of the International Council of the Aeronautical Sciences, ICAS 2021. All rights reserved.
DA  - 2021///
PY  - 2021
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124479654&partnerID=40&md5=0bc099ebd058683a2130fbd054580c2c
DB  - Scopus
KW  - Safety
KW  - Machine learning
KW  - Predictive models
KW  - Supervised learning
KW  - Predictive modeling
KW  - Machine-learning
KW  - Forecasting
KW  - Risk assessment
KW  - 'current
KW  - Safety engineering
KW  - Risk
KW  - Aviation
KW  - Safety analysis
KW  - Quality assurance
KW  - Aviation safety
KW  - Flight data
KW  - Eddy dissipation rate
KW  - Flight attendants
KW  - Turbulence
KW  - Turbulence detection
KW  - Turbulence prediction
ER  - 

TY  - JOUR
TI  - Robust M-Estimation Based Bayesian Cluster Enumeration for Real Elliptically Symmetric Distributions
AU  - Schroth, C.
AU  - Muma, M.
T2  - IEEE Transactions on Signal Processing
AB  - Robustly determining the optimal number of clusters in a data set is an essential factor in a wide range of applications. Cluster enumeration becomes challenging when the true underlying structure in the observed data is corrupted by heavy-tailed noise and outliers. Recently, Bayesian cluster enumeration criteria have been derived by formulating the cluster enumeration problem as a maximization of the posterior probability of candidate models. This article generalizes robust Bayesian cluster enumeration so that it can be used with any arbitrary Real Elliptically Symmetric (RES) distributed mixture model. Our framework also covers the case of M-estimators. These robust estimators allow for mixture models, which are decoupled from a specific probability distribution. Examples of Huber's and Tukey's M-estimators are discussed. We derive a robust criterion for data sets with finite sample size, and also provide an asymptotic approximation to reduce the computational cost at large sample sizes. The algorithms are applied to simulated and real-world data sets, including radar-based person identification and remote sensing, and they show a significant robustness improvement in comparison to existing methods.  © 1991-2012 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/TSP.2021.3072482
VL  - 69
SP  - 3525
EP  - 3540
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104243269&doi=10.1109%2fTSP.2021.3072482&partnerID=40&md5=e05e5544f3cb846cfb081ab9e611d949
DB  - Scopus
KW  - Robust
KW  - cluster analysis
KW  - M-estimation
KW  - Probability distributions
KW  - Sampling
KW  - unsupervised learning
KW  - Remote sensing
KW  - Spurious signal noise
KW  - Computational costs
KW  - outlier
KW  - Mixtures
KW  - EM algorithm
KW  - multivariate RES distributions
KW  - Asymptotic approximation
KW  - Bayesian information criterion (BIC)
KW  - Candidate models
KW  - cluster enumeration
KW  - Finite sample sizes
KW  - Heavy-tailed noise
KW  - Huber distribution
KW  - Person identification
KW  - Posterior probability
KW  - Symmetric distributions
KW  - Tukey's loss function
ER  - 

TY  - CHAP
TI  - A Comprehensive Study Toward Women Safety Using Machine Learning Along with Android App Development
AU  - Hariharan, K.
AU  - Jain, R.R.
AU  - Prasad, A.
AU  - Sharma, M.
AU  - Yadav, P.
AU  - Poorna, S.S.
AU  - Anuraj, K.
T2  - Lecture Notes on Data Engineering and Communications Technologies
AB  - In this modern era, women have shown excellence in all walks of life and stand equally with men in all sectors. So has increased violence against women due to this exposure. Hence, women security during travel is one of the critical issues faced by society, from the past and even today. The paper aims at providing a technological solution to this problem. For this, a system for forewarning and safeguarding the female cab users using machine learning is developed. An Android application is developed to collect data, and a virtual panic environment was created to collect the anomalies. The accelerometer data along the three coordinates was captured corresponding to normal and anomalies. Three machine learning models viz support vector machines, logistic regression, and Naïve Bayes are trained on data collected, and their test performance is compared in terms of accuracy. This trained model is further integrated with an Android application for real-time data collection and feedback. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2021.
DA  - 2021///
PY  - 2021
VL  - 55
SP  - 321
EP  - 330
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101061483&doi=10.1007%2f978-981-15-8677-4_26&partnerID=40&md5=4433751a42596a8dc9292209109b2aea
DB  - Scopus
KW  - Machine learning
KW  - Support vector machines
KW  - Learning systems
KW  - Machine learning models
KW  - Android (operating system)
KW  - Data acquisition
KW  - Support vector regression
KW  - Logistic regression
KW  - Women safety
KW  - SVM
KW  - Accelerometer data
KW  - Android
KW  - Android applications
KW  - Cloud database
KW  - Critical issues
KW  - LR
KW  - NB
KW  - Real time data collections
KW  - Technological solution
KW  - Test performance
ER  - 

TY  - JOUR
TI  - Occlusion-Aware Self-Supervised Monocular 6D Object Pose Estimation
AU  - Wang, G.
AU  - Manhardt, F.
AU  - Liu, X.
AU  - Ji, X.
AU  - Tombari, F.
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - 6D object pose estimation is a fundamental yet challenging problem in computer vision. Convolutional Neural Networks (CNNs) have recently proven to be capable of predicting reliable 6D pose estimates even under monocular settings. Nonetheless, CNNs are identified as being extremely data-driven, and acquiring adequate annotations is oftentimes very time-consuming and labor intensive. To overcome this limitation, we propose a novel monocular 6D pose estimation approach by means of self-supervised learning, removing the need of real annotations. After training our proposed network fully supervised with synthetic RGB data, we leverage current trends in noisy student training and differentiable rendering to further self-supervise the model on these unsupervised real RGB(-D) samples, seeking for a visually and geometrically optimal alignment. Moreover, employing both visible and amodal mask information, our self-supervision can be very robust towards challenging scenarios such as occlusion. Extensive evaluations demonstrate that our proposed self-supervision is able to significantly enhance the model's original performance, outperforming all other methods relying on synthetic data or employing elaborate techniques from the domain adaptation realm. Noteworthy, our self-supervised approach achieves almost 50% relative improvement between methods purely trained with synthetic data and fully-supervised methods trained with real-world annotations. IEEE
DA  - 2021///
PY  - 2021
DO  - 10.1109/TPAMI.2021.3136301
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121764142&doi=10.1109%2fTPAMI.2021.3136301&partnerID=40&md5=545ed40a6217309afd0b288bdf56a9f3
DB  - Scopus
KW  - Neural networks
KW  - Training
KW  - Supervised learning
KW  - Computer vision
KW  - Data visualization
KW  - Robustness (control systems)
KW  - Robustness
KW  - Self-supervised learning
KW  - Object pose
KW  - Pose-estimation
KW  - Solid modelling
KW  - Domain adaptation
KW  - Annotation
KW  - Annotations
KW  - Self-Supervised Learning
KW  - Pose estimation
KW  - 6d object pose estimation
KW  - 6D Object Pose Estimation
KW  - Differentiable rendering
KW  - Differentiable Rendering
KW  - Domain Adaptation
KW  - Rendering (computer graphic)
KW  - Rendering (computer graphics)
KW  - Solid modeling
KW  - Three dimensional computer graphics
KW  - Three dimensional displays
KW  - Three-dimensional display
KW  - Three-dimensional displays
ER  - 

TY  - CONF
TI  - Distantly-Supervised Named Entity Recognition with Noise-Robust Learning and Language Model Augmented Self-Training
AU  - Meng, Y.
AU  - Zhang, Y.
AU  - Huang, J.
AU  - Wang, X.
AU  - Zhang, Y.
AU  - Ji, H.
AU  - Han, J.
T2  - EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings
AB  - We study the problem of training named entity recognition (NER) models using only distantly-labeled data, which can be automatically obtained by matching entity mentions in the raw text with entity types in a knowledge base. The biggest challenge of distantly-supervised NER is that the distant supervision may induce incomplete and noisy labels, rendering the straightforward application of supervised learning ineffective. In this paper, we propose (1) a noise-robust learning scheme comprised of a new loss function and a noisy label removal step, for training NER models on distantly-labeled data, and (2) a self-training method that uses contextualized augmentations created by pre-trained language models to improve the generalization ability of the NER model. On three benchmark datasets, our method achieves superior performance, outperforming existing distantly-supervised NER models by significant margins. © 2021 Association for Computational Linguistics
DA  - 2021///
PY  - 2021
SP  - 10367
EP  - 10378
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121748854&partnerID=40&md5=0fb4ea97baff35f25aec98ee2a1ae5de
DB  - Scopus
KW  - Knowledge based systems
KW  - Learning systems
KW  - Benchmarking
KW  - Learning models
KW  - Natural language processing systems
KW  - Labeled data
KW  - Robust learning
KW  - Noise robust
KW  - Computational linguistics
KW  - Language model
KW  - Self-training
KW  - Character recognition
KW  - Noisy labels
KW  - Recognition models
KW  - Matchings
KW  - Named entity recognition
ER  - 

TY  - JOUR
TI  - 12th International Workshop on Biological Knowledge Discovery from Data, BIOKDD 2021, 5th International Workshop on Cyber-Security and Functional Safety in Cyber-Physical Systems, IWCFS 2021, 3rd International Workshop on Machine Learning and Knowledge Graphs, MLKgraphs 2021, 1st International Workshop on Artificial Intelligence for Clean, Affordable and Reliable Energy Supply, AI-CARES 2021, 1st International Workshop on Time Ordered Data, ProTime2021 and 1st International Workshop on AI System Engineering: Math, Modelling and Software, AISys2021 held at 32nd International Conference on Database and Expert Systems Applications, DEXA 2021
T2  - Communications in Computer and Information Science
AB  - The proceedings contain 23 papers. The special focus in this conference is on Database and Expert Systems Applications. The topics include: Semantic Influence Score: Tracing Beautiful Minds Through Knowledge Diffusion and Derivative Works; robust and Efficient Bio-Inspired Data-Sampling Prototype for Time-Series Analysis; membership-Mappings for Data Representation Learning: Measure Theoretic Conceptualization; membership-Mappings for Data Representation Learning: A Bregman Divergence Based Conditionally Deep Autoencoder; data Catalogs: A Systematic Literature Review and Guidelines to Implementation; task-Specific Automation in Deep Learning Processes; approximate Fault Tolerance for Edge Stream Processing; deep Learning Rule for Efficient Changepoint Detection in the Presence of Non-Linear Trends; time Series Pattern Discovery by Deep Learning and Graph Mining; a Conceptual Model for Mitigation of Root Causes of Uncertainty in Cyber-Physical Systems; integrating Gene Ontology Based Grouping and Ranking into the Machine Learning Algorithm for Gene Expression Data Analysis; SVM-RCE-R-OPT: Optimization of Scoring Function for SVM-RCE-R; short-Term Renewable Energy Forecasting in Greece Using Prophet Decomposition and Tree-Based Ensembles; a Comparative Study of Deep Learning Approaches for Day-Ahead Load Forecasting of an Electric Car Fleet; Security-Based Safety Hazard Analysis Using FMEA: A DAM Case Study; Privacy Preserving Machine Learning for Malicious URL Detection; remote Attestation of Bare-Metal Microprocessor Software: A Formally Verified Security Monitor; Provenance and Privacy in ProSA: A Guided Interview on Privacy-Aware Provenance; placeholder Constraint Evaluation in Simulation Graphs; Walk Extraction Strategies for Node Embeddings with RDF2Vec in Knowledge Graphs; bridging Semantic Web and Machine Learning: First Results of a Systematic Mapping Study.
DA  - 2021///
PY  - 2021
VL  - 1479 CCIS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115854950&partnerID=40&md5=1b6a89bdee2058c1a051cd730161ae5d
DB  - Scopus
ER  - 

TY  - JOUR
TI  - Mapping spatial variability of foliar nitrogen and carbon in Indian tropical moist deciduous sal (Shorea robusta) forest using machine learning algorithms and Sentinel-2 data
AU  - Vasudeva, V.
AU  - Nandy, S.
AU  - Padalia, H.
AU  - Srinet, R.
AU  - Chauhan, P.
T2  - International Journal of Remote Sensing
AB  - Foliar Nitrogen (N) and Carbon (C) are two vital leaf biochemical components that can indicate forest health. In this study, the spatial distribution of foliar N and C was mapped using Sentinel-2 data in a tropical moist deciduous sal (Shorea robusta) forest of northwest Himalayan foothills of India. Empirical relationships were established between satellite data-derived spectral indices, band reflectance and ground measured foliar N and C using machine learning algorithm (MLA). Performance of MLAs viz. Random Forest (RF), Artificial Neural Network (ANN) and Support Vector Machine (SVM) were assessed. Using all the independent spectral variables, RF performed better than ANN and SVM in explaining the variation in foliar N and C. RF was further used to optimize the independent variables for identifying the best predictor variables. It was found that foliar N is strongly related to shortwave infrared-1 (SWIR-1) band and Normalized Difference Red Edge Index (NDRE). Foliar C was found to be strongly related to SWIR-1 band and spectral vegetation indices: Green Normalized Difference Vegetation Index (GNDVI), Green Red Vegetation Index (GRVI), Green Chlorophyll Index (GCI), and Ratio of Modified Chlorophyll Absorption in Reflectance Index and Optimized Soil Adjusted Vegetation Index (MCARI/OSAVI). Using these best predictor variables, the spatial variability of foliar N and C was mapped using RF algorithm. On validation of the predicted N and C with ground measured foliar N and C, R 2 of 0.85 (RMSE = 0.04%) for N and R 2 of 0.86 (RMSE = 0.26%) for C were observed. It can be concluded that MLAs have great potential to map the spatial variability of foliar N and C in the tropical forests using the broad bands of Sentinel-2 imagery. © 2020 Informa UK Limited, trading as Taylor & Francis Group.
DA  - 2021///
PY  - 2021
DO  - 10.1080/01431161.2020.1823043
VL  - 42
IS  - 3
SP  - 1139
EP  - 1159
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097205205&doi=10.1080%2f01431161.2020.1823043&partnerID=40&md5=7c6c82470853c526460fcad05e4c5013
DB  - Scopus
KW  - machine learning
KW  - Decision trees
KW  - Neural networks
KW  - Support vector machines
KW  - Learning systems
KW  - Learning algorithms
KW  - algorithm
KW  - carbon
KW  - Carbon
KW  - nitrogen
KW  - Nitrogen
KW  - Forestry
KW  - India
KW  - satellite data
KW  - mapping
KW  - Biochemical components
KW  - Chlorophyll
KW  - deciduous forest
KW  - Empirical relationships
KW  - Green normalized difference vegetation index
KW  - Himalayas
KW  - Independent variables
KW  - Infrared radiation
KW  - leaf
KW  - Normalized differences
KW  - Predictor variables
KW  - Reflection
KW  - Sentinel
KW  - Shorea robusta
KW  - spatial distribution
KW  - Spatial variability
KW  - spatial variation
KW  - Spectral vegetation indices
KW  - tropical forest
KW  - Tropics
KW  - Vegetation
ER  - 

TY  - JOUR
TI  - A robust data-worth analysis framework for soil moisture flow by hybridizing sequential data assimilation and machine learning
AU  - Wang, Y.
AU  - Shi, L.
AU  - Lin, L.
AU  - Holzman, M.
AU  - Carmona, F.
AU  - Zhang, Q.
T2  - Vadose Zone Journal
AB  - As the collection of soil moisture data is often costly, it is essential to implement data-worth analysis in advance to obtain a cost-effective data collection scheme. In previous data-worth analysis, the model structural error is often neglected. In this paper, we propose a robust data-worth analysis framework based on a hybrid data assimilation method. By constructing Gaussian process (GP) error model, this study attempts to alleviate biased data-worth assessments caused by unknown model structural errors, and to excavate complementary values of multisource data without resorting to multiple governing equations. The results demonstrated that this proposed framework effectively identified and compensated for complex model structural errors. By training prior data, more accurate potential observations were obtained and data-worth estimation accuracy was improved. The scenario diversity played a crucial role in establishing an effective GP training system. The integration of soil temperature into GP training unraveled new information and improved the data-worth estimation. Instead of traditional evapotranspiration calculations, the direct inclusion of easy-to-obtain meteorological data into GP training yielded better data-worth assessment. © 2020 The Authors. Vadose Zone Journal published by Wiley Periodicals, Inc.
DA  - 2020///
PY  - 2020
DO  - 10.1002/vzj2.20026
VL  - 19
IS  - 1
SP  - 1
EP  - 18
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095110553&doi=10.1002%2fvzj2.20026&partnerID=40&md5=e9616cc18a3934fd5895d35ecbb8d99e
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Analysis frameworks
KW  - Errors
KW  - Cost effectiveness
KW  - estimation method
KW  - Gaussian process
KW  - soil moisture
KW  - Soil moisture
KW  - Training Systems
KW  - accuracy assessment
KW  - error analysis
KW  - Multisource data
KW  - assessment method
KW  - data assimilation
KW  - Data collection scheme
KW  - evapotranspiration
KW  - Excavata
KW  - Gaussian method
KW  - Governing equations
KW  - Meteorological data
KW  - Meteorology
KW  - Model structural error
KW  - Soil surveys
KW  - soil temperature
KW  - Structural analysis
ER  - 

TY  - JOUR
TI  - Robust data detection for MIMO systems with one-bit ADCs: A reinforcement learning approach
AU  - Jeon, Y.-S.
AU  - Lee, N.
AU  - Poor, H.V.
T2  - IEEE Transactions on Wireless Communications
AB  - The use of one-bit analog-to-digital converters (ADCs) at a receiver is a power-efficient solution for future wireless systems operating with a large signal bandwidth and/or a massive number of receive radio frequency chains. This solution, however, induces high channel estimation error and therefore makes it difficult to perform the optimal data detection that requires perfect knowledge of likelihood functions at the receiver. In this paper, we propose a likelihood function learning method for multiple-input multiple-output (MIMO) systems with one-bit ADCs using a reinforcement learning approach. The key idea is to exploit input-output samples obtained from data detection, to compensate for the mismatch in the likelihood function. The underlying difficulty of this idea is a label uncertainty in the samples caused by a data detection error. To resolve this problem, we define a Markov decision process (MDP) to maximize the accuracy of the likelihood function learned from the samples. We then develop a reinforcement learning algorithm that efficiently finds the optimal policy by approximating the transition function and the optimal state of the MDP. Simulation results demonstrate that the proposed method provides significant performance gains for data detection methods that suffer from the mismatch in the likelihood function. © 2002-2012 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/TWC.2019.2956044
VL  - 19
IS  - 3
SP  - 1663
EP  - 1676
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081734092&doi=10.1109%2fTWC.2019.2956044&partnerID=40&md5=e3eb84ea8da81766d713b35d89f505ca
DB  - Scopus
KW  - Reinforcement learning
KW  - reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Markov Decision Processes
KW  - Markov processes
KW  - Reinforcement learning approach
KW  - Robust datum
KW  - Feedback control
KW  - Error detection
KW  - MIMO systems
KW  - Analog to digital conversion
KW  - Analog to digital converters
KW  - Channel estimation errors
KW  - Digital radio
KW  - Future wireless systems
KW  - likelihood function learning
KW  - Likelihood functions
KW  - Multiple-input-multiple-output (MIMO)
KW  - one-bit analog-to-digital converter (ADC)
KW  - Power-efficient solutions
KW  - robust data detection
KW  - Signal receivers
KW  - Telecommunication repeaters
ER  - 

TY  - JOUR
TI  - 11th International Workshop on Biological Knowledge Discovery from Data, BIOKDD 2020,  the 4th International Workshop on Cyber-Security and Functional Safety in Cyber-Physical Systems, IWCFS 2020, the 2nd International Workshop on Machine Learning and Knowledge Graphs, MLKgraphs2019, held at the 31st International Conference on Database and Expert Systems Applications, DEXA 2020
T2  - Communications in Computer and Information Science
AB  - The proceedings contain 10 papers. The special focus in this conference is on Biological Knowledge Discovery from Data. The topics include: TopicsRanksDC: Distance-Based Topic Ranking Applied on Two-Class Data; YASSi: Yet Another Symbolic Simulator Large (Tool Demo); variational Optimization of Informational Privacy; An Architecture for Automated Security Test Case Generation for MQTT Systems; mode Switching from a Security Perspective: First Findings of a Systematic Literature Review; Exploiting MQTT-SN for Distributed Reflection Denial-of-Service Attacks; exploring the Influence of Data Aggregation in Parking Prediction; Building Knowledge Graph in Spark Without SPARQL.
DA  - 2020///
PY  - 2020
VL  - 1285 CCIS
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092097939&partnerID=40&md5=41c4e78176011793138f297982b38210
DB  - Scopus
ER  - 

TY  - CONF
TI  - Robust Review Rating Prediction Model based on Machine and Deep Learning: Yelp Dataset
AU  - Rafay, A.
AU  - Suleman, M.
AU  - Alim, A.
T2  - 2020 International Conference on Emerging Trends in Smart Technologies, ICETST 2020
AB  - Public reviews for a business are very important and help the business to measure the quality and excellence in different directions which leads to predict the worth of a business in the market. In other words, reviews have a very high impact on business revenue. In this paper, we focus on reviews for all kinds of restaurants business and have proposed a sentiment analysis and opinion mining model to perform the classification on business reviews. In order to achieve robust results both binary and multilabel classification are used used by using a large and rich text reviews dataset provided by Yelp Dataset Challenge round-13. Extensive and series of experiments have been done and compare the results of a machine learning based algorithm 'Multinomial Naive Bayes' and deep learning algorithm 'convolution Long Short Term Memory" (CLSTM) with word2vec and Global Vector (Glove). After analyzing the performance of each model with different metrics, it has been observed that the best model for classifying the review ratings is CLSTM. We have also found the role of bias in the machine and its importance in explaining the performance differences observed on specific problems. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ICETST49965.2020.9080713
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084947972&doi=10.1109%2fICETST49965.2020.9080713&partnerID=40&md5=93295e1fdee90a3fdb2cf882b0790653
DB  - Scopus
KW  - Deep learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Classification (of information)
KW  - LSTM
KW  - On-machines
KW  - Large dataset
KW  - Naive Bayes
KW  - Multi-label classifications
KW  - Multinomial naive bayes
KW  - Sentiment analysis
KW  - Prediction model
KW  - and predictions
KW  - Business reviews
KW  - Opinion mining
KW  - Public review
KW  - Specific problems
ER  - 

TY  - JOUR
TI  - Data challenges and practical aspects of machine learning-based statistical methods for the analyses of poultry data to improve food safety and production efficiency
AU  - Pitesky, M.
AU  - Gendreau, J.
AU  - Bond, T.
AU  - Carrasco-Medanic, R.
T2  - CAB Reviews: Perspectives in Agriculture, Veterinary Science, Nutrition and Natural Resources
AB  - Leveraging data collected by commercial poultry requires a deep understanding of the data that are collected. Machine learning (ML)-based techniques are capable of "learning by finding"nonobvious associations and patterns in the data in order to create more reliable, accurate, explanatory, and predictive statistical models. This article provides practical definitions and examples of ML-based statistical approaches for the analysis of poultry production and poultry food safety-based data. In addition to summarizing the literature, two real examples of the supervised machine learning ensemble technique, random forest (RF), are provided with respect to predicting egg weights from a commercial layer farm and identifying the potential causes of a Salmonella outbreak from a commercial broiler facility. Specifically, as an example, for the prediction of egg weights, a training model and a test model were created, and a modification of RF was used to explore the ability to predict egg weights. Results identified multiple variables including Age, Farm Location, Body Weight, Total Eggs, Hens Housed, and House Style which were predictive of the continuous variable Egg Weight. With respect to the accuracy of the variable Egg Weight, the average error between the predicted and actual egg weight was determined to be less than 3%. With respect to broiler food safety, a relational database was constructed and a supervised RF model was developed to identify the predictors of Salmonella in a grow-out farm and associated broiler processing plant. Predictors of Salmonella that included livability, density of birds in the grow-out farm, and breeder age were identified. The task of choosing the most appropriate ML-based model(s) that accounts for the large number of variables common to the poultry industry and addresses the intricate interdependence between several production parameters and inputs while predicting multiple sequential outputs is complex. The use of ML techniques in combination with new data streams including sensors (e.g., visual and audio), IoT, and Web-scraping could offer a more comprehensive, efficient, and timely approach toward evaluating productivity, food safety, and profitability in commercial poultry. © CAB International 2020.
DA  - 2020///
PY  - 2020
DO  - 10.1079/PAVSNNR202015049
VL  - 15
IS  - 49
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092733283&doi=10.1079%2fPAVSNNR202015049&partnerID=40&md5=0195511c219805008d7ce8610fde7d0d
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Data mining
KW  - Food safety
KW  - Exploratory data analysis
KW  - Knowledge discovery in databases
KW  - Predictions
KW  - Production efficiency
KW  - Supervised and unsupervised models
ER  - 

TY  - CONF
TI  - Towards deployment of robust cooperative ai agents: An algorithmic framework for learning adaptive policies
AU  - Ghosh, A.
AU  - Mahdavi, H.
AU  - Tschiatschek, S.
AU  - Singla, A.
T2  - Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS
AB  - We study the problem of designing an AI agent that can robustly cooperate with agents of unknown type (i.e., previously unobserved behavior) in multi-agent scenarios. Our work is inspired by real-world applications in which an AI agent, e.g., a virtual assistant, has to cooperate with new types of agents/users after its deployment. We model this problem via parametric Markov Decision Processes where the parameters correspond to a user's type and characterize her behavior. In the test phase, the AI agent has to interact with a user of an unknown type. We develop an algorithmic framework for learning adaptive policies: our approach relies on observing the user's actions to make inferences about the user's type and adapting the policy to facilitate efficient cooperation. We show that without being adaptive, an AI agent can end up performing arbitrarily bad in the test phase. Using our framework, we propose two concrete algorithms for computing policies that automatically adapt to the user in the test phase. We demonstrate the effectiveness of our algorithms in a cooperative gathering game environment for two agents. © 2020 International Foundation for Autonomous.
DA  - 2020///
PY  - 2020
VL  - 2020-May
SP  - 447
EP  - 455
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093460105&partnerID=40&md5=9647e6eca81c01f303cba645d35a90aa
DB  - Scopus
KW  - Reinforcement learning
KW  - Machine learning
KW  - Autonomous agents
KW  - Markov Decision Processes
KW  - Markov processes
KW  - Multi agent systems
KW  - Multi agent
KW  - Virtual assistants
KW  - Two agents
KW  - Algorithmic framework
KW  - Adaptive policy
KW  - Computing policies
KW  - Game environment
KW  - Learning agent-to-agent interactions
ER  - 

TY  - CHAP
TI  - Semi-supervised learning based on distributionally robust optimization
AU  - Blanchet, J.
AU  - Kang, Y.
T2  - Data Analysis and Applications 3: Computational, Classification, Financial, Statistical and Stochastic Methods
AB  - This chapter proposes a novel method for semi-supervised learning (SSL) based on data-driven distributionally robust optimization (DRO) using optimal transport metrics. The proposed method enhances generalization error by using the non-labeled data to restrict the support of the worstcase distribution in DRO formulation. The chapter describes the implementation of DRO formulation by proposing a stochastic gradient descent algorithm, and demonstrates that semi-supervised DRO method is able to improve the generalization error over natural supervised procedures and state-of-the-art SSL estimators. It includes a discussion on the large sample behavior of the optimal uncertainty region in the DRO formulation. The discussion exposes important aspects such as the role of dimension reduction in SSL. © ISTE Ltd 2020.
DA  - 2020///
PY  - 2020
SP  - 3
EP  - 33
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100526539&doi=10.1002%2f9781119721871.ch1&partnerID=40&md5=3f45c19a8a3b997d7869235b119de2c3
DB  - Scopus
KW  - Distributionally robust optimization
KW  - Generalization error
KW  - Semi-supervised learning estimators
KW  - Stochastic gradient descent algorithm
KW  - Transport metrics
ER  - 

TY  - CONF
TI  - A Principal Component Analysis Approach for Embedding Local Symmetries into Deep Learning Algorithms
AU  - Lagrave, P.-Y.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Building robust-by-design Machine Learning algorithms is key for critical tasks such as safety or military applications. By leveraging on the ideas developed in the context of building invariant Support Vectors Machines, this paper introduces a convenient methodology for embedding local Lie groups symmetries into Deep Learning algorithms by performing a Principal Component Analysis on the corresponding Tangent Covariance Matrix. The projection of the input data onto the principal directions leads to a new data representation which allows singling out the components conveying the semantic information useful to the considered algorithmic task while reducing the dimension of the input manifold. Besides, our numerical testing emphasizes that, although less efficient than using Group-Convolutional Neural Networks as only dealing with local symmetries, our approach does improve accuracy and robustness without introducing significant computational overhead. Performance improvements up to 5% were obtained for low capacity algorithms, making this approach of particular interest for the engineering of safe embedded Artificial Intelligence systems. © 2020, Springer Nature Switzerland AG.
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-55583-2_22
VL  - 12235 LNCS
SP  - 302
EP  - 314
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096594336&doi=10.1007%2f978-3-030-55583-2_22&partnerID=40&md5=26c5c385b8de90bde29d678864ad77a9
DB  - Scopus
KW  - Deep learning
KW  - Semantics
KW  - Convolutional neural networks
KW  - Learning systems
KW  - Learning algorithms
KW  - Critical tasks
KW  - Safety engineering
KW  - Embedded systems
KW  - Support vectors machine
KW  - Artificial intelligence systems
KW  - Military applications
KW  - Embeddings
KW  - Safe machine learning
KW  - System of systems
KW  - Data representations
KW  - Computational overheads
KW  - Covariance matrix
KW  - Data representation
KW  - Lie groups
KW  - Model-based engineering
KW  - Numerical testing
KW  - Principal directions
KW  - Robustness-by-design
KW  - Semantic information
ER  - 

TY  - CONF
TI  - A Framework for Building Uncertainty Wrappers for AI/ML-Based Data-Driven Components
AU  - Kläs, M.
AU  - Jöckel, L.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - More and more software-intensive systems include components that are data-driven in the sense that they use models based on artificial intelligence (AI) or machine learning (ML). Since the outcomes of such models cannot be assumed to always be correct, related uncertainties must be understood and taken into account when decisions are made using these outcomes. This applies, in particular, if such decisions affect the safety of the system. To date, however, hardly any AI-/ML-based model provides dependable estimates of the uncertainty remaining in its outcomes. In order to address this limitation, we present a framework for encapsulating existing models applied in data-driven components with an uncertainty wrapper in order to enrich the model outcome with a situation-aware and dependable uncertainty statement. The presented framework is founded on existing work on the concept and mathematical foundation of uncertainty wrappers. The application of the framework is illustrated using pedestrian detection as an example, which is a particularly safety-critical feature in the context of autonomous driving. The Brier score and its components are used to investigate how the key aspects of the framework (scoping, clustering, calibration, and confidence limits) can influence the quality of uncertainty estimates. © 2020, Springer Nature Switzerland AG.
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-55583-2_23
VL  - 12235 LNCS
SP  - 315
EP  - 327
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096598898&doi=10.1007%2f978-3-030-55583-2_23&partnerID=40&md5=83471415db0d0778b436e00a14267b50
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Autonomous driving
KW  - Pedestrian safety
KW  - Safety engineering
KW  - Uncertainty analysis
KW  - Data quality
KW  - Dependability
KW  - Embedded systems
KW  - Estimation
KW  - Mathematical foundations
KW  - Operational design domain
KW  - Uncertainty estimates
KW  - System of systems
KW  - Out-of-distribution
KW  - Pedestrian detection
KW  - Confidence limit
KW  - Critical features
KW  - Data encapsulation
KW  - Situation-aware
KW  - Software intensive systems
ER  - 

TY  - BOOK
TI  - Contemporary Experimental Design, Multivariate Analysis and Data Mining: Festschrift in Honour of Professor Kai-Tai Fang
AU  - Fan, J.
AU  - Pan, J.
T2  - Contemporary Experimental Design, Multivariate Analysis and Data Mining: Festschrift in Honour of Professor Kai-Tai Fang
AB  - The collection and analysis of data play an important role in many fields of science and technology, such as computational biology, quantitative finance, information engineering, machine learning, neuroscience, medicine, and the social sciences. Especially in the era of big data, researchers can easily collect data characterised by massive dimensions and complexity. In celebration of Professor Kai-Tai Fang’s 80th birthday, we present this book, which furthers new and exciting developments in modern statistical theories, methods and applications. The book features four review papers on Professor Fang’s numerous contributions to the fields of experimental design, multivariate analysis, data mining and education. It also contains twenty research articles contributed by prominent and active figures in their fields. The articles cover a wide range of important topics such as experimental design, multivariate analysis, data mining, hypothesis testing and statistical models. © Springer Nature Switzerland AG 2020.
DA  - 2020///
PY  - 2020
SP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134488682&doi=10.1007%2f978-3-030-46161-4&partnerID=40&md5=7819cc7b6bf19d9c8693f0973389e3bb
DB  - Scopus
KW  - machine learning
KW  - big data
KW  - variable selection
KW  - data mining
KW  - Robust design
KW  - experimental design
KW  - Covariance matrix
KW  - 62F 62H 62G 62K 62J 62N 62P
KW  - Composite design
KW  - Functional data
KW  - high-dimensional data
KW  - longitudinal data
KW  - multivariate data
KW  - network data
KW  - Quantile regression
KW  - survival data
ER  - 

TY  - CHAP
TI  - Data-driven approaches to fault-tolerant control of industrial robotic systems
AU  - Jiang, Y.
AU  - Yin, S.
T2  - Fault Diagnosis and Fault-Tolerant Control of Robotic and Autonomous Systems
AB  - Robotic systems in the modern industries are working in increasingly complex environment. The unexpected external disturbances and the abrupt change of working condition bring great challenges to the control of such systems. For some safetycritical applications, it is required to continuously stabilize the systems under faulty condition (including malfunctions and system failures). In this chapter, a data-driven fault-tolerant control (FTC) framework is introduced. As a semi-supervised machine learning technique that can learn from the rewards from external environment, reinforcement learning (RL) aims to maximize the long-term returns by, for instance, maintaining a value function. Based on the approximated value function, optimal control law can be derived. When using RL, although the convergence of the value function has been proved for some simple systems, such as the linear time invariant system, the internal stability of the close-loop system still remains unguaranteed. To deal with this problem, a novel framework for FTC system design based on Youla parameterization is introduced. It can be implemented in the modular and plug-and play manner. It should be noted that in this work RL acts as a supervising module that calculates optimized Youla matrix Qc in the design phase. Simulation results on a wheeled robot are provided to show the performance of the proposed approach in the continuously stabilizing framework. Some open questions and future work are summarized at the end of this chapter. © The Institution of Engineering and Technology 2020.
DA  - 2020///
PY  - 2020
SP  - 257
EP  - 284
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115704476&doi=10.1049%2fPBCE126E_ch12&partnerID=40&md5=e1fe0d4a8db0c51623004fd3bda157b0
DB  - Scopus
KW  - Reinforcement learning
KW  - System failures
KW  - Control system synthesis
KW  - Control engineering computing
KW  - Learning (artificial intelligence)
KW  - Mobile robots
KW  - Industrial robots
KW  - Faulty condition
KW  - Safety-critical software
KW  - Optimal control
KW  - Stability
KW  - Linear systems
KW  - Fault diagnosis
KW  - Optimal control law
KW  - Close-loop system
KW  - Data-driven fault-tolerant control
KW  - Fault tolerant control
KW  - FTC system design
KW  - Industrial robotic systems
KW  - Internal stability
KW  - Linear time invariant system
KW  - Safety-critical applications
KW  - Semisupervised machine learning
KW  - Wheeled robot
KW  - Youla matrix
ER  - 

TY  - CONF
TI  - Adversarial sample based semi-supervised learning for industrial soft sensor
AU  - Feng, L.
AU  - Zhao, C.
T2  - IFAC-PapersOnLine
AB  - In industrial processes, soft sensor techniques are often utilized to predict the hard-to-measure quality variables. However, the labeled data which are obtained from the offline lab analysis can be quite rare. In the present work, a new divergence-based semi-supervised learning method is developed to exploit the unlabeled samples together with labeled ones for soft sensor application, namely adversarial tri-regression. First, the adversarial samples are generated based on the consideration of maximum disturbance, and through training on the combination of the adversarial samples and the original labeled samples, three regressors are initialized with divergence. Second, for each regressor, an unlabeled sample is labeled when the other two regressors agree on the labeling of this sample, which actually provides that regressor with some unknown information based on the divergence. As the three regressors label more and more samples for each other, the final regression model obtained by averaging the three base regressors presents increasingly more accurate prediction. The proposed method tackles a practical soft sensor problem for the industrial production process of cigarette. Copyright © 2020 The Authors. This is an open access article under the CC BY-NC-ND license
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.ifacol.2020.12.647
VL  - 53
SP  - 11644
EP  - 11649
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105051015&doi=10.1016%2fj.ifacol.2020.12.647&partnerID=40&md5=8e1d7fe14832d0dd2ad722748e49cf48
DB  - Scopus
KW  - Deep learning
KW  - Learning systems
KW  - Supervised learning
KW  - Regression analysis
KW  - Semi-supervised learning
KW  - Unlabeled samples
KW  - Soft sensors
KW  - Robust modeling
KW  - Industrial processs
KW  - Soft sensor
KW  - Training strategy
KW  - Tri-training
KW  - Tri-training strategy
KW  - Adversarial sample
KW  - Adversarial samples
KW  - Divergence-based regressor
ER  - 

TY  - JOUR
TI  - A robust extreme learning machine framework for uncertain data classification
AU  - Jing, S.
AU  - Yang, L.
T2  - Journal of Supercomputing
AB  - Uncertain or missing data may occur in many practical applications. A principled strategy for handling this problem would therefore be very useful. We consider two-class and multi-class classification problems where the mean and covariance of each class are assumed to be known. With simple structure, fast speed and good performance, extreme learning machine (ELM) has been an important technology in machine learning. In this work, from the viewpoint of probability, we present a robust ELM framework (RELM) for missing data classification. Applying the Chebyshev–Cantelli inequality, the proposed RELM is reformulated as a second-order cone programming with global optimal solution. The proposed RELM only relates to the second moments of input samples and makes no assumption about the data probability distribution. Expectation maximization algorithm is used to fill in missing values and then obtain complete data. Numerical experiments are simulated in various datasets from UCI database and a practical application database. Experimental results show that the proposed method can achieve better performance than traditional methods. These results illustrate the feasibility and effectiveness of the proposed method for missing data classification. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2020///
PY  - 2020
DO  - 10.1007/s11227-018-2430-6
VL  - 76
IS  - 4
SP  - 2390
EP  - 2416
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081254670&doi=10.1007%2fs11227-018-2430-6&partnerID=40&md5=9d6880693d753dff20a823380e6433c1
DB  - Scopus
KW  - Machine learning
KW  - Classification (of information)
KW  - Uncertainty
KW  - Knowledge acquisition
KW  - Image segmentation
KW  - Extreme learning machine
KW  - Probability distributions
KW  - Maximum principle
KW  - Missing data
KW  - Expectation-maximization algorithms
KW  - Expectation maximization (EM) algorithm
KW  - Probability constraint
KW  - Probability constraints
KW  - Second-order cone programming
ER  - 

TY  - JOUR
TI  - Rocorl: Transferable Reinforcement Learning-Based Robust Control for Cyber-Physical Systems with Limited Data Updates
AU  - Yoo, G.
AU  - Yoo, M.
AU  - Yeom, I.
AU  - Woo, H.
T2  - IEEE Access
AB  - Autonomous control systems are increasingly using machine learning technologies to process sensor data, making timely and informed decisions about performing control functions based on the data processing results. Among such machine learning technologies, reinforcement learning (RL) with deep neural networks has been recently recognized as one of the feasible solutions, since it enables learning by interaction with environments of control systems. In this paper, we consider RL-based control models and address the problem of temporally outdated observations often incurred in dynamic cyber-physical environments. The problem can hinder broad adoptions of RL methods for autonomous control systems. Specifically, we present an RL-based robust control model, namely rocorl, that exploits a hierarchical learning structure in which a set of low-level policy variants are trained for stale observations and then their learned knowledge can be transferred to a target environment limited in timely data updates. In doing so, we employ an autoencoder-based observation transfer scheme for systematically training a set of transferable control policies and an aggregated model-based learning scheme for data-efficiently training a high-level orchestrator in a hierarchy. Our experiments show that rocorl is robust against various conditions of distributed sensor data updates, compared with several other models including a state-of-the-art POMDP method.  © 2013 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3044945
VL  - 8
SP  - 225370
EP  - 225383
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098557004&doi=10.1109%2fACCESS.2020.3044945&partnerID=40&md5=b2f97f48de08629474e2f1fe768b7127
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - reinforcement learning
KW  - Learning systems
KW  - Data handling
KW  - Robust control
KW  - Embedded systems
KW  - Cyber Physical System
KW  - Hierarchical learning
KW  - Machine learning technology
KW  - Autonomous control systems
KW  - model-based learning
KW  - Aggregated modeling
KW  - Control functions
KW  - Cyber-physical system
KW  - Distributed sensor
KW  - Feasible solution
KW  - Informed decision
KW  - real-time data
KW  - stale observations
ER  - 

TY  - CONF
TI  - Interpreting multimodal machine learning models trained for emotion recognition to address robustness and privacy concerns
AU  - Jaiswal, M.
T2  - AAAI 2020 - 34th AAAI Conference on Artificial Intelligence
AB  - Many mobile applications and virtual conversational agents now aim to recognize and adapt to emotions. These predicted emotions are used in variety of downstream applications: (a) generating more human like dialogues, (b) predicting mental health issues, and (c) hate speech detection and intervention. To enable this, data are transmitted from users' devices and stored on central servers. These data are then processed further, either annotated or used as inputs for training a model for a specific task. Yet, these data contain sensitive information that could be used by mobile applications without user's consent or, maliciously, by an eavesdropping adversary. My work focuses on two major issues that are faced while training emotion recognition algorithms: (a) privacy of the generated representations and, (b) explaining and ensuring that the predictions are robust to various situations. Tackling these issues would lead to emotion based algorithms that are deployable and helpful at a larger scale, thus enabling more human like experience when interacting with AI. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
DA  - 2020///
PY  - 2020
SP  - 13716
EP  - 13717
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106254338&partnerID=40&md5=954ab34c5bff3cbae066964f7ef8ac4e
DB  - Scopus
KW  - Machine learning
KW  - Speech recognition
KW  - Emotion recognition
KW  - Machine learning models
KW  - Privacy by design
KW  - Conversational agents
KW  - Sensitive informations
KW  - Downstream applications
KW  - Mobile agents
KW  - Mobile applications
KW  - Mobile computing
KW  - Privacy concerns
KW  - Speech detection
ER  - 

TY  - JOUR
TI  - Community College Students Who Attained a 4-Year Degree Accrued Lower Student Loan Debt than 4-Year Entrants Over 2 Decades: Is a 10 Percent Debt Accumulation Reduction Worth the Added “Risk”? If So, for Whom?
AU  - González Canché, M.S.
T2  - Research in Higher Education
AB  - The study of student loan debt remains a timely and relevant higher education finance research and policy-oriented topic, especially when considering the alarming growth rates of student loan debt balances. The Quarterly Report on Household Debt and Credit released in May of 2018 shows that among all debt balances, student loans remain the only form of debt that virtually sextupled over the last 15-years, and this trend is not slowing down. Although aggregated trends are important, by definition they are limited in their capabilities to providing researchers, policy- and decision-makers with insights related to individual debt accumulation and, perhaps more importantly, with knowledge about the factors associated with variation of individual debt burden. Accordingly, the overarching goal of this study is to ameliorate this limitation in three meaningful ways. First, this is the first study that offers inferential estimates of the magnitude of student debt accumulation increase across two different decades (1991–2013) and institutional sectors (public 2- and 4-year colleges). Second, these estimates are based on student level undergraduate non-self-reported longitudinal loan debt disbursements. Third, the estimates not only account for individuals’ baseline differences at the moment of college entry, but also account for institution- and state-level indicators that took place during college enrollment and that may be related to the variation of student loan debt reliance. Two nationally representative samples (NELS and ELS) complemented with other institution- and state-level data were analyzed using doubly robust estimators build from propensity score weights and entropy balancing approaches that were robust to unobservable selection issues using Oster’s approach (J Bus Econ Stat 37(2):1–18, 2017). The results consistently indicated that, among all participants, student borrowing participation increased by 15 percentage points in the 2000s, compared to the 1990s, and individual debt accumulation at least doubled across decades. Notably, among 4-year degree holders, the 2-year path toward a 4-year degree consistently resulted in about 10% lower debt accumulation compared to the 4-year path toward a 4-year degree. Students who did not attain a 4-year degree were better served by having started college in the 2-year sector. In terms of overall debt increase, 4-year degree holders accrued about $8000 more on average than their counterparts did during the 1990s, however, the recent cohort also repaid about $11,000 more, on average (or three times as much), than participants did in the 1990s. These higher repayment behaviors observed among 4-year degree holders, resulted in similar amounts of their respective debt balances across decades. The implications are clear: students with higher propensities toward a 4-year degree attainment are likely to incur lower debt if they start college in the community college sector. However, before fully recommending this pathway, 2- and 4-year colleges’ articulation agreements should be strengthened to ease transfer and eventual degree completion. Without recommending consolidation or merger between 2- and 4-year institutions, researchers and policy makers can learn from the strategies implemented by successful cases such as Perimeter College and Georgia State. Finally, 4-year entrants with lower likelihood to attain a 4-year degree may be better served by beginning college in the 2-year sector instead. Predictive analytics and machine learning techniques can be used to identify these cases, as depicted in the discussion section of the study. © 2019, Springer Nature B.V.
DA  - 2020///
PY  - 2020
DO  - 10.1007/s11162-019-09565-9
VL  - 61
IS  - 7
SP  - 871
EP  - 915
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068164940&doi=10.1007%2fs11162-019-09565-9&partnerID=40&md5=a43bdff8eeeef6d3cd6e9b1466ff5d7a
DB  - Scopus
KW  - Machine learning
KW  - Predictive analytics
KW  - Data science
KW  - Community college effects on student loan debt
KW  - Doubly-robust modeling
KW  - Entropy balancing
KW  - Higher education finance and college choice
KW  - Philosophy of Causation in the social sciences
KW  - Propensity score weighting
KW  - Quasi-causal estimates
KW  - Unobservable selection and Coefficient stability
ER  - 

TY  - JOUR
TI  - Robustness evaluations of sustainable machine learning models against data poisoning attacks in the internet of things
AU  - Dunn, C.
AU  - Moustafa, N.
AU  - Turnbull, B.
T2  - Sustainability (Switzerland)
AB  - With the increasing popularity of the Internet of Things (IoT) platforms, the cyber security of these platforms is a highly active area of research. One key technology underpinning smart IoT systems is machine learning, which classifies and predicts events from large-scale data in IoT networks. Machine learning is susceptible to cyber attacks, particularly data poisoning attacks that inject false data when training machine learning models. Data poisoning attacks degrade the performances of machine learning models. It is an ongoing research challenge to develop trustworthy machine learning models resilient and sustainable against data poisoning attacks in IoT networks. We studied the effects of data poisoning attacks on machine learning models, including the gradient boosting machine, random forest, naive Bayes, and feed-forward deep learning, to determine the levels to which the models should be trusted and said to be reliable in real-world IoT settings. In the training phase, a label modification function is developed to manipulate legitimate input classes. The function is employed at data poisoning rates of 5%, 10%, 20%, and 30% that allow the comparison of the poisoned models and display their performance degradations. The machine learning models have been evaluated using the ToN_IoT and UNSW NB-15 datasets, as they include a wide variety of recent legitimate and attack vectors. The experimental results revealed that the models' performances will be degraded, in terms of accuracy and detection rates, if the number of the trained normal observations is not significantly larger than the poisoned data. At the rate of data poisoning of 30% or greater on input data, machine learning performances are significantly degraded. © 2020 by the authors.
DA  - 2020///
PY  - 2020
DO  - 10.3390/SU12166434
VL  - 12
IS  - 17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090401066&doi=10.3390%2fSU12166434&partnerID=40&md5=6f5d67270d887a4171b7d46776286a3a
DB  - Scopus
KW  - machine learning
KW  - Deep learning
KW  - Internet
KW  - Internet of Things
KW  - detection method
KW  - performance assessment
KW  - Adversarial machine learning
KW  - accuracy assessment
KW  - research work
KW  - training
KW  - data assimilation
KW  - Data poisoning
KW  - Sustainable machine learning
ER  - 

TY  - JOUR
TI  - A machine-learning framework for robust and reliable prediction of short- and long-term treatment response in initially antipsychotic-naïve schizophrenia patients based on multimodal neuropsychiatric data
AU  - Ambrosen, K.S.
AU  - Skjerbæk, M.W.
AU  - Foldager, J.
AU  - Axelsen, M.C.
AU  - Bak, N.
AU  - Arvastson, L.
AU  - Christensen, S.R.
AU  - Johansen, L.B.
AU  - Raghava, J.M.
AU  - Oranje, B.
AU  - Rostrup, E.
AU  - Nielsen, M.Ø.
AU  - Osler, M.
AU  - Fagerlund, B.
AU  - Pantelis, C.
AU  - Kinon, B.J.
AU  - Glenthøj, B.Y.
AU  - Hansen, L.K.
AU  - Ebdrup, B.H.
T2  - Translational Psychiatry
AB  - The reproducibility of machine-learning analyses in computational psychiatry is a growing concern. In a multimodal neuropsychiatric dataset of antipsychotic-naïve, first-episode schizophrenia patients, we discuss a workflow aimed at reducing bias and overfitting by invoking simulated data in the design process and analysis in two independent machine-learning approaches, one based on a single algorithm and the other incorporating an ensemble of algorithms. We aimed to (1) classify patients from controls to establish the framework, (2) predict short- and long-term treatment response, and (3) validate the methodological framework. We included 138 antipsychotic-naïve, first-episode schizophrenia patients with data on psychopathology, cognition, electrophysiology, and structural magnetic resonance imaging (MRI). Perinatal data and long-term outcome measures were obtained from Danish registers. Short-term treatment response was defined as change in Positive And Negative Syndrome Score (PANSS) after the initial antipsychotic treatment period. Baseline diagnostic classification algorithms also included data from 151 matched controls. Both approaches significantly classified patients from healthy controls with a balanced accuracy of 63.8% and 64.2%, respectively. Post-hoc analyses showed that the classification primarily was driven by the cognitive data. Neither approach predicted short- nor long-term treatment response. Validation of the framework showed that choice of algorithm and parameter settings in the real data was successfully guided by results from the simulated data. In conclusion, this novel approach holds promise as an important step to minimize bias and obtain reliable results with modest sample sizes when independent replication samples are not available. © 2020, The Author(s).
DA  - 2020///
PY  - 2020
DO  - 10.1038/s41398-020-00962-8
VL  - 10
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089271341&doi=10.1038%2fs41398-020-00962-8&partnerID=40&md5=6caa1d65ba271881a1bdd0b22e0b28fd
DB  - Scopus
KW  - machine learning
KW  - Machine Learning
KW  - psychology
KW  - adult
KW  - controlled study
KW  - female
KW  - human
KW  - Humans
KW  - male
KW  - methodology
KW  - Article
KW  - major clinical study
KW  - reproducibility
KW  - Reproducibility of Results
KW  - mental disease
KW  - cohort analysis
KW  - nuclear magnetic resonance imaging
KW  - classification algorithm
KW  - predictive value
KW  - treatment response
KW  - Antipsychotic Agents
KW  - clozapine
KW  - cognition
KW  - electrophysiology
KW  - long term care
KW  - Magnetic Resonance Imaging
KW  - neuroleptic agent
KW  - neuropsychiatric inventory
KW  - patient coding
KW  - post hoc analysis
KW  - schizophrenia
KW  - Schizophrenia
KW  - Schizophrenic Psychology
KW  - short course therapy
ER  - 

TY  - JOUR
TI  - Training a robust reinforcement learning controller for the uncertain system based on policy gradient method
AU  - Li, Z.
AU  - Xue, S.
AU  - Lin, W.
AU  - Tong, M.
T2  - Neurocomputing
AB  - The target of this paper is to design a model-free robust controller for uncertain systems. The uncertainties of the control system mainly consists of model uncertainty and external disturbance, which widely exist in the practical utilization. These uncertainties will negatively influence the system performance and this motivates us to train a model-free controller to solve this problem. Reinforcement learning is an important branch of machine learning and is able to achieve well performed control results by optimizing a policy without the knowledge of mathematical plant model. In this paper, we construct a reward function module to describe the specific environment of the concerned system, taking uncertainties into account. Then we utilize a new policy gradient method to optimize the policy and implement this algorithm with the actor-critic structure neuro networks. These two networks are our reinforcement learning controllers. Finally, we illustrate the applicability and efficiency of the proposed method by applying it on an experimental helicopter platform model, which includes model uncertainties and external disturbances. © 2018 Elsevier B.V.
DA  - 2018///
PY  - 2018
DO  - 10.1016/j.neucom.2018.08.007
VL  - 316
SP  - 313
EP  - 321
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052158468&doi=10.1016%2fj.neucom.2018.08.007&partnerID=40&md5=ac0d3e85cc27ab5e2cf0e737451179f7
DB  - Scopus
KW  - machine learning
KW  - Reinforcement learning
KW  - uncertainty
KW  - Learning algorithms
KW  - article
KW  - Controllers
KW  - Uncertainty analysis
KW  - Gradient methods
KW  - reinforcement
KW  - reward
KW  - control system
KW  - Policy gradient
KW  - Reward function
KW  - Robust controllers
KW  - External disturbances
KW  - Flight control systems
KW  - Uncertain systems
KW  - Model uncertainties
KW  - helicopter
KW  - Helicopter platform
KW  - Model free controller
KW  - Policy gradient methods
KW  - Robust controller
ER  - 

TY  - CHAP
TI  - Machine Learning and Irresponsible Inference: Morally Assessing the Training Data for Image Recognition Systems
AU  - King, O.C.
T2  - Philosophical Studies Series
AB  - Just as humans can draw conclusions responsibly or irresponsibly, so too can computers. Machine learning systems that have been trained on data sets that include irresponsible judgments are likely to yield irresponsible predictions as outputs. In this paper I focus on a particular kind of inference a computer system might make: identification of the intentions with which a person acted on the basis of photographic evidence. Such inferences are liable to be morally objectionable, because of a way in which they are presumptuous. After elaborating this moral concern, I explore the possibility that carefully procuring the training data for image recognition systems could ensure that the systems avoid the problem. The lesson of this paper extends beyond just the particular case of image recognition systems and the challenge of responsibly identifying a person’s intentions. Reflection on this particular case demonstrates the importance (as well as the difficulty) of evaluating machine learning systems and their training data from the standpoint of moral considerations that are not encompassed by ordinary assessments of predictive accuracy. © 2019, Springer Nature Switzerland AG.
DA  - 2019///
PY  - 2019
VL  - 134
SP  - 265
EP  - 282
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068695369&doi=10.1007%2f978-3-030-01800-9_14&partnerID=40&md5=a7cda8ca88eeae6df60b79e3d4c9609d
DB  - Scopus
KW  - Machine learning algorithms
KW  - Training data
KW  - Image recognition systems
KW  - Ingrained responsibility
KW  - Intention ascription
KW  - Modular responsibility
KW  - Responsible AI judgment
ER  - 

TY  - CONF
TI  - Benchmark Meta-Dataset of High-Resolution Remote Sensing Imagery for Training Robust Deep Learning Models in Machine-Assisted Visual Analytics
AU  - Hurt, J.A.
AU  - Scott, G.J.
AU  - Anderson, D.T.
AU  - Davis, C.H.
T2  - Proceedings - Applied Imagery Pattern Recognition Workshop
AB  - Recent years have seen the publication of various high-resolution remote sensing imagery benchmark datasets. These datasets, while diverse in design, have many co-occurring object classes that are of interest for various application domains of Earth observation. In this research, we present our evaluation of a new meta-benchmark dataset combining object classes from the UC Merced, WHU-RS19, PatternNet, and RESISC-45 benchmark datasets. We provide open-source resources to acquire the individual benchmark datasets and then agglomerate them into a new meta-dataset (MDS). Prior research has shown that contemporary deep convolutional neural networks are able to achieve cross-validation accuracies in the range of 95-100% for the 33 identified object classes. Our analysis shows that the overall accuracy for all object classes from these benchmarks is approximately 98.6%. In this work, we investigate the utility of agglomerating the benchmarks into an MDS to train more generalizable, and therefore translatable from lab to real-world, deep machine learning (DML) models. We evaluate numerous state-of-the-art architectures, as well as our data-driven DML model fusion techniques. Finally, we compare MDS performance with that of the benchmark datasets to evaluate the performance versus cost trade-off of using multiple DML in an ensemble system. © 2018 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/AIPR.2018.8707433
VL  - 2018-October
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065994506&doi=10.1109%2fAIPR.2018.8707433&partnerID=40&md5=92eef0e1d7a644c58d9df4ec1b54937c
DB  - Scopus
KW  - Pattern recognition
KW  - Deep neural networks
KW  - Neural networks
KW  - State of the art
KW  - Economic and social effects
KW  - Convolutional neural network
KW  - Benchmarking
KW  - Benchmark datasets
KW  - Remote sensing
KW  - Cross validation
KW  - Earth observations
KW  - Ensemble systems
KW  - High resolution remote sensing imagery
KW  - Overall accuracies
ER  - 

TY  - JOUR
TI  - Towards intelligent robust detection of anatomical structures in incomplete volumetric data
AU  - Ghesu, F.C.
AU  - Georgescu, B.
AU  - Grbic, S.
AU  - Maier, A.
AU  - Hornegger, J.
AU  - Comaniciu, D.
T2  - Medical Image Analysis
AB  - Robust and fast detection of anatomical structures represents an important component of medical image analysis technologies. Current solutions for anatomy detection are based on machine learning, and are generally driven by suboptimal and exhaustive search strategies. In particular, these techniques do not effectively address cases of incomplete data, i.e., scans acquired with a partial field-of-view. We address these challenges by following a new paradigm, which reformulates the detection task to teaching an intelligent artificial agent how to actively search for an anatomical structure. Using the principles of deep reinforcement learning with multi-scale image analysis, artificial agents are taught optimal navigation paths in the scale-space representation of an image, while accounting for structures that are missing from the field-of-view. The spatial coherence of the observed anatomical landmarks is ensured using elements from statistical shape modeling and robust estimation theory. Experiments show that our solution outperforms marginal space deep learning, a powerful deep learning method, at detecting different anatomical structures without any failure. The dataset contains 5043 3D-CT volumes from over 2000 patients, totaling over 2,500,000 image slices. In particular, our solution achieves 0% false-positive and 0% false-negative rates at detecting whether the landmarks are captured in the field-of-view of the scan (excluding all border cases), with an average detection accuracy of 2.78 mm. In terms of runtime, we reduce the detection-time of the marginal space deep learning method by 20–30 times to under 40 ms, an unmatched performance for high resolution incomplete 3D-CT data. © 2018 Elsevier B.V.
DA  - 2018///
PY  - 2018
DO  - 10.1016/j.media.2018.06.007
VL  - 48
SP  - 203
EP  - 213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049348377&doi=10.1016%2fj.media.2018.06.007&partnerID=40&md5=9e2adcf8cb5f509e122ad9b17f97df7b
DB  - Scopus
KW  - machine learning
KW  - Deep learning
KW  - Reinforcement learning
KW  - causality
KW  - Deep Learning
KW  - Algorithms
KW  - Deep reinforcement learning
KW  - controlled study
KW  - human
KW  - Humans
KW  - algorithm
KW  - procedures
KW  - Article
KW  - priority journal
KW  - Medical imaging
KW  - random forest
KW  - image processing
KW  - false negative result
KW  - Image Processing, Computer-Assisted
KW  - Real-time detection
KW  - reinforcement
KW  - image analysis
KW  - Computerized tomography
KW  - task performance
KW  - consensus
KW  - Tomography, X-Ray Computed
KW  - x-ray computed tomography
KW  - 3D data
KW  - anatomic landmark
KW  - Anatomic Landmarks
KW  - anatomical concepts
KW  - aortic arch
KW  - aortic root
KW  - basilar artery
KW  - carotid artery
KW  - celiac artery
KW  - Image analysis
KW  - Imaging, Three-Dimensional
KW  - Incomplete 3D-data
KW  - learning environment
KW  - left lung
KW  - M-estimator sample consensus
KW  - Multi-scale
KW  - Multi-scale detection
KW  - right lung
KW  - Robust statistical shape-modeling
KW  - Sample consensus
KW  - Scale space models
KW  - Scale-space modeling
KW  - skull base
KW  - Statistical shape model
KW  - three dimensional imaging
KW  - vertebral artery
KW  - Volumetric analysis
KW  - volumetry
KW  - whole body CT
ER  - 

TY  - CONF
TI  - WellNet: Improvement of machine learning models robustness via comprehensive multi oilfield dataset
AU  - Reshytko, A.
AU  - Egorov, D.
AU  - Klenitskiy, A.
AU  - Shchepetnov, A.
T2  - EAGE Subsurface Intelligence Workshop 2019
AB  - In this work we test generalization capabilities of predictive machine learning models across multiple oilfields. For this purpose we introduce WellNet: a multi-oilfield dataset containing six oilfields from Western Siberia region. Series of experiments we conducted testing generalization capabilities of neural network GRU-CNN model. It was clearly shown that utilization of bigger amount of data for the task of well logs interpretation can considerably increase the model prediction accuracy in spite of the fact that data were taken from different fields, formations, geological and geophysical conditions. © EAGE Subsurface Intelligence Workshop 2019. All rights reserved.
DA  - 2019///
PY  - 2019
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088597487&partnerID=40&md5=ad2e768f755b26946be7b39316f1a76f
DB  - Scopus
KW  - Machine learning
KW  - Predictive analytics
KW  - Machine learning models
KW  - Well logging
KW  - Well logs
KW  - Model prediction
KW  - Generalization capability
KW  - CNN models
KW  - Geophysical conditions
KW  - Oil fields
KW  - Western siberia
ER  - 

TY  - CONF
TI  - Feature Robustness in Non-stationary Health Records: Caveats to Deployable Model Performance in Common Clinical Machine Learning Tasks
AU  - Nestor, B.
AU  - McDermott, M.B.A.
AU  - Boag, W.
AU  - Berner, G.
AU  - Naumann, T.
AU  - Hughes, M.C.
AU  - Goldenberg, A.
AU  - Ghassemi, M.
T2  - Proceedings of Machine Learning Research
AB  - When training clinical prediction models from electronic health records (EHRs), a key concern should be a model's ability to sustain performance over time when deployed, even as care practices, database systems, and population demographics evolve. Due to de-identification requirements, however, current experimental practices for public EHR benchmarks (such as the MIMIC-III critical care dataset) are time agnostic, assigning care records to train or test sets without regard for the actual dates of care. As a result, current benchmarks cannot assess how well models trained on one year generalise to another. In this work, we obtain a Limited Data Use Agreement to access year of care for each record in MIMIC and show that all tested state-of-the-art models decay in prediction quality when trained on historical data and tested on future data, particularly in response to a system-wide record-keeping change in 2008 (0.29 drop in AUROC for mortality prediction, 0.10 drop in AUROC for length-of-stay prediction with a random forest classifier). We further develop a simple yet effective mitigation strategy: by aggregating raw features into expert-defined clinical concepts, we see only a 0.06 drop in AUROC for mortality prediction and a 0.03 drop in AUROC for length-of-stay prediction. We demonstrate that this aggregation strategy outperforms other automatic feature preprocessing techniques aimed at increasing robustness to data drift. We release our aggregated representations and code to encourage more deployable clinical prediction models. © 2019 B. Nestor et al.
DA  - 2019///
PY  - 2019
VL  - 106
SP  - 381
EP  - 405
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161283968&partnerID=40&md5=bf0599530487b3b68d7af038b412130c
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Forecasting
KW  - 'current
KW  - Statistical tests
KW  - Modeling performance
KW  - Prediction modelling
KW  - Electronic health
KW  - Health records
KW  - Records management
KW  - Learning tasks
KW  - Drops
KW  - Length of stay
KW  - Modeling abilities
KW  - Nonstationary
ER  - 

TY  - JOUR
TI  - Data-Driven Robust Control of Discrete-Time Uncertain Linear Systems via Off-Policy Reinforcement Learning
AU  - Yang, Y.
AU  - Guo, Z.
AU  - Xiong, H.
AU  - Ding, D.-W.
AU  - Yin, Y.
AU  - Wunsch, D.C.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - This paper presents a model-free solution to the robust stabilization problem of discrete-time linear dynamical systems with bounded and mismatched uncertainty. An optimal controller design method is derived to solve the robust control problem, which results in solving an algebraic Riccati equation (ARE). It is shown that the optimal controller obtained by solving the ARE can robustly stabilize the uncertain system. To develop a model-free solution to the translated ARE, off-policy reinforcement learning (RL) is employed to solve the problem in hand without the requirement of system dynamics. In addition, the comparisons between on- and off-policy RL methods are presented regarding the robustness to probing noise and the dependence on system dynamics. Finally, a simulation example is carried out to validate the efficacy of the presented off-policy RL approach. © 2012 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/TNNLS.2019.2897814
VL  - 30
IS  - 12
SP  - 3735
EP  - 3747
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076449490&doi=10.1109%2fTNNLS.2019.2897814&partnerID=40&md5=5fd4ecd9996365d4c8b1af9038e95305
DB  - Scopus
KW  - Reinforcement learning
KW  - simulation
KW  - Machine learning
KW  - uncertainty
KW  - article
KW  - Controllers
KW  - linear system
KW  - Robust control
KW  - Model free
KW  - Dynamical systems
KW  - reinforcement learning (RL)
KW  - robust control
KW  - Robust control problems
KW  - reinforcement
KW  - System theory
KW  - Discrete time control systems
KW  - noise
KW  - Robust stabilization problem
KW  - Algebra
KW  - Riccati equations
KW  - Linear systems
KW  - Uncertain systems
KW  - System uncertainties
KW  - Linear control systems
KW  - system uncertainty
KW  - off-policy
KW  - Algebraic Riccati equations
KW  - Uncertain linear system
KW  - Discrete time linear dynamical systems
KW  - Mismatched uncertainty
KW  - Model-free
KW  - on-policy
ER  - 

TY  - JOUR
TI  - A machine learning based robust prediction model for real-life mobile phone data
AU  - Sarker, I.H.
T2  - Internet of Things (Netherlands)
AB  - Real-life mobile phone data may contain noisy instances, which is a fundamental issue for building a prediction model with many potential negative consequences. The complexity of the inferred model may increase, may arise over-fitting problem, and thereby the overall prediction accuracy of the model may decrease. In this paper, we address these issues and present a robust prediction model for real-life mobile phone data of individual users, in order to improve the prediction accuracy of the model. In our robust model, we first effectively identify and eliminate the noisy instances from the training dataset by determining a dynamic noise threshold using naive Bayes classifier and laplace estimator, which may differ from user-to-user according to their unique behavioral patterns. After that, we employ the most popular rule-based machine learning classification technique, i.e., decision tree, on the noise-free quality dataset to build the prediction model. Experimental results on the real-life mobile phone datasets (e.g., phone call log) of individual mobile phone users, show the effectiveness of our robust model in terms of precision, recall and f-measure. © 2019 Elsevier B.V.
DA  - 2019///
PY  - 2019
DO  - 10.1016/j.iot.2019.01.007
VL  - 5
SP  - 180
EP  - 193
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066814482&doi=10.1016%2fj.iot.2019.01.007&partnerID=40&md5=d9952b31f91018f0099e6875fe80b1ba
DB  - Scopus
KW  - Machine learning
KW  - Intelligent systems
KW  - Noise
KW  - Prediction model
KW  - Contexts
KW  - Mobile data mining
KW  - Personalization
KW  - User behavior modeling
ER  - 

TY  - JOUR
TI  - Data-Driven Safety Envelope of Lithium-Ion Batteries for Electric Vehicles
AU  - Li, W.
AU  - Zhu, J.
AU  - Xia, Y.
AU  - Gorji, M.B.
AU  - Wierzbicki, T.
T2  - Joule
AB  - In the accident scenarios of electric vehicles, the battery pack can be damaged catastrophically, resulting in the electric short circuit, thermal runaway, and possible fire and explosion. Therefore, it is important to investigate the range of conditions under which the safe operation of each individual cell is adequately controlled, known as the “safety envelope”. The biggest challenge of developing such a safety envelope lies in the acquisition of a large data bank of battery failure tests. In this study, we overcome the challenge by establishing a high-accuracy detailed computational model of lithium-ion pouch cells, in which all the component materials are characterized by well-calibrated constitutive models. A large matrix of extreme mechanical loading conditions is simulated, and a data-driven safety envelope is obtained using the machine learning algorithm. This work is a demonstration of combining numerical data generation with data-driven modeling to predict the safety of energy storage systems. The rapid improvement of battery technology has brought the world into a new era of EV. However, the industry is now facing a new challenge in this new era—the crash safety of EV compared to its gasoline counterpart. The most urgent task is to identify the range of mechanical loading conditions ensuring safe operation of battery cells, known as the “safety envelope.” To develop it requires a huge databank of mechanical tests, making it a daunting challenge. Here, we overcame this challenge by employing a high-accuracy finite element model of a pouch cell to produce over 2,500 simulations and analyzed the data with machine learning algorithms. We visualized the safety envelope with two types of phase diagrams, a classifier that fast predicts of short circuit or safe to a given loading condition and a regressor that quantitatively tells the amount of deformation needed to develop a short. The safety envelope provides important guidelines to the design of EV and batteries. We demonstrated the use of the powerful machine learning tool to develop the “safety envelope” of lithium-ion batteries for electric vehicles that provides the range of mechanical loading conditions ensuring safe operation. The daunting challenge of obtaining a large databank of battery tests was overcome by utilizing a high-accuracy finite element model of a pouch cell to generate over 2,500 numerical simulations. The safety envelope will serve as important guidelines to the design of EV and batteries. © 2019 Elsevier Inc.
DA  - 2019///
PY  - 2019
DO  - 10.1016/j.joule.2019.07.026
VL  - 3
IS  - 11
SP  - 2703
EP  - 2715
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074902968&doi=10.1016%2fj.joule.2019.07.026&partnerID=40&md5=72d0eb1fe88937d4a4d325c4b8c6d28f
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Accidents
KW  - Neural networks
KW  - standardization
KW  - Learning systems
KW  - electric vehicle
KW  - Learning algorithms
KW  - Accident prevention
KW  - safety
KW  - artificial neural network
KW  - Electric vehicles
KW  - Digital storage
KW  - Accident scenarios
KW  - Lithium-ion batteries
KW  - Data-driven model
KW  - Ions
KW  - Finite element method
KW  - Explosions
KW  - electric vehicles
KW  - data set
KW  - Failure (mechanical)
KW  - lithium-ion batteries
KW  - Battery Pack
KW  - Energy storage systems
KW  - Computational model
KW  - Battery technology
KW  - Component materials
KW  - data-driven modeling
KW  - failure analysis
KW  - mechanical failure
KW  - Mechanical failures
KW  - mechanical property
KW  - safety envelope
KW  - safety standardization
KW  - Safety standardizations
ER  - 

TY  - CONF
TI  - Robustly Predicting Pedestrian Destinations Using Pre-trained Machine Learning Model for a Voice Guidance Robot∗
AU  - Ohta, A.
AU  - Okano, S.
AU  - Matsuhira, N.
AU  - Kato, Y.
T2  - IECON Proceedings (Industrial Electronics Conference)
AB  - In this paper, we propose a method robustly predicting the destination of a pedestrian heading toward a robot in order to provide suitable voice guidance to him/her by communication robots installed at the reception desks of public facilities. For this purpose, we measure a pedestrian trajectory with a laser range scanner attached to the robot, and predict the destination among more than three branches by cascading multiple predictor models for two branches pre-trained by a machine learning algorithm. In order to verify the effectiveness of the proposed method, we conduct experiments using a dataset of tracking pedestrians at a shopping mall, and data observed in the real environment. The result shows that our method can predict three branch destinations with an accuracy of about 80%. © 2019 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/IECON.2019.8927554
VL  - 2019-October
SP  - 6922
EP  - 6927
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084140509&doi=10.1109%2fIECON.2019.8927554&partnerID=40&md5=e660bace98a4357efbf2f8de07477fc0
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Robots
KW  - Learning algorithms
KW  - Forecasting
KW  - Machine learning models
KW  - Three-branch
KW  - Real environments
KW  - Communication robot
KW  - dataset
KW  - Industrial electronics
KW  - Laser range scanners
KW  - pedestrian model
KW  - Pedestrian trajectories
KW  - pre-trained predictor
KW  - Public facilities
KW  - service robot
ER  - 

TY  - JOUR
TI  - Optimal machine learning models for robust materials classification using ToF-SIMS data
AU  - Madiona, R.M.T.
AU  - Winkler, D.A.
AU  - Muir, B.W.
AU  - Pigram, P.J.
T2  - Applied Surface Science
AB  - Surface interactions largely control how biomaterials interact with biology, and how other materials function in industrial applications. Surface analysis methods are therefore very important in understanding the molecular properties of materials surfaces, and in establishing mechanisms and design rules for new materials. Surface analysis instrumentation is developing at a rapid rate, generating data of unprecedented accuracy and quantity. However, computational methods for extracting knowledge from these data are lagging far behind, with simple, linear PCA methods being used most commonly. Here we shown how nonlinear machine learning methods can be used to very effectively and rapidly analyse large and complex surface science (ToF-SIMS) data sets and how parameters used to generate these nonlinear classification models can be optimized. We show that coarse-grained representations of mass spectra coupled with relatively small self-organized map sizes provide surprisingly good performance in analysing spectra of closely related materials. Although finer-grained mass spectral representations perform better, they only do so with larger map sizes due to the increase in noise or less relevant signals in the data matrices used to train the machine learning models. These methods promise faster, easier, and more accurate analysis of the increasingly large and complex surface science data sets that are appearing at an accelerating rate. © 2019 Elsevier B.V.
DA  - 2019///
PY  - 2019
DO  - 10.1016/j.apsusc.2019.05.123
VL  - 487
SP  - 773
EP  - 783
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066077077&doi=10.1016%2fj.apsusc.2019.05.123&partnerID=40&md5=a2b3d5b40cbf43e2c0fffc73611b9af0
DB  - Scopus
KW  - Machine learning
KW  - Classification (of information)
KW  - Machine learning models
KW  - Machine learning methods
KW  - Materials informatics
KW  - Multivariate analysis
KW  - Organic polymers
KW  - Biomaterials
KW  - Molecular properties
KW  - Multivariant analysis
KW  - Multivariate analysis (MVA)
KW  - Nonlinear classification
KW  - Secondary ion mass spectrometry
KW  - Self-organising maps (SOMs)
KW  - Surface analysis
KW  - Surface analysis methods
KW  - Time of flight secondary ion mass spectrometry
KW  - Time-of-flight secondary ion mass spectrometry (ToF-SIMS)
ER  - 

TY  - JOUR
TI  - A novel data-driven robust framework based on machine learning and knowledge graph for disease classification
AU  - Lei, Z.
AU  - Sun, Y.
AU  - Nanehkaran, Y.A.
AU  - Yang, S.
AU  - Islam, M.S.
AU  - Lei, H.
AU  - Zhang, D.
T2  - Future Generation Computer Systems
AB  - As Noncommunicable Diseases (NCDs) are affected or controlled by diverse factors such as age, regionalism, timeliness or seasonality, they are always challenging to be treated accurately, which has impacted on daily life and work of patients. Unfortunately, although a number of researchers have already made some achievements (including clinical or even computer-based) on certain diseases, current situation is eager to be improved via computer technologies such as data mining and Deep Learning. In addition, the progress of NCD research has been hampered by privacy of health and medical data. In this paper, a hierarchical idea has been proposed to study the effects of various factors on diseases, and a data-driven framework named d-DC with good extensibility is presented. d-DC is able to classify the disease according to the occupation on the premise where the disease is occurring in a certain region. During collecting data, we used a combination of personal or family medical records and traditional methods to build a data acquisition model. Not only can it realize automatic collection and replenishment of data, but it can also effectively tackle the cold start problem of the model with relatively few data effectively. The diversity of information gathering includes structured data and unstructured data (such as plain texts, images or videos), which contributes to improve the classification accuracy and new knowledge acquisition. Apart from adopting machine learning methods, d-DC has employed knowledge graph (KG) to classify diseases for the first time. The vectorization of medical texts by using knowledge embedding is a novel consideration in the classification of diseases. When results are singular, the medical expert system was proposed to address inconsistencies through knowledge bases or online experts. The results of d-DC are displayed by using a combination of KG and traditional methods, which intuitively provides a reasonable interpretation to the results (highly descriptive). Experiments show that d-DC achieved the improved accuracy than the other previous methods. Especially, a fusion method called RKRE based on both ResNet and the expert system attained an average correct proportion of 86.95%, which is a good feasibility study in the field of disease classification. © 2019 Elsevier B.V.
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.future.2019.08.030
VL  - 102
SP  - 534
EP  - 548
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072215486&doi=10.1016%2fj.future.2019.08.030&partnerID=40&md5=ece42282bdd032dcf61184e187efef15
DB  - Scopus
KW  - Deep learning
KW  - Machine learning
KW  - Knowledge graphs
KW  - Data mining
KW  - Learning systems
KW  - Classification (of information)
KW  - Expert systems
KW  - Machine learning methods
KW  - Image enhancement
KW  - Classification accuracy
KW  - Patient treatment
KW  - Data acquisition
KW  - Data fusion
KW  - Knowledge graph
KW  - Disease classification
KW  - NCDs
KW  - Information gathering
KW  - Medical expert system
KW  - Non-communicable disease
ER  - 

TY  - JOUR
TI  - A decision support framework for robust R&D budget allocation using machine learning and optimization
AU  - Jang, H.
T2  - Decision Support Systems
AB  - Considering that government funding agencies make decisions on research and development (R&D) budget allocation to support an increasing number of research proposals, effective decision support systems are necessarily required. Motivated by the efforts of the Korean government, we propose a new decision support framework for allocating an R&D budget such that it maximizes the total expected R&D output. The proposed framework incorporates an R&D output prediction model with an optimization technique. We first employ a machine learning algorithm to accurately estimate future R&D output. Then, we apply a robust optimization technique to hedge against uncertainty in the predicted R&D output values. If not properly accounted for, this uncertainty may yield an inefficient budget allocation plan, thus hindering the operation of the R&D budgeting system. We demonstrate the effectiveness of the proposed model by applying it to a national R&D program conducted by the Korean government. Specifically, using the same budget, our budget allocation plan can achieve an output 13.6% greater than the actual R&D output. Thus, our model helps to attain allocation efficiency by systematically allocating budgets. We also observe the price of robustness when our model conservatively allocates budgets in order to hedge against uncertainty in the R&D predictions. Our findings offer insights for both policymakers and researchers related to designing better budget allocation systems for national R&D programs. © 2019 Elsevier B.V.
DA  - 2019///
PY  - 2019
DO  - 10.1016/j.dss.2019.03.010
VL  - 121
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064259042&doi=10.1016%2fj.dss.2019.03.010&partnerID=40&md5=3594ad859a352918295583250a0a730e
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Decision support systems
KW  - Optimization
KW  - Robust optimization
KW  - Budget control
KW  - Research and development
KW  - Public policy
KW  - Allocation efficiencies
KW  - Budget allocation
KW  - Budget allocation plans
KW  - Data-driven R&D budget allocation framework
KW  - Decision support framework
KW  - Government funding
KW  - Optimization techniques
KW  - Public R&D program
KW  - Wooden fences
ER  - 

TY  - JOUR
TI  - Development of a methodological framework for a robust prediction of the main behaviours of dairy cows using a combination of machine learning algorithms on accelerometer data
AU  - Riaboff, L.
AU  - Poggi, S.
AU  - Madouasse, A.
AU  - Couvreur, S.
AU  - Aubin, S.
AU  - Bédère, N.
AU  - Goumand, E.
AU  - Chauvin, A.
AU  - Plantier, G.
T2  - Computers and Electronics in Agriculture
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.compag.2019.105179
VL  - 169
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078071682&doi=10.1016%2fj.compag.2019.105179&partnerID=40&md5=8272eb7a7adbc0192212facc38fe4fd0
DB  - Scopus
KW  - machine learning
KW  - prediction
KW  - methodology
KW  - data set
KW  - cattle
ER  - 

TY  - CONF
TI  - Determination of safe operating mud weight window from well logging data using machine learning algorithms
AU  - Abbas, A.K.
AU  - Almohammed, H.H.
AU  - Alqatran, G.
AU  - Mohammed, H.Q.
AU  - Mohammed, A.
T2  - Offshore Technology Conference Asia 2020, OTCA 2020
AB  - The Lower Cretaceous Zubair Formation is a regionally extended oil-producing sandstone sequence in Iraq, Kuwait, Syria, Iran, and Saudi Arabia. Wellbore instability is frequently reported as one of the most significant incidents while drilling this formation in several fields of Southern Iraq. Wellbore instability-related problems include borehole breakouts and tensile failure, which may lead to stuck pipe, reaming, sidetracking, and loss of circulation. In the present research, first, a comprehensive one-dimensional mechanical earth model (1D-MEM) was constructed based on well logging data, elastic moduli of rock, and appropriate failure criteria to determine the safe operating mud weight window of the Zubair Formation. The accuracy of the developed model was evaluated by comparing the predicted wellbore instability with the actual wellbore failure shown on caliper logs at a given mud weight. Then, appropriate machine-learning algorithms [i.e., artificial neural networks (ANNs) and a support vector machine (SVM)] were used to establish a relationship between well logging data and safe operating mud weight window, which could be used to drill future wells successfully. The learning process was conducted in such a way that conventional well logging data [i. e., compressional wave transit times (DTCO), shear wave transit times (DTSM), density (RHOZ), total porosity (PHIT), and gamma-ray (GR)] were the inputs and the safe operating mud weight window was the output. The results obtained from the developed ANNs and SVM were compared with the real condition in drilled oil wells in the related field which were so promising. The proposed ANNs and SVM approaches can be used as cost-effective tools when planning for future neighboring wells to create better drilling efficiency by reducing the nonproductive time (NPT) and well costs. Copyright 2020, Offshore Technology Conference
DA  - 2020///
PY  - 2020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097627717&partnerID=40&md5=b6bf5fcc26ad5b9c4f65799556c72218
DB  - Scopus
KW  - Neural networks
KW  - Support vector machines
KW  - Learning systems
KW  - Learning algorithms
KW  - Infill drilling
KW  - Well logging
KW  - Cost effectiveness
KW  - Borehole breakouts
KW  - Boreholes
KW  - Compressional waves
KW  - Drilling efficiency
KW  - Drilling machines (machine tools)
KW  - Gamma rays
KW  - Loss of circulations
KW  - Mechanical earth models
KW  - Mud weight windows
KW  - Non-productive time
KW  - Offshore oil well production
KW  - Offshore oil wells
KW  - Offshore technology
KW  - Oil field equipment
KW  - Oil well drilling
KW  - Oil well logging
KW  - Shear flow
KW  - Shear waves
KW  - Wellbore instability
ER  - 

TY  - CHAP
TI  - The evolution of passive brain-computer interfaces: Enhancing the human-machine interaction
AU  - Sciaraffa, N.
AU  - Aricò, P.
AU  - Borghini, G.
AU  - Di Flumeri, G.
AU  - Di Florio, A.
AU  - Babiloni, F.
T2  - Neurotechnology
AB  - In the last decade, a real revolution in the field of brain-computer interfaces (BCI) led from the “overt” detection of human intention to the " covert” assessment of the actual human mental states. While the first aspect is the basis of the traditional BCI systems, the latter represents the outcome of the passive BCI applications. In fact, passive BCI derives its outputs from brain activity arising without the purpose of voluntary control, but implicitly related to the human mental state. The necessity of monitoring human mental states driven by safety-critical application has been just the boost to the passive BCIs developing: more in general, passive BCI represents the implicit channel of information that enhances the goal-oriented cooperation of humans and machines as a whole, the so-called human-machine interaction. So far, there have been countless passive BCI applications in a wide range of contexts such as driving, gaming, and surgery. If on the one hand, this has been possible thanks to the development of more and more discrete neurotechnological devices, on the other hand, we must not overlook the significant step forward in the employed algorithms, with the adoption in this field of machine learning and deep learning enhancements. This chapter will retrace not only the major achievements but also the future trends, in terms of technologies, methods, and applications of what concerns the field of passive BCIs. The final aim of the work is to draw a mark on where we are nowadays and the future challenges, in order to make passive BCIs closer to being integrated into day-life applications. © The Institution of Engineering and Technology 2020.
DA  - 2020///
PY  - 2020
SP  - 155
EP  - 179
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118024830&doi=10.1049%2fpbhe019e_ch6&partnerID=40&md5=af3a1b591f73223ccfcd0372f29ead93
DB  - Scopus
KW  - Deep learning
KW  - Machine learning
KW  - User interfaces
KW  - Human-machine interaction
KW  - Learning (artificial intelligence)
KW  - BCI systems
KW  - Biology and medical computing
KW  - Brain-computer interfaces
KW  - Data security
KW  - Human mental states
KW  - Neural computing techniques
KW  - Neural nets
KW  - Passive brain-computer interfaces
KW  - Safety-critical application
KW  - Safety-critical software
KW  - Software engineering techniques
ER  - 

TY  - JOUR
TI  - A new robust ELM method based on a Bayesian framework with heavy-tailed distribution and weighted likelihood function
AU  - Ning, K.
AU  - Liu, M.
AU  - Dong, M.
T2  - Neurocomputing
AB  - In actual industrial processes, the data used for modeling usually contains some outliers, which may lead to a corrupted approximation function. In this paper, we propose a new Robust Extreme Learning Machine method based on a Bayesian framework (RBELM). The main idea of RBELM is to replace the Gaussian distribution with a heavy-tailed distribution as the probability density function of the model output and give weights to the likelihood function based on the error of the model output, which makes the model more robust to outliers. Two different heavy-tailed distributions are used in this paper. One is the Laplace distribution, and the corresponding model is denoted as RBELM-l. In RBELM-l, the posterior distribution is replaced by an approximate surrogate function, and then the parameters learning problem can be solved by means of Maximum Likelihood-type II (ML-II). The other is the Student's t-distribution, and the corresponding model is denoted as RBELM-t. In order to solve RBELM-t, the Student's t-distribution is written as a scale-mixture of infinitely many Normal distributions and a Gamma distribution. Then, the variational inference method is used to obtain an approximate solution for the parameters. Also, we propose two methods for giving weights to the likelihood function based on the concepts of robust statistic. Finally, a robust error measure is proposed for evaluating the performance of models with outliers in the testing data. Results of numerical comparison based on one synthesis data set, four real benchmark regression problems, and two actual industrial modeling problems show the usefulness of the proposed RBELM-l and RBELM-t. © 2014.
DA  - 2015///
PY  - 2015
DO  - 10.1016/j.neucom.2014.07.045
VL  - 149
IS  - PB
SP  - 891
EP  - 903
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027938211&doi=10.1016%2fj.neucom.2014.07.045&partnerID=40&md5=a0143f3a77735555d0de2a9d101ace3f
DB  - Scopus
KW  - Learning systems
KW  - prediction
KW  - Article
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - mathematical analysis
KW  - regression analysis
KW  - artificial neural network
KW  - Statistics
KW  - probability
KW  - mathematical model
KW  - support vector machine
KW  - conceptual framework
KW  - extreme learning machine
KW  - learning algorithm
KW  - Probability distributions
KW  - Probability density function
KW  - Bayesian learning
KW  - Robust modeling
KW  - Robust model
KW  - fuzzy system
KW  - validation process
KW  - Maximum likelihood
KW  - analytic method
KW  - Bayesian regression
KW  - Heavy-tailed distribution
KW  - Heavy-tailed distributions
KW  - Normal distribution
KW  - partial least squares regression
KW  - Robust Extreme Learning Machine method
KW  - Variational inference
KW  - Weighted likelihood
ER  - 

TY  - JOUR
TI  - Prediction of mine gas emission based on PCA-GA-ELM
AU  - Hong, L.
AU  - He, X.
AU  - Dong, X.
AU  - Yang, Z.
T2  - Liaoning Gongcheng Jishu Daxue Xuebao (Ziran Kexue Ban)/Journal of Liaoning Technical University (Natural Science Edition)
AB  - In order to forecast the coal mine gas emission, this paper used the method of combining the principal component analysis and the improved extreme learning machine, and absorbed the advantages of principal component analysis data dimension reduction in the screening of the sample data. The choice of data samples is concise and more representative. Making full use of the extreme learning machine training speed can obtain the global optimal solution and has the characteristics of good performance of shi, and combining with genetic algorithm (GA), and choosing the optimal input weight matrix and the hidden layer deviation, can avoid the error caused by random. Program is used to determine the number of hidden layer neurons, more accurate than relying on experience. Finally get successful application in practice. The results show that by using of the principal component analysis and improvement combined model to predict extreme learning machine, the results are accurate and reliable which overcomes the deficiency of the previous model. The model of mine gas emission prediction has a certain reference value. ©, 2015, Editorial Office of Journal of Liaoning Technical University. All right reserved.
DA  - 2015///
PY  - 2015
DO  - 10.11956/j.issn.1008-0562.2015.07.003
VL  - 34
IS  - 7
SP  - 779
EP  - 784
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940394845&doi=10.11956%2fj.issn.1008-0562.2015.07.003&partnerID=40&md5=f031cc094f335483e20be1fcc778e4a1
DB  - Scopus
KW  - Extreme learning machine
KW  - Principal component analysis
KW  - Data reduction
KW  - Genetic algorithm
KW  - Gas emission
KW  - Mining safety
ER  - 

TY  - CONF
TI  - Robust L2E parameter estimation of Gaussian mixture models: Comparison with expectation maximization
AU  - Thayasivam, U.
AU  - Kuruwita, C.
AU  - Ramachandran, R.P.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - The purpose of this paper is to discuss the use of L2E estimation that minimizes integrated square distance as a practical robust estimation tool for unsupervised clustering. Comparisons to the expectation maximization (EM) algorithm are made. The L2E approach for mixture models is particularly useful in the study of big data sets and especially those with a consistent numbers of outliers. The focus is on the comparison of L2 E and EM for parameter estimation of Gaussian Mixture Models. Simulation examples show that the L2E approach is more robust than EM when there is noise in the data (particularly outliers) and for the case when the underlying probability density function of the data does not match a mixture of Gaussians. © Springer International Publishing Switzerland 2015.
DA  - 2015///
PY  - 2015
DO  - 10.1007/978-3-319-26555-1_32
VL  - 9491
SP  - 281
EP  - 288
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958536590&doi=10.1007%2f978-3-319-26555-1_32&partnerID=40&md5=b6a9ceeb26ef08f0046fb2ed0f0492fd
DB  - Scopus
KW  - Algorithms
KW  - Robust estimation
KW  - Big data
KW  - Image segmentation
KW  - Statistics
KW  - Parameter estimation
KW  - Information science
KW  - Unsupervised learning
KW  - Object recognition
KW  - Probability density function
KW  - Simulation example
KW  - Gaussian distribution
KW  - Maximum principle
KW  - Gaussian mixture model
KW  - Expectation-maximization algorithms
KW  - Mixture of Gaussians
KW  - Expectation - maximizations
KW  - Communication channels (information theory)
KW  - Expectation maximization
KW  - Gaussian Mixture Model
KW  - Robust L
KW  - Robust L2E estimation
KW  - Unsupervised clustering
ER  - 

TY  - JOUR
TI  - An algorithm of robust online extreme learning machine for dynamic imbalanced datasets
AU  - Zhang, J.
AU  - Feng, L.
T2  - Jisuanji Yanjiu yu Fazhan/Computer Research and Development
AB  - With the coming of big data age, dynamic data has gradually appeared in various application fields, such as safety monitoring, financial forecasting, and medical diagnostics. Although existing knowledge discovery and data mining techniques have shown great success in many real-world applications, dynamic data has the features of imbalance and instability of data classes, the dynamic change of data volume, which makes it difficult for the classification of dynamic data. To solve these problems, in this paper a robust weighed online sequential extreme learning machine algorithm (RWOSELM) based on the online sequential extreme learning machine algorithm (OSELM) is presented. RWOSELM generates the local dynamic weighted matrix with the help of cost sensitive learning theory, thereby it optimizes the empirical risk of the classification model. Meanwhile, RWOSELM takes the data distribution changes which are caused by temporal properties change of dynamic data into consideration, thus it introduces the forgetting factor to enhance the sensitivity of the classifier to the change of data distribution. The method is able to deal with the data with imbalanced class distribution, and maintains the good robust on dynamic data. This paper tests on 24 datasets with different distribution, and the results show that RWOSELM gets good results on imbalanced dynamic dataset. ©, 2015, Science Press. All right reserved.
DA  - 2015///
PY  - 2015
DO  - 10.7544/issn1000-1239.2015.20140182
VL  - 52
IS  - 7
SP  - 1487
EP  - 1498
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941946343&doi=10.7544%2fissn1000-1239.2015.20140182&partnerID=40&md5=0d5cfccc4a7b4312a33f86ec5bd0b5ff
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Diagnosis
KW  - Learning algorithms
KW  - E-learning
KW  - Classification (of information)
KW  - Knowledge acquisition
KW  - Statistical tests
KW  - Extreme learning machine
KW  - Online sequential extreme learning machine
KW  - Cost sensitive learning
KW  - Cost-sensitive learning
KW  - Forgetting factor
KW  - Forgetting factors
KW  - Imbalanced dataset
ER  - 

TY  - CONF
TI  - When Neurons Fail
AU  - El Mhamdi, E.M.
AU  - Guerraoui, R.
T2  - Proceedings - 2017 IEEE 31st International Parallel and Distributed Processing Symposium, IPDPS 2017
AB  - Neural networks have been traditionally considered robust in the sense that their precision degrades gracefully with the failure of neurons and can be compensated by additional learning phases. Nevertheless, critical applications for which neural networks are now appealing solutions, cannot afford any additional learning at run-time. In this paper, we view a multilayer neural network as a distributed system of which neurons can fail independently, and we evaluate its robustness in the absence of any (recovery) learning phase. We give tight bounds on the number of neurons that can fail without harming the result of a computation. To determine our bounds, we leverage the fact that neuralactivation functions are Lipschitz-continuous. Our bound isgiven in the form of quantity, we call the Forward ErrorPropagation, computing this quantity only requires looking atthe topology of the network, while experimentally assessingthe robustness of a network requires the costly experiment oflooking at all the possible inputs and testing all the possibleconfigurations of the network corresponding to different failuresituations, facing a discouraging combinatorial explosion. We distinguish the case of neurons that can fail and stop their activity (crashed neurons) from the case of neurons that can fail by transmitting arbitrary values (Byzantine neurons). In the crash case, our bound involves the number of neuronsper layer, the Lipschitz constant of the neural activationfunction, the number of failing neurons, the synaptic weightsand the depth of the layer where the failure occurred. In thecase of Byzantine failures, our bound involves, in addition, thesynaptic transmission capacity. Interestingly, as we show inthe paper, our bound can easily be extended to the case wheresynapses can fail. We present three applications of our results. The first is aquantification of the effect of memory cost reduction on theaccuracy of a neural network. The second is a quantification ofthe amount of information any neuron needs from its precedinglayer, enabling thereby a boosting scheme that prevents neuronsfrom waiting for unnecessary signals. Our third applicationis a quantification of the trade-off between neural networksrobustness and learning cost. © 2017 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/IPDPS.2017.66
SP  - 1028
EP  - 1037
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027702685&doi=10.1109%2fIPDPS.2017.66&partnerID=40&md5=d12a7728772dcc4135077fd4178a0145
DB  - Scopus
KW  - Neural networks
KW  - Machine Learning
KW  - Neurons
KW  - Learning systems
KW  - Economic and social effects
KW  - Robustness (control systems)
KW  - Neural Networks
KW  - Robustness
KW  - Fault tolerance
KW  - Cost reduction
KW  - Distributed computer systems
KW  - Multilayer neural networks
KW  - Critical applications
KW  - Distributed systems
KW  - Fault tolerant computer systems
KW  - Combinatorial explosion
KW  - Amount of information
KW  - Byzantine fault tolerance
KW  - Byzantine Fault Tolerance
KW  - Distributed Systems
KW  - Lipschitz continuous
KW  - Neuromorphic computing
KW  - Transmission capacities
ER  - 

TY  - JOUR
TI  - Robust control scheme for a class of uncertain nonlinear systems with completely unknown dynamics using data-driven reinforcement learning method
AU  - Jiang, H.
AU  - Zhang, H.
AU  - Cui, Y.
AU  - Xiao, G.
T2  - Neurocomputing
AB  - This paper deals with the robust control issues for a class of uncertain nonlinear systems with completely unknown dynamics via a data-driven reinforcement learning method. Firstly, we formulate the optimal regulation control problem for the nominal system, and then, the robust controller for the original uncertain system is designed by adding a constant feedback gain to the optimal controller of the nominal system. Then, this scheme is extended to the optimal tracking control by means of augmented system and discount factor. It is also demonstrated that the proposed robust controller can achieve optimality with a new defined performance index function when there is no control perturbation. It is well known that the nonlinear optimal control problem relies on the solution of Hamilton–Jacobi–Bellman (HJB) equation, which is a nonlinear partial differential equation and impossible to be solved analytically. In order to overcome this difficulty, we introduce a model-based iterative learning algorithm to successively approximate the solution of HJB equation and provide its convergence proof. Subsequently, based on the structure of the model-based approach, a data-driven reinforcement learning method is derived, which only requires the sampling data from real system with different control inputs rather than the accurate mathematical system models. Neural networks (NNs) are utilized to implement this model-free method to approximate the optimal solutions and the least-square approach is employed to minimize the NN approximation residual errors. Finally, two numerical simulation examples are given to illustrate the effectiveness of our proposed method. © 2017
DA  - 2018///
PY  - 2018
DO  - 10.1016/j.neucom.2017.07.058
VL  - 273
SP  - 68
EP  - 77
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028857157&doi=10.1016%2fj.neucom.2017.07.058&partnerID=40&md5=ad019f371019986782fc2f6081441c7e
DB  - Scopus
KW  - Reinforcement learning
KW  - simulation
KW  - Neural networks
KW  - Learning systems
KW  - Learning algorithms
KW  - Controllers
KW  - Article
KW  - priority journal
KW  - Least squares approximations
KW  - artificial neural network
KW  - Robust control
KW  - mathematical parameters
KW  - Iterative methods
KW  - Model free
KW  - Nonlinear systems
KW  - feedback system
KW  - learning algorithm
KW  - Reinforcement learning method
KW  - Numerical methods
KW  - Adaptive dynamic programming
KW  - Dynamic programming
KW  - Optimal control systems
KW  - Data driven
KW  - nonlinear system
KW  - Discrete time control systems
KW  - Hamilton Jacobi Bellman equation
KW  - Data-driven
KW  - Nonlinear equations
KW  - Nonlinear optimal control problems
KW  - Model-free
KW  - constant feedback
KW  - data based reinforcement learning algorithm
KW  - Hamilton-Jacobi-Bellman equations
KW  - Iterative learning algorithms
KW  - model based iterative learning algorithm
KW  - Nonlinear partial differential equations
KW  - Partial differential equations
KW  - robust regulation controller design
KW  - robust tracking controller design
KW  - uncertain nonlinear system
ER  - 

TY  - JOUR
TI  - Tamoxifen pharmacovigilance: Implications for safe use in the future
AU  - Antimisiaris, D.
AU  - Bae, K.-H.G.
AU  - Morton, L.
AU  - Gully, Z.
T2  - Consultant Pharmacist
AB  - OBJECTIVE: To survey the status of current tamoxifen pharmacovigilance documentation reflecting tamoxifen use in an academic outpatient multispecialty practice in older adults. This data will help provide information to develop improved pharmacovigilance for a growing cohort of older adult users. The data will be utilized by an interdisciplinary team developing new methods of identifying factors for individualized pharmacovigilance in older adults. DESIGN: Retrospective chart review to gather descriptive and quantitative data on tamoxifen pharmacovigilance. SETTING: Multi-specialty clinic. PATIENTS: Ninety-three patients 60 years of age and older. MAIN OUTCOME MEASURES: Quantitative report of tamoxifen monitoring as well as descriptive analysis of individual cases. RESULTS: We found 19 cases of serious adverse events possibly related to tamoxifen (thrombi, uterine malignancies). There were 15 cases with no documentation of pharmacovigilance. All cases had incomplete pharmacovigilance documented. There were two cases of hypercalcemia. There was one case of tamoxifen discontinuation resulting from muscle pain and with chronic muscle pain complaints while receiving tamoxifen. We observed a correlation in older age or high comorbidity burden patients and adverse events patients. CONCLUSION: Some studies direct the important pharmacovigilance toward prevention of thrombi, uterine malignancies, and hypercalcemia; however, it is not easy to identify recommendations for frequency or focus of monitoring to prevent adverse events for individual older adults based on existing recommendations. The data collected and presented in this study serve to heighten awareness of tamoxifen pharmacovigilance and as a starting point for the application of machine learning techniques and modeling to identify high-risk patients and individualized pharmacovigilance recommendations. © 2017 American Society of Consultant Pharmacists, Inc. All rights reserved.
DA  - 2017///
PY  - 2017
DO  - 10.4140/TCP.n.2017.535
VL  - 32
IS  - 9
SP  - 535
EP  - 546
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028610450&doi=10.4140%2fTCP.n.2017.535&partnerID=40&md5=75c007bc3e5a8655b6fa0693136781a3
DB  - Scopus
KW  - Machine learning
KW  - Data
KW  - Predictive modeling
KW  - Predictive analytics
KW  - adult
KW  - female
KW  - human
KW  - Humans
KW  - male
KW  - Male
KW  - aged
KW  - Aged
KW  - Female
KW  - middle aged
KW  - Middle Aged
KW  - Article
KW  - major clinical study
KW  - medical record review
KW  - retrospective study
KW  - very elderly
KW  - treatment duration
KW  - drug safety
KW  - Pharmacovigilance
KW  - drug surveillance program
KW  - Monitoring
KW  - Electronic health record
KW  - Retrospective Studies
KW  - high risk patient
KW  - tamoxifen
KW  - Bayesian inference
KW  - myalgia
KW  - Aged, 80 and over
KW  - chemically induced
KW  - comorbidity
KW  - drug monitoring
KW  - drug use
KW  - Health record data
KW  - hypercalcemia
KW  - Hypercalcemia
KW  - Tamoxifen
KW  - Tamoxifen pharmacovigilance
KW  - Tamoxifen safety
KW  - Tamoxifen tamoxifen in older adults
KW  - thrombosis
KW  - Thrombosis
KW  - unspecified side effect
KW  - Uterine Neoplasms
KW  - uterus cancer
ER  - 

TY  - CONF
TI  - On the robustness of a neural network
AU  - Mhamdi, E.M.E.
AU  - Guerraoui, R.
AU  - Rouault, S.
T2  - Proceedings of the IEEE Symposium on Reliable Distributed Systems
AB  - With the development of neural networks based machine learning and their usage in mission critical applications, voices are rising against the black box aspect of neural networks as it becomes crucial to understand their limits and capabilities. With the rise of neuromorphic hardware, it is even more critical to understand how a neural network, as a distributed system, tolerates the failures of its computing nodes, neurons, and its communication channels, synapses. Experimentally assessing the robustness of neural networks involves the quixotic venture of testing all the possible failures, on all the possible inputs, which ultimately hits a combinatorial explosion for the first, and the impossibility to gather all the possible inputs for the second.In this paper, we prove an upper bound on the expected error of the output when a subset of neurons crashes. This bound involves dependencies on the network parameters that can be seen as being too pessimistic in the average case. It involves a polynomial dependency on the Lipschitz coefficient of the neurons' activation function, and an exponential dependency on the depth of the layer where a failure occurs. We back up our theoretical results with experiments illustrating the extent to which our prediction matches the dependencies between the network parameters and robustness. Our results show that the robustness of neural networks to the average crash can be estimated without the need to neither test the network on all failure configurations, nor access the training set used to train the network, both of which are practically impossible requirements. © 2017 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/SRDS.2017.21
VL  - 2017-September
SP  - 84
EP  - 93
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038116816&doi=10.1109%2fSRDS.2017.21&partnerID=40&md5=f5d2f53ddd8507b4abbbeb1bdff6acee
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Neural networks
KW  - Neurons
KW  - Learning systems
KW  - Robustness (control systems)
KW  - Robustness
KW  - Fault tolerance
KW  - Adversarial machine learning
KW  - Distributed computer systems
KW  - Computing nodes
KW  - Distributed systems
KW  - Fault tolerant computer systems
KW  - Activation functions
KW  - Combinatorial explosion
KW  - Neuromorphic computing
KW  - Mission critical applications
KW  - Network parameters
KW  - Neuromorphic hardwares
ER  - 

TY  - JOUR
TI  - Speeding Up Distributed Machine Learning Using Codes
AU  - Lee, K.
AU  - Lam, M.
AU  - Pedarsani, R.
AU  - Papailiopoulos, D.
AU  - Ramchandran, K.
T2  - IEEE Transactions on Information Theory
AB  - Codes are widely used in many engineering applications to offer robustness against noise. In large-scale systems, there are several types of noise that can affect the performance of distributed machine learning algorithms-straggler nodes, system failures, or communication bottlenecks-but there has been little interaction cutting across codes, machine learning, and distributed systems. In this paper, we provide theoretical insights on how coded solutions can achieve significant gains compared with uncoded ones. We focus on two of the most basic building blocks of distributed learning algorithms: matrix multiplication and data shuffling. For matrix multiplication, we use codes to alleviate the effect of stragglers and show that if the number of homogeneous workers is n, and the runtime of each subtask has an exponential tail, coded computation can speed up distributed matrix multiplication by a factor of n. For data shuffling, we use codes to reduce communication bottlenecks, exploiting the excess in storage. We show that when a constant fraction α of the data matrix can be cached at each worker, and n is the number of workers, coded shuffling reduces the communication cost by a factor of (α + 1n)γ (n) compared with uncoded shuffling, where γ (n) is the ratio of the cost of unicasting n messages to n users to multicasting a common message (of the same size) to n users. For instance, γ (n) n if multicasting a message to n users is as cheap as unicasting a message to one user. We also provide experimental results, corroborating our theoretical gains of the coded algorithms. © 1963-2012 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/TIT.2017.2736066
VL  - 64
IS  - 3
SP  - 1514
EP  - 1529
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028987787&doi=10.1109%2fTIT.2017.2736066&partnerID=40&md5=3efab5c678ea4fd420e0fc93bc00241e
DB  - Scopus
KW  - Artificial intelligence
KW  - Algorithm design and analysis
KW  - robustness
KW  - Learning systems
KW  - Learning algorithms
KW  - Systems engineering
KW  - Robustness (control systems)
KW  - Digital storage
KW  - Matrix algebra
KW  - Encoding (symbols)
KW  - Large scale systems
KW  - Runtimes
KW  - Distributed machine learning
KW  - machine learning algorithms
KW  - Engineering applications
KW  - Distributed database
KW  - Codes (symbols)
KW  - channel coding
KW  - distributed computing
KW  - distributed databases
KW  - Distributed learning algorithms
KW  - encoding
KW  - multicast communication
KW  - Multicast communication
KW  - Multicasting
KW  - Robustness against noise
KW  - runtime
ER  - 

TY  - JOUR
TI  - Data-driven stochastic robust optimization: General computational framework and algorithm leveraging machine learning for optimization under uncertainty in the big data era
AU  - Ning, C.
AU  - You, F.
T2  - Computers and Chemical Engineering
AB  - A novel data-driven stochastic robust optimization (DDSRO) framework is proposed for optimization under uncertainty leveraging labeled multi-class uncertainty data. Uncertainty data in large datasets are often collected from various conditions, which are encoded by class labels. Machine learning methods including Dirichlet process mixture model and maximum likelihood estimation are employed for uncertainty modeling. A DDSRO framework is further proposed based on the data-driven uncertainty model through a bi-level optimization structure. The outer optimization problem follows a two-stage stochastic programming approach to optimize the expected objective across different data classes; adaptive robust optimization is nested as the inner problem to ensure the robustness of the solution while maintaining computational tractability. A decomposition-based algorithm is further developed to solve the resulting multi-level optimization problem efficiently. Case studies on process network design and planning are presented to demonstrate the applicability of the proposed framework and algorithm. © 2017 Elsevier Ltd
DA  - 2018///
PY  - 2018
DO  - 10.1016/j.compchemeng.2017.12.015
VL  - 111
SP  - 115
EP  - 133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042329747&doi=10.1016%2fj.compchemeng.2017.12.015&partnerID=40&md5=b9d0d9ec8c9fda7b3fb4c4fc2182635e
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Bayesian networks
KW  - Machine learning methods
KW  - Big data
KW  - Uncertainty analysis
KW  - Stochastic systems
KW  - Stochastic programming
KW  - Large dataset
KW  - Optimization under uncertainty
KW  - Bayesian model
KW  - Maximum likelihood estimation
KW  - Structural optimization
KW  - Design and operations
KW  - Computational tractability
KW  - Two-stage stochastic programming
KW  - Dirichlet process mixture model
KW  - Framework and algorithms
KW  - Process design and operations
ER  - 

TY  - CONF
TI  - Identification of risk zones for road safety through unsupervised learning algorithms
AU  - Lovón-Melgarejo, J.
AU  - Tenorio-Trigoso, A.
AU  - Castillo-Cara, M.
AU  - Miranda, D.
T2  - Proceedings of the LACCEI international Multi-conference for Engineering, Education and Technology
DA  - 2018///
PY  - 2018
DO  - 10.18687/LACCEI2018.1.1.413
VL  - 2018-July
ST  - Identificación de zonas de riesgo para la Seguridad Vial mediante algoritmos de aprendizaje no supervisado
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057447347&doi=10.18687%2fLACCEI2018.1.1.413&partnerID=40&md5=757c3becfa63fe4f1fd6b4c9ffd2f3c2
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Smart city
KW  - PCA
KW  - Citizen security
KW  - K-Means
KW  - Open data
KW  - Safe routes
ER  - 

TY  - JOUR
TI  - Clustering fMRI data with a robust unsupervised learning algorithm for neuroscience data mining
AU  - Aljobouri, H.K.
AU  - Jaber, H.A.
AU  - Koçak, O.M.
AU  - Algin, O.
AU  - Çankaya, I.
T2  - Journal of Neuroscience Methods
AB  - Background: Clustering approaches used in functional magnetic resonance imaging (fMRI) research use brain activity to divide the brain into various parcels with some degree of homogeneous characteristics, but choosing the appropriate clustering algorithms remains a problem. New method: A novel application of the robust unsupervised learning approach is proposed in the current study. Robust growing neural gas (RGNG) algorithm was fed into fMRI data and compared with growing neural gas (GNG) algorithm, which has not been used for this purpose or any other medical application. Learning algorithms proposed in the current study are fed with real and free auditory fMRI datasets. Results: The fMRI result obtained by running RGNG was within the expected outcome and is similar to those found with the hypothesis method in detecting active areas within the expected auditory cortices. Comparison with existing method(s): The fMRI application of the presented RGNG approach is clearly superior to other approaches in terms of its insensitivity to different initializations and the presence of outliers, as well as its ability to determine the actual number of clusters successfully, as indicated by its performance measured by minimum description length (MDL) and receiver operating characteristic (ROC) analysis. Conclusions: The RGNG can detect the active zones in the brain, analyze brain function, and determine the optimal number of underlying clusters in fMRI datasets. This algorithm can define the positions of the center of an output cluster corresponding to the minimal MDL value. © 2018 Elsevier B.V.
DA  - 2018///
PY  - 2018
DO  - 10.1016/j.jneumeth.2018.02.007
VL  - 299
SP  - 45
EP  - 54
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042406696&doi=10.1016%2fj.jneumeth.2018.02.007&partnerID=40&md5=8e6bb4a7de828f9be2158b9a1e61a207
DB  - Scopus
KW  - Data mining
KW  - signal processing
KW  - brain
KW  - Algorithms
KW  - human
KW  - Humans
KW  - algorithm
KW  - procedures
KW  - comparative study
KW  - Article
KW  - priority journal
KW  - physiology
KW  - artificial neural network
KW  - Neural Networks (Computer)
KW  - cluster analysis
KW  - image processing
KW  - data mining
KW  - Data Mining
KW  - learning algorithm
KW  - Image Processing, Computer-Assisted
KW  - Brain
KW  - Signal Processing, Computer-Assisted
KW  - unsupervised machine learning
KW  - data analysis
KW  - nuclear magnetic resonance imaging
KW  - neuroscience
KW  - Unsupervised Machine Learning
KW  - Magnetic Resonance Imaging
KW  - Neurosciences
KW  - Cluster Analysis
KW  - auditory cortex
KW  - brain mapping
KW  - Brain Mapping
KW  - Clustering technique
KW  - functional magnetic resonance imaging
KW  - functional neuroimaging
KW  - growing neural gas
KW  - Growing neural gas (GNG)
KW  - robust growing neural gas
KW  - Robust growing neural gas (RGNG)
ER  - 

TY  - CONF
TI  - Gray-box adversarial training
AU  - Vivek, B.S.
AU  - Mopuri, K.R.
AU  - Babu, R.V.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Adversarial samples are perturbed inputs crafted to mislead the machine learning systems. A training mechanism, called adversarial training, which presents adversarial samples along with clean samples has been introduced to learn robust models. In order to scale adversarial training for large datasets, these perturbations can only be crafted using fast and simple methods (e.g., gradient ascent). However, it is shown that adversarial training converges to a degenerate minimum, where the model appears to be robust by generating weaker adversaries. As a result, the models are vulnerable to simple black-box attacks. In this paper we, (i) demonstrate the shortcomings of existing evaluation policy, (ii) introduce novel variants of white-box and black-box attacks, dubbed “gray-box adversarial attacks” based on which we propose novel evaluation method to assess the robustness of the learned models, and (iii) propose a novel variant of adversarial training, named “Gray-box Adversarial Training” that uses intermediate versions of the models to seed the adversaries. Experimental evaluation demonstrates that the models trained using our method exhibit better robustness compared to both undefended and adversarially trained models. © Springer Nature Switzerland AG 2018.
DA  - 2018///
PY  - 2018
DO  - 10.1007/978-3-030-01267-0_13
VL  - 11219 LNCS
SP  - 213
EP  - 228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055438686&doi=10.1007%2f978-3-030-01267-0_13&partnerID=40&md5=e7a92b9cac84761bd58ae819624a68fd
DB  - Scopus
KW  - Artificial intelligence
KW  - Learning systems
KW  - Machine learning models
KW  - Computer vision
KW  - On-machines
KW  - Large datasets
KW  - Adversarial training
KW  - Experimental evaluation
KW  - Adversarial perturbations
KW  - Attacks on machine learning models
KW  - Evaluation policy
KW  - Gradient ascent
KW  - Robust machine learning models
KW  - Robust models
ER  - 

TY  - CONF
TI  - In Light of the Legal Debate over Personal Data Privacy at a Time of Globalized Big Data: Making Big Data Researchers Cooperating with Lawmakers to Find Solutions for the Future
AU  - Rousseaux, F.
AU  - Saurel, P.
T2  - Proceedings - 13th IEEE International Conference on Ubiquitous Intelligence and Computing, 13th IEEE International Conference on Advanced and Trusted Computing, 16th IEEE International Conference on Scalable Computing and Communications, IEEE International Conference on Cloud and Big Data Computing, IEEE International Conference on Internet of People and IEEE Smart World Congress and Workshops, UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld 2016
AB  - At the same time as Big Data technologies are being constantly refined, the legislation relating to data privacy is changing. The invalidation by the Court of Justice of the European Union on October 6, 2015, of the agreement known as 'Safe Harbor', negotiated by the European Commission on behalf of the European Union with the United States has two consequences. The first is to announce its replacement by a new, still fragile, program, the 'Privacy Shield', which isn't yet definitive, which could also later be repealed by the Court of Justice of the European Union. For example, we are expecting to hear the opinion in mid-April 2016 of the group of data protection authorities for the various states of the European Union, known as G29. The second is to mobilize the Big Data community to take control of the question of data privacy management, to put in place an adequate internal program. © 2016 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0075
SP  - 398
EP  - 403
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013168673&doi=10.1109%2fUIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0075&partnerID=40&md5=8ca1cb63dcddf9271640f4c58506d977
DB  - Scopus
KW  - Data mining
KW  - Privacy
KW  - Machine Learning
KW  - Learning systems
KW  - Big Data
KW  - Big data
KW  - Data Mining
KW  - Laws and legislation
KW  - Data privacy
KW  - Trusted computing
KW  - Ubiquitous computing
KW  - Data preservations
KW  - Data technologies
KW  - European Commission
KW  - European union
KW  - International law
KW  - Predictive systems
KW  - Privacy management
KW  - Data-Driven Intelligent Predictive Systems
KW  - Personal data preservation
KW  - Privacy By Design
KW  - Privacy Shield
KW  - Safe Harbor
ER  - 

TY  - JOUR
TI  - Machine learning-based kinetic modeling: A robust and reproducible solution for quantitative analysis of dynamic PET data
AU  - Pan, L.
AU  - Cheng, C.
AU  - Haberkorn, U.
AU  - Dimitrakopoulou-Strauss, A.
T2  - Physics in Medicine and Biology
AB  - A variety of compartment models are used for the quantitative analysis of dynamic positron emission tomography (PET) data. Traditionally, these models use an iterative fitting (IF) method to find the least squares between the measured and calculated values over time, which may encounter some problems such as the overfitting of model parameters and a lack of reproducibility, especially when handling noisy data or error data. In this paper, a machine learning (ML) based kinetic modeling method is introduced, which can fully utilize a historical reference database to build a moderate kinetic model directly dealing with noisy data but not trying to smooth the noise in the image. Also, due to the database, the presented method is capable of automatically adjusting the models using a multi-thread grid parameter searching technique. Furthermore, a candidate competition concept is proposed to combine the advantages of the ML and IF modeling methods, which could find a balance between fitting to historical data and to the unseen target curve. The machine learning based method provides a robust and reproducible solution that is user-independent for VOI-based and pixel-wise quantitative analysis of dynamic PET data. © 2017 Institute of Physics and Engineering in Medicine.
DA  - 2017///
PY  - 2017
DO  - 10.1088/1361-6560/aa6244
VL  - 62
IS  - 9
SP  - 3566
EP  - 3581
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017430219&doi=10.1088%2f1361-6560%2faa6244&partnerID=40&md5=570cdbd51154a865bffa13bf13b1795c
DB  - Scopus
KW  - machine learning
KW  - Artificial intelligence
KW  - Support vector machines
KW  - Machine Learning
KW  - Learning systems
KW  - standards
KW  - Data handling
KW  - procedures
KW  - Least squares approximations
KW  - reproducibility
KW  - Reproducibility of Results
KW  - Models, Theoretical
KW  - theoretical model
KW  - Iterative methods
KW  - Reproducibilities
KW  - support vector machine (SVM)
KW  - Curve fitting
KW  - positron emission tomography
KW  - least square analysis
KW  - Least-Squares Analysis
KW  - Kinetics
KW  - Calculated values
KW  - compartment model
KW  - Compartment model
KW  - Iterative fitting
KW  - kinetic modeling
KW  - Kinetic modeling
KW  - Kinetic theory
KW  - Positron emission tomography
KW  - positron emission tomography (PET)
KW  - Positron emission tomography (PET)
KW  - Positron-Emission Tomography
KW  - Positrons
KW  - Reference database
KW  - Searching techniques
ER  - 

TY  - CONF
TI  - Enhancing robustness of machine learning systems via data transformations
AU  - Bhagoji, A.N.
AU  - Cullina, D.
AU  - Sitawarin, C.
AU  - Mittal, P.
T2  - 2018 52nd Annual Conference on Information Sciences and Systems, CISS 2018
AB  - We propose the use of data transformations as a defense against evasion attacks on ML classifiers. We present and investigate strategies for incorporating a variety of data transformations including dimensionality reduction via Principal Component Analysis to enhance the resilience of machine learning, targeting both the classification and the training phase. We empirically evaluate and demonstrate the feasibility of linear transformations of data as a defense mechanism against evasion attacks using multiple real-world datasets. Our key findings are that the defense is (i) effective against the best known evasion attacks from the literature, resulting in a two-fold increase in the resources required by a white-box adversary with knowledge of the defense for a successful attack, (ii) applicable across a range of ML classifiers, including Support Vector Machines and Deep Neural Networks, and (iii) generalizable to multiple application domains, including image classification and human activity classification. © 2018 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/CISS.2018.8362326
SP  - 1
EP  - 5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048547396&doi=10.1109%2fCISS.2018.8362326&partnerID=40&md5=1195fa5014b9ea5e75af443d4be4be66
DB  - Scopus
KW  - Artificial intelligence
KW  - Deep neural networks
KW  - Data transformation
KW  - Network security
KW  - Principal component analysis
KW  - Dimensionality reduction
KW  - White box
KW  - Real-world datasets
KW  - Mathematical transformations
KW  - Training phase
KW  - Multiple applications
KW  - Defense mechanism
KW  - Human activities
KW  - Linear transformations
ER  - 

TY  - JOUR
TI  - Probabilistic regularized extreme learning machine for robust modeling of noise data
AU  - Lu, X.
AU  - Ming, L.
AU  - Liu, W.
AU  - Li, H.-X.
T2  - IEEE Transactions on Cybernetics
AB  - The extreme learning machine (ELM) has been extensively studied in the machine learning field and has been widely implemented due to its simplified algorithm and reduced computational costs. However, it is less effective for modeling data with non-Gaussian noise or data containing outliers. Here, a probabilistic regularized ELM is proposed to improve modeling performance with data containing non-Gaussian noise and/or outliers. While traditional ELM minimizes modeling error by using a worst-case scenario principle, the proposed method constructs a new objective function to minimize both mean and variance of this modeling error. Thus, the proposed method considers the modeling error distribution. A solution method is then developed for this new objective function and the proposed method is further proved to be more robust when compared with traditional ELM, even when subject to noise or outliers. Several experimental cases demonstrate that the proposed method has better modeling performance for problems with non-Gaussian noise or outliers. © 2013 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/TCYB.2017.2738060
VL  - 48
IS  - 8
SP  - 2368
EP  - 2377
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028460503&doi=10.1109%2fTCYB.2017.2738060&partnerID=40&md5=da75ada09d12548091c3b6caab1ad5a6
DB  - Scopus
KW  - machine learning
KW  - Models
KW  - robustness
KW  - Learning systems
KW  - modeling
KW  - article
KW  - Robustness (control systems)
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - Statistics
KW  - Errors
KW  - Integrated circuit modeling
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Reactive power
KW  - noise
KW  - outlier
KW  - Probabilistic logics
KW  - Extreme learning machine (ELM)
KW  - Linear programming
KW  - Computational model
ER  - 

TY  - CONF
TI  - Algorithmic discrimination and responsibility: Selected examples from the United States of America and South America
AU  - Kapatamoyo, M.
AU  - Ramos-Gil, Y.T.
AU  - Márquez Dominiguez, C.
T2  - Communications in Computer and Information Science
AB  - This paper discusses examples and activities that promote consumer protection through adapting of non-discriminatory algorithms. The casual observer of data from smartphones to artificial intelligence believes in technological determinism. To them, data reveal real trends with neutral decision-makers that are not prejudiced. However, machine learning technologies are created by people. Therefore, creator biases can appear in decisions based on algorithms used for surveillance, social profiling, surveillance, and business intelligence. This paper adapts Lawrence Lessig’s framework (laws, markets, codes, and social norms). It highlights cases in the USA and South America where algorithms discriminated and how statutes tried to mitigate the negative consequences. Global companies such as Facebook and Amazon are among those discussed in the case studies. In the case of Ecuador, the algorithms and the lack of protection of personal data for citizens are not regulated or protected in the treatment of information that arises in social networks used by public and private institutions. Consequently, individual rights are not strictly shielded by national and international laws and or through regulations of telecommunications and digital networks. In the USA, a proposed bill, the “Algorithmic Accountability Act” would require large companies to audit their machine-learning powered automated systems such as facial recognition or ad targeting algorithm for bias. The Federal Trade Commission (FTC) will create rules for evaluating automated systems, while companies would evaluate the algorithms powering these tools for bias or discrimination, including threats to consumer privacy or security. © Springer Nature Switzerland AG 2019.
DA  - 2019///
PY  - 2019
DO  - 10.1007/978-3-030-32475-9_11
VL  - 1051 CCIS
SP  - 147
EP  - 157
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076289314&doi=10.1007%2f978-3-030-32475-9_11&partnerID=40&md5=dd23a9ae78859a862280d3c0ec1746aa
DB  - Scopus
KW  - Machine learning
KW  - Automation
KW  - Decision making
KW  - Privacy
KW  - Learning systems
KW  - Commerce
KW  - Face recognition
KW  - Data privacy
KW  - Machine learning technology
KW  - Algorithmic discrimination
KW  - Algorithmic responsibility
KW  - Consumer protection
KW  - Dirty data
KW  - Federal Trade commissions
KW  - Private institutions
KW  - Technological determinism
KW  - United States of America
ER  - 

TY  - CHAP
TI  - Robust fusion of unreliable data sources using error-correcting output codes
AU  - Vempaty, A.
AU  - Kailkhura, B.
AU  - Varshney, P.K.
T2  - Data Fusion in Wireless Sensor Networks
AB  - The emergence of big and dirty data era demands new distributed learning and inference solutions to tackle the problem of inference with corrupted data. The central goal of this chapter is to discuss the presence of corrupted data in the context of distributed inference networks (DINs) and discuss coding-theoretic strategies to ensure reliable inference performance in several practical scenarios. It discusses a generalization of the classical Byzantine Generals problem in the context of distributed inference to different topologies. Over the last three decades, research community has extensively studied the impact of imperfect transmission channels or sensor faults on distributed inference systems. However, corrupted (Byzantine) data models, considered in this chapter, are philosophically different from the imperfect channels or faulty sensor cases. Byzantines are intentional and intelligent and therefore can optimize over the data corruption parameters. While learning their behavior and actively countering them is a viable approach, this chapter presents a new paradigm of mitigation strategies that use coding-theoretic results. The general approach of error-correcting output codes (ECOC) for data fusion is presented and its applicability for several inference problems in practice dealing with unreliable data including Byzantines is shown. This approach is then shown to be applicable to a wider range of inference problems such as classification using crowdsourced data. © The Institution of Engineering and Technology 2019.
DA  - 2019///
PY  - 2019
SP  - 291
EP  - 311
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117998598&doi=10.1049%2fPBCE117E_ch12&partnerID=40&md5=c7334508b4b3a8a50b7d4bf13b57694b
DB  - Scopus
KW  - Sensor fusion
KW  - Learning (artificial intelligence)
KW  - Data fusion
KW  - Radio links and equipment
KW  - Chapter
KW  - Classical byzantine generals problem
KW  - Codes
KW  - Coding-theoretic results
KW  - Coding-theoretic strategies
KW  - Corrupted data models
KW  - Crowdsourced data
KW  - Data corruption parameters
KW  - Data handling techniques
KW  - Dirty data era demands new distributed learning
KW  - Distributed inference networks
KW  - Distributed inference systems
KW  - Error correction codes
KW  - Error-correcting output codes
KW  - Fault tolerant computing
KW  - General approach
KW  - Imperfect channels
KW  - Imperfect transmission channels
KW  - Inference mechanisms
KW  - Inference problems
KW  - Inference solutions
KW  - Knowledge engineering techniques
KW  - Other topics in statistics
KW  - Pattern classification
KW  - Reliable inference performance
KW  - Robust fusion
KW  - Unreliable data sources
ER  - 

TY  - JOUR
TI  - Frequency Safety Assessment of Power System Based on Multi-layer Extreme Learning Machine
AU  - Wen, Y.
AU  - Zhao, R.
AU  - Xiao, Y.
AU  - Liu, Z.
T2  - Dianli Xitong Zidonghua/Automation of Electric Power Systems
AB  - The random, intermittent and weak inertia characteristics of renewable energy generation have led to a prominent problem in the frequency safety of high-rate renewable energy power systems. The use of time-domain simulation for frequency safety assessment has the disadvantages of large amount of calculation and long time. It is difficult to meet the rapid assessment requirement of frequency safety under the "combined explosion" of multiple complex uncertainties. In order to realize online analysis and prediction of frequency safety, a method based on multi-layer extreme learning machine (ML-ELM) is applied. The non-linear mapping relationship between the input layer and the hidden layer is built by the deep structure theory and in the layer-wise unsupervised training, automatic encoder algorithms and regularization coefficients are introduced to optimize the weight matrix between the input layer and the hidden layer, so that the ML-ELM can effectively represent complex functions and improve predictive accuracy and generalization ability. Case studies of the IEEE RTS-79 system demonstrate the rapidity, high accuracy and well generalization ability of the proposed method. © 2019 Automation of Electric Power Systems Press.
DA  - 2019///
PY  - 2019
DO  - 10.7500/AEPS20180629012
VL  - 43
IS  - 1
SP  - 133
EP  - 140
ST  - 基于多层极限学习机的电力系统频率安全评估方法
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062847534&doi=10.7500%2fAEPS20180629012&partnerID=40&md5=40580bc6e7ba8332d84b773e32e9f76f
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Big data
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - Renewable energy resources
KW  - Explosions
KW  - Extreme learning machine (ELM)
KW  - Artificial intelligence (AI)
KW  - Generalization ability
KW  - Frequency safety
KW  - Low inertia system
KW  - Prediction of frequency
KW  - Regularization coefficients
KW  - Renewable energy generation
KW  - Renewable energy power
KW  - Time domain analysis
KW  - Time-domain simulations
ER  - 

TY  - CONF
TI  - Machine learning - Based detection of water contamination in water distribution systems
AU  - Mohammed, H.
AU  - Hameed, I.A.
AU  - Seidu, R.
T2  - GECCO 2018 Companion - Proceedings of the 2018 Genetic and Evolutionary Computation Conference Companion
AB  - Accurate detection of natural or intentional contamination events in water distribution pipes is critical to drinking water safety. Efficient early warning systems that can detect contamination events require detection algorithms that can accurately predict the occurrence of such events. This paper presents the development of adaptive neuro-fuzzy inference system (ANFIS) models for detecting the safety condition of water in pipe networks when concentrations of water quality variables in the pipes exceed their maximum thresholds. The event detection is based on time series data composed of pH, turbidity, color and bacteria count measured at the effluent of a drinking water utility and nine different locations of sensors in the distribution network in the city of Ålesund, Norway. The proposed ANFIS models correctly detected between 92% and 96% of the safety condition of the water in the pipe network, with approximately 1% false alarm rate during the testing stage. The models also achieved high rates of specificity and precision, with very high correlations between the predictions and actual conditions of the water in the pipes. The accuracy of the models achieved in this study suggests that the models can be useful in real time contamination event detection in the pipe networks.
DA  - 2018///
PY  - 2018
SP  - 1664
EP  - 1671
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051482676&partnerID=40&md5=61fcbf53e7d70a9622fc8b27db85a67c
DB  - Scopus
KW  - Fuzzy neural networks
KW  - Learning systems
KW  - Learning algorithms
KW  - Evolutionary algorithms
KW  - Safety testing
KW  - Electric power distribution
KW  - Water quality
KW  - Early Warning System
KW  - Potable water
KW  - Water distribution systems
KW  - Water safety
KW  - Fuzzy inference
KW  - Fuzzy systems
KW  - Contamination
KW  - Water pollution
KW  - Adaptive neuro fuzzy inference systems (ANFIS)
KW  - Contaminant detection
KW  - Contamination events
KW  - Distribution network
KW  - Effluents
KW  - Intentional contaminations
KW  - Machine-learning algorithms
KW  - Pollution detection
KW  - Water distribution pipes
KW  - Water quality variables
ER  - 

TY  - JOUR
TI  - Comparison of differences in resolution and sources of controlling factors for gully erosion susceptibility mapping
AU  - Garosi, Y.
AU  - Sheklabadi, M.
AU  - Pourghasemi, H.R.
AU  - Besalatpour, A.A.
AU  - Conoscenti, C.
AU  - Van Oost, K.
T2  - Geoderma
AB  - Gully erosion has been identified as an important soil degradation process and sediment source, especially in arid and semiarid areas. Thus, it is useful to identify the spatial occurrence of this form of water erosion in the landscape and the most vulnerable areas. In this study, we explored the effects of different pixel sizes on some controlling factors extracted from a digital elevation model and remote sensing data when producing a gully erosion susceptibility map (GESM) of Ekbatan Dam Basin, Hamadan, Iran. An inventory map of the gully landforms was prepared based on global positioning system routes of the gullies, extensive field surveys, and visual interpretations of satellite images obtained from Google Earth. Five data sets with pixel sizes ranging from 2 to 30 m were obtained using topographic attributes and remote sensing data comprising the elevation, slope degree, slope aspect, catchment area, plan curvature, profile curvature, stream power index, topographic position index, topographic wetness index, land use, and normalized difference vegetation index, which can affect the distribution of gully erosion. For each data set, 70% and 30% of the data were selected randomly for calibrating and validating the models, respectively. The statistical relationships between the occurrence of gully erosion and controlling factors were calculated using four machine-learning models, i.e., generalized linear model, boosted regression tree (BRT), multivariate adaptive regression spline, and artificial neural network (ANN). Statistical tests comprising the kappa coefficient and the area under the receiver operating characteristic curve (AUC) were calculated for both the calibration and validation data sets to estimate the optimal pixel size. The results showed that among the data sets with different pixel sizes, the optimal pixel size was 10 m for each model. In addition, the capacity of the four techniques for modeling gully erosion occurrence was quite stable when the calibration and validation samples were changed in the data set. Finally, based on three changes of the calibration and validation data sets with a pixel size of 10 m, the BRT and ANN models obtained outstanding performance (AUC > 0.9), where they had the highest goodness-of-fit and predictive power, and thus the greatest robustness to changes in the calibration/validation data (i.e., lowest sensitivity to altering calibration/validation data). Our results demonstrate the importance of selecting a suitable pixel size when producing a GESM for soil and water management practices. © 2018 Elsevier B.V.
DA  - 2018///
PY  - 2018
DO  - 10.1016/j.geoderma.2018.05.027
VL  - 330
SP  - 65
EP  - 78
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048458001&doi=10.1016%2fj.geoderma.2018.05.027&partnerID=40&md5=c0e3a8d3f4285ee0b32187c4d5b6e51c
DB  - Scopus
KW  - Neural networks
KW  - Learning systems
KW  - Water management
KW  - Learning algorithms
KW  - Machine learning models
KW  - Adaptive control systems
KW  - Robustness (control systems)
KW  - Robustness
KW  - Landforms
KW  - Remote sensing
KW  - Land use
KW  - Pixels
KW  - Catchments
KW  - Calibration
KW  - Machine learning model
KW  - Receiver operating characteristic curves
KW  - Multivariate adaptive regression splines
KW  - Calibration and validations
KW  - Erosion
KW  - Geomorphology
KW  - Gully erosion
KW  - Normalized difference vegetation index
KW  - Remote sensing data
KW  - Topographic attribute
ER  - 

TY  - JOUR
TI  - An Overview of Robust Subspace Recovery
AU  - Lerman, G.
AU  - Maunu, T.
T2  - Proceedings of the IEEE
AB  - This paper will serve as an introduction to the body of work on robust subspace recovery. Robust subspace recovery involves finding an underlying low-dimensional subspace in a data set that is possibly corrupted with outliers. While this problem is easy to state, it has been difficult to develop optimal algorithms due to its underlying nonconvexity. This work emphasizes advantages and disadvantages of proposed approaches and unsolved problems in the area. © 1963-2012 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/JPROC.2018.2853141
VL  - 106
IS  - 8
SP  - 1380
EP  - 1410
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051231696&doi=10.1109%2fJPROC.2018.2853141&partnerID=40&md5=272d155f65e2d2062bf714b42b0927c9
DB  - Scopus
KW  - Recovery
KW  - Robustness (control systems)
KW  - Big data
KW  - Robustness
KW  - Unsupervised learning
KW  - Electrical engineering
KW  - Nonconvex optimization
KW  - Dimension reduction
KW  - Low-dimensional subspace
KW  - Nonconvexity
KW  - Optimal algorithm
KW  - Recovery guarantees
KW  - Subspace modeling
KW  - Subspace recoveries
KW  - Unsolved problems
ER  - 

TY  - CHAP
TI  - Photometric Invariance by Machine Learning
AU  - Álvarez, J.M.
AU  - López, A.M.
T2  - Color in Computer Vision: Fundamentals and Applications
AB  - As shown in the previous chapters, the choice of a color model is of great importance for many computer vision algorithms, as the chosen color model induces the equivalence classes to the actual algorithms. As there are many color models available, the inherent difficulty is how to automatically select a single color model or, alternatively, a weighted subset of color models producing the best result for a particular task. The subsequent hurdle is how to obtain a proper fusion scheme for the algorithms so that the results are combined in a proper setting. In the previous chapters, physical reflection models (e.g., Lambertian or dichromatic reflectance) are used to derive color invariant models. However, this approach may be too restricted to model real-world scenes in which different reflectance mechanisms can hold simultaneously. Instead of modeling the world by a single reflection model, we now focus on how color invariance can be obtained by machine learning. The learning process is based on the selection of positive examples (e.g., colored image patches of a certain object to be recognized) to obtain color invariant ensembles. Of course, the training examples should include a broad range of pixel values capturing all possible imaging conditions under which the object can be captured. Using these training samples, the aim is to arrive at color ensembles that yield a proper balance between invariance (repeatability) and discriminative power (distinctiveness). In this chapter, a learning approach that minimizes the estimation error is presented. The method is also suited to deal with sequential data. A weighting scheme is used to incorporate the dynamics of observations over time. The ensemble is periodically updated considering the new data and its temporal order. The chapter is organized as follows. First, the learning-based fusion scheme is discussed. Then, the evolution of data over time is included. Finally, the approach is applied to two applications: facial skin detection and road detection (RD). More information can be found in Reference 71. © 2012 John Wiley & Sons, Inc.
DA  - 2012///
PY  - 2012
SP  - 113
EP  - 134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886336926&doi=10.1002%2f9781118350089.ch7&partnerID=40&md5=f62af206b2a9e283c14ff12131cca10f
DB  - Scopus
KW  - Combining color models, robust to data uncertainty with color invariants
KW  - Learning approach in error estimation minimization, also for sequential data
KW  - Machine learning in facial skin detection, and RD using wilcoxon test
KW  - Photometric invariance by machine learning, deriving color invariance
KW  - Temporal ensemble and weighting process, EWMA and GARCH
ER  - 

TY  - JOUR
TI  - Robustness of semi-supervised learning algorithm LLGC trained using soft labels for misclassified data
AU  - Liu, X.
AU  - Hao, Z.
AU  - Yang, X.
AU  - Deng, X.
T2  - Journal of Information and Computational Science
AB  - The labeling process is prone to errors, human or otherwise. In this paper we consider the semi-supervised classification problem with misclassified data which constantly turns up in real-life applications. In order to enhance the ability of resisting label noise, soft labels are introduced to semi-supervised classifier local and global consistency (LLGC). We compare between the robustness of classifier LLGC trained using several soft labels opposed to LLGC trained with crisp labels against errors in the labels. Experimental results on several UCI datasets show that LLGC algorithm with GNPC soft approach is more resistant to noise even with few labeled data in training set. LLGC algorithm with KNN soft approach can exert its advantage only when the number of the labeled data in training set is not too small. © 2010 Binary Information Press.
DA  - 2010///
PY  - 2010
VL  - 7
IS  - 9
SP  - 1827
EP  - 1837
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952463727&partnerID=40&md5=41079e4d15a3b9b7c0257ff98eb51bc8
DB  - Scopus
KW  - Supervised learning
KW  - Learning algorithms
KW  - Semi-supervised learning
KW  - Errors
KW  - LLGC
KW  - Misclassified data
KW  - Noise label
KW  - Soft labels
ER  - 

TY  - CONF
TI  - Automatic document metadata extraction using support vector machines
AU  - Han, H.
AU  - Giles, C.L.
AU  - Manavoglu, E.
AU  - Zha, H.
AU  - Zhang, Z.
AU  - Fox, E.A.
T2  - Proceedings of the ACM/IEEE Joint Conference on Digital Libraries
AB  - Automatic metadata generation provides scalability and usability for digital libraries and their collections. Machine learning methods offer robust and adaptable automatic metadata extraction. We describe a support vector machine classification-based method for metadata extraction from header part of research papers and show that it outperforms other machine learning methods on the same task. The method first classifies each line of the header into one or more of 15 classes. An iterative convergence procedure is then used to improve the line classification by using the predicted class labels of its neighbor lines in the previous round. Further metadata extraction is done by seeking the best chunk boundaries of each line. We found that discovery and use of the structural patterns of the data and domain based word clustering can improve the metadata extraction performance. An appropriate feature normalization also greatly improves the classification performance. Our metadata extraction method was originally designed to improve the metadata extraction quality of the digital libraries Citeseer [S. Lawrence et al., (1999)] and EbizSearch [Y. Petinot et al., (2003)]. We believe it can be generalized to other digital libraries. © 2003 IEEE.
DA  - 2003///
PY  - 2003
DO  - 10.1109/JCDL.2003.1204842
VL  - 2003-January
SP  - 37
EP  - 48
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941274546&doi=10.1109%2fJCDL.2003.1204842&partnerID=40&md5=49ba08a1b899d72626d60cd588907485
DB  - Scopus
KW  - Artificial intelligence
KW  - Data mining
KW  - Support vector machines
KW  - Learning systems
KW  - Extraction
KW  - Robustness (control systems)
KW  - Robustness
KW  - Vectors
KW  - Iterative methods
KW  - Semantic Web
KW  - Scalability
KW  - Metadata
KW  - Convergence
KW  - Support vector machine classification
KW  - Digital libraries
KW  - Design methodology
KW  - Design Methodology
KW  - Software libraries
KW  - Usability
ER  - 

TY  - JOUR
TI  - Robust supervised classification with mixture models: Learning from data with uncertain labels
AU  - Bouveyron, C.
AU  - Girard, S.
T2  - Pattern Recognition
AB  - In the supervised classification framework, human supervision is required for labeling a set of learning data which are then used for building the classifier. However, in many applications, human supervision is either imprecise, difficult or expensive. In this paper, the problem of learning a supervised multi-class classifier from data with uncertain labels is considered and a model-based classification method is proposed to solve it. The idea of the proposed method is to confront an unsupervised modeling of the data with the supervised information carried by the labels of the learning data in order to detect inconsistencies. The method is able afterward to build a robust classifier taking into account the detected inconsistencies into the labels. Experiments on artificial and real data are provided to highlight the main features of the proposed method as well as an application to object recognition under weak supervision. © 2009 Elsevier Ltd. All rights reserved.
DA  - 2009///
PY  - 2009
DO  - 10.1016/j.patcog.2009.03.027
VL  - 42
IS  - 11
SP  - 2649
EP  - 2658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649389414&doi=10.1016%2fj.patcog.2009.03.027&partnerID=40&md5=32d729d76c33d6f8ee081360fb958e28
DB  - Scopus
KW  - Learning systems
KW  - Robustness
KW  - Education
KW  - Object recognition
KW  - Label noise
KW  - Mixtures
KW  - Mixture models
KW  - Supervised classification
KW  - Classifiers
KW  - Data with uncertain labels
KW  - Labels
KW  - Weakly supervised classification
ER  - 

TY  - CONF
TI  - COPLINK center: Social network analysis and identity deception detection for law enforcement and homeland security intelligence and security informatics: A crime data mining approach to developing border safe research
AU  - Chen, H.
AU  - Atabakhsh, H.
AU  - Wang, A.G.
AU  - Kaza, S.
AU  - Tseng, L.C.
AU  - Wang, Y.
AU  - Joshi, S.
AU  - Petersen, T.
AU  - Violette, C.
T2  - ACM International Conference Proceeding Series
AB  - In this paper, we describe the highlights of the COPLINK Center for law enforcement and homeland security project. Two new components of the project are described, namely, identity resolution and mutual information.
DA  - 2006///
PY  - 2006
DO  - 10.1145/1146598.1146618
VL  - 151
SP  - 49
EP  - 50
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250698940&doi=10.1145%2f1146598.1146618&partnerID=40&md5=21042bfc8b147258faf19266a80ab294
DB  - Scopus
KW  - Data mining
KW  - Bayesian networks
KW  - Security of data
KW  - Semi-supervised learning
KW  - Law enforcement
KW  - Border safety
KW  - Homeland security
KW  - Homeland security intelligence
KW  - Identity matching
KW  - Identity resolution
KW  - Intelligence and security informatics
KW  - Mutual information
KW  - Naïve bayes model
KW  - Social aspects
ER  - 

TY  - JOUR
TI  - Data-based robust adaptive control for a class of unknown nonlinear constrained-input systems via integral reinforcement learning
AU  - Yang, X.
AU  - Liu, D.
AU  - Luo, B.
AU  - Li, C.
T2  - Information Sciences
AB  - This paper presents a data-based robust adaptive control methodology for a class of nonlinear constrained-input systems with completely unknown dynamics. By introducing a value function for the nominal system, the robust control problem is transformed into a constrained optimal control problem. Due to the unavailability of system dynamics, a data-based integral reinforcement learning (RL) algorithm is developed to solve the constrained optimal control problem. Based on the present algorithm, the value function and the control policy can be updated simultaneously using only system data. The convergence of the developed algorithm is proved via an established equivalence relationship. To implement the integral RL algorithm, an actor neural network (NN) and a critic NN are separately utilized to approximate the control policy and the value function, and the least squares method is employed to estimate the unknown parameters. By using Lyapunov's direct method, the obtained approximate optimal control is verified to guarantee the unknown nonlinear system to be stable in the sense of uniform ultimate boundedness. Two examples are provided to demonstrate the effectiveness and applicability of the theoretical results. © 2016 Elsevier Inc.
DA  - 2016///
PY  - 2016
DO  - 10.1016/j.ins.2016.07.051
VL  - 369
SP  - 731
EP  - 747
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994409135&doi=10.1016%2fj.ins.2016.07.051&partnerID=40&md5=2b3599a1ed6641330ec90068ebc07eb2
DB  - Scopus
KW  - Reinforcement learning
KW  - Neural networks
KW  - Adaptive control systems
KW  - Least squares approximations
KW  - Robust control
KW  - Adaptive dynamic programming
KW  - Dynamic programming
KW  - Optimal control
KW  - Optimal control systems
KW  - Optimal controls
KW  - Constrained optimal control problems
KW  - Input constraints
KW  - Unknown nonlinear systems
KW  - Constrained input systems
KW  - Uniform ultimate boundedness
KW  - Equivalence relationship
KW  - Input constraint
ER  - 

TY  - JOUR
TI  - Predicting reduced driver alertness on monotonous highways
AU  - Larue, G.S.
AU  - Rakotonirainy, A.
AU  - Pettitt, A.N.
T2  - IEEE Pervasive Computing
AB  - Impaired driver alertness increases the likelihood of a driver making mistakes and reacting too late to unexpected events. This is a particular concern on monotonous roads, where a drivers attention can decrease rapidly. Although effective countermeasures dont currently exist, the development of in-vehicle sensors opens avenues for monitoring driving behavior in real time. The aim of this study is to predict driver alertness levels using surrogate measures collected from in-vehicle sensors. Electroencephalographic activity is used as a reference to evaluate alertness. Based on a sample of 25 drivers, the authors collected data in a driving simulator instrumented with an eye-tracking system, a heart-rate monitor, and an electrodermal activity device. They tested various classification models, from linear regressions to Bayesians and data mining techniques. Results indicate that neural networks were the most efficient model for detecting lapses in alertness. Findings also show that reduced alertness can be predicted up to five minutes in advance with 90 percent accuracy using surrogate measures such as time to line crossing, blink frequency, and skin conductance level. Such a method could be used to warn drivers of their alertness levels through the development of an in-vehicle device that monitors, in real time, driver behavior on highways. © 2015 IEEE.
DA  - 2015///
PY  - 2015
DO  - 10.1109/MPRV.2015.38
VL  - 14
IS  - 2
SP  - 78
EP  - 85
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928722668&doi=10.1109%2fMPRV.2015.38&partnerID=40&md5=0df515332e5ed2e7c7af6330a69fc35e
DB  - Scopus
KW  - Artificial intelligence
KW  - Data mining
KW  - Intelligent systems
KW  - Vehicles
KW  - intelligent systems
KW  - Learning systems
KW  - Behavioral research
KW  - Accident prevention
KW  - safety
KW  - Classification models
KW  - Transportation
KW  - Electrodermal activity
KW  - Data reduction
KW  - Machine learning techniques
KW  - data analysis
KW  - machine learning techniques
KW  - Ubiquitous computing
KW  - bid data
KW  - driver alertness modeling
KW  - Eye tracking systems
KW  - Heart-rate monitors
KW  - Patient monitoring
KW  - pervasive computing
KW  - time predictions
KW  - Time predictions
KW  - Time-to-line crossing
ER  - 

TY  - JOUR
TI  - Empirical prediction of leaf area index (LAI) of endangered tree species in intact and fragmented indigenous forests ecosystems using WorldView-2 data and two robust machine learning algorithms
AU  - Omer, G.
AU  - Mutanga, O.
AU  - Abdel-Rahman, E.M.
AU  - Adam, E.
T2  - Remote Sensing
AB  - Leaf area index (LAI) is an important biophysical trait for forest ecosystem and ecological modeling, as it plays a key role for the forest productivity and structural characteristics. The groundbased methods like the handheld optical instruments for predicting LAI are subjective, pricy and time-consuming. The advent of very high spatial resolutions multispectral data and robust machine learning regression algorithms like support vector machines (SVM) and artificial neural networks (ANN) has provided an opportunity to estimate LAI at tree species level. The objective of the this study was therefore to test the utility of spectral vegetation indices (SVI) calculated from the multispectral WorldView-2 (WV-2) data in predicting LAI at tree species level using the SVM and ANN machine learning regression algorithms. We further tested whether there are significant differences between LAI of intact and fragmented (open) indigenous forest ecosystems at tree species level. The study shows that LAI at tree species level could accurately be estimated using the fragmented stratum data compared with the intact stratum data. Specifically, our study shows that the accurate LAI predictions were achieved for Hymenocardia ulmoides using the fragmented stratum data and SVM regression model based on a validation dataset (R2                             Val = 0.75, RMSEVal = 0.05 (1.37% of the mean)). Our study further showed that SVM regression approach achieved more accurate models for predicting the LAI of the six endangered tree species compared with ANN regression method. It is concluded that the successful application of the WV-2 data, SVM and ANN methods in predicting LAI of six endangered tree species in the Dukuduku indigenous forest could help in making informed decisions and policies regarding management, protection and conservation of these endangered tree species. © 2016 by the authors.
DA  - 2016///
PY  - 2016
DO  - 10.3390/rs8040324
VL  - 8
IS  - 4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971618277&doi=10.3390%2frs8040324&partnerID=40&md5=cefa680224377576304369c01de49714
DB  - Scopus
KW  - Artificial neural networks
KW  - Neural networks
KW  - Support vector machines
KW  - Learning algorithms
KW  - Forecasting
KW  - Regression analysis
KW  - Forestry
KW  - Ecosystems
KW  - Spectral vegetation indices
KW  - Regression algorithms
KW  - Conservation
KW  - Endangered tree species
KW  - Indigenous forest
KW  - Leaf area index
KW  - Leaf Area Index
KW  - Plants (botany)
KW  - Structural characteristics
KW  - Tree species
KW  - Very high spatial resolutions
KW  - Worldview-2
KW  - WorldView-2
ER  - 

TY  - JOUR
TI  - Adversarial concept drift detection under poisoning attacks for robust data stream mining
AU  - Korycki, Ł.
AU  - Krawczyk, B.
T2  - Machine Learning
AB  - Continuous learning from streaming data is among the most challenging topics in the contemporary machine learning. In this domain, learning algorithms must not only be able to handle massive volume of rapidly arriving data, but also adapt themselves to potential emerging changes. The phenomenon of evolving nature of data streams is known as concept drift. While there is a plethora of methods designed for detecting its occurrence, all of them assume that the drift is connected with underlying changes in the source of data. However, one must consider the possibility of a malicious injection of false data that simulates a concept drift. This adversarial setting assumes a poisoning attack that may be conducted in order to damage the underlying classification system by forcing an adaptation to false data. Existing drift detectors are not capable of differentiating between real and adversarial concept drift. In this paper, we propose a framework for robust concept drift detection in the presence of adversarial and poisoning attacks. We introduce the taxonomy for two types of adversarial concept drifts, as well as a robust trainable drift detector. It is based on the augmented restricted Boltzmann machine with improved gradient computation and energy function. We also introduce Relative Loss of Robustness—a novel measure for evaluating the performance of concept drift detectors under poisoning attacks. Extensive computational experiments, conducted on both fully and sparsely labeled data streams, prove the high robustness and efficacy of the proposed drift detection framework in adversarial scenarios. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s10994-022-06177-w
VL  - 112
IS  - 10
SP  - 4013
EP  - 4048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131681406&doi=10.1007%2fs10994-022-06177-w&partnerID=40&md5=781bffd9711404b5b706feb53abf56f6
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Learning algorithms
KW  - Concept drift
KW  - Concept drifts
KW  - Data streams
KW  - Robust datum
KW  - Robust machine learning
KW  - Adversarial learning
KW  - Poisoning attacks
KW  - Boltzmann machine
KW  - Boltzmann machines
KW  - Data stream
KW  - Data stream mining
KW  - Data streams mining
KW  - Drift detectors
KW  - False data
ER  - 

TY  - JOUR
TI  - Reinforcement Learning for Adaptive Optimal Stationary Control of Linear Stochastic Systems
AU  - Pang, B.
AU  - Jiang, Z.-P.
T2  - IEEE Transactions on Automatic Control
AB  - This article studies the adaptive optimal stationary control of continuous-time linear stochastic systems with both additive and multiplicative noises, using reinforcement learning techniques. Based on policy iteration, a novel off-policy reinforcement learning algorithm, named optimistic least-squares-based policy iteration, is proposed, which is able to find iteratively near-optimal policies of the adaptive optimal stationary control problem directly from input/state data without explicitly identifying any system matrices, starting from an initial admissible control policy. The solutions given by the proposed optimistic least-squares-based policy iteration are proved to converge to a small neighborhood of the optimal solution with probability one, under mild conditions. The application of the proposed algorithm to a triple inverted pendulum example validates its feasibility and effectiveness.  © 1963-2012 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TAC.2022.3172250
VL  - 68
IS  - 4
SP  - 2383
EP  - 2390
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129687719&doi=10.1109%2fTAC.2022.3172250&partnerID=40&md5=d7b0ec9fc7eaad454eb2e079e1173349
DB  - Scopus
KW  - Reinforcement learning
KW  - Process control
KW  - reinforcement learning
KW  - robustness
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Adaptive control systems
KW  - Optimization
KW  - Stochastic systems
KW  - Iterative methods
KW  - Heuristic algorithms
KW  - Optimal controls
KW  - Heuristics algorithm
KW  - Random processes
KW  - Continuous time systems
KW  - Adaptive optimal control
KW  - Policy iteration
KW  - Performances analysis
KW  - Stochastic control systems
KW  - data-driven control
KW  - Inverted pendulum
KW  - stochastic control
KW  - Continous time
KW  - Least Square
KW  - Linear stochastic system
KW  - Optimistics
KW  - policy iteration
KW  - Stationary controls
ER  - 

TY  - JOUR
TI  - Distribution Network Power Flow Optimization Method Based on Robust Reinforcement Learning
AU  - Li, X.
AU  - Tian, M.
AU  - Zhu, Z.
AU  - Dong, Z.
AU  - Gong, L.
AU  - Wang, X.
T2  - Gaodianya Jishu/High Voltage Engineering
AB  - Traditional deep reinforcement learning is prone to interference such as sensor observation errors when optimizing distribution network power flow, and its robustness is poor. Therefore, a distribution network power flow optimization method based on robust reinforcement learning is proposed. Firstly, a distribution network power flow optimization model including distributed generation, energy storage, and load cells is established with the goal of minimizing distribution network power losses and the security constraints of voltage and power flow exceeding limits. Then, the interference is modeled as an attack agent, which perturbs the observed state of the main agent for distribution network power flow optimization, thus a robust reinforcement learning model for a dual agent zero sum game is constructed. Finally, a dual agent Lagrange multiplier trust region strategy optimization algorithm is proposed, in which the main agent and the attacking agent of distribution network power flow optimization can train synchronously, learn asynchronously, and play games against each other. The simulation results show that the distribution network power flow optimization agent trained by this method can make security decisions under different types of interference, improving the robustness and security of distribution network power flow optimization. © 2023 Science Press. All rights reserved.
DA  - 2023///
PY  - 2023
DO  - 10.13336/j.1003-6520.hve.20230511
VL  - 49
IS  - 6
SP  - 2329
EP  - 2338
ST  - 基于鲁棒强化学习的配网潮流优化方法
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164280499&doi=10.13336%2fj.1003-6520.hve.20230511&partnerID=40&md5=c7a8de0a0d964561f5e03408c2c42c29
DB  - Scopus
KW  - Deep learning
KW  - Game theory
KW  - Reinforcement learning
KW  - Reinforcement learnings
KW  - Network security
KW  - Optimization
KW  - Lagrange multipliers
KW  - robust reinforcement learning
KW  - Electric load flow
KW  - Robust reinforcement learning
KW  - Power quality
KW  - Zero-sum game
KW  - Optimization method
KW  - zero-sum game
KW  - distribution network power flow optimization
KW  - Distribution network power flow optimization
KW  - Network power
KW  - Power flow optimizations
KW  - Power flows
KW  - Security decision
KW  - security decisions
KW  - state disturbance
KW  - State disturbance
ER  - 

TY  - JOUR
TI  - Enhanced robust capacity estimation of lithium-ion batteries with unlabeled dataset and semi-supervised machine learning
AU  - Ye, M.
AU  - Wang, Q.
AU  - Yan, L.
AU  - Wei, M.
AU  - Lian, G.
AU  - Zhao, K.
AU  - Zhu, W.
T2  - Expert Systems with Applications
AB  - The capacity estimation is a crucial task in battery health and safety management. The majority existing capacity estimation methods heavily rely on supervised learning with accurately labelled dataset collected at room temperature. However, the unlabeled dataset and the influence of ambient temperature on lithium-ion batteries degradation are rarely considered in the existing works. To address these issues, semi-supervised machine learning based noise-immune capacity estimation approach is proposed by utilizing both labelled and unlabeled datasets. By considering both the deployment and the accuracy, the optimal health indicator is extracted based on detailed analysis of limited labelled dataset. Then, the semi-supervised machine learning is proposed to improve the capacity estimation by using abundant unlabeled dataset. Specifically, low-complexity network with different training algorithms are employed to map the nonlinear relationship between the feature and capacity with the total loss of labelled and unlabeled datasets. By further exploiting the unlabeled dataset, the maximum errors of capacity estimation at three different temperatures are improved by 85%, 13%, and 48% with strong robustness, respectively. The proposed approach shows superior performance to the state-of-the-art supervised methods. The encouraged performance indicates the effectiveness of using large unlabeled battery dataset to improve the capacity estimation in real-world applications. © 2023 Elsevier Ltd
DA  - 2024///
PY  - 2024
DO  - 10.1016/j.eswa.2023.121892
VL  - 238
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173284805&doi=10.1016%2fj.eswa.2023.121892&partnerID=40&md5=109254f4d2fb882b0bd0d9370dffcf99
DB  - Scopus
KW  - Learning systems
KW  - Supervised learning
KW  - Performance
KW  - Supervised machine learning
KW  - Battery management systems
KW  - Lithium-ion batteries
KW  - Large dataset
KW  - Semi-supervised
KW  - Ions
KW  - Semi-supervised machine learning
KW  - Battery health
KW  - Battery safety
KW  - Capacity estimation
KW  - Labeled dataset
KW  - Lithium-ion battery
KW  - Robust capacity
KW  - Unlabeled dataset
ER  - 

TY  - CONF
TI  - Ground Truth Or Dare: Factors Affecting The Creation Of Medical Datasets For Training AI
AU  - Zajac, H.D.
AU  - Avlona, N.R.
AU  - Kensing, F.
AU  - Andersen, T.O.
AU  - Shklovski, I.
T2  - AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society
AB  - One of the core goals of responsible AI development is ensuring high-quality training datasets. Many researchers have pointed to the importance of the annotation step in the creation of high-quality data, but less attention has been paid to the work that enables data annotation. We define this work as the design of ground truth schema and explore the challenges involved in the creation of datasets in the medical domain even before any annotations are made. Based on extensive work in three health-tech organisations, we describe five external and internal factors that condition medical dataset creation processes. Three external factors include regulatory constraints, the context of creation and use, and commercial and operational pressures. These factors condition medical data collection and shape the ground truth schema design. Two internal factors include epistemic differences and limits of labelling. These directly shape the design of the ground truth schema. Discussions of what constitutes high-quality data need to pay attention to the factors that shape and constrain what is possible to be created, to ensure responsible AI design.  © 2023 Owner/Author.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3600211.3604766
SP  - 351
EP  - 362
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173607091&doi=10.1145%2f3600211.3604766&partnerID=40&md5=aca75e62f54fa36d00b20c8e23eb3095
DB  - Scopus
KW  - Machine learning
KW  - Ground truth
KW  - Machine-learning
KW  - Condition
KW  - Artificial intelligence learning
KW  - Internal factors
KW  - Data creation
KW  - Data Creation
KW  - External factors
KW  - High quality data
KW  - Medical data sets
KW  - Medical Datasets
KW  - Responsible artificial intelligence and machine learning
KW  - Responsible Artificial Intelligence and Machine Learning
ER  - 

TY  - JOUR
TI  - Robust and data-efficient generalization of self-supervised machine learning for diagnostic imaging
AU  - Azizi, S.
AU  - Culp, L.
AU  - Freyberg, J.
AU  - Mustafa, B.
AU  - Baur, S.
AU  - Kornblith, S.
AU  - Chen, T.
AU  - Tomasev, N.
AU  - Mitrović, J.
AU  - Strachan, P.
AU  - Mahdavi, S.S.
AU  - Wulczyn, E.
AU  - Babenko, B.
AU  - Walker, M.
AU  - Loh, A.
AU  - Chen, P.-H.C.
AU  - Liu, Y.
AU  - Bavishi, P.
AU  - McKinney, S.M.
AU  - Winkens, J.
AU  - Roy, A.G.
AU  - Beaver, Z.
AU  - Ryan, F.
AU  - Krogue, J.
AU  - Etemadi, M.
AU  - Telang, U.
AU  - Liu, Y.
AU  - Peng, L.
AU  - Corrado, G.S.
AU  - Webster, D.R.
AU  - Fleet, D.
AU  - Hinton, G.
AU  - Houlsby, N.
AU  - Karthikesalingam, A.
AU  - Norouzi, M.
AU  - Natarajan, V.
T2  - Nature Biomedical Engineering
AB  - Machine-learning models for medical tasks can match or surpass the performance of clinical experts. However, in settings differing from those of the training dataset, the performance of a model can deteriorate substantially. Here we report a representation-learning strategy for machine-learning models applied to medical-imaging tasks that mitigates such ‘out of distribution’ performance problem and that improves model robustness and training efficiency. The strategy, which we named REMEDIS (for ‘Robust and Efficient Medical Imaging with Self-supervision’), combines large-scale supervised transfer learning on natural images and intermediate contrastive self-supervised learning on medical images and requires minimal task-specific customization. We show the utility of REMEDIS in a range of diagnostic-imaging tasks covering six imaging domains and 15 test datasets, and by simulating three realistic out-of-distribution scenarios. REMEDIS improved in-distribution diagnostic accuracies up to 11.5% with respect to strong supervised baseline models, and in out-of-distribution settings required only 1–33% of the data for retraining to match the performance of supervised models retrained using all available data. REMEDIS may accelerate the development lifecycle of machine-learning models for medical imaging. © 2023, The Author(s), under exclusive licence to Springer Nature Limited.
DA  - 2023///
PY  - 2023
DO  - 10.1038/s41551-023-01049-7
VL  - 7
IS  - 6
SP  - 756
EP  - 779
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161459421&doi=10.1038%2fs41551-023-01049-7&partnerID=40&md5=eb0e89129fff65cdcaf223bdc4ad0426
DB  - Scopus
KW  - machine learning
KW  - Machine Learning
KW  - Learning systems
KW  - Diagnostic imaging
KW  - Supervised learning
KW  - Diagnosis
KW  - Performance
KW  - article
KW  - controlled study
KW  - human
KW  - Machine learning models
KW  - Medical imaging
KW  - Supervised machine learning
KW  - learning
KW  - supervised machine learning
KW  - Supervised Machine Learning
KW  - Life cycle
KW  - Learning strategy
KW  - diagnostic imaging
KW  - transfer of learning
KW  - Training dataset
KW  - Generalisation
KW  - diagnostic accuracy
KW  - Diagnostic Imaging
KW  - feature learning (machine learning)
KW  - Imaging task
KW  - Model training
KW  - Performance problems
ER  - 

TY  - JOUR
TI  - Towards adversarial realism and robust learning for IoT intrusion detection and classification
AU  - Vitorino, J.
AU  - Praça, I.
AU  - Maia, E.
T2  - Annales des Telecommunications/Annals of Telecommunications
AB  - The internet of things (IoT) faces tremendous security challenges. Machine learning models can be used to tackle the growing number of cyber-attack variations targeting IoT systems, but the increasing threat posed by adversarial attacks restates the need for reliable defense strategies. This work describes the types of constraints required for a realistic adversarial cyber-attack example and proposes a methodology for a trustworthy adversarial robustness analysis with a realistic adversarial evasion attack vector. The proposed methodology was used to evaluate three supervised algorithms, random forest (RF), extreme gradient boosting (XGB), and light gradient boosting machine (LGBM), and one unsupervised algorithm, isolation forest (IFOR). Constrained adversarial examples were generated with the adaptative perturbation pattern method (A2PM), and evasion attacks were performed against models created with regular and adversarial training. Even though RF was the least affected in binary classification, XGB consistently achieved the highest accuracy in multi-class classification. The obtained results evidence the inherent susceptibility of tree-based algorithms and ensembles to adversarial evasion attacks and demonstrate the benefits of adversarial training and a security-by-design approach for a more robust IoT network intrusion detection and cyber-attack classification. © 2023, The Author(s).
DA  - 2023///
PY  - 2023
DO  - 10.1007/s12243-023-00953-y
VL  - 78
IS  - 7-8
SP  - 401
EP  - 412
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149924562&doi=10.1007%2fs12243-023-00953-y&partnerID=40&md5=c79de6bb1617bce80b9a4ddb43b7a9a8
DB  - Scopus
KW  - Machine learning
KW  - Intrusion detection
KW  - Internet of things
KW  - Machine-learning
KW  - Classification (of information)
KW  - Gradient boosting
KW  - Network security
KW  - Crime
KW  - Computer crime
KW  - Random forests
KW  - Adversarial attack
KW  - Perturbation techniques
KW  - Cybersecurity
KW  - Adversarial attacks
KW  - Robust learning
KW  - Forestry
KW  - Cyber-attacks
KW  - Intrusion-Detection
KW  - Adversarial robustness
KW  - Security challenges
KW  - Tabular data
ER  - 

TY  - JOUR
TI  - Improving fairness generalization through a sample-robust optimization method
AU  - Ferry, J.
AU  - Aïvodji, U.
AU  - Gambs, S.
AU  - Huguet, M.-J.
AU  - Siala, M.
T2  - Machine Learning
AB  - Unwanted bias is a major concern in machine learning, raising in particular significant ethical issues when machine learning models are deployed within high-stakes decision systems. A common solution to mitigate it is to integrate and optimize a statistical fairness metric along with accuracy during the training phase. However, one of the main remaining challenges is that current approaches usually generalize poorly in terms of fairness on unseen data. We address this issue by proposing a new robustness framework for statistical fairness in machine learning. The proposed approach is inspired by the domain of distributionally robust optimization and works in ensuring fairness over a variety of samplings of the training set. Our approach can be used to quantify the robustness of fairness but also to improve it when training a model. We empirically evaluate the proposed method and show that it effectively improves fairness generalization. In addition, we propose a simple yet powerful heuristic application of our framework that can be integrated into a wide range of existing fair classification techniques to enhance fairness generalization. Our extensive empirical study using two existing fair classification methods demonstrates the efficiency and scalability of the proposed heuristic approach. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media LLC, part of Springer Nature.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s10994-022-06191-y
VL  - 112
IS  - 6
SP  - 2131
EP  - 2192
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133582221&doi=10.1007%2fs10994-022-06191-y&partnerID=40&md5=07ba1bd2f24d1fcdbb25acd34bbbbe73
DB  - Scopus
KW  - Machine learning
KW  - Fairness
KW  - Supervised learning
KW  - Machine-learning
KW  - Machine learning models
KW  - Optimization
KW  - Robust optimization
KW  - Heuristic methods
KW  - Training phasis
KW  - Distributionally robust optimization
KW  - Generalization
KW  - Generalisation
KW  - Ethical issues
KW  - Decision systems
KW  - Robust optimization method
ER  - 

TY  - CONF
TI  - Phyllis: Physics-Informed Lifelong Reinforcement Learning for Data Center Cooling Control
AU  - Wang, R.
AU  - Cao, Z.
AU  - Zhou, X.
AU  - Wen, Y.
AU  - Tan, R.
T2  - e-Energy 2023 - Proceedings of the 2023 14th ACM International Conference on Future Energy Systems
AB  - Deep reinforcement learning (DRL) has shown good performance in data center cooling control for improving energy efficiency. The main challenge in deploying the DRL agent to real-world data centers is how to quickly adapt the agent to the ever-changing system with thermal safety compliance. Existing approaches rely on DRL's native fine-tuning or a learned data-driven dynamics model to assist the adaptation. However, they require long-term unsafe exploration before the agent or the model can capture a new environment. This paper proposes Phyllis, a physics-informed reinforcement learning approach to assist the DRL agent's lifelong learning under evolving data center environment. Phyllis first identifies a transition model to capture the data hall thermodynamics in the offline stage. When the environment changes in the online stage, Phyllis assists the adaptation by i) supervising safe data collection with the identified transition model, ii) fitting power usage and residual thermal models, iii) pretraining the agent by interacting with these models, and iv) deploying the agent for further fine-tuning. Phyllis uses known physical laws to inform the transition and power models for improving the extrapolation ability to unseen states. Extensive evaluation for two simulated data centers with different system changes shows that Phyllis saves 5.7% to 13.8% energy usage compared with feedback cooling control and adapts to new environments 8x to 10x faster than fine-tuning with at most 0.74°C temperature overshoot. © 2023 Owner/Author.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3575813.3595189
SP  - 114
EP  - 126
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163716832&doi=10.1145%2f3575813.3595189&partnerID=40&md5=fe75cb830846d727b97f01cfa0dc8077
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - domain adaptation
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Energy efficiency
KW  - Energy utilization
KW  - Datacenter
KW  - Green computing
KW  - Cooling
KW  - Cooling control
KW  - Domain adaptation
KW  - Data centers
KW  - Safe exploration
KW  - safe exploration
KW  - Lifelong reinforcement learning
KW  - Fine tuning
KW  - Control optimization
KW  - cooling control optimization
KW  - Cooling control optimization
KW  - lifelong reinforcement learning
KW  - Transition model
ER  - 

TY  - JOUR
TI  - Supervised machine learning-based multi-class phase prediction in high-entropy alloys using robust databases
AU  - Oñate, A.
AU  - Sanhueza, J.P.
AU  - Zegpi, D.
AU  - Tuninetti, V.
AU  - Ramirez, J.
AU  - Medina, C.
AU  - Melendrez, M.
AU  - Rojas, D.
T2  - Journal of Alloys and Compounds
AB  - This work evaluated the phase prediction capability of high entropy alloys using four supervised machine learning models K-Nearest Neighbors (KNN), Multinomial Regression, Extreme Gradient Boosting (XGBoost), and Random Forest. The study addresses the challenge of predicting multicomponent alloys by considering the overlapping of multicategorical stability parameters. Eight prediction classes (FCC, BCC, FCC+BCC, FCC+Im, BCC+Im, FCC+BCC+Im, Im and AM) were used. Finally, the predicted results were compared with those of two new alloys fabricated by induction melting in a controlled atmosphere using X-ray diffraction (XRD). The results indicate that with a robust database, appropriate data treatment, and training, satisfactory and competitive prediction indicators can be obtained with traditional machine learning predictions based on four prediction classes: Solid Solution (SS), Solid Solution with Intermetallic (SS+Im), intermetallic (Im), and amorphous (AM). The best predictive model obtained from the four evaluated models was Random Forest, with an accuracy of 72.8% and ROC AUC of 93.1%. © 2023 Elsevier B.V.
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.jallcom.2023.171224
VL  - 962
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164304117&doi=10.1016%2fj.jallcom.2023.171224&partnerID=40&md5=d0c12b45380828bef64f75112cb3a946
DB  - Scopus
KW  - Machine Learning
KW  - Learning systems
KW  - Supervised learning
KW  - Machine-learning
KW  - Forecasting
KW  - Machine learning models
KW  - Nearest neighbor search
KW  - Supervised machine learning
KW  - Adaptive boosting
KW  - Random forests
KW  - Entropy
KW  - Forestry
KW  - Nearest-neighbour
KW  - Prediction capability
KW  - High entropy alloys
KW  - Intermetallic prediction
KW  - Intermetallics
KW  - Intermetallics prediction
KW  - Multinomials
KW  - Phase prediction
KW  - Solid solutions
ER  - 

TY  - JOUR
TI  - Visual Spatial Attention and Proprioceptive Data-Driven Reinforcement Learning for Robust Peg-in-Hole Task Under Variable Conditions
AU  - Yasutomi, A.Y.
AU  - Ichiwara, H.
AU  - Ito, H.
AU  - Mori, H.
AU  - Ogata, T.
T2  - IEEE Robotics and Automation Letters
AB  - Anchor-bolt insertion is a peg-in-hole task performed in the construction field for holes in concrete. Efforts have been made to automate this task, but the variable lighting and hole surface conditions, as well as the requirements for short setup and task execution time make the automation challenging. In this study, we introduce a vision and proprioceptive data-driven robot control model for this task that is robust to challenging lighting and hole surface conditions. This model consists of a spatial attention point network (SAP) and a deep reinforcement learning (DRL) policy that are trained jointly end-to-end to control the robot. The model is trained in an offline manner, with a sample-efficient framework designed to reduce training time and minimize the reality gap when transferring the model to the physical world. Through evaluations with an industrial robot performing the task in 12 unknown holes, starting from 16 different initial positions, and under three different lighting conditions (two with misleading shadows), we demonstrate that SAP can generate relevant attention points of the image even in challenging lighting conditions. We also show that the proposed model enables task execution with higher success rate and shorter task completion time than various baselines. Due to the proposed model's high effectiveness even in severe lighting, initial positions, and hole conditions, and the offline training framework's high sample-efficiency and short training time, this approach can be easily applied to construction.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/LRA.2023.3243526
VL  - 8
IS  - 3
SP  - 1834
EP  - 1841
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148458598&doi=10.1109%2fLRA.2023.3243526&partnerID=40&md5=09108939b9118b98fa48cce3bc576a81
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Robot kinematics
KW  - Task analysis
KW  - reinforcement learning
KW  - Features extraction
KW  - Job analysis
KW  - Reinforcement learnings
KW  - Data visualization
KW  - Data driven
KW  - Lighting
KW  - Peg-in-hole tasks
KW  - Automation in construction
KW  - deep learning for visual perception
KW  - Deep learning for visual perception
KW  - Robotic and automation in construction
KW  - Robotics and automation in construction
KW  - Visual perception
ER  - 

TY  - JOUR
TI  - Methodology for Collecting and Aligning Correlative SEM, CLSM and LOM Images of Bulk Material Microstructure to Create a Large Machine Learning Training Dataset
AU  - Čermák, J.
AU  - Ambrož, O.
AU  - Zouhar, M.
AU  - Jozefovič, P.
AU  - Mikmeková, Š.
T2  - Microscopy and microanalysis : the official journal of Microscopy Society of America, Microbeam Analysis Society, Microscopical Society of Canada
DA  - 2023///
PY  - 2023
DO  - 10.1093/micmic/ozad067.1044
VL  - 29
IS  - 1
SP  - 2016
EP  - 2018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168594976&doi=10.1093%2fmicmic%2fozad067.1044&partnerID=40&md5=7544237e02bb701b733ed49aa722202a
DB  - Scopus
ER  - 

TY  - JOUR
TI  - Supervised contrastive learning for robust text adversarial training
AU  - Li, W.
AU  - Zhao, B.
AU  - An, Y.
AU  - Shangguan, C.
AU  - Ji, M.
AU  - Yuan, A.
T2  - Neural Computing and Applications
AB  - The lack of robustness is a serious problem for deep neural networks (DNNs) and makes DNNs vulnerable to adversarial examples. A promising solution is applying adversarial training to alleviate this problem, which allows the model to learn the features from adversarial examples. However, adversarial training usually produces overfitted models and may not work when facing a new attack. We believe this is because the previous adversarial training using cross-entropy loss ignores the similarity between the adversarial examples and the original examples, which will result in a low margin. Accordingly, we propose a supervised adversarial contrastive learning (SACL) approach for adversarial training. SACL uses supervised adversarial contrastive loss which contains both the cross-entropy term and adversarial contrastive term. The cross-entropy term is used for guiding DNN inductive bias learning, and the adversarial contrastive term can help models learn example representations by maximizing feature consistency under different original examples, which fits well with the goal of solving low margins. In addition, SACL only uses adversarial examples which can successfully fool the model and their corresponding original examples for training. This process is more advantageous to provide the model with more accurate information about the decision boundary and obtain a model that fits the example distribution. Experiments show that SACL can reduce the attack success rate of multiple adversarial attack algorithms against different models on text classification tasks. The defensive performance is significantly better than other adversarial training approaches without reducing the generalization ability of the model. In addition, the DNN model trained by our approach has high transferability and robustness. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s00521-022-07871-5
VL  - 35
IS  - 10
SP  - 7357
EP  - 7368
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144688930&doi=10.1007%2fs00521-022-07871-5&partnerID=40&md5=1494523c566a87356fb3d171b70d52cf
DB  - Scopus
KW  - Deep neural networks
KW  - Learning systems
KW  - Supervised learning
KW  - Neural network
KW  - Classification (of information)
KW  - Learning approach
KW  - Text processing
KW  - Learn+
KW  - Neural-networks
KW  - Entropy
KW  - Adversarial attack
KW  - Contrastive learning
KW  - Bias Learning
KW  - Cross entropy
KW  - Entropy loss
KW  - HELP model
KW  - Inductive bias
ER  - 

TY  - JOUR
TI  - Robust unsupervised feature selection via data relationship learning
AU  - Huang, P.
AU  - Kong, Z.
AU  - Xie, M.
AU  - Yang, X.
T2  - Pattern Recognition
AB  - Unsupervised feature selection robust to many outliers is a challenging task. The crucial difficulty is learning a robust subspace, which preserves local structure. The most common solution is to reduce fitting error by applying different robust norms. However, there are three shortcomings. Firstly, they are not robust enough when outliers distributed both randomly and concentratedly are widely present. Secondly, outlier removal is not considered. Thirdly, it is not easy to understand and choose an euclidean distance threshold that decides a sample as an outlier in different scenarios. The first two shortcomings make previous methods fail to achieve their expected learning results, and the third one increases the application difficulty in different fields. To address these issues, a robust unsupervised feature selection via data relationship learning (RUFSDR) is proposed in this paper. Specifically, scores representing the data's importance will be learned and assigned to each sample. Inliers will be given different positive scores. Outliers will be given 0 such that a subspace, which preserves the local structure better, can be learned without prior knowledge about the distance threshold. The experiments conducted on various datasets with several scenarios show the superiority of RUFSDR. © 2023 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.patcog.2023.109676
VL  - 142
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85157979167&doi=10.1016%2fj.patcog.2023.109676&partnerID=40&md5=e578f9dcc9433a9fe6632ccea4ee4c0b
DB  - Scopus
KW  - Learning systems
KW  - Anomaly detection
KW  - Robustness
KW  - Statistics
KW  - Outlier
KW  - Prior-knowledge
KW  - Feature Selection
KW  - Unsupervised feature selection
KW  - Local structure
KW  - Data relationships
KW  - Euclidean distance
KW  - Fitting error
KW  - Outlier removals
ER  - 

TY  - JOUR
TI  - A criminal macrocause classification model: An enhancement for violent crime analysis considering an unbalanced dataset
AU  - Santos, R.D.V.D.
AU  - Coelho, J.V.V.
AU  - Cacho, N.A.A.
AU  - de Araújo, D.S.A.
T2  - Expert Systems with Applications
AB  - This study introduces a novel model designed to classify macrocauses of violent crimes. The model's practical application is demonstrated through its integration into the framework of the Natal Smart City Initiative in Brazil. Utilizing the Design Science methodology, the study details the model's development, its subsequent implementation through a machine learning pipeline, and its assessment employing four prominent classification techniques: Decision Trees, Logistic Regression, Random Forest, and XGBoost. XGBoost performed exceptionally well, achieving an average accuracy of 0.961791, an F1-Score of 0.961410, and an AUC of ROC curve of 0.994732. Accurate classification of criminal macrocauses is crucial for developing effective public safety policies. The proposed model can provide public safety institutions and criminal analysts with a valuable tool for better understanding aspects related to violent crime analysis in their cities. This can streamline the analysis and management process and provide more accurate information for decision-making. This study also has important implications for the emerging field of smart cities. By providing a tool to assist in decision-making and planning public safety strategies, this work contributes to the development of innovative, data-based, and theory-based solutions to address urban challenges. © 2023 Elsevier Ltd
DA  - 2024///
PY  - 2024
DO  - 10.1016/j.eswa.2023.121702
VL  - 238
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173048339&doi=10.1016%2fj.eswa.2023.121702&partnerID=40&md5=b83d51febfb073692db90c1269fc6a18
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Smart city
KW  - Decisions makings
KW  - Machine-learning
KW  - Classification (of information)
KW  - Classification models
KW  - Crime
KW  - Safety engineering
KW  - Logistic regression
KW  - Feature engineering
KW  - Public safety
KW  - Crime analyse
KW  - Feature engineerings
KW  - Predictive policing
KW  - Crime analysis
KW  - Criminal macrocause
KW  - Design science methodologies
KW  - Smart cities
KW  - Unbalanced dataset
KW  - Unbalanced datasets
ER  - 

TY  - JOUR
TI  - Adaptive autoencoder latent space tuning for more robust machine learning beyond the training set for six-dimensional phase space diagnostics of a time-varying ultrafast electron-diffraction compact accelerator
AU  - Scheinker, A.
AU  - Cropp, F.
AU  - Filippetto, D.
T2  - Physical Review E
AB  - We present a general adaptive latent space tuning approach for improving the robustness of machine learning tools with respect to time variation and distribution shift. We demonstrate our approach by developing an encoder-decoder convolutional neural network-based virtual 6D phase space diagnostic of charged particle beams in the HiRES ultrafast electron diffraction (UED) compact particle accelerator with uncertainty quantification. Our method utilizes model-independent adaptive feedback to tune a low-dimensional 2D latent space representation of ∼1 million dimensional objects which are the 15 unique 2D projections (x,y),...,(z,pz) of the 6D phase space (x,y,z,px,py,pz) of the charged particle beams. We demonstrate our method with numerical studies of short electron bunches utilizing experimentally measured UED input beam distributions. © 2023 American Physical Society.
DA  - 2023///
PY  - 2023
DO  - 10.1103/PhysRevE.107.045302
VL  - 107
IS  - 4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158889810&doi=10.1103%2fPhysRevE.107.045302&partnerID=40&md5=ea41e4d40d04d061066d4526b25fbcfe
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - convolutional neural network
KW  - uncertainty
KW  - autoencoder
KW  - Machine-learning
KW  - article
KW  - Feedback
KW  - Numerical methods
KW  - Tuning
KW  - Time varying
KW  - Training sets
KW  - Auto encoders
KW  - Learning tool
KW  - Phase space methods
KW  - Charged particle beams
KW  - Charged particles
KW  - Compact accelerators
KW  - Dimensional phase spaces
KW  - electron diffraction
KW  - Phase spaces
KW  - Ultrafast electron diffraction
ER  - 

TY  - JOUR
TI  - Data-Driven Safe Deliveries: The Synergy of IoT and Machine Learning in Shared Mobility
AU  - Elwy, F.
AU  - Aburukba, R.
AU  - Al-Ali, A.R.
AU  - Nabulsi, A.A.
AU  - Tarek, A.
AU  - Ayub, A.
AU  - Elsayeh, M.
T2  - Future Internet
AB  - Shared mobility is one of the smart city applications in which traditional individually owned vehicles are transformed into shared and distributed ownership. Ensuring the safety of both drivers and riders is a fundamental requirement in shared mobility. This work aims to design and implement an adequate framework for shared mobility within the context of a smart city. The characteristics of shared mobility are identified, leading to the proposal of an effective solution for real-time data collection, tracking, and automated decisions focusing on safety. Driver and rider safety is considered by identifying dangerous driving behaviors and the prompt response to accidents. Furthermore, a trip log is recorded to identify the reasons behind the accident. A prototype implementation is presented to validate the proposed framework for a delivery service using motorbikes. The results demonstrate the scalability of the proposed design and the integration of the overall system to enhance the rider’s safety using machine learning techniques. The machine learning approach identifies dangerous driving behaviors with an accuracy of 91.59% using the decision tree approach when compared against the support vector machine and K-nearest neighbor approaches. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/fi15100333
VL  - 15
IS  - 10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174862132&doi=10.3390%2ffi15100333&partnerID=40&md5=968697b6b9734ba5a68ca39b68421bd5
DB  - Scopus
KW  - Decision trees
KW  - Accidents
KW  - Support vector machines
KW  - Learning systems
KW  - smart cities
KW  - Internet of things
KW  - Smart city
KW  - Smart transportation
KW  - Machine-learning
KW  - Driving behaviour
KW  - Nearest neighbor search
KW  - Data driven
KW  - IoT
KW  - Dangerous drivings
KW  - Delivery service
KW  - delivery services
KW  - Distributed ownership
KW  - shared mobility
KW  - Shared mobility
KW  - Shared ownerships
KW  - smart transportation
ER  - 

TY  - JOUR
TI  - Reinforcement learning for robust voltage control in distribution grids under uncertainties
AU  - Petrusev, A.
AU  - Putratama, M.A.
AU  - Rigo-Mariani, R.
AU  - Debusschere, V.
AU  - Reignier, P.
AU  - Hadjsaid, N.
T2  - Sustainable Energy, Grids and Networks
AB  - Traditional optimization-based voltage controllers for distribution grid applications require consumption/production values from the meters as well as accurate grid data (i.e., line impedances) for modeling purposes. Those algorithms are sensitive to uncertainties, notably in consumption and production forecasts or grid models. This paper focuses on the latter. Indeed, line parameters gradually deviate from their original values over time due to exploitation and weather conditions. Also, those data are oftentimes not fully available at the low voltage side thus creating sudden changes between the datasheet and the actual value. To mitigate the impact of uncertain line parameters, this paper proposes the use of a deep reinforcement learning algorithm for voltage regulation purposes in a distribution grid with PV production by controlling the setpoints of distributed storage units as flexibilities. Two algorithms are considered, namely TD3PG and PPO. A two-stage strategy is also proposed, with offline training on a grid model and further online training on an actual system (with distinct impedance values). The controllers’ performances are assessed concerning the algorithms’ hyperparameters, and the obtained results are compared with a second-order conic relaxation optimization-based control. The results show the relevance of the RL-based control, in terms of accuracy, robustness to gradual or sudden variations on the line impedances, and significant speed improvement (once trained). Validation runs are performed on a simple 11-bus system before the method's scalability is tested on a 55-bus network. © 2022 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.segan.2022.100959
VL  - 33
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144055189&doi=10.1016%2fj.segan.2022.100959&partnerID=40&md5=69a406e278ba76f0db07b5250a004b6f
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Controllers
KW  - Uncertainty
KW  - Uncertainty analysis
KW  - Digital storage
KW  - Electric load flow
KW  - Electric power system control
KW  - Batteries
KW  - Battery
KW  - Electric power distribution
KW  - Voltage control
KW  - Electric batteries
KW  - Voltage regulators
KW  - Flexibility
KW  - Optimal power flow
KW  - Optimal power flows
KW  - Distribution grid
KW  - Second orders
KW  - PPO
KW  - PV production
KW  - Second-order conic relaxation
KW  - TD3PG
ER  - 

TY  - JOUR
TI  - Robust Autonomous Vehicle Computer-Vision-Based Localization in Challenging Environmental Conditions
AU  - Chuprov, S.
AU  - Belyaev, P.
AU  - Gataullin, R.
AU  - Reznik, L.
AU  - Neverov, E.
AU  - Viksnin, I.
T2  - Applied Sciences (Switzerland)
AB  - In this paper, we present a novel autonomous vehicle (AV) localization design and its implementation, which we recommend to employ in challenging navigation conditions with a poor quality of the satellite navigation system signals and computer vision images. In the case when the GPS signal becomes unstable, other auxiliary navigation systems, such as computer-vision-based positioning, are employed for more accurate localization and mapping. However, the quality of data obtained from AV’s sensors might be deteriorated by the extreme environmental conditions too, which infinitely leads to the decrease in navigation performance. To verify our computer-vision-based localization system design, we considered the Arctic region use case, which poses additional challenges for the AV’s navigation and might employ artificial visual landmarks for improving the localization quality, which we used for the computer vision training. We further enhanced our data by applying affine transformations to increase its diversity. We selected YOLOv4 image detection architecture for our system design, as it demonstrated the highest performance in our experiments. For the computational platform, we employed a Nvidia Jetson AGX Xavier device, as it is well known and widely used in robotic and AV computer vision, as well as deep learning applications. Our empirical study showed that the proposed computer vision system that was further trained on the dataset enhanced by affine transformations became robust regarding image quality degradation caused by extreme environmental conditions. It was effectively able to detect and recognize images of artificial visual landmarks captured in the extreme Arctic region’s conditions. The developed system can be integrated into vehicle navigation facilities to improve their effectiveness and efficiency and to prevent possible navigation performance deterioration. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/app13095735
VL  - 13
IS  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159360973&doi=10.3390%2fapp13095735&partnerID=40&md5=8b92935f2fe2eaefc800c46e2f4445b5
DB  - Scopus
KW  - machine learning
KW  - computer vision
KW  - data quality
KW  - robust vehicle localization
ER  - 

TY  - JOUR
TI  - Privacy-preserving energy trading management in networked microgrids via data-driven robust optimization assisted by machine learning
AU  - Mohseni, S.
AU  - Pishvaee, M.S.
AU  - Dashti, R.
T2  - Sustainable Energy, Grids and Networks
AB  - Trading mechanism design, uncertainty treatment and privacy protection are the main issues in the energy management of networked microgrids (MGs). To address these issues in a comprehensive manner, this paper proposes a data-driven two-level transactive energy management framework, where the upper-level determines the optimal strategies of internal scheduling within MGs and external trading between MGs while the lower-level formulates a Nash bargaining game model for the fair allocation of trading benefits. The uncertainties of renewable energy sources are fully captured by an adjustable data-driven robust optimization approach with an uncertainty set constructed using the robust kernel density estimation (RKDE) as a machine learning technique. The resulting uncertainty set can provide robust scheduling and trading schemes even when the power generation data of wind turbines and photovoltaic systems are contaminated with anomalous samples, whereas conventional sets are not reliable in the case of contaminated data. To preserve the operational independence and information privacy of MGs, the proposed model is solved in a distributed manner by the alternating direction method of multipliers (ADMM) and the augmented Lagrange-based alternating direction inexact Newton (ALADIN) algorithms. ADMM is commonly used in previous studies, but it has low computational efficiency for handling the consensus process among a large number of MGs. This paper applies ADMM and ALADIN to enhance the applicability of the proposed model when the size and complexity of the networks increase. Numerical tests show the effectiveness of the proposed framework and solution methodology in terms of system cost, solution robustness, and convergence speed. © 2023 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.segan.2023.101011
VL  - 34
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147089242&doi=10.1016%2fj.segan.2023.101011&partnerID=40&md5=6476d2318dee58ab1c5120886feadc25
DB  - Scopus
KW  - Game theory
KW  - Machine learning
KW  - Uncertainty
KW  - Machine design
KW  - Optimization
KW  - Microgrid
KW  - Renewable energy resources
KW  - Data driven
KW  - Microgrids
KW  - Privacy-preserving techniques
KW  - Computational efficiency
KW  - Alternating directions method of multipliers
KW  - Data-driven optimization
KW  - ADMM
KW  - Distributed optimization
KW  - Energy trading
KW  - Nash bargaining game
KW  - Peer to peer
KW  - Peer-to-peer energy trading
ER  - 

TY  - JOUR
TI  - Robustness of machine learning to color, size change, normalization, and image enhancement on micrograph datasets with large sample differences
AU  - Pei, X.
AU  - Zhao, Y.H.
AU  - Chen, L.
AU  - Guo, Q.
AU  - Duan, Z.
AU  - Pan, Y.
AU  - Hou, H.
T2  - Materials and Design
AB  - Appropriate image preprocessing could improve machine learning performance, but the robustness of machine learning to preprocessing methods in micrograph datasets with significant sample differences remains unexplored. Here we collected hundreds of optical micrographs varied in color, contrast, size and brightness and tensile strength from published literature. After preprocessing including color transformation, size adjustment, normalization and image enhancement, classification model of whether it was texture or not and tensile strength prediction model were established using transfer learning and VGG16 model. Our results showed comparable accuracy between classification models using grayscale and color micrographs. Based on grayscale images, classification model utilizing center cropping achieved an average accuracy 1.09% higher than model employing scaling, while coefficient of determination (R2) of regression model showed an average increase of 0.0404. The combination of cropping and dividing by 255 was preferable for classification model, yielding an accuracy of 90.79%. Similarly, the combination of cropping and min–max normalization had a better effect on regression model, yielding R2 of 0.2167. Histogram equalization emerged as the optimal technique for improving classification model, yielding 2.63% increase in accuracy compared to models without image enhancement. For regression models, gamma correction exhibited the highest improvement effect, with an R2 of 0.2681. © 2023 The Authors
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.matdes.2023.112086
VL  - 232
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162116647&doi=10.1016%2fj.matdes.2023.112086&partnerID=40&md5=fde0c9a2da6f463fad94358216c951a5
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Image classification
KW  - Classification models
KW  - Image enhancement
KW  - Classification
KW  - Regression modelling
KW  - Learning performance
KW  - Large dataset
KW  - Textures
KW  - Regression
KW  - Tensile strength
KW  - Color
KW  - Normalisation
KW  - Pre-processing method
KW  - Image preprocessing
KW  - Micrograph
KW  - Optical micrographs
ER  - 

TY  - JOUR
TI  - BIO-CXRNET: a robust multimodal stacking machine learning technique for mortality risk prediction of COVID-19 patients using chest X-ray images and clinical data
AU  - Rahman, T.
AU  - Chowdhury, M.E.H.
AU  - Khandakar, A.
AU  - Mahbub, Z.B.
AU  - Hossain, M.S.A.
AU  - Alhatou, A.
AU  - Abdalla, E.
AU  - Muthiyal, S.
AU  - Islam, K.F.
AU  - Kashem, S.B.A.
AU  - Khan, M.S.
AU  - Zughaier, S.M.
AU  - Hossain, M.
T2  - Neural Computing and Applications
AB  - Nowadays, quick, and accurate diagnosis of COVID-19 is a pressing need. This study presents a multimodal system to meet this need. The presented system employs a machine learning module that learns the required knowledge from the datasets collected from 930 COVID-19 patients hospitalized in Italy during the first wave of COVID-19 (March–June 2020). The dataset consists of twenty-five biomarkers from electronic health record and Chest X-ray (CXR) images. It is found that the system can diagnose low- or high-risk patients with an accuracy, sensitivity, and F1-score of 89.03%, 90.44%, and 89.03%, respectively. The system exhibits 6% higher accuracy than the systems that employ either CXR images or biomarker data. In addition, the system can calculate the mortality risk of high-risk patients using multivariate logistic regression-based nomogram scoring technique. Interested physicians can use the presented system to predict the early mortality risks of COVID-19 patients using the web-link: Covid-severity-grading-AI. In this case, a physician needs to input the following information: CXR image file, Lactate Dehydrogenase (LDH), Oxygen Saturation (O2%), White Blood Cells Count, C-reactive protein, and Age. This way, this study contributes to the management of COVID-19 patients by predicting early mortality risk. © 2023, The Author(s).
DA  - 2023///
PY  - 2023
DO  - 10.1007/s00521-023-08606-w
VL  - 35
IS  - 24
SP  - 17461
EP  - 17483
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158046326&doi=10.1007%2fs00521-023-08606-w&partnerID=40&md5=081225c7a4e0deec24a96265efd6ea0e
DB  - Scopus
KW  - Deep learning
KW  - Learning systems
KW  - COVID-19
KW  - Diagnosis
KW  - Machine-learning
KW  - Forecasting
KW  - Grading
KW  - Biomarkers
KW  - Blood
KW  - Chest X-ray
KW  - Chest X-ray image
KW  - Classical machine learning
KW  - Clinical data
KW  - High-risk patients
KW  - Mortality risk
KW  - Multimodal system
KW  - Prognostic model
KW  - Prognostic modeling
ER  - 

TY  - JOUR
TI  - Semi-Supervised Learning for Robust Emotional Speech Synthesis with Limited Data
AU  - Zhang, J.
AU  - Wushouer, M.
AU  - Tuerhong, G.
AU  - Wang, H.
T2  - Applied Sciences (Switzerland)
AB  - Emotional speech synthesis is an important branch of human–computer interaction technology that aims to generate emotionally expressive and comprehensible speech based on the input text. With the rapid development of speech synthesis technology based on deep learning, the research of affective speech synthesis has gradually attracted the attention of scholars. However, due to the lack of quality emotional speech synthesis corpus, emotional speech synthesis research under low-resource conditions is prone to overfitting, exposure error, catastrophic forgetting and other problems leading to unsatisfactory generated speech results. In this paper, we proposed an emotional speech synthesis method that integrates migration learning, semi-supervised training and robust attention mechanism to achieve better adaptation to the emotional style of the speech data during fine-tuning. By adopting an appropriate fine-tuning strategy, trade-off parameter configuration and pseudo-labels in the form of loss functions, we efficiently guided the learning of the regularized synthesis of emotional speech. The proposed SMAL-ET2 method outperforms the baseline methods in both subjective and objective evaluations. It is demonstrated that our training strategy with stepwise monotonic attention and semi-supervised loss method can alleviate the overfitting phenomenon and improve the generalization ability of the text-to-speech model. Our method can also enable the model to successfully synthesize different categories of emotional speech with better naturalness and emotion similarity. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/app13095724
VL  - 13
IS  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159341427&doi=10.3390%2fapp13095724&partnerID=40&md5=f9842eb3a15c0a1fb92608b150ac3433
DB  - Scopus
KW  - transfer learning
KW  - emotional speech corpus
KW  - low resource
KW  - pseudo label
KW  - speech synthesis
ER  - 

TY  - CONF
TI  - A framework for individual adaptation of driver assistance system design methodology with utilizing real-world naturalistic driving database
AU  - Raksincharoensak, P.
AU  - Michitsuji, Y.
AU  - Khaisongkram, W.
AU  - Maeda, K.
AU  - Nagai, M.
T2  - FISITA World Automotive Congress 2008, Congress Proceedings - Vehicle Safety
AB  - Recent advances in practical adaptive driver assistance systems and sensing technology have led to a detailed study of individual driver behaviour. The design of cooperative control among the currently developed active safety devices, which fits the driver behaviour/intention and ongoing traffic situation, is required. To realize such systems, an extensive study of individual driver behaviour model is necessary. This paper describes the modelling of naturalistic driving behaviour in real-world traffic situation, based on driving data collected by using the experimental car equipped with the continuous sensing drive recorder. The driving route includes several types of roadways in urban area of Tokyo. The continuous sensing drive recorder includes the information of road environment (GPS data and headway distance), driver operation (steering, pedal, winker), and vehicle dynamics data (speed, acceleration, yaw rate, etc.). The video images of front scenery, rear scenery, driver's face and driver's foot operation are captured in synchronization with the sensor data. The real-time driving state recognition algorithm, in longitudinal vehicle operation, is described as one of the core technology of individual adaptation technique. The driver model in urban area is assumed to be in the form of state flow diagram. In this paper, the longitudinal driving sequence is classified into five categories with symbols corresponding to driving states (modes): car following, braking (when there is a preceding vehicle, obstacle), free following (independent driving), deceleration (when there is no preceding vehicle) and stopping. In this paper, Boosting Sequential Labelling Method, which describes the relationship between the sensor data of drive recorder and the symbolized driving state as the conditional probability feature, is employed to train the driver-vehicle-environment model in the manner of data-driven method for recognizing driving manoeuvres in real time. The conditional probability of driving sequential label with respect to drive recorder sensor data can be computed based on Logistic Regression Model. The combination of optimized weak classifiers, described as if-then rules, represents the classification of each driving state. In the full paper, the accuracy of the estimation method, evaluated as F-value, is investigated by comparing the estimated label with the ground truth of the driving state labels.
DA  - 2008///
PY  - 2008
VL  - 2
SP  - 283
EP  - 290
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866126498&partnerID=40&md5=2f8bc114a743727f539708a7c70fa5d5
DB  - Scopus
KW  - Urban areas
KW  - Intelligent systems
KW  - Vehicle dynamics
KW  - Vehicles
KW  - Ground truth
KW  - Automobile drivers
KW  - Driver training
KW  - Regression analysis
KW  - Sensor data
KW  - Driver assistance system
KW  - Driving behaviour
KW  - Real time
KW  - Car following
KW  - Co-operative control
KW  - Estimation methods
KW  - Sensors
KW  - Data-driven methods
KW  - Statistical machine learning
KW  - Active safety
KW  - Conditional probabilities
KW  - Driver behaviour
KW  - Weak classifiers
KW  - Design Methodology
KW  - Adaptation techniques
KW  - Continuous sensing
KW  - Core technology
KW  - Driver models
KW  - Driving database
KW  - Driving state
KW  - Driving-state recognition
KW  - GPS data
KW  - Headway distance
KW  - If-then rules
KW  - Independent driving
KW  - Logistic regression models
KW  - Logistics
KW  - Longitudinal driving
KW  - Road environment
KW  - Sensing technology
KW  - State flow
KW  - Traffic situations
KW  - Vehicle operations
KW  - Video image
KW  - Yaw rate
ER  - 

TY  - CONF
TI  - Image database categorization using robust unsupervised learning of finite generalized dirichlet mixture models
AU  - Ben Ismail, M.M.
AU  - Frigui, H.
T2  - Proceedings - International Conference on Image Processing, ICIP
AB  - We propose a novel image database categorization approach using robust unsupervised learning of finite generalized dirichlet mixture models with feature discrimination. The proposed algorithm is based on optimizing an objective function that associates two types of memberships with each data sample. The first one is the posterior probability and indicates how well a sample fits each estimated distribution. The second membership represents the degree of typicality and is used to identify and discard noise points and outliers. In addition, RULe-GDM learns an optimal relevance weight for each feature subset within each cluster. These properties make RULe-GDM suitable for noisy and high-dimensional feature spaces. We also extend our algorithm to find the optimal number of clusters in an unsupervised and efficient way by exploiting some properties of the possibilistic membership function. RULe-GDM is used to categorize a collection of color images. The performance of RULe-GDM is illustrated and compared to similar algorithms. © 2011 IEEE.
DA  - 2011///
PY  - 2011
DO  - 10.1109/ICIP.2011.6116157
SP  - 2457
EP  - 2460
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856247403&doi=10.1109%2fICIP.2011.6116157&partnerID=40&md5=72669e82f284b3f75600a37b5c752e6b
DB  - Scopus
KW  - Optimization
KW  - Image processing
KW  - Database systems
KW  - Clustering algorithms
KW  - Unsupervised learning
KW  - Probability distributions
KW  - Objective functions
KW  - Membership functions
KW  - Mixtures
KW  - Posterior probability
KW  - Color images
KW  - Data sample
KW  - Dirichlet mixture
KW  - Dirichlet mixture model
KW  - Feature discrimination
KW  - Feature subset
KW  - feature weighting
KW  - Feature weighting
KW  - Generalized Dirichlet mixture
KW  - High-dimensional feature space
KW  - image database categorization
KW  - Image database categorization
KW  - mixture models
KW  - Optimal number
KW  - Possibilistic
ER  - 

TY  - CONF
TI  - The Impact of Training Data Shortfalls on Safety of AI-Based Clinical Decision Support Systems
AU  - Ryan Conmy, P.
AU  - Ozturk, B.
AU  - Lawton, T.
AU  - Habli, I.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Decision support systems with Artificial intelligence (AI) and specifically Machine Learning (ML) components present many challenges when assuring trust in operational performance, particularly in a safety-critical domain such as healthcare. During operation the Human in/on The Loop (HTL) may need assistance in determining when to trust the ML output and when to override it, particularly to prevent hazardous situations. In this paper, we consider how issues with training data shortfalls can cause varying safety performance in ML. We present a case study using an ML-based clinical decision support system for Type-2 diabetes related co-morbidity prediction (DCP). The DCP ML component is trained using real patient data, but the data was taken from a very large live database gathered over many years, and the records vary in distribution and completeness. Research developing similar clinical predictor systems describe different methods to compensate for training data shortfalls, but concentrate only on fixing the data to maximise the ML performance without considering a system safety perspective. This means the impact of the ML’s varying performance is not fully understood at the system level. Further, methods such as data imputation can introduce a further risk of bias which is not addressed. This paper combines the use of ML data shortfall compensation measures with exploratory safety analysis to ensure all means of reducing risk are considered. We demonstrate that together these provide a richer picture allowing more effective identification and mitigation of risks from training data shortfalls. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-40923-3_16
VL  - 14181 LNCS
SP  - 213
EP  - 226
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172132940&doi=10.1007%2f978-3-031-40923-3_16&partnerID=40&md5=b49696a7d7d3cc22771c063c5846947e
DB  - Scopus
KW  - Machine learning
KW  - Training data
KW  - Machine Learning
KW  - Learning algorithms
KW  - Machine-learning
KW  - Risk assessment
KW  - Decision support systems
KW  - Safety engineering
KW  - Machine components
KW  - Safety performance
KW  - Clinical research
KW  - Medical Devices
KW  - Safety-critical domain
KW  - Operational performance
KW  - Clinical decision support systems
KW  - Comorbidities
KW  - Device safeties
KW  - Hospital data processing
KW  - Medical device safety
KW  - Training Data
ER  - 

TY  - CONF
TI  - Leveraging synthetic data for AI bias mitigation
AU  - Patrikar, A.M.
AU  - Mahenthiran, A.
AU  - Said, A.
T2  - Proceedings of SPIE - The International Society for Optical Engineering
AB  - Widespread adoption of artificial intelligence (AI) in civilian and defense government agencies requires the stakeholders to have trust in AI solutions. One of the five principles of ethical AI, identified by the Department of Defense, emphasizes that AI solutions be equitable. The AI system involves a series of choices from data selection to model definition, each of which is subject to human and algorithmic biases and can lead to unintended consequences. This paper focuses on allowing AI bias mitigation with the use of synthetic data. The proposed technique, named Fair-GAN, builds upon the recently developed Fair-SMOTE approach, which used synthesized data to fix class and other imbalances caused by protected attributes such as race and gender. Fair-GAN uses Generative Adversarial Networks (GAN) instead of the Synthetic Minority Oversampling Technique (SMOTE). While SMOTE can only synthesize tabular and numerical data, GAN can synthesize tabular data with numerical, binary, and categorical variables. GAN can also synthesize other data forms such as images, audio and text. In our experiments, we use the Synthetic Data Vault (SDV), which implements approaches such as conditional tabular GAN (CTGAN) and tabular variational autoencoders (TVAE). We show the applicability of Fair-GAN to several benchmark problems, which are used to evaluate the efficacy of AI bias mitigation algorithms. It is shown that Fair-GAN leads to significant improvements in metrics used for evaluating AI fairness such as the statistical parity difference, disparate impact, average odds difference, and equal opportunities difference. © 2023 SPIE.
DA  - 2023///
PY  - 2023
DO  - 10.1117/12.2662276
VL  - 12529
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171187393&doi=10.1117%2f12.2662276&partnerID=40&md5=673fcd11ad7298387142e151ae8fb503
DB  - Scopus
KW  - machine learning
KW  - Artificial intelligence
KW  - trustworthy AI
KW  - responsible AI
KW  - Machine-learning
KW  - Network security
KW  - Responsible artificial intelligence
KW  - Synthetic data
KW  - Trustworthy artificial intelligence
KW  - Generative adversarial networks
KW  - Tabular data
KW  - AI bias mitigation
KW  - AI fairness
KW  - Artificial intelligence bias mitigation
KW  - Artificial intelligence fairness
KW  - Department of Defence
KW  - Government agencies
KW  - synthetic data
KW  - Synthetic minority over-sampling techniques
ER  - 

TY  - JOUR
TI  - Three-Stage Deep Reinforcement Learning for Privacy-and Safety-Aware Smart Electric Vehicle Charging Station Scheduling and Volt/VAR Control
AU  - Lee, S.
AU  - Choi, D.
T2  - IEEE Internet of Things Journal
AB  - This paper proposes a three-stage privacy-and safety-aware deep reinforcement learning framework for coordinating smart electric vehicle charging stations (EVCSs) integrated with a photovoltaic system/energy storage system (ESS) and Volt/VAR control in a power distribution system. The proposed framework aims to maximize the EVCS profit and minimize the network real power loss while ensuring zero ESS state of charge (SOC) and voltage violation as well as preserving the privacy of the EVCS net load schedule data. In Stage 1 with 30-min resolution, each charging station operator (CSO) agent of the EVCS performs day-ahead profitable real power charging/discharging of the ESS without violating its SOC constraint via a safety layer during training. In Stage 2, using the -differential privacy method, the CSO agents encrypt the EVCS net load schedule data delivered from Stage 1. In Stage 3 with 5-min resolution, the distribution system operator agent conducts real-time reactive power charging/discharging of the ESSs to minimize the real power loss while removing voltage violations completely via iterative safe exploration of the agent with iteration penalties during training. The proposed framework was assessed on the IEEE 33-bus system for its privacy preserving and safety performances. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/JIOT.2023.3319588
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173024945&doi=10.1109%2fJIOT.2023.3319588&partnerID=40&md5=a3c7d9541663a3c8e9b4d225a5a76421
DB  - Scopus
KW  - Privacy
KW  - Training
KW  - safety
KW  - Schedules
KW  - deep reinforcement learning
KW  - Voltage control
KW  - Data privacy
KW  - Reactive power
KW  - Volt/VAR control
KW  - Electric vehicle charging station
KW  - Power distribution
KW  - privacy preserving
ER  - 

TY  - JOUR
TI  - Blockchain-FRL for Vehicular Lane-Changing: Towards Traffic, Data and Training Safety
AU  - Fan, B.
AU  - Dong, Y.
AU  - Li, T.
AU  - Wu, Y.
T2  - IEEE Internet of Things Journal
AB  - Reinforcement learning has been adopted to improve the efficiency of vehicular lane-changing (LC) decisions. However, since the local vehicular data needs to be uploaded to the edge node for accomplishing the learning and decision tasks, the data and traffic safety are under critical threat. Illegal data usage or attacks can generate misleading LC decisions such as collisions or rollover, which severely degrades the traffic safety. Therefore, this paper investigates a blockchain-FRL (federated reinforcement learning) approach for the LC decisions, which jointly accounts for the traffic, data and training safety of the LC decision-making. A vehicular reputation model based on the Bayesian risk situation is constructed and combined with the FRL. The proposed model can help evaluate the traffic safety, select the vehicles for participating in the FRL training, and adjust the FRL aggregation weights. The FRL can protect the data safety by enabling the exchange and aggregation of the LC decision network parameters. The blockchain can ensure the FRL training safety by recording the FRL task information. In addition, a Proof of Work (PoW) consensus scheme is devised to increase the FRL robustness, where the vehicles can collaboratively join the blockchain consensus and accomplish the FRL aggregation in a distributed manner. Two typical scenarios are selected for the experimental evaluation, including the highway scenario and the merging scenario. The experiment results indicate that the proposed method shows better efficiency, convergence and message safety delivery ratio by comparing with the existing studies. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/JIOT.2023.3303918
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167801209&doi=10.1109%2fJIOT.2023.3303918&partnerID=40&md5=04e9f080be19a46767e7dd5d0a6bc645
DB  - Scopus
KW  - Reinforcement learning
KW  - Decision making
KW  - Blockchain
KW  - Accident prevention
KW  - Reinforcement learnings
KW  - Traffic safety
KW  - Efficiency
KW  - Traffic data
KW  - Data privacy
KW  - Block-chain
KW  - Data safeties
KW  - Lane changing decisions
KW  - Federated reinforcement learning
KW  - Lane changing
KW  - Training safety
KW  - Vehicular lane-changing
ER  - 

TY  - JOUR
TI  - Targeted adversarial attacks on wind power forecasts
AU  - Heinrich, R.
AU  - Scholz, C.
AU  - Vogt, S.
AU  - Lehna, M.
T2  - Machine Learning
AB  - In recent years, researchers proposed a variety of deep learning models for wind power forecasting. These models predict the wind power generation of wind farms or entire regions more accurately than traditional machine learning algorithms or physical models. However, latest research has shown that deep learning models can often be manipulated by adversarial attacks. Since wind power forecasts are essential for the stability of modern power systems, it is important to protect them from this threat. In this work, we investigate the vulnerability of two different forecasting models to targeted, semi-targeted, and untargeted adversarial attacks. We consider a long short-term memory (LSTM) network for predicting the power generation of individual wind farms and a convolutional neural network (CNN) for forecasting the wind power generation throughout Germany. Moreover, we propose the Total Adversarial Robustness Score (TARS), an evaluation metric for quantifying the robustness of regression models to targeted and semi-targeted adversarial attacks. It assesses the impact of attacks on the model’s performance, as well as the extent to which the attacker’s goal was achieved, by assigning a score between 0 (very vulnerable) and 1 (very robust). In our experiments, the LSTM forecasting model was fairly robust and achieved a TARS value of over 0.78 for all adversarial attacks investigated. The CNN forecasting model only achieved TARS values below 0.10 when trained ordinarily, and was thus very vulnerable. Yet, its robustness could be significantly improved by adversarial training, which always resulted in a TARS above 0.46. © 2023, The Author(s).
DA  - 2023///
PY  - 2023
DO  - 10.1007/s10994-023-06396-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171334375&doi=10.1007%2fs10994-023-06396-9&partnerID=40&md5=c2e86a807121a58fa33f7f9a01ddf00f
DB  - Scopus
KW  - Deep learning
KW  - Convolutional neural networks
KW  - Learning systems
KW  - Machine-learning
KW  - Regression analysis
KW  - Long short-term memory
KW  - Learning models
KW  - Adversarial machine learning
KW  - Power generation
KW  - Robustness evaluation
KW  - Weather forecasting
KW  - Adversarial training
KW  - Wind farm
KW  - Time series forecasting
KW  - Forecasting models
KW  - Electric utilities
KW  - Wind power forecast
KW  - Windpowe forecasting
KW  - Windpower forecasting
ER  - 

TY  - JOUR
TI  - Adversarial Reinforcement Learning-Based Coordinated Robust Spatial Reuse in Broadcast-Overlaid WLANs
AU  - Kihira, Y.
AU  - Koda, Y.
AU  - Yamamoto, K.
AU  - Nishio, T.
T2  - IEICE Transactions on Communications
AB  - Broadcast services for wireless local area networks (WLANs) are being standardized in the IEEE 802.11 task group bc. Envisaging the upcoming coexistence of broadcast access points (APs) with densely-deployed legacy APs, this paper addresses a learning-based spatial reuse with only partial receiver-awareness. This partial awareness means that the broadcast APs can leverage few acknowledgment frames (ACKs) from recipient stations (STAs). This is in view of the specific concerns of broadcast communications. In broadcast communications for a very large number of STAs, ACK implosions occur unless some STAs are stopped from responding with ACKs. Given this, the main contribution of this paper is to demonstrate the feasibility to improve the robustness of learning-based spatial reuse to hidden interferers only with the partial receiver-awareness while discarding any re-training of broadcast APs. The core idea is to leverage robust adversarial reinforcement learning (RARL), where before a hidden interferer is installed, a broadcast AP learns a rate adaptation policy in a competition with a proxy interferer that provides jamming signals intelligently. Therein, the recipient STAs experience interference and the partial STAs provide a feedback overestimating the effect of interference, allowing the broadcast AP to select a data rate to avoid frame losses in a broad range of recipient STAs. Simulations demonstrate the suppression of the throughput degradation under a sudden installation of a hidden interferer, indicating the feasibility of acquiring robustness to the hidden interferer. Copyright © 2023 The Institute of Electronics, Information and Communication Engineers.
DA  - 2023///
PY  - 2023
DO  - 10.1587/transcom.2022EBP3026
VL  - E106B
IS  - 2
SP  - 203
EP  - 212
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150644267&doi=10.1587%2ftranscom.2022EBP3026&partnerID=40&md5=2311da03892bd3cfb03ce211ccc99081
DB  - Scopus
KW  - Reinforcement learning
KW  - Reinforcement learnings
KW  - Learn+
KW  - IEEE Standards
KW  - Wireless local area networks (WLAN)
KW  - Signal receivers
KW  - Access points
KW  - broadcast communication
KW  - Broadcast communication
KW  - Broadcast services
KW  - data rate adaptation
KW  - Data rate adaptation
KW  - IEEE 802.11bc
KW  - robust adversarial reinforcement learning
KW  - Robust adversarial reinforcement learning
KW  - spatial reuse
KW  - Spatial reuse
KW  - Task groups
ER  - 

TY  - JOUR
TI  - Dynamic optimization with side information
AU  - Bertsimas, D.
AU  - McCord, C.
AU  - Sturt, B.
T2  - European Journal of Operational Research
AB  - We develop a tractable and flexible data-driven approach for incorporating side information into multi-stage stochastic programming. The proposed framework uses predictive machine learning methods (such as k-nearest neighbors, kernel regression, and random forests) to weight the relative importance of various data-driven uncertainty sets in a robust optimization formulation. Through a novel measure concentration result for a class of supervised machine learning methods, we prove that the proposed approach is asymptotically optimal for multi-period stochastic programming with side information. We also describe a general-purpose approximation for these optimization problems, based on overlapping linear decision rules, which is computationally tractable and produces high-quality solutions for dynamic problems with many stages. Across a variety of multi-stage and single-stage examples in inventory management, finance, and shipment planning, our method achieves improvements of up to 15% over alternatives and requires less than one minute of computation time on problems with twelve stages. © 2022 Elsevier B.V.
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.ejor.2022.03.030
VL  - 304
IS  - 2
SP  - 634
EP  - 651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127700596&doi=10.1016%2fj.ejor.2022.03.030&partnerID=40&md5=d4f3b427ba5365f99832e52d77e052da
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Supervised learning
KW  - Uncertainty
KW  - Machine learning methods
KW  - Nearest neighbor search
KW  - Robust optimization
KW  - Data-driven approach
KW  - Stochastic systems
KW  - Distributionally robust optimization
KW  - Stochastic programming
KW  - Data driven
KW  - Inventory control
KW  - k-nearest neighbors
KW  - Dynamic optimization
KW  - Kernel regression
KW  - Multi-stage stochastic programming
KW  - Side information
ER  - 

TY  - CONF
TI  - Bidirectional Adaptation for Robust Semi-Supervised Learning with Inconsistent Data Distributions
AU  - Jia, L.-H.
AU  - Guo, L.-Z.
AU  - Zhou, Z.
AU  - Shao, J.-J.
AU  - Xiang, Y.-K.
AU  - Li, Y.-F.
T2  - Proceedings of Machine Learning Research
AB  - Semi-supervised learning (SSL) suffers from severe performance degradation when labeled and unlabeled data come from inconsistent data distributions. However, there is still a lack of sufficient theoretical guidance on how to alleviate this problem. In this paper, we propose a general theoretical framework that demonstrates how distribution discrepancies caused by pseudo-label predictions and target predictions can lead to severe generalization errors. Through theoretical analysis, we identify three main reasons why previous SSL algorithms cannot perform well with inconsistent distributions: coupling between the pseudo-label predictor and the target predictor, biased pseudo labels, and restricted sample weights. To address these challenges, we introduce a practical framework called Bidirectional Adaptation that can adapt to the distribution of unlabeled data for debiased pseudo-label prediction and to the target distribution for debiased target prediction, thereby mitigating these shortcomings. Extensive experimental results demonstrate the effectiveness of our proposed framework. © 2023 Proceedings of Machine Learning Research. All rights reserved.
DA  - 2023///
PY  - 2023
VL  - 202
SP  - 14886
EP  - 14901
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174426186&partnerID=40&md5=83bb3938b25b176e9237be2cf5d0084a
DB  - Scopus
KW  - Supervised learning
KW  - Learning algorithms
KW  - Forecasting
KW  - Semi-supervised learning
KW  - Performance degradation
KW  - Generalization Error
KW  - Data distribution
KW  - Theoretical framework
KW  - Target prediction
KW  - Label predictions
KW  - Labeled and unlabeled data
KW  - Inconsistent data
KW  - Samples weight
ER  - 

TY  - CONF
TI  - CROP: Towards Distributional-Shift Robust Reinforcement Learning Using Compact Reshaped Observation Processing
AU  - Altmann, P.
AU  - Ritz, F.
AU  - Feuchtinger, L.
AU  - Nüßlein, J.
AU  - Linnhoff-Popien, C.
AU  - Phan, T.
T2  - IJCAI International Joint Conference on Artificial Intelligence
AB  - The safe application of reinforcement learning (RL) requires generalization from limited training data to unseen scenarios. Yet, fulfilling tasks under changing circumstances is a key challenge in RL. Current state-of-the-art approaches for generalization apply data augmentation techniques to increase the diversity of training data. Even though this prevents overfitting to the training environment(s), it hinders policy optimization. Crafting a suitable observation, only containing crucial information, has been shown to be a challenging task itself. To improve data efficiency and generalization capabilities, we propose Compact Reshaped Observation Processing (CROP) to reduce the state information used for policy optimization. By providing only relevant information, overfitting to a specific training layout is precluded and generalization to unseen environments is improved. We formulate three CROPs that can be applied to fully observable observation- and action-spaces and provide methodical foundation. We empirically show the improvements of CROP in a distributionally shifted safety gridworld. We furthermore provide benchmark comparisons to full observability and data-augmentation in two different-sized procedurally generated mazes. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.
DA  - 2023///
PY  - 2023
VL  - 2023-August
SP  - 3414
EP  - 3422
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170359176&partnerID=40&md5=324523ba832f4699dfb4c359f306a724
DB  - Scopus
KW  - Reinforcement learning
KW  - Training data
KW  - Reinforcement learnings
KW  - 'current
KW  - Policy optimization
KW  - Data augmentation
KW  - Generalisation
KW  - Crops
KW  - Overfitting
KW  - State-of-the-art approach
KW  - Augmentation techniques
KW  - Limited training data
ER  - 

TY  - CONF
TI  - Distributed Neural Network-Based DDoS Detection in Vehicular Communication Systems
AU  - Jaton, N.
AU  - Gyawali, S.
AU  - Qian, Y.
T2  - 2023 16th International Conference on Signal Processing and Communication System, ICSPCS 2023 - Proceedings
AB  - As modern vehicular communication systems advance, the demand for robust security measures becomes increasingly critical. A misbehavior detection systems (MDS) is a tool developed to detect if a vehicular network is being attacked so that the system can take steps to mitigate harm from the attacker. Vehicular communication systems face significant risks from distributed denial of service (DDoS) attacks. During a DDoS attack, multiple nodes are used to flood the target with an overwhelming amount of communication packets. In this paper, we first survey the current MDS literature and how it is used to detect and mitigate DDoS attacks. We then propose a new distributed multilayer perceptron classifier (MLPC) for DDoS detection and evaluate the performance of the proposed detection scheme in vehicular communication systems. For the evaluations using simulations, two specific implementations of the attacks are conducted. Apache Spark is then used to create the distributed MLPC. The median F1-score for this MLPC method was 95%. The proposed method outperformed linear regression and support vector machines, which achieved 89% and 88% respectively, but is unable to perform better than random forests and gradient boosted trees which both achieved a 97% F1-score. Using Amazon Web Services (AWS), it is determined that model training and detection time are not significantly increased with the inclusion of additional nodes after three nodes including the master.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICSPCS58109.2023.10261135
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174491837&doi=10.1109%2fICSPCS58109.2023.10261135&partnerID=40&md5=196e5656b21915352958a21fc8464764
DB  - Scopus
KW  - machine learning
KW  - Vehicle safety
KW  - Artificial neural networks
KW  - Neural networks
KW  - Support vector machines
KW  - Machine-learning
KW  - Web services
KW  - Network security
KW  - Denial-of-service attack
KW  - Denialof- service attacks
KW  - Communications systems
KW  - Distributed computer systems
KW  - vehicle safety
KW  - Networks security
KW  - Sensor nodes
KW  - Distributed denial of service
KW  - Vehicular communications
KW  - Vehicular networks
KW  - wireless sensor networks
KW  - distributed computing
KW  - vehicular communication networks
KW  - Vehicular Communication Networks
KW  - vehicular network security
KW  - Vehicular network security
ER  - 

TY  - JOUR
TI  - A closed-loop data-driven optimization framework for the unit commitment problem: A Q-learning approach under real-time operation
AU  - Jiménez, D.
AU  - Angulo, A.
AU  - Street, A.
AU  - Mancilla-David, F.
T2  - Applied Energy
AB  - Real-time operation of electric power systems under high penetration of renewable energy generation has to incorporate strategies for managing the uncertainty associated with this type of power sources. In the case of the unit commitment problem, models based on robust optimization have been widely used for the day-ahead computation of power dispatch and reserves schedule. Typical approaches use uncertainty sets with fixed levels of conservativeness, without considering the real-time performance of the solutions. This paper proposes a solution scheme for the adaptive robust unit commitment problem using online adjusted data-driven uncertainty sets. Conservativeness parameters of the uncertainty sets are dynamically calculated as a function of previous operating results and incoming data via reinforcement learning, resulting in an online learning-optimization framework. The paper also develops an experimental framework to simulate real-time operation under the proposed methodology. Out-of-sample experiments illustrate the effectiveness of the proposed scheme against well-known benchmarks with fixed robustness levels. Results show improvements in power generation costs, voltage violations, and use of reserves. Two systems of different sizes are analyzed, illustrating the scalability of the proposed approach. © 2022 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.apenergy.2022.120348
VL  - 330
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142689540&doi=10.1016%2fj.apenergy.2022.120348&partnerID=40&md5=06e51f8c8aac1c2890571603534b4e47
DB  - Scopus
KW  - Reinforcement learning
KW  - Internet
KW  - E-learning
KW  - Real time systems
KW  - Reinforcement learnings
KW  - experimental study
KW  - Uncertainty
KW  - Optimization
KW  - computer simulation
KW  - optimization
KW  - Robust optimization
KW  - uncertainty analysis
KW  - benchmarking
KW  - Renewable energy resources
KW  - Data driven
KW  - Electric load dispatching
KW  - Unit commitment
KW  - Unit Commitment
KW  - power generation
KW  - alternative energy
KW  - Data-driven uncertainty set
KW  - electrical power
KW  - Online optimization
KW  - Optimization framework
KW  - Real-time operation
KW  - Unit-commitment problems
ER  - 

TY  - JOUR
TI  - Predicting the Level of Safety Feeling of Bangladeshi Internet users using Data Mining and Machine Learning
AU  - Alam, M.S.
AU  - Roy, A.
AU  - Majumder, P.P.
AU  - Khushbu, S.A.
T2  - International Journal of Advanced Computer Science and Applications
AB  - An amazing combination of cutting-edge data mining and machine learning methodologies to predict the level of safety feeling among Bangladeshi internet users, which is a significant departure in this subject. By leveraging cutting-edge algorithms and innovative data sources, this work provides previously unheard-of insights into how this demographic perceives online safety, shedding light on an essential yet underappreciated aspect of their digital lives. This exceptional study's original research increases the body of knowledge of online safety and sets the road for policy recommendations and intervention tactics that will enable Bangladesh to become a global leader in internet security. © (2023), (Science and Information Organization). All Rights Reserved.
DA  - 2023///
PY  - 2023
DO  - 10.14569/IJACSA.2023.0140976
VL  - 14
IS  - 9
SP  - 725
EP  - 739
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173603605&doi=10.14569%2fIJACSA.2023.0140976&partnerID=40&md5=286f9e513998c96cab0673883beebb27
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Data mining
KW  - prediction
KW  - Machine-learning
KW  - Forecasting
KW  - data mining
KW  - Bangladesh
KW  - data analysis
KW  - Data-source
KW  - Cutting tools
KW  - Cutting edges
KW  - Performance evaluation metrics
KW  - Internet users
KW  - Edge data
KW  - Important factor
KW  - important factors
KW  - Level of safeties
KW  - performance evaluation metrics
KW  - safety level
KW  - Safety level
ER  - 

TY  - JOUR
TI  - From Regression to Classification: Fuzzy Multikernel Subspace Learning for Robust Prediction and Drug Screening
AU  - Quan, T.
AU  - Yuan, Y.
AU  - Luo, Y.
AU  - Song, Y.
AU  - Zhou, T.
AU  - Wang, J.
T2  - IEEE Transactions on Industrial Informatics
AB  - Data-driven machine learning is increasingly involved in human life and industrial development due to its large-scale testing and low time cost. However, existing learning algorithms are not suitable for real-world applications with data dilemmas, such as extremely high-dimension-low-sample-size problems, non-Gaussian noise, and uncertainty. In this article, we propose a novel fuzzy multikernel subspace learning (FMKSL) to address these problems, which provides a robust multikernel representation with a fuzzy constraint and sparse coding. We then develop an adaptive learner chain optimization method based on the iterative process of FMKSL to speed up learning and achieve the best performance. Different from previous methods, we also design a flexible data augmentation method, namely generalized correntropy-based adaptive data augmentation (GC-ADA), to effectively use the <inline-formula><tex-math notation="LaTeX">$\alpha$</tex-math></inline-formula>-order statistics between samples to transform the exact value prediction task into a simpler classification one. It is important that our general framework only needs an extremely small dataset to predict the related ranking of the sample since the exact label value measured by different institutions in reality varies largely. A typical scenario is the drug screening task, i.e., the inhibitory potency prediction of the nicotinamide phosphoribosyltransferase inhibitors. Extensive experiments on nine real-world datasets (four tasks) show that our framework outperforms state-of-the-art methods in prioritizing candidate samples and chemicals for experimental research and analysis via a data-driven computational approach. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TII.2023.3321332
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173445388&doi=10.1109%2fTII.2023.3321332&partnerID=40&md5=df8c2db357f495052fc6d8289733e5d5
DB  - Scopus
KW  - Machine learning
KW  - Task analysis
KW  - Training
KW  - Learning algorithms
KW  - Machine-learning
KW  - Classification (of information)
KW  - Forecasting
KW  - Robust
KW  - Costs
KW  - Iterative methods
KW  - Gaussian noise (electronic)
KW  - Data driven
KW  - Data augmentation
KW  - Data-driven machine learning
KW  - Drug
KW  - robust
KW  - Mathematical transformations
KW  - Subspace learning
KW  - Compound
KW  - Compounds
KW  - drug screening
KW  - Drug-screening
KW  - Drugs
KW  - Fuzzy multikernel subspace learning
KW  - fuzzy multikernel subspace learning (FMKSL)
KW  - Inhibitor
KW  - Inhibitors
KW  - Multi-kernel
ER  - 

TY  - JOUR
TI  - Robust learning from noisy web data for fine-Grained recognition
AU  - Cai, Z.
AU  - Xie, G.-S.
AU  - Huang, X.
AU  - Huang, D.
AU  - Yao, Y.
AU  - Tang, Z.
T2  - Pattern Recognition
AB  - Due to DNNs’ memorization effect, label noise lessens the performance of the web-supervised fine-grained visual categorization task. Previous literature primarily relies on small-loss instances for subsequent training. The current state-of-the-art approach JoCoR additionally employs explicit consistency constraints to make clean samples more confident. However, a joint loss designed for both sample selection criteria and parameter updating is not competent for training a robust model in the presence of web noise. Especially, false positives are assigned with larger weights, causing the model to pay more attention to misclassified noisy images. Besides, leveraging weight decay to forget discarded noisy instances is too slow and implicit to take effect. Therefore, we propose a simple yet effective approach named MS-DeJOR (Multi-Scale training with Decoupled Joint Optimization and Refurbishment). In contrast to JoCoR, we decouple sample selection from training procedure to handle the above problems. Specifically, a negative entropy term is applied to prevent false positives from being overemphasized. The model can explicitly forget those samples identified as noise by imposing such a regularization term on all training data. Furthermore, we use accumulated predictions to refurbish the noisy labels and re-weight training images to boost the model performance. A multi-scale feature enhancement module is adopted to extract discriminative and subtle feature representations. Extensive experiments show that MS-DeJOR yields state-of-the-art performances on three web-supervised fine-grained datasets, demonstrating the effectiveness of our approach. The data and source code have been available at https://github.com/msdejor/MS-DeJOR. © 2022 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.patcog.2022.109063
VL  - 134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139399952&doi=10.1016%2fj.patcog.2022.109063&partnerID=40&md5=cc4870143217ec5842e92992fb02f26d
DB  - Scopus
KW  - Performance
KW  - Robust learning
KW  - Multi-scales
KW  - Samples selection
KW  - HTTP
KW  - False positive
KW  - Fine grained
KW  - Fine-grained
KW  - Joint optimization
KW  - Noisy web data
KW  - Web data
KW  - Web-supervised
ER  - 

TY  - CONF
TI  - Towards Lightweight Data Integration Using Multi-Workflow Provenance and Data Observability
AU  - Souza, R.
AU  - Skluzacek, T.J.
AU  - Wilkinson, S.R.
AU  - Ziatdinov, M.
AU  - Da Silva, R.F.
T2  - Proceedings 2023 IEEE 19th International Conference on e-Science, e-Science 2023
AB  - Modern large-scale scientific discovery requires multidisciplinary collaboration across diverse computing facilities, including High Performance Computing (HPC) machines and the Edge-to-Cloud continuum. Integrated data analysis plays a crucial role in scientific discovery, especially in the current AI era, by enabling Responsible AI development, FAIR, Reproducibility, and User Steering. However, the heterogeneous nature of science poses challenges such as dealing with multiple supporting tools, cross-facility environments, and efficient HPC execution. Building on data observability, adapter system design, and provenance, we propose MIDA: an approach for lightweight runtime Multi-workflow Integrated Data Analysis. MIDA defines data observability strategies and adaptability methods for various parallel systems and machine learning tools. With observability, it intercepts the dataflows in the background without requiring instrumentation while integrating domain, provenance, and telemetry data at runtime into a unified database ready for user steering queries. We conduct experiments showing end-to-end multi-workflow analysis integrating data from Dask and MLFlow in a real distributed deep learning use case for materials science that runs on multiple environments with up to 276 GPUs in parallel. We show near-zero overhead running up to 100,000 tasks on 1,680 CPU cores on the Summit supercomputer.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/e-Science58273.2023.10254822
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174251062&doi=10.1109%2fe-Science58273.2023.10254822&partnerID=40&md5=e3de59a245bcdab77c390b7eac94e125
DB  - Scopus
KW  - Explainability
KW  - Deep learning
KW  - Deep Learning
KW  - Machine Learning
KW  - Learning systems
KW  - Machine-learning
KW  - Responsible AI
KW  - Query languages
KW  - Information analysis
KW  - Data integration
KW  - Work-flows
KW  - Program processors
KW  - Adaptability
KW  - Cross-facility
KW  - Dask
KW  - Data Integration
KW  - Data observability
KW  - Data Observability
KW  - Lineage
KW  - Observability
KW  - Provenance
KW  - Supercomputers
KW  - Workflows
ER  - 

TY  - CONF
TI  - Towards Robust and Safe Reinforcement Learning with Benign Off-policy Data
AU  - Liu, Z.
AU  - Guo, Z.
AU  - Cen, Z.
AU  - Zhang, H.
AU  - Yao, Y.
AU  - Hu, H.
AU  - Zhao, D.
T2  - Proceedings of Machine Learning Research
AB  - Previous work demonstrates that the optimal safe reinforcement learning policy in a noise-free environment is vulnerable and could be unsafe under observational attacks. While adversarial training effectively improves robustness and safety, collecting samples by attacking the behavior agent online could be expensive or prohibitively dangerous in many applications. We propose the robuSt vAriational ofF-policy lEaRning (SAFER) approach, which only requires benign training data without attacking the agent. SAFER obtains an optimal non-parametric variational policy distribution via convex optimization and then uses it to improve the parameterized policy robustly via supervised learning. The two-stage policy optimization facilitates robust training, and extensive experiments on multiple robot platforms show the efficiency of SAFER in learning a robust and safe policy: achieving the same reward with much fewer constraint violations during training than on-policy baselines. © 2023 Proceedings of Machine Learning Research. All rights reserved.
DA  - 2023///
PY  - 2023
VL  - 202
SP  - 22249
EP  - 22265
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174408788&partnerID=40&md5=6463a867d47c3f19ff2fbca9a27362f9
DB  - Scopus
KW  - Reinforcement learning
KW  - Training data
KW  - Reinforcement learnings
KW  - Convex optimization
KW  - Policy learning
KW  - Learning policy
KW  - Convex optimisation
KW  - Parameterized
KW  - Behavior agents
KW  - Noise-free environments
KW  - Nonparametrics
KW  - Policy distribution
ER  - 

TY  - JOUR
TI  - Domain Generalization in Machine Learning Models for Wireless Communications: Concepts, State-of-the-Art, and Open Issues
AU  - Akrout, M.
AU  - Feriani, A.
AU  - Bellili, F.
AU  - Mezghani, A.
AU  - Hossain, E.
T2  - IEEE Communications Surveys and Tutorials
AB  - Data-driven machine learning (ML) is promoted as one potential technology to be used in next-generation wireless systems. This led to a large body of research work that applies ML techniques to solve problems in different layers of the wireless transmission link. However, most of these applications rely on supervised learning which assumes that the source (training) and target (test) data are independent and identically distributed (i.i.d). This assumption is often violated in the real world due to domain or distribution shifts between the source and the target data. Thus, it is important to ensure that these algorithms generalize to out-of-distribution (OOD) data. In this context, domain generalization (DG) tackles the OOD-related issues by learning models on different and distinct source domains/datasets with generalization capabilities to unseen new domains without additional finetuning. Motivated by the importance of DG requirements for wireless applications, we present a comprehensive overview of the recent developments in DG and the different sources of domain shift. We also summarize the existing DG methods and review their applications in selected wireless communication problems, and conclude with insights and open questions. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/COMST.2023.3326399
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174810153&doi=10.1109%2fCOMST.2023.3326399&partnerID=40&md5=346a11b663a9016c7ac976240d0fed87
DB  - Scopus
KW  - Tutorials
KW  - Machine learning
KW  - Training
KW  - Learning systems
KW  - Supervised learning
KW  - Transfer learning
KW  - Machine-learning
KW  - Surveys
KW  - Robustness
KW  - Generalisation
KW  - Out-of-distribution generalization
KW  - Wireless networks
KW  - Domain generalization
KW  - Machine learning-aided wireless network
KW  - ML-aided wireless networks
KW  - Tutorial
ER  - 

TY  - JOUR
TI  - A Combination of Transfer Learning and Support Vector Machine for Robust Classification on Small Weed and Potato Datasets
AU  - Adhinata, F.D.
AU  - Ramadhan, N.G.
AU  - Fauzi, M.D.
AU  - Ferani Tanjung, N.A.
T2  - International Journal on Informatics Visualization
AB  - Agriculture is the primary sector in Indonesia for meeting people's daily food demands. One of the agricultural commodities that replace rice is potatoes. Potato growth needs to be protected from weeds that compete for nutrients. Spraying using pesticides can cause environmental pollution, affecting cultivated plants. Currently, smart agriculture is being developed using an Artificial Intelligence (AI) approach to classifying crops. The classification process using AI depends on the number of datasets obtained. The number of datasets obtained in this research is not too large, so it requires a particular approach regarding the AI method used. This research aims to use a combination of feature extraction methods with local and deep feature approaches with supervised machine learning to classify small datasets. The local feature method used in this research is Local Binary Pattern (LBP) and Histogram of Oriented Gradients (HOG), while the deep feature method used is MobileNet and MobileNetV2. The famous Support Vector Machine (SVM) uses the classification method to separate two data classes. The experimental results showed that the local feature HOG method was the fastest in the training process. However, the most accurate result was using the MobileNetV2 deep feature method with an accuracy of 98%. Deep features produced the best accuracy because the feature extraction process went through many neural network layers. This research can provide insight into how to analyze a small number of datasets by combining several strategies. © 2023, Politeknik Negeri Padang. All rights reserved.
DA  - 2023///
PY  - 2023
DO  - 10.30630/joiv.7.2.1164
VL  - 7
IS  - 2
SP  - 535
EP  - 541
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166090354&doi=10.30630%2fjoiv.7.2.1164&partnerID=40&md5=bbe00e1d4e7ecdb5dcdd78a3af619c33
DB  - Scopus
KW  - machine learning
KW  - local and deep feature
KW  - potatoes
KW  - small dataset
KW  - Smart agriculture
KW  - weed
ER  - 

TY  - JOUR
TI  - MANGEM: A web app for multimodal analysis of neuronal gene expression, electrophysiology, and morphology
AU  - Olson, R.H.
AU  - Cohen Kalafut, N.
AU  - Wang, D.
T2  - Patterns
AB  - Single-cell techniques like Patch-seq have enabled the acquisition of multimodal data from individual neuronal cells, offering systematic insights into neuronal functions. However, these data can be heterogeneous and noisy. To address this, machine learning methods have been used to align cells from different modalities onto a low-dimensional latent space, revealing multimodal cell clusters. The use of those methods can be challenging without computational expertise or suitable computing infrastructure for computationally expensive methods. To address this, we developed a cloud-based web application, MANGEM (multimodal analysis of neuronal gene expression, electrophysiology, and morphology). MANGEM provides a step-by-step accessible and user-friendly interface to machine learning alignment methods of neuronal multimodal data. It can run asynchronously for large-scale data alignment, provide users with various downstream analyses of aligned cells, and visualize the analytic results. We demonstrated the usage of MANGEM by aligning multimodal data of neuronal cells in the mouse visual cortex. © 2023 The Authors
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.patter.2023.100847
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174066501&doi=10.1016%2fj.patter.2023.100847&partnerID=40&md5=59555a831ae77dc25a9b9ac3312b7a68
DB  - Scopus
KW  - Machine learning
KW  - Neurons
KW  - Machine-learning
KW  - Manifold learning
KW  - Gene expression
KW  - Cloud-based
KW  - Electrophysiology
KW  - Cross-modal
KW  - web application
KW  - WEB application
KW  - Web applications
KW  - Cytology
KW  - Single cells
KW  - Multiple domains
KW  - Production data
KW  - Morphology
KW  - gene expression
KW  - Modal analysis
KW  - Asynchronoi computation
KW  - asynchronous computation
KW  - Cell clusters
KW  - Cell phenotype
KW  - cloud-based machine learning
KW  - Cloud-based machine learning
KW  - Cross-modal cell cluster and phenotype
KW  - cross-modal cell clusters and phenotypes
KW  - Data alignments
KW  - DSML 4: production: data science output be validated, understand, and regularly used for multiple domain/platform
KW  - DSML 4: Production: Data science output is validated, understood, and regularly used for multiple domains/platforms
KW  - Genes expression
KW  - manifold learning
KW  - Multi-modal data
KW  - Multi-modality
KW  - multimodal data alignment
KW  - Multimodal data alignment
KW  - neuronal electrophysiology and morphology
KW  - Neuronal electrophysiology and morphology
KW  - Patch-seq analyse
KW  - patch-seq analysis
KW  - single-cell multimodalities
KW  - Single-cell multimodality
ER  - 

TY  - JOUR
TI  - Distributionally robust end-to-end portfolio construction
AU  - Costa, G.
AU  - Iyengar, G.N.
T2  - Quantitative Finance
AB  - We propose an end-to-end distributionally robust system for portfolio construction that integrates the asset return prediction model with a distributionally robust portfolio optimization model. We also show how to learn the risk-tolerance parameter and the degree of robustness directly from data. End-to-end systems have an advantage in that information can be communicated between the prediction and decision layers during training, allowing the parameters to be trained for the final task rather than solely for predictive performance. However, existing end-to-end systems are not able to quantify and correct for the impact of model risk on the decision layer. Our proposed distributionally robust end-to-end portfolio selection system explicitly accounts for the impact of model risk. The decision layer chooses portfolios by solving a minimax problem where the distribution of the asset returns is assumed to belong to an ambiguity set centered around a nominal distribution. Using convex duality, we recast the minimax problem in a form that allows for efficient training of the end-to-end system. © 2023 Informa UK Limited, trading as Taylor & Francis Group.
DA  - 2023///
PY  - 2023
DO  - 10.1080/14697688.2023.2236148
VL  - 23
IS  - 10
SP  - 1465
EP  - 1482
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171160499&doi=10.1080%2f14697688.2023.2236148&partnerID=40&md5=537f7f8201b13a5869bf3006214bd02e
DB  - Scopus
KW  - Machine learning
KW  - Distributionally robust optimization
KW  - Portfolio optimization
KW  - Asset allocation
KW  - Statistical ambiguity
ER  - 

TY  - CONF
TI  - Improving Machine Learning Robustness via Adversarial Training
AU  - Dang, L.
AU  - Hapuarachchi, T.
AU  - Xiong, K.
AU  - Lin, J.
T2  - Proceedings - International Conference on Computer Communications and Networks, ICCCN
AB  - As Machine Learning (ML) is increasingly used in solving various tasks in real-world applications, it is crucial to ensure that ML algorithms are robust to any potential worst-case noises, adversarial attacks, and highly unusual situations when they are designed. Studying ML robustness will significantly help in the design of ML algorithms. In this paper, we investigate ML robustness using adversarial training in centralized and decentralized environments, where ML training and testing are conducted in one or multiple computers. In the centralized environment, we achieve a test accuracy of 65.41% and 83.0% when classifying adversarial examples generated by Fast Gradient Sign Method and DeepFool, respectively. Comparing to existing studies, these results demonstrate an improvement of 18.41% for FGSM and 47% for DeepFool. In the decentralized environment, we study Federated learning (FL) robustness by using adversarial training with independent and identically distributed (IID) and non-IID data, respectively, where CIFAR-10 is used in this research. In the IID data case, our experimental results demonstrate that we can achieve such a robust accuracy that it is comparable to the one obtained in the centralized environment. Moreover, in the non-IID data case, the natural accuracy drops from 66.23% to 57.82%, and the robust accuracy decreases by 25% and 23.4% in C&W and Projected Gradient Descent (PGD) attacks, compared to the IID data case, respectively. We further propose an IID data-sharing approach, which allows for increasing the natural accuracy to 85.04% and the robust accuracy from 57% to 72% in C&W attacks and from 59% to 67% in PGD attacks. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICCCN58024.2023.10230138
VL  - 2023-July
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173587747&doi=10.1109%2fICCCN58024.2023.10230138&partnerID=40&md5=39307fd66c57626e402a9a0ca5cad66b
DB  - Scopus
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Machine-learning
KW  - Computer vision
KW  - Gradient methods
KW  - Federated learning
KW  - Projected gradient
KW  - Adversarial training
KW  - Decentralised
KW  - Centralised
KW  - Distributed data
KW  - Independent and identically distributed  and non-identically distributed data
KW  - Independent and identically distributed (IID) and non-IID data
KW  - Machine learning robustness
ER  - 

TY  - JOUR
TI  - ImageNet-Patch: A dataset for benchmarking machine learning robustness against adversarial patches
AU  - Pintor, M.
AU  - Angioni, D.
AU  - Sotgiu, A.
AU  - Demetrio, L.
AU  - Demontis, A.
AU  - Biggio, B.
AU  - Roli, F.
T2  - Pattern Recognition
AB  - Adversarial patches are optimized contiguous pixel blocks in an input image that cause a machine-learning model to misclassify it. However, their optimization is computationally demanding, and requires careful hyperparameter tuning, potentially leading to suboptimal robustness evaluations. To overcome these issues, we propose ImageNet-Patch, a dataset to benchmark machine-learning models against adversarial patches. The dataset is built by first optimizing a set of adversarial patches against an ensemble of models, using a state-of-the-art attack that creates transferable patches. The corresponding patches are then randomly rotated and translated, and finally applied to the ImageNet data. We use ImageNet-Patch to benchmark the robustness of 127 models against patch attacks, and also validate the effectiveness of the given patches in the physical domain (i.e., by printing and applying them to real-world objects). We conclude by discussing how our dataset could be used as a benchmark for robustness, and how our methodology can be generalized to other domains. We open source our dataset and evaluation code at https://github.com/pralab/ImageNet-Patch. © 2022 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.patcog.2022.109064
VL  - 134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139413180&doi=10.1016%2fj.patcog.2022.109064&partnerID=40&md5=f0d3dad8a0bffeda87d509e7b5c937c3
DB  - Scopus
KW  - Machine learning
KW  - Neural networks
KW  - Detection
KW  - Machine-learning
KW  - Open source software
KW  - Machine learning models
KW  - Optimisations
KW  - Neural-networks
KW  - Adversarial machine learning
KW  - Hyper-parameter
KW  - Defense
KW  - Adversarial patch
KW  - Adversarial patches
KW  - Input image
KW  - Open systems
ER  - 

TY  - JOUR
TI  - Trade-Off Between Robustness and Rewards Adversarial Training for Deep Reinforcement Learning Under Large Perturbations
AU  - Huang, J.
AU  - Choi, H.J.
AU  - Figueroa, N.
T2  - IEEE Robotics and Automation Letters
AB  - Deep Reinforcement Learning (DRL) has become a popular approach for training robots due to its generalization promise, complex task capacity and minimal human intervention. Nevertheless, DRL-trained controllers are vulnerable to even the smallest of perturbations on its inputs which can lead to catastrophic failures in real-world human-centric environments with large and unexpected perturbations. In this work, we study the vulnerability of state-of-the-art DRL subject to large perturbations and propose a novel adversarial training framework for robust control. Our approach generates aggressive attacks on the state space and the expected state-action values to emulate real-world perturbations such as sensor noise, perception failures, physical perturbations, observations mismatch, etc. To achieve this, we reformulate the adversarial risk to yield a trade-off between rewards and robustness (TBRR). We show that TBRR-aided DRL training is robust to aggressive attacks and outperforms baselines on standard DRL benchmarks (Cartpole, Pendulum), Meta-World tasks (door manipulation) and a vision-based grasping task with a 7DoF manipulator. Finally, we show that the vision-based grasping task trained in simulation via TBRR transfers sim2real with 70&#x0025; success rate subject to sensor impairment and physical perturbations without any retraining. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/LRA.2023.3324590
SP  - 1
EP  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174857468&doi=10.1109%2fLRA.2023.3324590&partnerID=40&md5=f15018515890d511f2c18b2b4c137e5a
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robots
KW  - Training
KW  - Perturbation methods
KW  - Standards
KW  - Reinforcement learnings
KW  - Economic and social effects
KW  - Risk perception
KW  - Human robot interaction
KW  - Real-world
KW  - Robustness
KW  - Robust control
KW  - Trade off
KW  - Perturbation method
KW  - Perturbation techniques
KW  - Generalisation
KW  - Complex task
KW  - Robot sensing system
KW  - Vision-based grasping
ER  - 

TY  - CONF
TI  - Extraction of Ship Route Using Gaussian Process Regression for Passenger Ships
AU  - Liu, Z.
AU  - Gong, Z.
AU  - Zhang, M.
AU  - Wang, X.
AU  - Yang, Q.
AU  - Wang, H.
T2  - 7th IEEE International Conference on Transportation Information and Safety, ICTIS 2023
AB  - The extraction of passenger ship routes plays a crucial role in managing and regulating passenger ship traffic and ensuring safe navigation. This paper proposes a novel method for extracting passenger ship routes based on the Gaussian process regression (GPR) model. The method utilizes the Automatic Identification System (AIS) data to obtain the berthing trajectory segments based on the behavioral characteristics of ships. Next, the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) method is used to identify the berthing areas. The passenger ship trajectories are divided based on the identified berthing areas and are classified into different trajectory clusters based on their departure and arrival zones. The trajectory length and geographic coordinates (longitude and latitude) are modeled separately, and the GPR is employed to extract the trajectory centerline by aggregating the posterior distribution of the functions. The proposed method is evaluated by experimentation, which demonstrates its effectiveness in estimating the trajectory centerline more accurately. The research findings provide valuable support for designing and optimizing passenger ship routes and enhancing safety management.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICTIS60134.2023.10243761
SP  - 1720
EP  - 1727
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174239696&doi=10.1109%2fICTIS60134.2023.10243761&partnerID=40&md5=c0cb7adae69e957a0cab3a9277cdd6fc
DB  - Scopus
KW  - Machine learning
KW  - Automation
KW  - Machine-learning
KW  - Regression analysis
KW  - Traffic safety
KW  - Extraction
KW  - Ships
KW  - Trajectories
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Gaussian process regression
KW  - AIS data
KW  - Automatic identification system
KW  - Automatic identification system data
KW  - Centerlines
KW  - Passenger ships
KW  - Ship routes
KW  - Ship traffic
KW  - Trajectory centerline
ER  - 

TY  - CONF
TI  - Data Analytics for Athlete Safety in Training
AU  - Prayaga, C.
AU  - Prayaga, L.
AU  - Wade, A.
AU  - Chamblee, J.
AU  - Rank, K.
T2  - Lecture Notes in Electrical Engineering
AB  - Data Analytics for Athlete Safety in Training (DFAST) is a system designed to improve performance and safety in athlete training. Wearable devices on the athlete send real-time data on movement, accelerations, rotations, heartrate, etc., to the system during workout. The system uses machine learning to analyze the data and send back real-time alerts to the athlete via the wearable device so that the athlete can correct posture and technique, thereby increasing safety. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-981-99-2058-7_4
VL  - 1038 LNEE
SP  - 31
EP  - 38
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172247575&doi=10.1007%2f978-981-99-2058-7_4&partnerID=40&md5=3525126604808d56f9aa0ea24acce1f0
DB  - Scopus
KW  - Safety
KW  - Machine learning
KW  - Data analytics
KW  - Machine-learning
KW  - Real- time
KW  - Data Analytics
KW  - Real-time data
KW  - System use
KW  - Improve performance
KW  - Heart-rate
KW  - Wearable devices
KW  - Wearable technology
KW  - Sports
KW  - Athlete training
ER  - 

TY  - JOUR
TI  - Attention-based Highway Safety Planner for Autonomous Driving via Deep Reinforcement Learning
AU  - Chen, G.
AU  - Zhang, Y.
AU  - Li, X.
T2  - IEEE Transactions on Vehicular Technology
AB  - In this paper, a motion planning for autonomous driving on highway is studied. A high-level motion planning controller with discrete action space is designed based on deep Q network (DQN). An occupancy grid based state presentation aiming at specific scenarios is proposed and then a novel attention mechanism named external spatial attention (ESA) is designed for occupancy grid to improve the network performance. Con-sidering both computational complexity and interpretability, a lightweight data-driven safety layer consisting of two-dimensional linear biased support vector machine (2D-LBSVM) is proposed to improve safety. The advantages of this controller and the role of each module are illustrated by experiments. In addition, the superior performance of occupancy grid state and the interpretability of safety layer are further analyzed. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TVT.2023.3304530
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167804766&doi=10.1109%2fTVT.2023.3304530&partnerID=40&md5=c5f06af5cc551a16db5a9f5bb44e8ed6
DB  - Scopus
KW  - Deep learning
KW  - Autonomous vehicles
KW  - Safety
KW  - Planning
KW  - Vehicle dynamics
KW  - Trajectory
KW  - Training
KW  - safety layer
KW  - attention
KW  - deep reinforcement learn-ing
ER  - 

TY  - CONF
TI  - Alignment Offset Based Adaptive Training for Simultaneous Machine Translation
AU  - Liang, Q.
AU  - Liu, Y.
AU  - Meng, F.
AU  - Xu, J.
AU  - Chen, Y.
AU  - Zhou, J.
T2  - Proceedings - 2023 5th International Conference on Natural Language Processing, ICNLP 2023
AB  - Given incomplete source sentences as inputs, it is generally difficult for Simultaneous Machine Translation (SiMT) models to generate a target token once its aligned source tokens are absent. How to measure such difficulty and further conduct adaptive training for SiMT models are not sufficiently studied. In this paper, we propose a new metric named alignment offset (AO) to quantify the learning difficulty of target tokens for SiMT models. Given a target token, its AO is calculated by the offset between its aligned source tokens and the already received source tokens. Furthermore, we design two AO-based adaptive training methods to improve the training of SiMT models. Firstly, we introduce token-level curriculum learning based on AO, which progressively switches the training process from easy target tokens to difficult ones. Secondly, we assign an appropriate weight to the training loss of each target token according to its AO. Experimental results on four datasets demonstrate that our methods significantly and consistently outperform all the strong baselines.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICNLP58431.2023.00035
SP  - 157
EP  - 164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173006022&doi=10.1109%2fICNLP58431.2023.00035&partnerID=40&md5=dba04e6982cdb205cd2c3263dab34728
DB  - Scopus
KW  - Learning systems
KW  - Alignment
KW  - Training methods
KW  - Training process
KW  - Computational linguistics
KW  - Curricula
KW  - Adaptive training
KW  - Machine translation
KW  - Computer aided language translation
KW  - Machine translations
KW  - Adaptive Training
KW  - Curriculum learning
KW  - Curriculum Learning
KW  - Learning difficulties
KW  - Machine translation models
KW  - Simultaneous machine translation
KW  - Simultaneous Machine Translation
ER  - 

TY  - CONF
TI  - DHC-R: Evaluating “Distributed Heuristic Communication” and Improving Robustness for Learnable Decentralized PO-MAPF
AU  - Savinov, V.
AU  - Yakovlev, K.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Multi-agent pathfinding (MAPF) is a problem of coordinating the movements of multiple agents operating a shared environment that has numerous industrial and research applications. In many practical cases the agents (robots) have limited visibility of the environment and must rely on local observations to make decisions. This scenario, known as partially observable MAPF (PO-MAPF), can be solved through decentralized approaches. In recent years, several learnable algorithms have been proposed for solving PO-MAPF. However, their performance is oftentimes not validated out-of-distribution (OOD), and the code is often not properly open-sourced. In this study, we conduct a comprehensive empirical evaluation of one of the state-of-the-art decentralized PO-MAPF algorithms, Distributed Heuristic Communication (DHC), Ma, Z., Luo, Y., Ma, H.: Distributed heuristic multi-agent path finding with communication. In: 2021 International Conference on Robotics and Automation (ICRA), pp. 8699–8705. IEEE, Xi’an, China (2021), which incorporates communication between agents. Our experiments reveal that the performance of DHC deteriorates when agents encounter complete packet loss during communication. To address this issue, we propose a novel algorithm called DHC-R that employs a similar architecture to the original DHC but introduces randomness into the graph neural network-based communication block, preventing the passage of some data packets during training. Empirical evaluation confirms that DHC-R outperforms DHC in scenarios with packet loss. Open-sourced model weights and the codebase are provided: https://github.com/acforvs/dhc-robust-mapf. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-43111-1_14
VL  - 14214 LNAI
SP  - 151
EP  - 163
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172274932&doi=10.1007%2f978-3-031-43111-1_14&partnerID=40&md5=a6ade7af7a3ffe92aafe4983b3783eb1
DB  - Scopus
KW  - Reinforcement learning
KW  - Robotics
KW  - Performance
KW  - Reinforcement learnings
KW  - Multi agent systems
KW  - Industrial research
KW  - Heuristic algorithms
KW  - Multi agent
KW  - Reinforcement Learning
KW  - Generalization
KW  - AI safety
KW  - Generalisation
KW  - Decentralised
KW  - Path finding
KW  - Out-of-distribution
KW  - Distributed heuristics
KW  - Packet loss
KW  - Partially observable MAPF
KW  - PO-MAPF
ER  - 

TY  - JOUR
TI  - Semantic Data Type Detection via Machine Learning using Semi-synthetic Data and Robust Features
AU  - Chevallier, M.
AU  - Rogovschi, N.
AU  - Boufarès, F.
AU  - Grozavu, N.
T2  - International Journal of Computer Information Systems and Industrial Management Applications
AB  - Being able to automatically identify the semantic type of tabular data is a useful feature in many areas of the data landscape. This information is especially important for data integration, data science, and data cleaning. Traditional semantic type detection tools based on dictionaries and regular expressions have recently been challenged by methods using machine learning. These new methods are very efficient but require a large amount of data to learn, which limits the use of these methods to semantic types and languages for which a large amount of data is available. To overcome these drawbacks, we introduce a data generation method to produce training data with minimal real data. In addition, we propose several new feature extraction methods that are less dependent on column length, language independent (for a given alphabet) and robust to errors in the data. Experiments conducted on synthetic and real data indicate an accuracy higher than 0.9 which is equivalent to classical methods. © MIR Labs, www.mirlabs.net/ijcisim/index.html
DA  - 2023///
PY  - 2023
VL  - 15
IS  - 2023
SP  - 489
EP  - 499
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167920982&partnerID=40&md5=0d95f8bab9d5cad662be2cf8fbb61c9e
DB  - Scopus
KW  - Machine learning
KW  - Tabular data
KW  - Data Profiling
KW  - Knowledge discovery
KW  - Semantic types
KW  - Type detection
ER  - 

TY  - JOUR
TI  - Graph Adversarial Immunization for Certifiable Robustness
AU  - Tao, S.
AU  - Cao, Q.
AU  - Shen, H.
AU  - Wu, Y.
AU  - Hou, L.
AU  - Cheng, X.
T2  - IEEE Transactions on Knowledge and Data Engineering
AB  - Despite achieving great success, graph neural networks (GNNs) are vulnerable to adversarial attacks. Existing defenses focus on developing adversarial training or model modification. In this paper, we propose and formulate <italic>graph adversarial immunization</italic>, i.e., vaccinating part of graph structure to improve certifiable robustness of graph against any admissible adversarial attack. We first propose edge-level immunization to vaccinate node pairs. Unfortunately, such edge-level immunization cannot defend against emerging node injection attacks, since it only immunizes existing node pairs. To this end, we further propose node-level immunization. To avoid computationally intensive combinatorial optimization associated with adversarial immunization, we develop <italic>AdvImmune-Edge</italic> and <italic>AdvImmune-Node</italic> algorithms to effectively obtain the immune node pairs or nodes. Extensive experiments demonstrate the superiority of AdvImmune methods. In particular, AdvImmune-Node remarkably improves the ratio of robust nodes by 79<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula>, 294<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula>, and 100<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula>, after immunizing only 5<inline-formula><tex-math notation="LaTeX">$\%$</tex-math></inline-formula> of nodes. Furthermore, AdvImmune methods show excellent defensive performance against various attacks, outperforming state-of-the-art defenses. To the best of our knowledge, this is the first attempt to improve certifiable robustness from graph data perspective without losing performance on clean graphs, providing new insights into graph adversarial learning. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TKDE.2023.3311105
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170515688&doi=10.1109%2fTKDE.2023.3311105&partnerID=40&md5=0e443cca0df9a3c6816b3b2053b5f75f
DB  - Scopus
KW  - Task analysis
KW  - Training
KW  - Job analysis
KW  - Machine-learning
KW  - Optimisations
KW  - Optimization
KW  - Robustness
KW  - Adversarial attack
KW  - Graph neural networks
KW  - Adversarial machine learning
KW  - Graph theory
KW  - Adversarial Attack
KW  - Combinatorial optimization
KW  - Adversarial immunization
KW  - Adversarial Immunization
KW  - Bars
KW  - Certifiable robustness
KW  - Certifiable Robustness
KW  - Graph Neural Networks
KW  - Immunization
KW  - Node classification
KW  - Node Classification
ER  - 

TY  - JOUR
TI  - A Novel Robust Meta-Model Framework for Predicting Crop Yield Probability Distributions Using Multisource Data
AU  - Ermolieva, T.
AU  - Havlík, P.
AU  - Lessa-Derci-Augustynczik, A.
AU  - Boere, E.
AU  - Frank, S.
AU  - Kahil, T.
AU  - Wang, G.
AU  - Balkovič, J.
AU  - Skalský, R.
AU  - Folberth, C.
AU  - Komendantova, N.
AU  - Knopov, P.S.
T2  - Cybernetics and Systems Analysis
AB  - There is an urgent need to better understand and predict crop yield responses to weather disturbances, in particular, of extreme nature, such as heavy precipitation events, droughts, and heat waves, to improve future crop production projections under weather variability, extreme events, and climate change. In this paper, we develop quantile regression models for estimating crop yield probability distributions depending on monthly temperature and precipitation values and soil quality characteristics, which can be made available for different climate change projections. Crop yields, historical and those simulated by the EPIC model, are analyzed and distinguished according to their levels, i.e., mean and critical quantiles. Then, the crop yield quantiles are approximated by fitting separate quantile-based regression models. The developed statistical crop yield meta-model enables the analysis of crop yields and respective probabilities of their occurrence as a function of the exogenous parameters such as temperature and precipitation and endogenous, in general, decision-dependent parameters (such as soil characteristics), which can be altered by land use practices. Statistical and machine learning models can be used as reduced form scenario generators (meta-models) of stochastic events (scenarios), as a submodel of more complex models, e.g., Integrated Assessment model (IAM) GLOBIOM. © 2023, Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s10559-023-00620-z
VL  - 59
IS  - 5
SP  - 844
EP  - 858
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173566911&doi=10.1007%2fs10559-023-00620-z&partnerID=40&md5=c525faa9b91af3c8d319798bc3ff234d
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Regression analysis
KW  - Robust estimation
KW  - climate change
KW  - Climate change
KW  - Stochastic models
KW  - Stochastic systems
KW  - Probability distributions
KW  - Land use
KW  - Probability: distributions
KW  - Food security
KW  - Climate models
KW  - Crops
KW  - Cultivation
KW  - Quantile regression
KW  - Extreme events
KW  - Crop yield
KW  - Crop yield projection
KW  - crop yields projections
KW  - extreme events
KW  - food security
KW  - Food supply
KW  - probability distributions
KW  - quantile regressions
KW  - robust estimation and machine learning
KW  - Robust estimation and machine learning
KW  - two-stage STO
KW  - Two-stage STO
ER  - 

TY  - JOUR
TI  - Integrating Inverse Data Envelopment Analysis and Machine Learning for Enhanced Road Transport Safety in Iran
AU  - Tabatabai, S.M.
AU  - Tabatabai, F.A.-S.
T2  - Journal of Soft Computing in Civil Engineering
AB  - The purpose of this research is to present a new method for considering accidents according to the environmental, traffic and geometrical conditions of the road, which considers accidents according to the interaction of the components that lead to them. In order to enter the physical characteristics, this approach divides the road into units or parts with homogeneous physical characteristics, and as a result, the decision about the safety status of the road is made for a length of road with specific characteristics instead of a single point. This approach has been carried out using the Data Envelopment Analysis (DEA) method, which, unlike regression methods, does not require obtaining the distribution function and considering hypotheses about it. This method gives scores (inefficiencies) that allow road segments to be appropriately ranked and prioritized in terms of accident proneness. In the current research, a case study was conducted on routes with a length of 144.4 kilometers, which resulted in the identification of 154 road sections with different relative risk scores, thus the accident sections were identified and prioritized with the proposed method, which in terms of the definition of entry indicators and the output based on the data coverage analysis method is considered as a new experience for the priority of road sections. Furthermore, this study focuses on the application of artificial neural networks (ANNs) in analyzing road safety. An idealized ANN model is developed using a database of various input parameters related to road segments, and the weighted index of accidents as the target variable. The results reveal the relative importance of different parameters on the weighted index, with the Ratio of curvature, Length of the segment, and Condition of the pavement identified as the most influential factors. These findings highlight the significance of road curvature, segment length, and pavement condition in determining accident severity. The study underscores the potential of ANNs for assessing road safety and informs targeted interventions to mitigate accidents. © 2023 The Authors.
DA  - 2024///
PY  - 2024
DO  - 10.22115/SCCE.2023.399661.1657
VL  - 8
IS  - 1
SP  - 141
EP  - 160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169147066&doi=10.22115%2fSCCE.2023.399661.1657&partnerID=40&md5=5748eac18ce0c0d3e01fdfb6a656b6c4
DB  - Scopus
KW  - ANN
KW  - Sensitivity analysis
KW  - DEA
KW  - Inefficiency
KW  - Risk scores
KW  - Safety status
ER  - 

TY  - JOUR
TI  - Saliency-Aided Online RPCA for Moving Target Detection in Infrared Maritime Scenarios
AU  - Pulpito, O.
AU  - Acito, N.
AU  - Diani, M.
AU  - Ferri, G.
AU  - Grasso, R.
AU  - Zissis, D.
T2  - Sensors
AB  - Moving target detection (MTD) is a crucial task in computer vision applications. In this paper, we investigate the problem of detecting moving targets in infrared (IR) surveillance video sequences captured using a steady camera in a maritime setting. For this purpose, we employ robust principal component analysis (RPCA), which is an improvement of principal component analysis (PCA) that separates an input matrix into the following two matrices: a low-rank matrix that is representative, in our case study, of the slowly changing background, and a sparse matrix that is representative of the foreground. RPCA is usually implemented in a non-causal batch form. To pursue a real-time application, we tested an online implementation, which, unfortunately, was affected by the presence of the target in the scene during the initialization phase. Therefore, we improved the robustness by implementing a saliency-based strategy. The advantages offered by the resulting technique, which we called “saliency-aided online moving window RPCA” (S-OMW-RPCA) are the following: RPCA is implemented online; along with the temporal features exploited by RPCA, the spatial features are also taken into consideration by using a saliency filter; the results are robust against the condition of the scene during the initialization. Finally, we compare the performance of the proposed technique in terms of precision, recall, and execution time with that of an online RPCA, thus, showing the effectiveness of the saliency-based approach. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/s23146334
VL  - 23
IS  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166017275&doi=10.3390%2fs23146334&partnerID=40&md5=9232b997143ec8c60d48bfcc5a577b79
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - E-learning
KW  - Machine-learning
KW  - Principal component analysis
KW  - Real- time
KW  - Security systems
KW  - Data driven
KW  - Robust principal component analysis
KW  - real time
KW  - robust principal component analysis
KW  - Infrared image
KW  - Infrared imaging
KW  - automatic surveillance
KW  - Automatic surveillance
KW  - data driven
KW  - infrared images
KW  - maritime scenario
KW  - Maritime scenario
KW  - moving target detection
KW  - Moving target detection
KW  - naval targets
KW  - Naval targets
KW  - saliency
KW  - Saliency
ER  - 

TY  - JOUR
TI  - Data-driven robust optimization using deep neural networks
AU  - Goerigk, M.
AU  - Kurtz, J.
T2  - Computers and Operations Research
AB  - Robust optimization has been established as a leading methodology to approach decision problems under uncertainty. To derive a robust optimization model, a central ingredient is to identify a suitable model for uncertainty, which is called the uncertainty set. An ongoing challenge in the recent literature is to derive uncertainty sets from given historical data that result in solutions that are robust regarding future scenarios. In this paper we use an unsupervised deep learning method to learn and extract hidden structures and anomalies from data, leading to non-convex uncertainty sets and better robust solutions. We prove that most of the classical uncertainty classes are special cases of our derived sets and that optimizing over them is strongly NP-hard. Nevertheless, we show that the trained neural networks can be integrated into a robust optimization model by formulating the adversarial problem as a convex quadratic mixed-integer program. This allows us to derive robust solutions through an iterative scenario generation process. In our computational experiments, we compare this approach to a similar approach using kernel-based support vector clustering and to other benchmark methods. We find that uncertainty sets derived by the unsupervised deep learning method find a better description of data and lead to robust solutions that often outperform the comparison methods both with respect to objective value and feasibility. © 2022 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.cor.2022.106087
VL  - 151
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142739153&doi=10.1016%2fj.cor.2022.106087&partnerID=40&md5=95616b5db9216cb8eea09885ede9542c
DB  - Scopus
KW  - Deep neural networks
KW  - Learning systems
KW  - Uncertainty
KW  - Robust optimization
KW  - Decision theory
KW  - Iterative methods
KW  - Learning methods
KW  - Unsupervised machine learning
KW  - Historical data
KW  - Data driven
KW  - Integer programming
KW  - Robust solutions
KW  - Deep neural network
KW  - Robust optimization models
KW  - Data-driven optimization
KW  - Decision problems
ER  - 

TY  - JOUR
TI  - IoT-Enabled WBAN and Machine Learning for Speech Emotion Recognition in Patients
AU  - Olatinwo, D.D.
AU  - Abu-Mahfouz, A.
AU  - Hancke, G.
AU  - Myburgh, H.
T2  - Sensors
AB  - Internet of things (IoT)-enabled wireless body area network (WBAN) is an emerging technology that combines medical devices, wireless devices, and non-medical devices for healthcare management applications. Speech emotion recognition (SER) is an active research field in the healthcare domain and machine learning. It is a technique that can be used to automatically identify speakers’ emotions from their speech. However, the SER system, especially in the healthcare domain, is confronted with a few challenges. For example, low prediction accuracy, high computational complexity, delay in real-time prediction, and how to identify appropriate features from speech. Motivated by these research gaps, we proposed an emotion-aware IoT-enabled WBAN system within the healthcare framework where data processing and long-range data transmissions are performed by an edge AI system for real-time prediction of patients’ speech emotions as well as to capture the changes in emotions before and after treatment. Additionally, we investigated the effectiveness of different machine learning and deep learning algorithms in terms of performance classification, feature extraction methods, and normalization methods. We developed a hybrid deep learning model, i.e., convolutional neural network (CNN) and bidirectional long short-term memory (BiLSTM), and a regularized CNN model. We combined the models with different optimization strategies and regularization techniques to improve the prediction accuracy, reduce generalization error, and reduce the computational complexity of the neural networks in terms of their computational time, power, and space. Different experiments were performed to check the efficiency and effectiveness of the proposed machine learning and deep learning algorithms. The proposed models are compared with a related existing model for evaluation and validation using standard performance metrics such as prediction accuracy, precision, recall, F1 score, confusion matrix, and the differences between the actual and predicted values. The experimental results proved that one of the proposed models outperformed the existing model with an accuracy of about 98%. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/s23062948
VL  - 23
IS  - 6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151222829&doi=10.3390%2fs23062948&partnerID=40&md5=c392846d6b52cafde68f69c09d3c2ea5
DB  - Scopus
KW  - machine learning
KW  - Deep learning
KW  - Emotions
KW  - deep learning
KW  - Speech recognition
KW  - Machine Learning
KW  - Convolutional neural networks
KW  - Learning systems
KW  - emotion
KW  - CNN
KW  - Data handling
KW  - Internet of things
KW  - Internet of Things
KW  - Learning algorithms
KW  - Machine-learning
KW  - human
KW  - Humans
KW  - Convolutional neural network
KW  - Forecasting
KW  - Complex networks
KW  - Speech
KW  - Patient treatment
KW  - Emotion Recognition
KW  - data augmentation
KW  - Data augmentation
KW  - Neural Networks, Computer
KW  - speech
KW  - Min-max
KW  - Edge AI
KW  - Wireless local area networks (WLAN)
KW  - Bidirectional long short-term memory
KW  - BiLSTM
KW  - edge AI
KW  - Internet of thing wireless body area network
KW  - IoT WBAN
KW  - Mel spectrogram
KW  - MFCC
KW  - min–max scaler
KW  - Min–max scaler
KW  - Regularization technique
KW  - regularization techniques
KW  - robust scaler
KW  - Robust scaler
KW  - spectrograms
KW  - Spectrograms
KW  - speech emotion
KW  - Speech emotions
KW  - standard scaler
KW  - Standard scaler
KW  - Wireless body area network
ER  - 

TY  - CONF
TI  - Distributionally Robust Data Join
AU  - Awasthi, P.
AU  - Jung, C.
AU  - Morgenstern, J.
T2  - Leibniz International Proceedings in Informatics, LIPIcs
AB  - Suppose we are given two datasets: a labeled dataset and unlabeled dataset which also has additional auxiliary features not present in the first dataset. What is the most principled way to use these datasets together to construct a predictor? The answer should depend upon whether these datasets are generated by the same or different distributions over their mutual feature sets, and how similar the test distribution will be to either of those distributions. In many applications, the two datasets will likely follow different distributions, but both may be close to the test distribution. We introduce the problem of building a predictor which minimizes the maximum loss over all probability distributions over the original features, auxiliary features, and binary labels, whose Wasserstein distance is r1 away from the empirical distribution over the labeled dataset and r2 away from that of the unlabeled dataset. This can be thought of as a generalization of distributionally robust optimization (DRO), which allows for two data sources, one of which is unlabeled and may contain auxiliary features. © Pranjal Awasthi, Christopher Jung, and Jamie Morgenstern; licensed under Creative Commons License CC-BY 4.0.
DA  - 2023///
PY  - 2023
DO  - 10.4230/LIPIcs.FORC.2023.10
VL  - 256
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163637863&doi=10.4230%2fLIPIcs.FORC.2023.10&partnerID=40&md5=38ea67601a667f286d55fe59221d562f
DB  - Scopus
KW  - Supervised learning
KW  - Learning algorithms
KW  - Optimization
KW  - Semi-supervised learning
KW  - Robust optimization
KW  - Distributionally robust optimization
KW  - Probability distributions
KW  - Robust datum
KW  - Probability: distributions
KW  - Semi-Supervised Learning
KW  - Different distributions
KW  - Learning Theory
KW  - Labeled dataset
KW  - Binary labels
KW  - Distributionally Robust Optimization
KW  - Features sets
ER  - 

TY  - JOUR
TI  - Distributionally robust unsupervised domain adaptation
AU  - Wang, Y.
AU  - Wang, H.
T2  - Journal of Computational and Applied Mathematics
AB  - Obtaining ground-truth label information from real-world data along with uncertainty quantification can be difficult or even infeasible. In the absence of labeled data for a certain task, unsupervised domain adaptation (UDA) techniques have shown great accomplishment by learning transferable knowledge from labeled source domain data and applying it to unlabeled target domain data, yet scarce studies consider addressing uncertainties under domain shifts to improve the model robustness. Distributionally robust learning (DRL) is emerging as a high-potential technique for building reliable learning systems that are robust to distribution shifts. In this study, we propose a distributionally robust unsupervised domain adaptation (DRUDA) method to enhance the machine learning model generalization ability under input space perturbations. The DRL-based UDA learning scheme is formulated as a min–max optimization problem by optimizing worst-case perturbations of the training source data. Our Wasserstein distributionally robust framework can reduce the shifts in the joint distributions across domains. The proposed DRUDA has been tested on digit datasets and the Office-31 dataset, compared with other state-of-the-art domain adaptation techniques. Our experimental results show that the proposed DRUDA leads to improvements in domain adaptation accuracy performance on target domains. © 2023 Elsevier B.V.
DA  - 2024///
PY  - 2024
DO  - 10.1016/j.cam.2023.115369
VL  - 436
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163101154&doi=10.1016%2fj.cam.2023.115369&partnerID=40&md5=6ad3f3f207322a56cb233b2306bad9f4
DB  - Scopus
KW  - Deep learning
KW  - Ground truth
KW  - Learning systems
KW  - Real-world
KW  - Unsupervised learning
KW  - Robust learning
KW  - Domain adaptation
KW  - Uncertainty quantifications
KW  - Adaptation techniques
KW  - Distributionally robust learning
KW  - Label information
KW  - Target domain
ER  - 

TY  - CONF
TI  - Increasing the Robustness of a Machine Learning-based IoT Malware Detection Method with Adversarial Training
AU  - Sándor, J.
AU  - Nagy, R.
AU  - Buttyán, L.
T2  - WiseML 2023 - Proceedings of the 2023 ACM Workshop on Wireless Security and Machine Learning
AB  - We study the robustness of SIMBIoTA-ML, a recently proposed machine learning-based IoT malware detection solution against adversarial samples. First, we propose two adversarial sample creation strategies that modify existing malware binaries by appending extra bytes to them such that those extra bytes are never executed, but they make the modified samples dissimilar to the original ones. We show that SIMBIoTA-ML is robust against the first strategy, but it can be misled by the second one. To overcome this problem, we propose to use adversarial training, i.e., to extend the training set of SIMBIoTA-ML with samples that are crafted by using the adversarial evasion strategies. We measure the detection accuracy of SIMBIoTA-ML trained on such an extended training set and show that it remains high both for the original malware samples and for the adversarial samples. © 2023 ACM.
DA  - 2023///
PY  - 2023
DO  - 10.1145/3586209.3591401
SP  - 3
EP  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166022791&doi=10.1145%2f3586209.3591401&partnerID=40&md5=9c87dbff81a856d312db90f0db879f47
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Internet of things
KW  - Machine-learning
KW  - Malware
KW  - Malwares
KW  - Adversarial example
KW  - adversarial training
KW  - Training sets
KW  - Adversarial training
KW  - adversarial examples
KW  - Detection accuracy
KW  - Malware detection
KW  - Detection methods
KW  - Evasion strategy
KW  - internet-of-things
KW  - malware detection
ER  - 

TY  - JOUR
TI  - Training sample selection for robust multi-year within-season crop classification using machine learning
AU  - Gao, Z.
AU  - Guo, D.
AU  - Ryu, D.
AU  - Western, A.W.
T2  - Computers and Electronics in Agriculture
AB  - Within-season crop classification using multispectral imagery is an effective way to generate timely crop maps that can support water and crop management; however, developing such models is challenging due to limited satellite imagery and ground truth data available during the season. This study investigated ways to optimize the use of multi-year samples in a within-season crop classification model, aiming to enable accurate within-season crop mapping across years. Our study focused on classifying field-scale corn/maize, cotton, and rice in south-eastern Australia from 2013 to 2019. The crop classification model was based on the random forest and support vector machine algorithms applied to Landsat 8 multispectral bands. We designed four experiments to understand the influences of training sample selection on model accuracy. Specifically, we analyzed how the within-season classification accuracies are affected by 1) training sample size; 2) proportions of classification classes; 3) the inclusion of a non-crop class (e.g., fallow land) in the training sample, and 4) training samples collected from different years. We found that 1) the training sample size should be sufficiently large to ensure within-season classification accuracy; 2) using training samples for each crop type in proportion to their occurrence within the landscape results in more accurate multi-year classification; 3) the inclusion of the non-crop class can reduce the accuracy with which crop types are distinguished, so the proportion of the non-crop class should be maintained at a relatively low level, and 4) predicting the current year with training samples from previous years can lead to a minor decline in accuracy compared to using samples only from the current year. These training sample settings were adopted to develop a final model. We found that the model accuracy continues to improve as more input imagery is added as the cropping season progresses, with a rapid rate of initial improvement which then slows. December, the third month of the summer growing season, is the earliest time that reliable maps were generated, with an overall accuracy of 86 % and user's accuracies for all crops exceeding 80 %. Our proposed experiments are robust and transferable to other regions and seasons to assist the development of within-season crop maps, and can thus be valuable tools to support agricultural management. © 2023 Elsevier B.V.
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.compag.2023.107927
VL  - 210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160410466&doi=10.1016%2fj.compag.2023.107927&partnerID=40&md5=3fee514543461b720c653b43dfc130f5
DB  - Scopus
KW  - machine learning
KW  - Support vector machines
KW  - image classification
KW  - Classification (of information)
KW  - algorithm
KW  - Australia
KW  - Image enhancement
KW  - support vector machine
KW  - Random forests
KW  - Sampling
KW  - Support vectors machine
KW  - Forestry
KW  - Random forest
KW  - Support vector machine
KW  - Crops
KW  - Cultivation
KW  - Training sample
KW  - Crop class
KW  - Crop classification
KW  - crop plant
KW  - Landsat
KW  - LANDSAT
KW  - Landsat 8
KW  - landscape ecology
KW  - Multi-year
KW  - Training sample selection
KW  - Within-season crop classification
ER  - 

TY  - JOUR
TI  - Robust multi-agent reinforcement learning via Bayesian distributional value estimation
AU  - Du, X.
AU  - Chen, H.
AU  - Wang, C.
AU  - Xing, Y.
AU  - Yang, J.
AU  - Yu, P.S.
AU  - Chang, Y.
AU  - He, L.
T2  - Pattern Recognition
AB  - Reinforcement learning in multi-agent scenarios is essential for real-world applications as it can vividly depict agents’ collaborative and competitive behaviors from a perspective closer to reality. However, most existing studies suffer from poor robustness, preventing multi-agent reinforcement learning from practical applications where robustness is the core indicator of system security and stability. In view of this, we propose a novel Bayesian Multi-Agent Reinforcement Learning method, named BMARL, which leverages the distributional value function calculated by Bayesian inference to improve the robustness of the model. Specifically, Bayesian linear regression is adopted to estimate a posterior distribution concerning value function parameters, rather than approximating an expectation value for Q-value by point estimation. In this way, the value function is more generalized than previously obtained by point estimation, which is beneficial to the robustness of our model. Meanwhile, we utilize the Gaussian prior knowledge to integrate more prior knowledge while estimating the value function, which improves learning efficiency. Extensive experimental results on three benchmark multi-agent environments comparing with seven state-of-the-art methods demonstrate the superiority of BMARL in terms of both robustness and efficiency. © 2023 Elsevier Ltd
DA  - 2024///
PY  - 2024
DO  - 10.1016/j.patcog.2023.109917
VL  - 145
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169977108&doi=10.1016%2fj.patcog.2023.109917&partnerID=40&md5=e595d43fa1635c5e71562359b2cf6266
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Bayesian networks
KW  - Efficiency
KW  - Inference engines
KW  - Multi agent systems
KW  - Multi-agent reinforcement learning
KW  - Prior-knowledge
KW  - Bayesian
KW  - Value functions
KW  - Bayesian inference
KW  - Distributional value function
KW  - Point estimation
KW  - Value estimation
ER  - 

TY  - JOUR
TI  - Value of handcrafted and deep radiomic features towards training robust machine learning classifiers for prediction of prostate cancer disease aggressiveness
AU  - Rodrigues, A.
AU  - Rodrigues, N.
AU  - Santinha, J.
AU  - Lisitskaya, M.V.
AU  - Uysal, A.
AU  - Matos, C.
AU  - Domingues, I.
AU  - Papanikolaou, N.
T2  - Scientific Reports
AB  - There is a growing piece of evidence that artificial intelligence may be helpful in the entire prostate cancer disease continuum. However, building machine learning algorithms robust to inter- and intra-radiologist segmentation variability is still a challenge. With this goal in mind, several model training approaches were compared: removing unstable features according to the intraclass correlation coefficient (ICC); training independently with features extracted from each radiologist’s mask; training with the feature average between both radiologists; extracting radiomic features from the intersection or union of masks; and creating a heterogeneous dataset by randomly selecting one of the radiologists’ masks for each patient. The classifier trained with this last resampled dataset presented with the lowest generalization error, suggesting that training with heterogeneous data leads to the development of the most robust classifiers. On the contrary, removing features with low ICC resulted in the highest generalization error. The selected radiomics dataset, with the randomly chosen radiologists, was concatenated with deep features extracted from neural networks trained to segment the whole prostate. This new hybrid dataset was then used to train a classifier. The results revealed that, even though the hybrid classifier was less overfitted than the one trained with deep features, it still was unable to outperform the radiomics model. © 2023, The Author(s).
DA  - 2023///
PY  - 2023
DO  - 10.1038/s41598-023-33339-0
VL  - 13
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152696391&doi=10.1038%2fs41598-023-33339-0&partnerID=40&md5=2a495f7664f6b4662aceb0f0ee1d8239
DB  - Scopus
KW  - machine learning
KW  - Artificial Intelligence
KW  - artificial intelligence
KW  - Machine Learning
KW  - Algorithms
KW  - human
KW  - Humans
KW  - male
KW  - Male
KW  - algorithm
KW  - diagnostic imaging
KW  - prostate tumor
KW  - Prostatic Neoplasms
ER  - 

TY  - JOUR
TI  - Analysis of bitcoin prices using a heavy-tailed version of Dagum distribution and machine learning methods
AU  - Ting, L.
AU  - Abd El-Raouf, M.M.
AU  - Bakr, M.E.
AU  - Alsahangiti, A.M.
T2  - Alexandria Engineering Journal
AB  - Statistical modeling and forecasting are very important for decision-making in any field of life. This paper has two major objectives, namely, statistical modeling and forecasting of real phenomena. For covering the first aim (i.e., statistical modeling), we introduce a new probabilistic model. The new model is introduced by mixing the Dagum distribution with the weighted TX family approach. The proposed model is called the weighted TX Dagum distribution and possesses heavy-tailed characteristics. The new model is illustrated by analyzing real-life data related to Bitcoin prices. To cover the second aim (i.e., forecasting), we take into account six macroeconomic and financial indicators to investigate their impact on Bitcoin prices such as the Adaptive least absolute shrinkage and selection operator (Alasso), elastic net, and minimax concave penalty. After analyzing the data, it is found that Alasso and MCP have retained all the included predictors, except import, while Enet holds all the predictors. The root means square error and mean absolute error associated with MCP are lower than Alasso and Enet, which reveals that MCP fits the data very well as compared to rival methods. © 2023 The Author(s)
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.aej.2023.08.025
VL  - 80
SP  - 572
EP  - 583
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170421403&doi=10.1016%2fj.aej.2023.08.025&partnerID=40&md5=b2c70b742a372f1005e118c45035f647
DB  - Scopus
KW  - Machine learning
KW  - Decision making
KW  - Machine-learning
KW  - Forecasting
KW  - Regression analysis
KW  - Costs
KW  - Robust regressions
KW  - Statistic modeling
KW  - Least absolute shrinkage and selection operators
KW  - Bitcoin
KW  - Regression method
KW  - Macroeconomic variables
KW  - Bitcoin price
KW  - Bitcoin prices
KW  - Dagum distribution
KW  - Heavy-tailed characteristics
KW  - Machine learning and robust regression method
KW  - Machine learning and robust regression methods
ER  - 

TY  - JOUR
TI  - Toward safer highway work zones: An empirical analysis of crash risks using improved safety potential field and machine learning techniques
AU  - Wang, B.
AU  - Chen, T.
AU  - Zhang, C.
AU  - Wong, Y.D.
AU  - Zhang, H.
AU  - Zhou, Y.
T2  - Accident Analysis and Prevention
AB  - Due to complex traffic conditions, transition areas in highway work zones are associated with a higher crash risk than other highway areas. Understanding risk-contributing features in transition areas is essential for ensuring traffic safety on highways. However, conventional surrogate safety measures (SSMs) are quite limited in identifying the crash risk in transition areas due to the complex traffic environment. To this end, this study proposes an improved safety potential field, named the Work-Zone Crash Risk Field (WCRF). The WCRF force can be used to measure the crash risk of individual vehicles that enter a work zone considering the influence of multiple features, upon which the overall crash risk of the road segment in a specific time window can be estimated. With the overall crash risk used as a label, the time-window-based traffic data are used to train and validate an eXtreme Gradient Boosting (XGBoost) classifier, and the Shapley Additive Explanations (SHAP) method is integrated with the XGBoost classifier to identify the key risk-contributing traffic features. To assess the proposed approach, a case study is conducted using real-time vehicle trajectory data collected in two work zones along a highway in China. The results demonstrate that the WCRF-based SSM outperforms conventional SSMs in identifying crash risks in work zone transition areas on highways. In addition, we perform lane-based analysis regarding the impact of setting up work zones on highway safety and investigate the heterogeneity in risk-contributing features across different work zones. Several interesting findings from the analysis are reported in this paper. Compared to existing SSMs, the WCRF-based SSM offers a more practical and comprehensive way to describe the crash risk in work zones. The approach using the developed WCRF technique offers improved capabilities in identifying key risk-contributing features, which is expected to facilitate the development of safety management strategies for work zones. © 2023
DA  - 2024///
PY  - 2024
DO  - 10.1016/j.aap.2023.107361
VL  - 194
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174741073&doi=10.1016%2fj.aap.2023.107361&partnerID=40&md5=cb971b618778876aa928be37bf7c00ef
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Risk perception
KW  - Motor transportation
KW  - Risk assessment
KW  - Highway accidents
KW  - Safety measures
KW  - Highway engineering
KW  - Crash risk
KW  - Trajectories datum
KW  - Improved crash risk field
KW  - Key risk-contributing feature
KW  - Key risk-contributing features
KW  - Real-time trajectories
KW  - Real-time trajectory data
KW  - Work zone safety
KW  - Work zones
ER  - 

TY  - JOUR
TI  - Class-Specific Distribution Alignment for semi-supervised medical image classification
AU  - Huang, Z.
AU  - Wu, J.
AU  - Wang, T.
AU  - Li, Z.
AU  - Ioannou, A.
T2  - Computers in Biology and Medicine
AB  - Despite the success of deep neural networks in medical image classification, the problem remains challenging as data annotation is time-consuming, and the class distribution is imbalanced due to the relative scarcity of diseases. To address this problem, we propose Class-Specific Distribution Alignment (CSDA), a semi-supervised learning framework based on self-training that is suitable to learn from highly imbalanced datasets. Specifically, we first provide a new perspective to distribution alignment by considering the process as a change of basis in the vector space spanned by marginal predictions, and then derive CSDA to capture class-dependent marginal predictions on both labeled and unlabeled data, in order to avoid the bias towards majority classes. Furthermore, we propose a Variable Condition Queue (VCQ) module to maintain a proportionately balanced number of unlabeled samples for each class. Experiments on three public datasets HAM10000, CheXpert and Kvasir show that our method provides competitive performance on semi-supervised skin disease, thoracic disease, and endoscopic image classification tasks. © 2023 Elsevier Ltd
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.compbiomed.2023.107280
VL  - 164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166250908&doi=10.1016%2fj.compbiomed.2023.107280&partnerID=40&md5=504696251ed84d03ee45a6f53c41544f
DB  - Scopus
KW  - Deep neural networks
KW  - prediction
KW  - Image classification
KW  - Classification (of information)
KW  - controlled study
KW  - human
KW  - Article
KW  - disease classification
KW  - major clinical study
KW  - information processing
KW  - Medical imaging
KW  - Semi-supervised learning
KW  - artificial neural network
KW  - learning
KW  - Learning frameworks
KW  - supervised machine learning
KW  - Supervised Machine Learning
KW  - Learn+
KW  - Alignment
KW  - Semi-supervised
KW  - image analysis
KW  - thorax radiography
KW  - data analysis
KW  - Neural Networks, Computer
KW  - Self-training
KW  - Vector spaces
KW  - Data annotation
KW  - Medical image classification
KW  - skin disease
KW  - Distribution alignment
KW  - Class distributions
KW  - endoscopy
KW  - Endoscopy
KW  - Specific distribution
KW  - thorax disease
ER  - 

TY  - JOUR
TI  - Robust Dynamic Bus Control: a Distributional Multi-Agent Reinforcement Learning Approach
AU  - Wang, J.
AU  - Sun, L.
T2  - IEEE Transactions on Intelligent Transportation Systems
AB  - The bus system is a critical component of sustainable urban transportation. However, the operation of a bus fleet is unstable in nature, and bus bunching has become a common phenomenon that undermines the efficiency and reliability of bus systems. Recently research has demonstrated the promising application of multi-agent reinforcement learning (MARL) to achieve efficient vehicle holding control to avoid bus bunching. However, existing studies essentially overlook the robustness issue resulting from perturbations and anomalies in a transit system, which is of utmost importance when transferring the models for real-world deployment/application. In this study, we integrate implicit quantile network and meta-learning to develop a distributional MARL framework - IQNC-M - to learn continuous control. The proposed IQNC-M framework achieves efficient and reliable control decisions through better handling various uncertainties in real-time transit operations. Specifically, we introduce an interpretable meta-learning module to incorporate global information into the distributional MARL framework, which is an effective solution to circumvent the credit assignment issue in the transit system. In addition, we design a specific learning procedure to train each agent within the framework to pursue a robust control policy. We develop simulation environments based on real-world bus services and passenger demand data and evaluate the proposed framework against both traditional holding control models and state-of-the-art MARL models. Our results show that the proposed IQNC-M framework can effectively handle the general perturbations and various extreme events, such as traffic state perturbations and demand surges, thus improving both efficiency and reliability of the transit system.  © 2000-2011 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TITS.2022.3229527
VL  - 24
IS  - 4
SP  - 4075
EP  - 4088
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146240787&doi=10.1109%2fTITS.2022.3229527&partnerID=40&md5=2f7acdeda25b52e240c8532baf6f0860
DB  - Scopus
KW  - Reinforcement learning
KW  - Fleet operations
KW  - Interactive computer systems
KW  - Real - Time system
KW  - Real time systems
KW  - Reinforcement learnings
KW  - Buses
KW  - Uncertainty
KW  - Robustness (control systems)
KW  - Robustness
KW  - Robust control
KW  - Multi agent systems
KW  - Fertilizers
KW  - Multi-agent reinforcement learning
KW  - Urban transportation
KW  - Adaptation models
KW  - Vehicle's dynamics
KW  - meta-learning
KW  - Metalearning
KW  - multi-agent reinforcement learning
KW  - Bus bunching
KW  - Bus transportation
KW  - distributional reinforcement learning
KW  - Distributional reinforcement learning
KW  - robust holding control
KW  - Robust holding control
ER  - 

TY  - JOUR
TI  - Robust machine learning segmentation for large-scale analysis of heterogeneous clinical brain MRI datasets
AU  - Billot, B.
AU  - Magdamo, C.
AU  - Cheng, Y.
AU  - Arnold, S.E.
AU  - Das, S.
AU  - Iglesias, J.E.
T2  - Proceedings of the National Academy of Sciences of the United States of America
AB  - Every year, millions of brain MRI scans are acquired in hospitals, which is a figure considerably larger than the size of any research dataset. Therefore, the ability to analyze such scans could transform neuroimaging research. Yet, their potential remains untapped since no automated algorithm is robust enough to cope with the high variability in clinical acquisitions (MR contrasts, resolutions, orientations, artifacts, and subject populations). Here, we present SynthSeg+, an AI segmentation suite that enables robust analysis of heterogeneous clinical datasets. In addition to whole-brain segmentation, SynthSeg+ also performs cortical parcellation, intracranial volume estimation, and automated detection of faulty segmentations (mainly caused by scans of very low quality). We demonstrate SynthSeg+ in seven experiments, including an aging study on 14,000 scans, where it accurately replicates atrophy patterns observed on data of much higher quality. SynthSeg+ is publicly released as a ready-to-use tool to unlock the potential of quantitative morphometry. Copyright © 2023 the Author(s). Published by PNAS.
DA  - 2023///
PY  - 2023
DO  - 10.1073/pnas.2216399120
VL  - 120
IS  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148398423&doi=10.1073%2fpnas.2216399120&partnerID=40&md5=9dbd19ce94f4896c5610997c89a8b9a4
DB  - Scopus
KW  - machine learning
KW  - deep learning
KW  - artificial intelligence
KW  - Machine Learning
KW  - brain
KW  - segmentation
KW  - image quality
KW  - Algorithms
KW  - adult
KW  - female
KW  - human
KW  - male
KW  - algorithm
KW  - procedures
KW  - aged
KW  - Article
KW  - major clinical study
KW  - image processing
KW  - Image Processing, Computer-Assisted
KW  - Brain
KW  - diagnostic imaging
KW  - image segmentation
KW  - neuroimaging
KW  - nuclear magnetic resonance imaging
KW  - Neuroimaging
KW  - Magnetic Resonance Imaging
KW  - brain cortex
KW  - brain size
KW  - clinical brain MRI
KW  - domain-agnostic
KW  - morphometry
ER  - 

TY  - JOUR
TI  - Comparative study of multiple machine learning algorithms for risk level prediction in goaf
AU  - Zhang, B.
AU  - Hu, S.
AU  - Li, M.
T2  - Heliyon
AB  - With the acceleration of the mining process, the goaf has become one of the main sources of danger in underground mines, seriously threatening the safe production of mines. To make an accurate prediction of the risk level of the goaf quickly, this paper optimizes the features of the goaf by correlation analysis and feature importance and constructs a combination of feature parameters for the risk level prediction of the goaf to solve the problem of redundancy of evaluation indexes. Multiple machine learning algorithms are applied to 121 sets of goaf data respectively, and the optimal algorithm and the best combination of feature parameters are obtained by evaluating the mining area with multiple indicators such as accuracy and kappa coefficient. The best combination of features parameters are ground-water, goaf layout, volume of goaf, goaf volume, span-height ratio, and mining disturbance, and the optimal algorithm is Extra Tree (ET), which needles the goaf risk level prediction problem with the accuracy of 94%. This model can be used to solve the problem of how to quickly and accurately predict the risk level of the goaf. © 2023
DA  - 2023///
PY  - 2023
DO  - 10.1016/j.heliyon.2023.e19092
VL  - 9
IS  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167623901&doi=10.1016%2fj.heliyon.2023.e19092&partnerID=40&md5=c252e3b83c4808c430f12eff762a10c6
DB  - Scopus
KW  - Machine learning
KW  - Risk prediction
KW  - Data classification
KW  - Data processing
KW  - Mine safety
ER  - 

TY  - JOUR
TI  - Asynchronous Updating Reinforcement Learning Algorithm for Decision-making Operational Indices of Uncertain Industrial Processes
AU  - Li, J.-N.
AU  - Yuan, L.
AU  - Ding, J.-L.
T2  - Zidonghua Xuebao/Acta Automatica Sinica
AB  - The decision-making operational index has been a key issue for achieving safe and optimal operation of industrial processes. Considering the complexity of decision making of multiple operational indices and the uncertainty of production indices caused by changes of working condition in industrial processes, this paper proposes a reinforcement learning algorithm with policy asynchronous updating for the first time aiming at self-learning operational indices, followed by the theoretical proof of convergence of the proposed algorithm. To this end, under the framework of stochastic adaptive dynamic programming, the sample mean is utilized rather than calculating the state transition probability matrix of production indices, with the outcome that the state transition probability matrix of production indices is not required to be known a priori. Distinctly from traditional synchronized policy updating, the centralized policy evaluation and asynchronous updating of multiple policies are implemented in the proposed algorithm based on the introduction of a time clock with its threshold, such that solving the concerned decision-making problem of multiple operational indices becomes easier and the learning efficiency of reinforcement learning is improved. Thus, the self-learned operational indices using measured data can ensure the optimality of production indices and limit them within the prescribed range. Experiments are conducted using the real date collected from a large-scale mineral processing plant in west China in order to illustrate the effectiveness of the approach. © 2023 Science Press. All rights reserved.
DA  - 2023///
PY  - 2023
DO  - 10.16383/j.aas.c210983
VL  - 49
IS  - 2
SP  - 461
EP  - 472
ST  - 不确定工业过程运行指标异步更新强化学习决策算法
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174420503&doi=10.16383%2fj.aas.c210983&partnerID=40&md5=2d2601a1a1b7397d03580dc28219b7fb
DB  - Scopus
KW  - Reinforcement learning
KW  - Decision making
KW  - reinforcement learning
KW  - Decisions makings
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Stochastic systems
KW  - Adaptive dynamic programming
KW  - Dynamic programming
KW  - Reinforcement learning algorithms
KW  - Matrix algebra
KW  - Data-driven control
KW  - Safe operation
KW  - adaptive dynamic programming
KW  - data-driven control
KW  - Industrial processs
KW  - Operational control
KW  - Optimal operational control
KW  - Production index
KW  - safe operation
ER  - 

TY  - JOUR
TI  - Robust and Distributionally Robust Optimization Models for Linear Support Vector Machine
AU  - Faccini, D.
AU  - Maggioni, F.
AU  - Potra, F.A.
T2  - Computers and Operations Research
AB  - In this paper we present novel data-driven optimization models for Support Vector Machines (SVM), with the aim of linearly separating two sets of points that have non-disjoint convex closures. Traditional classification algorithms assume that the training data points are always known exactly. However, real-life data are often subject to noise. To handle such uncertainty, we formulate robust models with uncertainty sets in the form of hyperrectangles or hyperellipsoids, and propose a moment-based distributionally robust optimization model enforcing limits on first-order deviations along principal directions. All the formulations reduce to convex programs. The efficiency of the new classifiers is evaluated on real-world databases. Experiments show that robust classifiers are especially beneficial for data sets with a small number of observations. As the dimension of the data sets increases, features behavior is gradually learned and higher levels of out-of-sample accuracy can be achieved via the considered distributionally robust optimization method. The proposed formulations, overall, allow finding a trade-off between increasing the average performance accuracy and protecting against uncertainty, with respect to deterministic approaches. © 2022 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.cor.2022.105930
VL  - 147
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134321541&doi=10.1016%2fj.cor.2022.105930&partnerID=40&md5=8c475b88897d6b59c573aeb908443e6b
DB  - Scopus
KW  - Support vector machines
KW  - Machine Learning
KW  - Machine-learning
KW  - Classification (of information)
KW  - Economic and social effects
KW  - Uncertainty
KW  - Robust optimization
KW  - Distributionally robust optimization
KW  - Support vectors machine
KW  - Support Vector Machine
KW  - Convex optimization
KW  - Data set
KW  - Robust optimization models
KW  - Data-driven optimization
KW  - Linear Support Vector Machines
ER  - 

TY  - JOUR
TI  - RIS-Aided Ground-Aerial NOMA Communications: A Distributionally Robust DRL Approach
AU  - Zhao, J.
AU  - Yu, L.
AU  - Cai, K.
AU  - Zhu, Y.
AU  - Han, Z.
T2  - IEEE Journal on Selected Areas in Communications
AB  - A reconfigurable intelligent surface (RIS) aided air-to-ground uplink non-orthogonal transmission framework is investigated for next generation multiple access. Occupying the same spectrum resource, unmanned aerial vehicle (UAV) users and ground users (GUs) are connected to terrestrial cellular networks via the uplink non-orthogonal multiple access (NOMA) protocol. As the flight safety is important for employing UAVs in civil airspace, the collision avoidance mechanism has to be considered during the flight. Therefore, a joint optimization problem of the UAV trajectory design, RIS configuration, and uploading power control is formulated for maximizing the network sum rate, while ensuring the UAV's fight safety and satisfying the minimum data rate requirements of both the UAV and GU. The resultant problem is a sequential decision making one across multiple coherent time slots. Besides, the unknown locations of obstacles bring uncertainties into the decision making process. To tackle this challenging problem, a sample-efficient deep reinforcement learning (DRL) algorithm is proposed to optimize the UAV trajectory, RIS configuration, and power control simultaneously. Moreover, considering the ambiguous uncertainties in the environment, a distributionally robust DRL algorithm is further proposed to provide the worst-case performance guarantee. Numerical results demonstrate that the two proposed DRL algorithms outperform the conventional ones in terms of learning efficiency and robustness. It is also shown that the network sum rate is significantly improved by the proposed RIS-NOMA scheme compared to the conventional RIS-orthogonal multiple access (OMA) scheme and the case where no RIS is deployed.  © 1983-2012 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/JSAC.2022.3143230
VL  - 40
IS  - 4
SP  - 1287
EP  - 1301
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123302041&doi=10.1109%2fJSAC.2022.3143230&partnerID=40&md5=9bd6a3098413d008a008530428825988
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Decision making
KW  - Learning algorithms
KW  - Uncertainty
KW  - Trajectories
KW  - Unmanned aerial vehicles (UAV)
KW  - Aircraft control
KW  - Antennas
KW  - Power control
KW  - Reconfigurable
KW  - Air-to-ground communications
KW  - Medium access control
KW  - distributionally robust deep reinforcement learning
KW  - Distributionally robust deep reinforcement learning
KW  - Multiple access
KW  - next generation multiple access
KW  - Next generation multiple access
KW  - Non-orthogonal
KW  - non-orthogonal multiple access
KW  - Non-orthogonal multiple access
KW  - Power-control
KW  - reconfigurable intelligent surface
KW  - Reconfigurable intelligent surface
KW  - Uplink
ER  - 

TY  - JOUR
TI  - Hamilton-Jacobi equations on graphs with applications to semi-supervised learning and data depth
AU  - Calder, J.
AU  - Ettehad, M.
T2  - Journal of Machine Learning Research
AB  - Shortest path graph distances are widely used in data science and machine learning, since they can approximate the underlying geodesic distance on the data manifold. However, the shortest path distance is highly sensitive to the addition of corrupted edges in the graph, either through noise or an adversarial perturbation. In this paper we study a family of Hamilton-Jacobi equations on graphs that we call the p-eikonal equation. We show that the p-eikonal equation with p = 1 is a provably robust distance-type function on a graph, and the p → ∞ limit recovers shortest path distances. While the p-eikonal equation does not correspond to a shortest-path graph distance, we nonetheless show that the continuum limit of the p-eikonal equation on a random geometric graph recovers a geodesic density weighted distance in the continuum. We consider applications of the p-eikonal equation to data depth and semi-supervised learning, and use the continuum limit to prove asymptotic consistency results for both applications. Finally, we show the results of experiments with data depth and semi-supervised learning on real image datasets, including MNIST, FashionMNIST and CIFAR-10, which show that the p-eikonal equation offers significantly better results compared to shortest path distances. © 2022 Jeff Calder and Mahmood Ettehad.
DA  - 2022///
PY  - 2022
VL  - 23
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140785634&partnerID=40&md5=7903896cff49284956a079a6a78e9b67
DB  - Scopus
KW  - Geodesy
KW  - Semi-supervised learning
KW  - Graph theory
KW  - Short-path
KW  - Differential equations
KW  - Robust statistics
KW  - Graph learning
KW  - Continuum limits
KW  - Data depth
KW  - Discrete to continuum limit
KW  - discrete to continuum limits
KW  - Eikonal equation
KW  - Geometrical optics
KW  - Hamilton - Jacobi equations
KW  - Hamilton-Jacobi equation
KW  - partial differential equations
KW  - viscosity solutions
KW  - Viscosity solutions
ER  - 

TY  - JOUR
TI  - SETTI: A Self-supervised AdvErsarial Malware DeTection ArchiTecture in an IoT Environment
AU  - Golmaryami, M.
AU  - Taheri, R.
AU  - Pooranian, Z.
AU  - Shojafar, M.
AU  - Xiao, P.
T2  - ACM Transactions on Multimedia Computing, Communications and Applications
AB  - In recent years, malware detection has become an active research topic in the area of Internet of Things (IoT) security. The principle is to exploit knowledge from large quantities of continuously generated malware. Existing algorithms practise available malware features for IoT devices and lack real-time prediction behaviours. More research is thus required on malware detection to cope with real-time misclassification of the input IoT data. Motivated by this, in this article, we propose an adversarial self-supervised architecture for detecting malware in IoT networks, SETTI, considering samples of IoT network traffic that may not be labeled. In the SETTI architecture, we design three self-supervised attack techniques, namely, Self-MDS, GSelf-MDS, and ASelf-MDS. The Self-MDS method considers the IoT input data and the adversarial sample generation in real-time. The GSelf-MDS builds a generative adversarial network model to generate adversarial samples in the self-supervised structure. Finally, ASelf-MDS utilises three well-known perturbation sample techniques to develop adversarial malware and inject it over the self-supervised architecture. Also, we apply a defence method to mitigate these attacks, namely, adversarial self-supervised training, to protect the malware detection architecture against injecting the malicious samples. To validate the attack and defence algorithms, we conduct experiments on two recent IoT datasets: IoT23 and NBIoT. Comparison of the results shows that in the IoT23 dataset, the Self-MDS method has the most damaging consequences from the attacker's point of view by reducing the accuracy rate from 98% to 74%. In the NBIoT dataset, the ASelf-MDS method is the most devastating algorithm that can plunge the accuracy rate from 98% to 77%.  © 2022 Association for Computing Machinery.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3536425
VL  - 18
IS  - 2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142474764&doi=10.1145%2f3536425&partnerID=40&md5=859c11415609a37610343c4ef33a2b43
DB  - Scopus
KW  - Machine learning
KW  - robustness
KW  - Internet of things
KW  - Machine-learning
KW  - Network architecture
KW  - Robustness
KW  - Machine Learning (ML)
KW  - Real- time
KW  - Perturbation techniques
KW  - Malware
KW  - Malwares
KW  - Adversarial example
KW  - Generative adversarial networks
KW  - adversarial examples
KW  - Malware detection
KW  - Internet of thing
KW  - Internet of Things (IoT)
KW  - Supervised trainings
KW  - malware detection
KW  - Self-supervised training (SSL)
KW  - Self-Supervised Training (SSL)
ER  - 

TY  - JOUR
TI  - Machine learning using genetic and clinical data identifies a signature that robustly predicts methotrexate response in rheumatoid arthritis
AU  - Lim, L.J.
AU  - Lim, A.J.W.
AU  - Ooi, B.N.S.
AU  - Tan, J.W.L.
AU  - Koh, E.T.
AU  - Chong, S.S.
AU  - Khor, C.C.
AU  - Tucker-Kellogg, L.
AU  - Lee, C.G.
AU  - Leong, K.P.
T2  - Rheumatology (United Kingdom)
AB  - Objective: To develop a hypothesis-free model that best predicts response to MTX drug in RA patients utilizing biologically meaningful genetic feature selection of potentially functional single nucleotide polymorphisms (pfSNPs) through robust machine learning (ML) feature selection methods. Methods: MTX-Treated RA patients with known response were divided in a 4:1 ratio into training and test sets. From the patients' exomes, potential features for classifier prediction were identified from pfSNPs and non-genetic factors through ML using recursive feature elimination with cross-validation incorporating the random forest classifier. Feature selection was repeated on random subsets of the training cohort, and consensus features were assembled into the final feature set. This feature set was evaluated for predictive potential using six ML classifiers, first by cross-validation within the training set, and finally by analysing its performance with the unseen test set. Results: The final feature set contains 56 pfSNPs and five non-genetic factors. The majority of these pfSNPs are located in pathways related to RA pathogenesis or MTX action and are predicted to modulate gene expression. When used for training in six ML classifiers, performance was good in both the training set (area under the curve: 0.855-0.916; sensitivity: 0.715-0.892; and specificity: 0.733-0.862) and the unseen test set (area under the curve: 0.751-0.826; sensitivity: 0.581-0.839; and specificity: 0.641-0.923). Conclusion: Sensitive and specific predictors of MTX response in RA patients were identified in this study through a novel strategy combining biologically meaningful and machine learning feature selection and training. These predictors may facilitate better treatment decision-making in RA management. © 2022 The Author(s). Published by Oxford University Press on behalf of the British Society for Rheumatology. All rights reserved.
DA  - 2022///
PY  - 2022
DO  - 10.1093/rheumatology/keac032
VL  - 61
IS  - 10
SP  - 4175
EP  - 4186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128258596&doi=10.1093%2frheumatology%2fkeac032&partnerID=40&md5=c22ba4a84323094958b397cd290e6233
DB  - Scopus
KW  - machine learning
KW  - Machine Learning
KW  - prediction
KW  - adult
KW  - human
KW  - Humans
KW  - Article
KW  - cross validation
KW  - major clinical study
KW  - methotrexate
KW  - sensitivity and specificity
KW  - genetics
KW  - random forest
KW  - feature selection
KW  - classifier
KW  - pathology
KW  - cohort analysis
KW  - phenotype
KW  - consensus
KW  - treatment response
KW  - gene expression
KW  - recursive feature elimination
KW  - single nucleotide polymorphism
KW  - whole exome sequencing
KW  - Arthritis, Rheumatoid
KW  - Cohort Studies
KW  - exome
KW  - genetic polymorphism
KW  - Methotrexate
KW  - pathogenesis
KW  - Polymorphism, Single Nucleotide
KW  - proton pump inhibitor
KW  - purine metabolism
KW  - rheumatoid arthritis
KW  - untranslated region
ER  - 

TY  - CONF
TI  - Towards Robust Off-Policy Evaluation via Human Inputs
AU  - Singh, H.
AU  - Joshi, S.
AU  - Doshi-Velez, F.
AU  - Lakkaraju, H.
T2  - AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society
AB  - Off-policy Evaluation (OPE) methods are crucial tools for evaluating policies in high-stakes domains such as healthcare, where direct deployment is often infeasible, unethical, or expensive. When deployment environments are expected to undergo changes (that is, dataset shifts), it is important for OPE methods to perform robust evaluation of the policies amidst such changes. Existing approaches consider robustness against a large class of shifts that can arbitrarily change any observable property of the environment. This often results in highly pessimistic estimates of the utilities, thereby invalidating policies that might have been useful in deployment. In this work, we address the aforementioned problem by investigating how domain knowledge can help provide more realistic estimates of the utilities of policies. We leverage human inputs on which aspects of the environments may plausibly change, and adapt the OPE methods to only consider shifts on these aspects. Specifically, we propose a novel framework, Robust OPE (ROPE), which considers shifts on a subset of covariates in the data based on user inputs, and estimates worst-case utility under these shifts. We then develop computationally efficient algorithms for OPE that are robust to the aforementioned shifts for contextual bandits and Markov decision processes. We also theoretically analyze the sample complexity of these algorithms. Extensive experimentation with synthetic and real world datasets from the healthcare domain demonstrates that our approach not only captures realistic dataset shifts accurately, but also results in less pessimistic policy evaluations.  © 2022 ACM.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3514094.3534198
SP  - 686
EP  - 699
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137169796&doi=10.1145%2f3514094.3534198&partnerID=40&md5=adb078c8cd93894d712ddc5b63ed82f8
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Evaluation methods
KW  - Markov processes
KW  - Health care
KW  - adversarial machine learning
KW  - Adversarial machine learning
KW  - Robust learning
KW  - Domain knowledge
KW  - Domain Knowledge
KW  - Computational complexity
KW  - Property
KW  - robust learning
KW  - Covariates
KW  - Dataset shifts
KW  - Human-in-the-loop
KW  - dataset shift
KW  - human-in-The-loop
KW  - policy evaluation
KW  - Policy evaluation
ER  - 

TY  - JOUR
TI  - Safe deployment of a reinforcement learning robot using self stabilization
AU  - Sreenivas, N.K.
AU  - Rao, S.
T2  - Intelligent Systems with Applications
AB  - In toy environments like video games, a reinforcement learning agent is deployed and operates within the same state space in which it was trained. However, in robotics applications such as industrial systems or autonomous vehicles, this cannot be guaranteed. A robot can be pushed out of its training space by some unforeseen perturbation, which may cause it to go into an unknown state from which it has not been trained to move towards its goal. While most prior work in the area of RL safety focuses on ensuring safety in the training phase, this paper focuses on ensuring the safe deployment of a robot that has already been trained to operate within a safe space. This work defines a condition on the state and action spaces, that if satisfied, guarantees the robot's recovery to safety independently. We also propose a strategy and design that facilitate this recovery within a finite number of steps after perturbation. This is implemented and tested against a standard RL model, and the results indicate a significant improvement in performance. © 2022 The Author(s)
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.iswa.2022.200105
VL  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136463389&doi=10.1016%2fj.iswa.2022.200105&partnerID=40&md5=233c5a9b4ebca810a6095f340733ad72
DB  - Scopus
KW  - Reinforcement learning
KW  - Robots
KW  - Autonomous Vehicles
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - State-space
KW  - Stabilization
KW  - Industrial systems
KW  - Robotics applications
KW  - Safety in robotic
KW  - Safety in robotics
KW  - Self stabilization
KW  - Unknown state
KW  - Video-games
ER  - 

TY  - JOUR
TI  - Distributionally robust optimization: A review on theory and applications
AU  - Lin, F.
AU  - Fang, X.
AU  - Gao, Z.
T2  - Numerical Algebra, Control and Optimization
AB  - In this paper, we survey the primary research on the theory and applications of distributionally robust optimization (DRO). We start with review-ing the modeling power and computational attractiveness of DRO approaches, induced by the ambiguity sets structure and tractable robust counterpart refor-mulations. Next, we summarize the efficient solution methods, out-of-sample performance guarantee, and convergence analysis. Then, we illustrate some applications of DRO in machine learning and operations research, and finally, we discuss the future research directions. © 2022, American Institute of Mathematical Sciences. All rights reserved.
DA  - 2022///
PY  - 2022
DO  - 10.3934/naco.2021057
VL  - 12
IS  - 1
SP  - 159
EP  - 212
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121985630&doi=10.3934%2fnaco.2021057&partnerID=40&md5=9559a65463486359c551dc676f295454
DB  - Scopus
KW  - Machine learning
KW  - Distributionally robust optimization
KW  - Operations research
KW  - Tractable methods
KW  - Uncertain decision-making
ER  - 

TY  - JOUR
TI  - AlphaQO: Robust Learned Query Optimizer
AU  - Yu, X.
AU  - Chai, C.-L.
AU  - Zhang, X.-N.
AU  - Tang, N.
AU  - Sun, J.
AU  - Li, G.-L.
T2  - Ruan Jian Xue Bao/Journal of Software
AB  - Learned database query optimizers, which are typically empowered by (deep) learning models, have attracted significant attention recently, because they can offer similar or even better performance than the state-of-the-art commercial optimizers that require hundreds of expert-hours to tune. A crucial factor of successfully training learned optimizers is training queries. Unfortunately, a good query workload that is sufficient for training learned optimizers is not always available. This study proposes a framework, called AlphaQO, on generating queries for learned optimizers with reinforcement learning (RL). AlphaQO is a loop system that consists of two main components, query generator and learned optimizer. Query generator aims at generating “hard” queries (i.e., those queries that the learned optimizer provides poor estimates). The learned optimizer will be trained using generated queries, as well as providing feedbacks (in terms of numerical rewards) to the query generator. If the generated queries are good, the query generator will get a high reward; otherwise, the query generator will get a low reward. The above process is performed iteratively, with the main goal that within a small budget, the learned optimizer can be trained and generalized well to a wide range of unseen queries. Extensive experiments show that AlphaQO can generate a relatively small number of queries and train a learned optimizer to outperform commercial optimizers. Moreover, learned optimizers need much less queries from AlphaQO than randomly generated queries, in order to well train the learned optimizer. © Copyright 2022, Institute of Software, the Chinese Academy of Sciences. All rights reserved.
DA  - 2022///
PY  - 2022
DO  - 10.13328/j.cnki.jos.006452
VL  - 33
IS  - 3
SP  - 814
EP  - 831
ST  - AlphaQO: 鲁棒的学习型查询优化器
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126986269&doi=10.13328%2fj.cnki.jos.006452&partnerID=40&md5=fa861c7db5f6caf85a53d18e1289b76a
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Performance
KW  - Reinforcement learnings
KW  - Learning models
KW  - Query processing
KW  - Robustness
KW  - Budget control
KW  - Optimizers
KW  - AI4DB
KW  - Database
KW  - Database queries
KW  - Learned optimizer
KW  - Query generation
KW  - Query optimizer
ER  - 

TY  - JOUR
TI  - Data-Driven Robust Control Using Reinforcement Learning
AU  - Ngo, P.D.
AU  - Tejedor, M.
AU  - Godtliebsen, F.
T2  - Applied Sciences (Switzerland)
AB  - This paper proposes a robust control design method using reinforcement learning for controlling partially-unknown dynamical systems under uncertain conditions. The method extends the optimal reinforcement learning algorithm with a new learning technique based on the robust control theory. By learning from the data, the algorithm proposes actions that guarantee the stability of the closed-loop system within the uncertainties estimated also from the data. Control policies are calculated by solving a set of linear matrix inequalities. The controller was evaluated using simulations on a blood glucose model for patients with Type 1 diabetes. Simulation results show that the proposed methodology is capable of safely regulating the blood glucose within a healthy level under the influence of measurement and process noises. The controller has also significantly reduced the post-meal fluctuation of the blood glucose. A comparison between the proposed algorithm and the existing optimal reinforcement learning algorithm shows the improved robustness of the closed-loop system using our method. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2022///
PY  - 2022
DO  - 10.3390/app12042262
VL  - 12
IS  - 4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125134457&doi=10.3390%2fapp12042262&partnerID=40&md5=c4c84136a56e7d11553422311b082db1
DB  - Scopus
KW  - Reinforcement learning
KW  - Robust control
KW  - Data-driven
ER  - 

TY  - JOUR
TI  - Distributionally-robust machine learning using locally differentially-private data
AU  - Farokhi, F.
T2  - Optimization Letters
AB  - We consider machine learning, particularly regression, using locally-differentially private datasets. The Wasserstein distance is used to define an ambiguity set centered at the empirical distribution of the dataset corrupted by local differential privacy noise. The radius of the ambiguity set is selected based on privacy budget, spread of data, and size of the problem. Machine learning with private dataset is rewritten as a distributionally-robust optimization. For general distributions, the distributionally-robust optimization problem can be relaxed as a regularized machine learning problem with the Lipschitz constant of the machine learning model as a regularizer. For Gaussian data, the distributionally-robust optimization problem can be solved exactly to find an optimal regularizer. Training with this regularizer can be posed as a semi-definite program. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
DA  - 2022///
PY  - 2022
DO  - 10.1007/s11590-021-01765-6
VL  - 16
IS  - 4
SP  - 1167
EP  - 1179
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107473237&doi=10.1007%2fs11590-021-01765-6&partnerID=40&md5=d7c0bbdf3241da2e0b7eed287f8ca7e6
DB  - Scopus
KW  - Machine learning
KW  - Machine learning models
KW  - Optimization
KW  - Robust optimization
KW  - Budget control
KW  - Wasserstein distance
KW  - Differential privacies
KW  - Regularization
KW  - Distributionally-robust optimization
KW  - Empirical distributions
KW  - Lipschitz constant
KW  - Local differential privacy
KW  - Machine learning problem
KW  - Semidefinite programs
ER  - 

TY  - JOUR
TI  - Robustness test of the spacegroupMining model for determining space groups from atomic pair distribution function data
AU  - Lan, L.
AU  - Liu, C.-H.
AU  - Du, Q.
AU  - Billinge, S.J.L.
T2  - Journal of Applied Crystallography
AB  - Machine learning models based on convolutional neural networks have been used for predicting space groups of crystal structures from their atomic pair distribution function (PDF). However, the PDFs used to train the model are calculated using a fixed set of parameters that reflect specific experimental conditions, and the accuracy of the model when given PDFs generated with different choices of these parameters is unknown. In this work, the results of the top-1 accuracy and top-6 accuracy are robust when applied to PDFs of different choices of experimental parameters r max, Q max, Q damp and atomic displacement parameters.  © 2022.
DA  - 2022///
PY  - 2022
DO  - 10.1107/S1600576722002990
VL  - 55
SP  - 626
EP  - 630
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131692416&doi=10.1107%2fS1600576722002990&partnerID=40&md5=8826204aff0e88de0f9bd063c3de46d4
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Data mining
KW  - Convolutional neural networks
KW  - Convolution
KW  - Convolutional neural network
KW  - Machine learning models
KW  - data mining
KW  - Model-based OPC
KW  - Robustness testing
KW  - robustness testing
KW  - Distribution functions
KW  - Robustness tests
KW  - Atomic pair distribution functions
KW  - Atoms
KW  - Crystal atomic structure
KW  - Crystals structures
KW  - Fixed sets
KW  - pair distribution functions
KW  - Pair distribution functions
KW  - space groups
KW  - Space Groups
ER  - 

TY  - JOUR
TI  - Superquantile-Based Learning: A Direct Approach Using Gradient-Based Optimization
AU  - Laguel, Y.
AU  - Malick, J.
AU  - Harchaoui, Z.
T2  - Journal of Signal Processing Systems
AB  - We consider a formulation of supervised learning that endows models with robustness to distributional shifts from training to testing. The formulation hinges upon the superquantile risk measure, also known as the conditional value-at-risk, which has shown promise in recent applications of machine learning and signal processing. We show that, thanks to a direct smoothing of the superquantile function, a superquantile-based learning objective is amenable to gradient-based optimization, using batch optimization algorithms such as gradient descent or quasi-Newton algorithms, or using stochastic optimization algorithms such as stochastic gradient algorithms. A companion software SPQR implements in Python the algorithms described and allows practitioners to experiment with superquantile-based supervised learning. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2022///
PY  - 2022
DO  - 10.1007/s11265-021-01716-5
VL  - 94
IS  - 2
SP  - 161
EP  - 177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122750673&doi=10.1007%2fs11265-021-01716-5&partnerID=40&md5=661e4300b7c5a1156766154faab4ee16
DB  - Scopus
KW  - Machine learning
KW  - Signal processing
KW  - Supervised learning
KW  - Learning algorithms
KW  - Risk assessment
KW  - Optimization
KW  - Computer software
KW  - Stochastic systems
KW  - Python
KW  - Gradient methods
KW  - Conditional Value-at-Risk
KW  - Value engineering
KW  - Optimization algorithms
KW  - Learning objectives
KW  - Signal-processing
KW  - Risk measures
KW  - Batch optimization
KW  - Direct approach
KW  - Distributional robustness
KW  - Gradient-based optimization
KW  - Nonsmooth optimization
KW  - Risk measure
ER  - 

TY  - JOUR
TI  - Optimal Bi-Level Bidding and Dispatching Strategy between Active Distribution Network and Virtual Alliances Using Distributed Robust Multi-Agent Deep Reinforcement Learning
AU  - Zhu, Z.
AU  - Chan, K.W.
AU  - Xia, S.
AU  - Bu, S.
T2  - IEEE Transactions on Smart Grid
AB  - The deregulated active distribution network (ADN) would incorporate numerous autonomous stakeholders, including some emerging distributed virtual alliances (DVAs) like virtual microgrids and virtual power plants. Those DVAs would autonomously participate in energy market trading through bidding among themselves and dispatching conducted by the ADN. In this paper, the optimal bidding and dispatching model for DVAs and ADN in the day-ahead market is first developed as a stochastic dynamic programming model with the risk of misconduct considered, and then re-formulated as a Markov Decision Process to be solved by a new Distributed Robust Multi-Agent Deep Deterministic Policy Gradient algorithm based on the concept of robust Nash equilibrium (RNE). This algorithm is a fully distributed online optimization that would converge to RNE. It is an effective risk-averse method to obtain the optimal bidding strategies of DVAs and the optimal dispatching decisions of distribution system operator (DSO). Its high computational performance is demonstrated in the case studies, and the strategic decisions of DVAs and DSO are thoroughly analyzed.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TSG.2022.3164080
VL  - 13
IS  - 4
SP  - 2833
EP  - 2843
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127524977&doi=10.1109%2fTSG.2022.3164080&partnerID=40&md5=9b15428da7f144cdbfe746a7ef28bcc4
DB  - Scopus
KW  - Intelligent agents
KW  - Deep learning
KW  - Reinforcement learning
KW  - reinforcement learning
KW  - Autonomous agents
KW  - Learning algorithms
KW  - Interactive computer systems
KW  - Real - Time system
KW  - Real time systems
KW  - Uncertainty
KW  - Smart power grids
KW  - Markov processes
KW  - Multi agent systems
KW  - Stochastic models
KW  - Stochastic systems
KW  - Heuristic algorithms
KW  - Dynamic programming
KW  - Heuristics algorithm
KW  - Index
KW  - Load modeling
KW  - Active distribution network
KW  - Active distributions
KW  - bidding strategy
KW  - Bidding strategy
KW  - Dispatching
KW  - distributed virtual alliance
KW  - Distributed virtual alliance
KW  - Reinforcement learning.
KW  - Virtual alliances
ER  - 

TY  - CONF
TI  - Picket: guarding against corrupted data in tabular data during learning and inference
AU  - Liu, Z.
AU  - Zhou, Z.
AU  - Rekatsinas, T.
T2  - VLDB Journal
AB  - Data corruption is an impediment to modern machine learning deployments. Corrupted data can severely bias the learned model and can also lead to invalid inferences. We present, Picket, a simple framework to safeguard against data corruptions during both training and deployment of machine learning models over tabular data. For the training stage, Picket identifies and removes corrupted data points from the training data to avoid obtaining a biased model. For the deployment stage, Picket flags, in an online manner, corrupted query points to a trained machine learning model that due to noise will result in incorrect predictions. To detect corrupted data, Picket uses a self-supervised deep learning model for mixed-type tabular data, which we call PicketNet. To minimize the burden of deployment, learning a PicketNet model does not require any human-labeled data. Picket is designed as a plugin that can increase the robustness of any machine learning pipeline. We evaluate Picket on a diverse array of real-world data considering different corruption models that include systematic and adversarial noise during both training and testing. We show that Picket consistently safeguards against corrupted data during both training and deployment of various models ranging from SVMs to neural networks, beating a diverse array of competing methods that span from data quality validation models to robust outlier detection models. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
DA  - 2022///
PY  - 2022
DO  - 10.1007/s00778-021-00699-w
VL  - 31
SP  - 927
EP  - 955
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116992995&doi=10.1007%2fs00778-021-00699-w&partnerID=40&md5=f39479b0085d63525e4e6ef09d485368
DB  - Scopus
KW  - Deep learning
KW  - Data handling
KW  - Anomaly detection
KW  - Machine learning models
KW  - Crime
KW  - Statistics
KW  - Simple++
KW  - Robust machine learning
KW  - Error detection
KW  - Outlier Detection
KW  - Robust outlier detection
KW  - Data corruption
KW  - Tabular data
KW  - Corrupted data
KW  - Data validation
KW  - Datapoints
ER  - 

TY  - JOUR
TI  - scTenifoldKnk: An efficient virtual knockout tool for gene function predictions via single-cell gene regulatory network perturbation
AU  - Osorio, D.
AU  - Zhong, Y.
AU  - Li, G.
AU  - Xu, Q.
AU  - Yang, Y.
AU  - Tian, Y.
AU  - Chapkin, R.S.
AU  - Huang, J.Z.
AU  - Cai, J.J.
T2  - Patterns
AB  - Gene knockout (KO) experiments are a proven, powerful approach for studying gene function. However, systematic KO experiments targeting a large number of genes are usually prohibitive due to the limit of experimental and animal resources. Here, we present scTenifoldKnk, an efficient virtual KO tool that enables systematic KO investigation of gene function using data from single-cell RNA sequencing (scRNA-seq). In scTenifoldKnk analysis, a gene regulatory network (GRN) is first constructed from scRNA-seq data of wild-type samples, and a target gene is then virtually deleted from the constructed GRN. Manifold alignment is used to align the resulting reduced GRN to the original GRN to identify differentially regulated genes, which are used to infer target gene functions in analyzed cells. We demonstrate that the scTenifoldKnk-based virtual KO analysis recapitulates the main findings of real-animal KO experiments and recovers the expected functions of genes in relevant cell types. © 2022 The Author(s)
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.patter.2022.100434
VL  - 3
IS  - 3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124906786&doi=10.1016%2fj.patter.2022.100434&partnerID=40&md5=11c439df5d45e81fcf83a494ce160a4c
DB  - Scopus
KW  - Machine learning
KW  - Animals
KW  - RNA
KW  - Proof of concept
KW  - Unsupervised machine learning
KW  - unsupervised machine learning
KW  - Cytology
KW  - Single cells
KW  - Domain problems
KW  - Genes
KW  - tensor decomposition
KW  - Tensor decomposition
KW  - Single-cell RNA sequencing
KW  - Manifold alignments
KW  - manifold alignment
KW  - DSML 2: Proof-of-Concept: Data science output has been formulated, implemented, and tested for one domain/problem
KW  - DSML 2: proof-of-concept: data science output have been formulated, implemented, and tested for one domain/problem
KW  - functional genomics
KW  - Functional genomics
KW  - gene knockout
KW  - Gene knockout
KW  - gene regulatory network
KW  - Gene regulatory networks
KW  - perturbation analysis
KW  - Perturbation Analysis
KW  - scRNA-seq
KW  - single-cell RNA sequencing
ER  - 

TY  - JOUR
TI  - Evolutionary polynomial regression algorithm combined with robust bayesian regression
AU  - Marasco, S.
AU  - Marano, G.C.
AU  - Cimellaro, G.P.
T2  - Advances in Engineering Software
AB  - Recent developments in the fields of scientific computation and Machine Learning (ML) techniques have led to a proliferation of algorithms capable of interpreting data and predict results. Among the others, the Evolutionary Polynomial Regression (EPR) has gained particular attention for many engineering applications. This paper presents a novel robust Evolutionary Polynomial Bayesian Regression (EPBR) algorithm. The optimal polynomial structure is selected using GAs. The model parameters are assumed as random variables whose posterior distributions are assessed by a robust Bayesian regression algorithm. To reduce the effects of the outliers, the model disturbance is described by a Student-t distribution whose degrees of freedoms are sampled from an objective prior probability density function. The proposed technique is applied to a dataset consisting of experimental shear strength values related to Reinforced Concrete (RC) beams without stirrups. The optimal EPBR model is compared with different experimental and design formulations to emphasize its accuracy and consistency. © 2022
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.advengsoft.2022.103101
VL  - 167
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126143568&doi=10.1016%2fj.advengsoft.2022.103101&partnerID=40&md5=77cc54993ae080d5b10b523cae8ad50d
DB  - Scopus
KW  - Machine learning
KW  - Learning algorithms
KW  - Regression analysis
KW  - Evolutionary algorithms
KW  - Machine learning techniques
KW  - Probability distributions
KW  - Probability density function
KW  - Reinforced concrete
KW  - Engineering applications
KW  - Structural optimization
KW  - Bayesian regression
KW  - Regression algorithms
KW  - Polynomials
KW  - Student's t distribution
KW  - Evolutionary polynomial regression
KW  - Evolutionary polynomial regressions
KW  - Robust bayesian regression
KW  - Robust Bayesian regression
KW  - Scientific computation
KW  - Shear strength
KW  - Shears strength
KW  - Student-t distribution
ER  - 

TY  - CONF
TI  - Conditional Synthetic Data Generation for Robust Machine Learning Applications with Limited Pandemic Data
AU  - Das, H.P.
AU  - Tran, R.
AU  - Singh, J.
AU  - Yue, X.
AU  - Tison, G.
AU  - Sangiovanni-Vincentelli, A.
AU  - Spanos, C.J.
T2  - Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022
AB  - Background: At the onset of a pandemic, such as COVID-19, data with proper labeling/attributes corresponding to the new disease might be unavailable or sparse. Machine Learning (ML) models trained with the available data, which is limited in quantity and poor in diversity, will often be biased and inaccurate. At the same time, ML algorithms designed to fight pandemics must have good performance and be developed in a time-sensitive manner. To tackle the challenges of limited data, and label scarcity in the available data, we propose generating conditional synthetic data, to be used alongside real data for developing robust ML models. Methods: We present a hybrid model consisting of a conditional generative flow and a classifier for conditional synthetic data generation. The classifier decouples the feature representation for the condition, which is fed to the flow to extract the local noise. We generate synthetic data by manipulating the local noise with fixed conditional feature representation. We also propose a semi-supervised approach to generate synthetic samples in the absence of labels for a majority of the available data. Results: We performed conditional synthetic generation for chest computed tomography (CT) scans corresponding to normal, COVID-19, and pneumonia afflicted patients. We show that our method significantly outperforms existing models both on qualitative and quantitative performance, and our semi-supervised approach can efficiently synthesize conditional samples under label scarcity. As an example of downstream use of synthetic data, we show improvement in COVID-19 detection from CT scans with conditional synthetic data augmentation. Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.
DA  - 2022///
PY  - 2022
VL  - 36
SP  - 11792
EP  - 11800
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141319028&partnerID=40&md5=4d6d36fb6d0aee43f4ece86e2a5b055f
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - COVID-19
KW  - Performance
KW  - Classification (of information)
KW  - Machine learning models
KW  - Labelings
KW  - Feature representation
KW  - Machine learning applications
KW  - Synthetic data
KW  - Semi-supervised
KW  - Computerized tomography
KW  - Computed tomography scan
KW  - Synthetic data generations
KW  - Time machine
ER  - 

TY  - JOUR
TI  - Adaptative Perturbation Patterns: Realistic Adversarial Learning for Robust Intrusion Detection
AU  - Vitorino, J.
AU  - Oliveira, N.
AU  - Praça, I.
T2  - Future Internet
AB  - Adversarial attacks pose a major threat to machine learning and to the systems that rely on it. In the cybersecurity domain, adversarial cyber-attack examples capable of evading detection are especially concerning. Nonetheless, an example generated for a domain with tabular data must be realistic within that domain. This work establishes the fundamental constraint levels required to achieve realism and introduces the adaptative perturbation pattern method (A2PM) to fulfill these constraints in a gray-box setting. A2PM relies on pattern sequences that are independently adapted to the characteristics of each class to create valid and coherent data perturbations. The proposed method was evaluated in a cybersecurity case study with two scenarios: Enterprise and Internet of Things (IoT) networks. Multilayer perceptron (MLP) and random forest (RF) classifiers were created with regular and adversarial training, using the CIC-IDS2017 and IoT-23 datasets. In each scenario, targeted and untargeted attacks were performed against the classifiers, and the generated examples were compared with the original network traffic flows to assess their realism. The obtained results demonstrate that A2PM provides a scalable generation of realistic adversarial examples, which can be advantageous for both adversarial training and attacks. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2022///
PY  - 2022
DO  - 10.3390/fi14040108
VL  - 14
IS  - 4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128354258&doi=10.3390%2ffi14040108&partnerID=40&md5=da0f27530ebbd54e3e12f18929ca3b56
DB  - Scopus
KW  - machine learning
KW  - Decision trees
KW  - Machine learning
KW  - Intrusion detection
KW  - Internet of things
KW  - Classification (of information)
KW  - Adversarial attack
KW  - Perturbation techniques
KW  - Cyber security
KW  - Cybersecurity
KW  - Cyber-attacks
KW  - adversarial attacks
KW  - Adversarial learning
KW  - Intrusion-Detection
KW  - adversarial robustness
KW  - Adversarial robustness
KW  - Tabular data
KW  - Fundamental constraints
KW  - intrusion detection
KW  - Perturbation patterns
KW  - Realistic adversarial example
KW  - realistic adversarial examples
KW  - tabular data
ER  - 

TY  - JOUR
TI  - EFFECTIVE DATA ALIGNMENT AND KEY EXTRACTION TECHNIQUES FOR GENERATION OF REGULAR EXPRESSIONS USING MACHINE LEARNING TECHNIQUES
AU  - Puri, D.D.
AU  - Patnaik, G.K.
T2  - Journal of Theoretical and Applied Information Technology
AB  - Machine learning supervised classification plays a significant role in large text classification. Health care data contribute to generating privacy and security for a couple of years. Such electric records might take extensive data from storage devices, so it needs to optimize with some processing techniques. For generation of regular expression, data should be in structured form. The conversion of unstructured data in to structured form is done through modified data alignment and key extraction techniques. The Smith-Waterman method compares two sequences to find comparable review statements. Smith-Waterman method employs an evolutionary algorithm to find improved local alignments of pairs. It can identify the best local alignment using the supplied score system. The NLP process has been used to generate the keys from such large text. In this paper, we proposed a sequence alignment generation using Smith-Waterman (SW) algorithm and key extraction from generated sequence using Natural Language Processing (NLP) technique has used for effective regular expression building. The filtration techniques have been used to eliminate redundant features, and the Machine Learning (ML) algorithm has been used as post-processing for classification. The generated regular expression by the SW algorithm gives better classification accuracy using NLP and Machine leavening. Generated regular expressions are filtered using 100% precision as threshold. We applied various Machine learning algorithms out of which SVM gives highest accuracy. © 2022 Little Lion Scientific.
DA  - 2022///
PY  - 2022
VL  - 100
IS  - 17
SP  - 5367
EP  - 5376
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138874858&partnerID=40&md5=dea2a6ba51f44376c3833a3ba6263304
DB  - Scopus
KW  - Classification
KW  - NLP
KW  - Key Extraction
KW  - Regular Expression
KW  - Sentence Alignment
KW  - Sequence Generation
KW  - Smith Waterman Algorithm
ER  - 

TY  - JOUR
TI  - Measuring disparate outcomes of content recommendation algorithms with distributional inequality metrics
AU  - Lazovich, T.
AU  - Belli, L.
AU  - Gonzales, A.
AU  - Bower, A.
AU  - Tantipongpipat, U.
AU  - Lum, K.
AU  - Huszár, F.
AU  - Chowdhury, R.
T2  - Patterns
AB  - The harmful impacts of algorithmic decision systems have recently come into focus, with many examples of machine learning (ML) models amplifying societal biases. In this paper, we propose adapting income inequality metrics from economics to complement existing model-level fairness metrics, which focus on intergroup differences of model performance. In particular, we evaluate their ability to measure disparities between exposures that individuals receive in a production recommendation system, the Twitter algorithmic timeline. We define desirable criteria for metrics to be used in an operational setting by ML practitioners. We characterize engagements with content on Twitter using these metrics and use the results to evaluate the metrics with respect to our criteria. We also show that we can use these metrics to identify content suggestion algorithms that contribute more strongly to skewed outcomes between users. Overall, we conclude that these metrics can be a useful tool for auditing algorithms in production settings. © 2022 The Authors
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.patter.2022.100568
VL  - 3
IS  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135962645&doi=10.1016%2fj.patter.2022.100568&partnerID=40&md5=388bfec9f0211930b38233fc8cd6ea10
DB  - Scopus
KW  - Machine learning
KW  - AI ethics
KW  - Machine-learning
KW  - Social networking (online)
KW  - Proof of concept
KW  - Algorithmics
KW  - AI ethic
KW  - Domain problems
KW  - DSML 2: proof-of-concept: data science output have been formulated, implemented, and tested for one domain/problem
KW  - attention inequality
KW  - Attention inequality
KW  - DSML 2: Proof-of-concept: Data science output has been formulated, implemented, and tested for one domain/problem
KW  - Inequality metric
KW  - inequality metrics
KW  - ranking and recommendation
KW  - Ranking and recommendation
KW  - responsible machine learning
KW  - Responsible machine learning
ER  - 

TY  - JOUR
TI  - An online decision-making method based on multi-agent interaction for coordinated load restoration
AU  - Fan, R.
AU  - Sun, R.
AU  - Liu, Y.
AU  - Hassan, R.U.
T2  - Frontiers in Energy Research
AB  - Load restoration coordinating transmission grid, distribution grid, and microgrids is an effective measure that is taken into consideration while improving the power system resilience in extreme weather conditions. An online decision-making method is proposed to deal with the unexpected nature of power supply issues regarding the re-energization of microgrids and transmission grids. In this research work, an online multi-agent interaction technique is used for coordinated load restoration. The main algorithm comprises of two subsections, namely, a resilience index and a multi-agent-based decision-making system which are used to administer the coordination among the transmission grid, distribution grid, and microgrids. A distributionally robust optimization model is used to evaluate the power supply capability of microgrids on the basis of load restoration parameters. Finally, a step-by-step decision-making method, based on a deep Q-network, is proposed for distribution network reconfiguration considering the uncertainty of power supply capabilities of transmission grid and microgrids. Simulation results demonstrated that the proposed method can perform the online decision-making of substation load restoration, which significantly improves the load restoration efficiency. Copyright © 2022 Fan, Sun, Liu and Hassan.
DA  - 2022///
PY  - 2022
DO  - 10.3389/fenrg.2022.992966
VL  - 10
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139031711&doi=10.3389%2ffenrg.2022.992966&partnerID=40&md5=832f4dc0bad173367f2bc112109358c1
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Decision making
KW  - E-learning
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Electric power transmission networks
KW  - Smart grid
KW  - Smart power grids
KW  - Optimization
KW  - Robust optimization
KW  - Multi agent systems
KW  - Microgrid
KW  - distributionally robust optimization
KW  - Distributionally robust optimization
KW  - deep reinforcement learning
KW  - Multi agent
KW  - resilience
KW  - Resilience
KW  - Smart Grid
KW  - Restoration
KW  - Load restoration
KW  - load restoration
KW  - microgrid
KW  - multi-agent
KW  - Transmission grids
ER  - 

TY  - JOUR
TI  - Synchronizing victim evacuation and debris removal: A data-driven robust prediction approach
AU  - Nabavi, S.M.
AU  - Vahdani, B.
AU  - Nadjafi, B.A.
AU  - Adibi, M.A.
T2  - European Journal of Operational Research
AB  - This study introduces a new perspective in disaster management's response and post-disaster phases to synchronize multiple vehicles for victim evacuation and debris removal processes. A broad range of interrelated scheduling and routing operations and various synchronization aspects of heterogeneous vehicles are considered in this regard. A novel bi-objective mixed-integer programming model is presented, where the first objective function aims to minimize the total costs of the relief logistics network, and the second one minimizes the total operation times of vehicles. Moreover, due to extensive empirical and analytical errors, preliminary travel and service times are inexact and unreliable. Hence, a novel two-stage data-driven approach is rendered to predict reliable travel and service times. In the first stage, a new hybrid machine learning model is rendered to predict these times, and in the second stage, the distributionally robust optimization with φ-divergence is employed to surmount the unreliability of predicted times. A real case study is examined to illustrate the validity of the proposed model and solution approach. In addition, several simulation experiments are conducted to demonstrate the superiority of the proposed solution method in terms of robustness. Finally, the proposed framework can improve the planning by rendering meaningful insights concerning significant parameters' influence over the schedule and routing consequences. © 2021 Elsevier B.V.
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.ejor.2021.09.051
VL  - 300
IS  - 2
SP  - 689
EP  - 712
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118565021&doi=10.1016%2fj.ejor.2021.09.051&partnerID=40&md5=758effbafe1c5f73a1608a0129b0bbf7
DB  - Scopus
KW  - Machine learning
KW  - Vehicles
KW  - Forecasting
KW  - Robust optimization
KW  - Distributionally robust optimization
KW  - Data driven
KW  - Robust predictions
KW  - Emergency services
KW  - Integer programming
KW  - Debris
KW  - Disaster prevention
KW  - Debris removal
KW  - Disaster relief
KW  - OR in disaster relief
KW  - Service time
KW  - Travel-time
KW  - Victim evacuation
ER  - 

TY  - JOUR
TI  - Fairness-Aware PAC Learning from Corrupted Data
AU  - Konstantinov, N.
AU  - Lampert, C.H.
T2  - Journal of Machine Learning Research
AB  - Addressing fairness concerns about machine learning models is a crucial step towards their long-term adoption in real-world automated systems. While many approaches have been developed for training fair models from data, little is known about the robustness of these methods to data corruption. In this work we consider fairness-aware learning under worst-case data manipulations. We show that an adversary can in some situations force any learner to return an overly biased classifier, regardless of the sample size and with or without degrading accuracy, and that the strength of the excess bias increases for learning problems with underrepresented protected groups in the data. We also prove that our hardness results are tight up to constant factors. To this end, we study two natural learning algorithms that optimize for both accuracy and fairness and show that these algorithms enjoy guarantees that are order-optimal in terms of the corruption ratio and the protected groups frequencies in the large data limit. © 2022 Nikola Konstantinov and Christoph H. Lampert.
DA  - 2022///
PY  - 2022
VL  - 23
SP  - 1
EP  - 60
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133202575&partnerID=40&md5=a3691301cdf042a15a9e7fd9fe8dea6c
DB  - Scopus
KW  - Machine learning
KW  - Automation
KW  - Fairness
KW  - robustness
KW  - trustworthy machine learning
KW  - Learning algorithms
KW  - Machine-learning
KW  - Machine learning models
KW  - Real-world
KW  - Crime
KW  - Robustness (control systems)
KW  - Robustness
KW  - Trustworthy machine learning
KW  - Data poisoning
KW  - Fairness concerns
KW  - Corrupted data
KW  - data poisoning
KW  - PAC learning
ER  - 

TY  - JOUR
TI  - Real-time detection of wind power abnormal data based on semi-supervised learning Robust Random Cut Forest
AU  - Dong, M.
AU  - Sun, M.
AU  - Song, D.
AU  - Huang, L.
AU  - Yang, J.
AU  - Joo, Y.H.
T2  - Energy
AB  - Due to extreme weather or wind turbine (WT) fault, WTs often collects abnormal data, which often interferes with the real-time control strategy of WT. To detect the abnormal data in real time, a detection framework suitable for wind power data is proposed, integrating the semi-supervised learning mechanism into the Robust Random Cut Forest algorithm. To do so, the normal data around the wind power curve are firstly selected and used to establish the structure model of normal data, considering the magnitude orders and distribution of different features. In each sample, the new sample data are inserted into the model, of which the complexity change is compared with a dynamic threshold, so as to judge whether the new sample data are abnormal. To reduce the dependence on the selection of the labeled normal data in modelling, it is presented a real-time model updating strategy based on self-training idea in semi-supervised learning. The experimental results show that the detection accuracy of the proposed method can reach 95% with only 1000 groups of the labeled normal data, and the detection time of a single sample is only 50 ms, which can detect abnormal data in real time for facilitating control strategy and other work. © 2022 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.energy.2022.124761
VL  - 257
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134527089&doi=10.1016%2fj.energy.2022.124761&partnerID=40&md5=16dfc3d444449945c833cb31d7e80465
DB  - Scopus
KW  - machine learning
KW  - Decision trees
KW  - Machine learning
KW  - Learning systems
KW  - Learning algorithms
KW  - algorithm
KW  - Semi-supervised learning
KW  - Wind power
KW  - Model complexity
KW  - supervised learning
KW  - detection method
KW  - Signal detection
KW  - Real time control
KW  - Real- time
KW  - Real-time detection
KW  - Abnormal data
KW  - complexity
KW  - Modeling complexity
KW  - Wind turbines
KW  - real time
KW  - Model updates
KW  - Abnormal detection
KW  - Extreme weather
KW  - Model update
KW  - Real-time abnormal detection
KW  - Sample data
KW  - wind power
KW  - Wind turbine
ER  - 

TY  - CONF
TI  - Robust federated learning based on metrics learning and unsupervised clustering for malicious data detection
AU  - Li, J.
AU  - Zhang, X.
AU  - Zhao, L.
T2  - Proceedings of the 2022 ACMSE Conference - ACMSE 2022: The Annual ACM Southeast Conference
AB  - Federated Learning has emerged as a new paradigm for improving communication efficiency and data privacy in various machine learning tasks. It allows the distributed devices to train the model collaboratively using their local dataset only. However, correctly labeled training data is a precondition for generating a high-quality model, whereas the real-world scenario usually cannot promise this condition. Conventional countermeasures mainly detect the corrupt local update and preclude them from the global weights aggregation phase to mitigate the impact of malicious data. Instead of discarding the weights update of clients, we propose a novel robust federated learning method that utilizes Metrics Learning to encode the local data and leverages the unsupervised clustering method K-means to preclude malicious data during local training. Therefore, correctly labeled data still contribute to the global model weight update with that the global model tends to be more generic. We evaluate the proposed method on two public image classification datasets, Fashion-MNIST and CIFAR-10. The simulation results demonstrate that the proposed scheme is robust for performing federated learning in the presence of malicious data.  © 2022 ACM.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3476883.3520221
SP  - 238
EP  - 242
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130490175&doi=10.1145%2f3476883.3520221&partnerID=40&md5=c93299a58fc808f2143805a89b96b338
DB  - Scopus
KW  - Machine learning
KW  - federated learning
KW  - neural networks
KW  - Classification (of information)
KW  - Metric learning
KW  - Neural-networks
KW  - Federated learning
KW  - Data privacy
KW  - Robust machine learning
KW  - Cluster analysis
KW  - K-means clustering
KW  - Global models
KW  - Unsupervised clustering
KW  - Communications data
KW  - Data-detection
KW  - Learning clustering
KW  - metrics learning
KW  - robust machine learning
KW  - Weight update
ER  - 

TY  - JOUR
TI  - Impact of data processing and robust machine learning process on accurate estimation of specific heat capacity property in energy storage applications
AU  - Adun, H.
AU  - Olusola, B.
AU  - Kavaz, D.
AU  - Dagbasi, M.
T2  - Journal of Energy Storage
AB  - The specific heat capacity propery is a critical thermal property because it is directly related to heat storage and transfer. The need for better and novel thermal energy storage materials have led to the discovery of high temperature nanofluids with molten salts (nanosalts). The utilization of novel machine learning tools in accurately estimating the specific heat capacity of nanofluids, would further pave the way for more innovative studies on nanosalt, hence the prediction of specific heat capacity of hybrid nanofluids constitute a significant research area. Despite the few researches conducted in the area of prediction of these fluids, priority with regards to the robust analysis of input variables for different machine learning algorithms have not been given due consideration. Therefore, this present study aims to develop and validate a robust package of machine learning algorithms (twenty machine learning algorithms) in estimating the specific heat capacity of hybrid nanofluids, across different feature spaces. The different algorithm hyperparameters were adjusted to give optimum prediction. A total of 600 data points were retrieved and split into training, testing, and validation data set, for which the validation dataset was not used in the training and testing process. The input variables used in the training of the machine learning models are temperature, volume fraction, the specific heat capacity of the base fluid, the specific heat capacity of individual nanoparticles, and the mixture ratio of individual nanoparticles. The Model A, which constituted the seven (7) input variables gave the best prediction accuracy with validation score of 0.999703, while the Model C, which contained the feature variables of temperature, volume fraction and specific heat capacity of the base fluid gave the least prediction accuracy. The optimal machine algorithms retrieved for the Model A, B, C and D was the Ridge, Gradient Boost regressor, Passive Aggressive regressor, and Kernel ridge regressor. The combination of ensemble tree regressors and online learning algorithms can be coded and used in future prediction analysis of SHC, as they have both shown accurate prediction quality. © 2022 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.est.2022.105359
VL  - 55
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135104780&doi=10.1016%2fj.est.2022.105359&partnerID=40&md5=04ab20e18515b534e511387709340b51
DB  - Scopus
KW  - Machine learning
KW  - Neural networks
KW  - Machine learning algorithms
KW  - Data handling
KW  - Learning algorithms
KW  - Machine-learning
KW  - Forecasting
KW  - Quality control
KW  - Statistical tests
KW  - Digital storage
KW  - Support vector regression
KW  - Support vector regressions
KW  - Artificial neural network
KW  - Heat storage
KW  - Nanoparticles
KW  - Prediction accuracy
KW  - Input variables
KW  - Hybrid nanofluid
KW  - Individual nanoparticles
KW  - Molten salt
KW  - Nanofluidics
KW  - Nanofluids
KW  - Specific heat
KW  - Specific heat capacity
KW  - Storage (materials)
KW  - Volume fraction
ER  - 

TY  - CONF
TI  - Safety Assurance with Ensemble-based Uncertainty Estimation and overlapping alternative Predictions in Reinforcement Learning
AU  - Eilers, D.
AU  - Burton, S.
AU  - Roza, F.S.
AU  - Roscher, K.
T2  - CEUR Workshop Proceedings
AB  - A number of challenges are associated with the use of machine learning technologies in safety-related applications. These include the difficulty of specifying adequately safe behaviour in complex environments (specification uncertainty), ensuring a predictably safe behaviour under all operating conditions (technical uncertainty) and arguing that the safety goals of the system have been met with sufficient confidence (assurance uncertainty). An assurance argument is therefore required that demonstrates that the effects of these uncertainties do not lead to an unacceptable level of risk during operation. A reinforcement learning model will predict an action in whatever state it is in - even in previously unseen states for which a valid (safe) outcome cannot be determined due to lack of training. Uncertainty estimation is a well understood approach in machine learning to identify states with a high probability of an invalid action due a lack of training experience, thus addressing technical uncertainty. However, the impact of alternative possible predictions which may be equally valid (and represent a safe state) in estimating uncertainty in reinforcement learning is not so clear and to our knowledge, not so well documented in current literature. In this paper we build on work where we investigated uncertainty estimation on simplified scenarios in a gridworld environment. Using model ensemble-based uncertainty estimation we proposed an algorithm based on action count variance to deal with discrete action spaces whilst considering in-distribution action variance calculation to handle the overlap with alternative predictions. The method indicates potentially unsafe states when the agent is near out-of-distribution elements and can distinguish it from overlapping alternative, but equally valid predictions. Here, we present these results within the context of a safety assurance framework and highlight the activities and evidences required to build a convincing safety argument. We show that our previous approach is able to act as an external observer and can fulfil the requirements of an assurance argumentation for systems based on machine learning with ontological uncertainty. © 2023 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)
DA  - 2023///
PY  - 2023
VL  - 3381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159259475&partnerID=40&md5=2c11248b544075497117f0dc81f91729
DB  - Scopus
KW  - Reinforcement learning
KW  - Machine-learning
KW  - Reinforcement learnings
KW  - Forecasting
KW  - Uncertainty
KW  - Safety engineering
KW  - Uncertainty analysis
KW  - Safe reinforcement learning
KW  - Uncertainty estimation
KW  - Safety assurance
KW  - Distributional shift
KW  - Distributional Shift
KW  - Ensemble-based uncertainty estimation
KW  - Ensemble-based Uncertainty Estimation
KW  - Out-of-distribution  detection
KW  - Out-of-Distribution (OOD) detection
KW  - Safe Reinforcement Learning (Safe RL)
KW  - Safety assurance argumentation
KW  - Safety Assurance Argumentation
ER  - 

TY  - CONF
TI  - Doubly Robust Joint Learning for Factorization Machine on Data Missing Not at Random
AU  - Hong, X.
AU  - Li, M.
AU  - Li, D.
AU  - Liu, Z.
AU  - Zhang, H.
T2  - Proceedings of SPIE - The International Society for Optical Engineering
AB  - When a recommendation system is preferred to use for predicting the ratings, it is common that many users-to-items ratings cannot be found. And what makes the prediction even trickier is that these missing ratings are missing not at random (MNAR), meaning that there are other factors contributing to why some ratings cannot be found. In order to make better predictions, common approaches to reducing the prediction errors for those missing ratings are using imputed errors and weighting the ratings that are observed with the observed propensities, but each of them is not perfect enough (since they still show bad performance with bias or heavily influenced by the variance of propensities in estimation). To generate a better recommendation system algorithm that could produce a satisfactory outcome, a new estimator combining the imputed errors and propensities in a doubly-robust way is designed to perform an unbiased estimation and meanwhile reduce the influence caused by the propensity variance. In addition, joint learning with error imputation and rating prediction based on the estimator is adopted to acquire a more reliable performance, which shows a better result than the dataset without doubly-robust joint learning. © 2023 SPIE.
DA  - 2023///
PY  - 2023
DO  - 10.1117/12.2674648
VL  - 12626
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160002720&doi=10.1117%2f12.2674648&partnerID=40&md5=cc0bc71b2d031c76f0f85417bfab081d
DB  - Scopus
KW  - Recommender systems
KW  - Learning systems
KW  - Forecasting
KW  - Medical imaging
KW  - Errors
KW  - Logistic Regression
KW  - Logistics regressions
KW  - Propensity score
KW  - Factorization machines
KW  - Data missing
KW  - Doubly robust
KW  - Doubly Robust (DR)
KW  - EIB (error-imputation-based)
KW  - Error-imputation-based
KW  - Inverse-propensity-score
KW  - IPS (inverse-propensity-score)
KW  - Items ratings
KW  - Joint learning
KW  - Joint Learning
KW  - Missing not at random
ER  - 

TY  - JOUR
TI  - Efficient and flexible mediation analysis with time-varying mediators, treatments, and confounders
AU  - Díaz, I.
AU  - Williams, N.
AU  - Rudolph, K.E.
T2  - Journal of Causal Inference
AB  - Understanding the mechanisms of action of interventions is a major general goal of scientific inquiry. The collection of statistical methods that use data to achieve this goal is referred to as mediation analysis. Natural direct and indirect effects provide a definition of mediation that matches scientific intuition, but they are not identified in the presence of time-varying confounding. Interventional effects have been proposed as a solution to this problem, but existing estimation methods are limited to assuming simple (e.g., linear) and unrealistic relations between the mediators, treatments, and confounders. We present an identification result for interventional effects in a general longitudinal data structure that allows flexibility in the specification of treatment-outcome, treatment-mediator, and mediator-outcome relationships. Identification is achieved under the standard no-unmeasured-confounders and positivity assumptions. In this article, we study semi-parametric efficiency theory for the functional identifying the mediation parameter, including the non-parametric efficiency bound, and was used to propose non-parametrically efficient estimators. Implementation of our estimators only relies on the availability of regression algorithms, and the estimators in a general framework that allows the analyst to use arbitrary regression machinery were developed. The estimators are doubly robust, n \sqrt{n} -consistent, asymptotically Gaussian, under slow convergence rates for the regression algorithms used. This allows the use of flexible machine learning for regression while permitting uncertainty quantification through confidence intervals and p p -values. A free and open-source R package implementing the methods is available on GitHub. The proposed estimator to a motivating example from a trial of two medications for opioid-use disorder was applied, where we estimate the extent to which differences between the two treatments on risk of opioid use are mediated by craving symptoms.  © 2023 the author(s), published by De Gruyter.
DA  - 2023///
PY  - 2023
DO  - 10.1515/jci-2022-0077
VL  - 11
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164383412&doi=10.1515%2fjci-2022-0077&partnerID=40&md5=44192c4275c76ef300c21704c6ccdc2e
DB  - Scopus
KW  - machine learning
KW  - mediation analysis
KW  - longitudinal data
KW  - efficient estimation
KW  - sequential double robustness
ER  - 

TY  - JOUR
TI  - Autonomous Driving Based on Approximate Safe Action
AU  - Wang, X.
AU  - Zhang, J.
AU  - Hou, D.
AU  - Cheng, Y.
T2  - IEEE Transactions on Intelligent Transportation Systems
AB  - Safety limits the application of traditional reinforcement learning (RL) methods to autonomous driving. To address the challenge of safe exploration in autonomous driving tasks, a novel safe RL method called Twin Delayed Deep Deterministic Policy Gradient based on Approximate Safe Action (TD3-ASA) is proposed in this paper. In TD3-ASA, the action output by the current policy during the exploration process is modified to obtain an approximate safe action, and then the approximate safe action is utilized to train a safe policy for deployment. TD3-ASA offers several advantages: 1) TD3-ASA is sample efficient and does not need any prior knowledge; 2) TD3-ASA enhances safety both during training and deployment; 3) TD3-ASA introduces an adjustable safety correction factor that enables a tradeoff between exploration and safety. Experimental results conducted on both the MetaDrive and SpeedLimit autonomous driving test platforms demonstrate the effectiveness of TD3-ASA. TD3-ASA exhibits more than triple safety during training on MetaDrive compared to the current state-of-the-art RL method, achieving a high success rate and low deployment risk. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TITS.2023.3292253
SP  - 1
EP  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165244656&doi=10.1109%2fTITS.2023.3292253&partnerID=40&md5=7445db2b76952552f770caaebfdbfef6
DB  - Scopus
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Safety
KW  - Task analysis
KW  - Training
KW  - Autonomous driving
KW  - Autonomous Vehicles
KW  - Job analysis
KW  - Reinforcement learnings
KW  - Optimisations
KW  - Optimization
KW  - Safety factor
KW  - Markov processes
KW  - Costs
KW  - Safe reinforcement learning
KW  - Reinforcement learning method
KW  - safe reinforcement learning
KW  - Cost benefit analysis
KW  - approximate safe action
KW  - Approximate safe action
KW  - Correction factors
KW  - safety correction factor
KW  - Safety correction factor
ER  - 

TY  - CONF
TI  - Data-driven stability of stochastic mean-field type games via noncooperative neural network adversarial training
AU  - Barreiro-Gomez, J.
AU  - Choutri, S.E.
T2  - Asian Journal of Control
AB  - We propose an approach to neural network stochastic differential games of mean-field type and its corresponding stochastic stability analysis by means of adversarial training (aka adversarial attacks). This is a class of data-driven differential games where the distribution of the variables such as the system states and the decision-makers' strategies (control inputs) is incorporated into the problem. This work casts the cooperative/noncooperative game terminology into the deep learning framework where we talk about cooperative and noncooperative neural network computations that involve learning capabilities and neural network architectures. We suggest a method to computationally validate the feasibility of the approximated solutions via neural networks and evaluate the stochastic stability of the associated closed-loop system (state feedback Nash). Moreover, we enhance the stochastic stability by enlarging the training set with adversarial initial states to obtain a more robust neural network for a particular decision-maker. Finally, a worked-out example based on the linear-quadratic mean-field type game (LQ-MTG) that illustrates our methodology is presented. © 2023 Chinese Automatic Control Society and John Wiley & Sons Australia, Ltd.
DA  - 2023///
PY  - 2023
DO  - 10.1002/asjc.3175
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165190275&doi=10.1002%2fasjc.3175&partnerID=40&md5=195c40ecc8cdfc432209accfb8eeae3a
DB  - Scopus
KW  - Deep learning
KW  - Game theory
KW  - Decision making
KW  - robustness
KW  - Supervised learning
KW  - neural networks
KW  - Network architecture
KW  - Robustness
KW  - Supervised machine learning
KW  - supervised machine learning
KW  - Stochastic systems
KW  - Closed loop systems
KW  - Neural-networks
KW  - Data driven
KW  - Stability
KW  - adversarial training
KW  - Stochastics
KW  - Mean-field
KW  - Adversarial training
KW  - State feedback
KW  - Data-driven differential game
KW  - data-driven differential games
KW  - Differential games
KW  - Stochastic mean-field type game
KW  - stochastic mean-field type games
KW  - stochastic stability
KW  - Stochastic stability
ER  - 

TY  - CONF
TI  - Towards Safety Assurance of Uncertainty-Aware Reinforcement Learning Agents
AU  - Roza, F.S.
AU  - Hadwiger, S.
AU  - Thorn, I.
AU  - Roscher, K.
T2  - CEUR Workshop Proceedings
AB  - The necessity of demonstrating that Machine Learning (ML) systems can be safe escalates with the ever-increasing expectation of deploying such systems to solve real-world tasks. While recent advancements in Deep Learning reignited the conviction that ML can perform at the human level of reasoning, the dimensionality and complexity added by Deep Neural Networks pose a challenge to using classical safety verification methods. While some progress has been made towards making verification and validation possible in the supervised learning landscape, works focusing on sequential decision-making tasks are still sparse. A particularly popular approach consists of building uncertainty-aware models, able to identify situations where their predictions might be unreliable. In this paper, we provide evidence obtained in simulation to support that uncertainty estimation can also help to identify scenarios where Reinforcement Learning (RL) agents can cause accidents when facing obstacles semantically different from the ones experienced while learning, focusing on industrial-grade applications. We also discuss the aspects we consider necessary for building a safety assurance case for uncertainty-aware RL models. © 2023 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)
DA  - 2023///
PY  - 2023
VL  - 3381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159331048&partnerID=40&md5=990bb0d95ed3edfd02bff6eeb01ac8df
DB  - Scopus
KW  - Intelligent agents
KW  - Reinforcement learning
KW  - Decision making
KW  - Deep neural networks
KW  - Learning systems
KW  - Machine-learning
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Uncertainty
KW  - Functional Safety
KW  - Uncertainty estimation
KW  - Reinforcement Learning
KW  - Machine learning systems
KW  - Safety assurance
KW  - Real-world task
KW  - Distributional shift
KW  - Distributional shifts
ER  - 

TY  - JOUR
TI  - An Unsupervised Learning Approach for Robust Denied Boarding Probability Estimation Using Smart Card and Operation Data in Urban Railways
AU  - Tuncel, K.S.
AU  - Koutsopoulos, H.N.
AU  - Ma, Z.
T2  - IEEE Intelligent Transportation Systems Magazine
AB  - Urban railway systems in many cities are facing increasing levels of crowding and operating near capacity. Crowding at stations and on trains is a concern due to its impact on safety, service quality, and operating efficiency. Denied boarding is becoming a key measure of the impact of near-capacity operations on customers, and it is fundamental for calculating other performance metrics, such as the expected waiting time. Several approaches have been proposed to infer denied boarding using smart card and train movement data. They formulate the inference as a maximum-likelihood estimation problem on observed trip journey times, with an a priori model assumption on independent journey time components, and they require extensive ground truth data collection and model calibration for practical deployment. This article proposes a data-driven unsupervised clustering-based approach to robustly infer denied boarding probabilities for access-plus-waiting times by decomposing trip journey times (instead of directly on journey times). The approach is applicable to closed fare collection systems and consists of two main steps: grouping passengers to trains via trip exit information by using a probabilistic model and inferring denied boarding probabilities by using a structured mixture distribution model with physical constraints and systematic parameter initialization. The method is data driven and requires neither observations of denied boarding nor assumptions about model components&#x2019; independence and parameter calibrations. Case studies validate the proposed method by using actual data and comparing it with state-of-the-art models and survey data. The results demonstrate the proposed model&#x2019;s robustness and applicability for estimating denied boarding under both normal and abnormal operation conditions. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/MITS.2023.3289969
SP  - 2
EP  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164678974&doi=10.1109%2fMITS.2023.3289969&partnerID=40&md5=e0c1180c29908c5b45ee18671d33cf54
DB  - Scopus
KW  - Urban areas
KW  - Data models
KW  - Time measurement
KW  - Railroads
KW  - Pandemics
KW  - Learning approach
KW  - Railroad transportation
KW  - Monitoring
KW  - Data driven
KW  - Calibration
KW  - Maximum likelihood estimation
KW  - Journey time
KW  - Maximum-likelihood estimation
KW  - Pandemic
KW  - Probability estimation
KW  - Railway system
KW  - Smart cards
KW  - Urban railway
KW  - Waiting time
ER  - 

TY  - JOUR
TI  - Multi Agent Safe Graph Reinforcement Learning for PV Inverter s Based Real-Time De centralized Volt/Var Control in Zoned Distribution Networks
AU  - Yan, R.
AU  - Xing, Q.
AU  - Xu, Y.
T2  - IEEE Transactions on Smart Grid
AB  - To realize real-time voltage/var control (VVC) in active distribution networks (ADNs), this paper proposes a new multi-agent safe graph reinforcement learning method to optimize reactive power output from PV inverters. The network is divided into several zones, and a decentralized framework is proposed for coordinated control of reactive power output in each zone to regulate voltage profiles and minimize network energy loss. The VVC problem is formulated as a multi-agent decentralized partially observable constrained Markov decision process. Each zone has a central control agent that embeds graph convolution networks (GCNs) in the policy network to improve the decision-making capability. The GCN extracts graph-structured features from the ADN topology, reflecting the relationship between VVC and grid topology, and can filter noise and impute missing data. The training process includes primal-dual policy optimization to rigorously satisfy voltage safety constraints. Simulations on a 141-bus distribution system demonstrate that the proposed method can effectively minimize network energy loss and reduce voltage deviations, even in the presence of noisy or incomplete input measurements. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TSG.2023.3277087
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160265820&doi=10.1109%2fTSG.2023.3277087&partnerID=40&md5=4e4f6b69b16b2ea36343f11856df5fad
DB  - Scopus
KW  - Reinforcement learning
KW  - Decision making
KW  - Real-time systems
KW  - Behavioral research
KW  - Interactive computer systems
KW  - Real - Time system
KW  - Real time systems
KW  - Reinforcement learnings
KW  - Optimisations
KW  - Optimization
KW  - Markov processes
KW  - Multi agent systems
KW  - Multi-agent reinforcement learning
KW  - Electric inverters
KW  - Multi agent
KW  - Electric power distribution
KW  - Energy dissipation
KW  - Topology
KW  - Reactive power
KW  - multi-agent reinforcement learning
KW  - Inverter
KW  - Distribution networks
KW  - Inverters
KW  - Graph learning
KW  - Active distribution network
KW  - Active distributions
KW  - Active distribution networks
KW  - Energy loss
KW  - graph learning
KW  - Voltage var controls
KW  - voltage/var control
ER  - 

TY  - JOUR
TI  - Adversarial Spatiotemporal Contrastive Learning for Electrocardiogram Signals
AU  - Wang, N.
AU  - Feng, P.
AU  - Ge, Z.
AU  - Zhou, Y.
AU  - Zhou, B.
AU  - Wang, Z.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - Extracting invariant representations in unlabeled electrocardiogram (ECG) signals is a challenge for deep neural networks (DNNs). Contrastive learning is a promising method for unsupervised learning. However, it should improve its robustness to noise and learn the spatiotemporal and semantic representations of categories, just like cardiologists. This article proposes a patient-level adversarial spatiotemporal contrastive learning (ASTCL) framework, which includes ECG augmentations, an adversarial module, and a spatiotemporal contrastive module. Based on the ECG noise attributes, two distinct but effective ECG augmentations, ECG noise enhancement, and ECG noise denoising, are introduced. These methods are beneficial for ASTCL to enhance the robustness of the DNN to noise. This article proposes a self-supervised task to increase the antiperturbation ability. This task is represented as a game between the discriminator and encoder in the adversarial module, which pulls the extracted representations into the shared distribution between the positive pairs to discard the perturbation representations and learn the invariant representations. The spatiotemporal contrastive module combines spatiotemporal prediction and patient discrimination to learn the spatiotemporal and semantic representations of categories. To learn category representations effectively, this article only uses patient-level positive pairs and alternately uses the predictor and the stop-gradient to avoid model collapse. To verify the effectiveness of the proposed method, various groups of experiments are conducted on four ECG benchmark datasets and one clinical dataset compared with the state-of-the-art methods. Experimental results showed that the proposed method outperforms the state-of-the-art methods. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNNLS.2023.3272153
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164724296&doi=10.1109%2fTNNLS.2023.3272153&partnerID=40&md5=01f7938179a80ba8cbdfade5a6bb8126
DB  - Scopus
KW  - Semantics
KW  - Task analysis
KW  - Artificial neural networks
KW  - Deep neural networks
KW  - Job analysis
KW  - Robustness
KW  - Learn+
KW  - Electrocardiography
KW  - Self-supervised learning
KW  - Contrastive learning
KW  - data augmentation
KW  - Data augmentation
KW  - Adversarial learning
KW  - Electrocardiograms
KW  - contrastive learning
KW  - Electrocardiogram
KW  - electrocardiogram (ECG)
KW  - Electrocardiogram signal
KW  - Spatiotemporal phenomena
KW  - Spatiotemporal phenomenon
ER  - 

TY  - CONF
TI  - Group Distributionally Robust Reinforcement Learning with Hierarchical Latent Variables
AU  - Xu, M.
AU  - Huang, P.
AU  - Niu, Y.
AU  - Kumar, V.
AU  - Qiu, J.
AU  - Fang, C.
AU  - Lee, K.-H.
AU  - Qi, X.
AU  - Lam, H.
AU  - Li, B.
AU  - Zhao, D.
T2  - Proceedings of Machine Learning Research
AB  - One key challenge for multi-task Reinforcement learning (RL) in practice is the absence of task specifications. Robust RL has been applied to deal with task ambiguity but may result in over-conservative policies. To balance the worst-case (robustness) and average performance, we propose Group Distributionally Robust Markov Decision Process (GDR-MDP), a flexible hierarchical MDP formulation that encodes task groups via a latent mixture model. GDR-MDP identifies the optimal policy that maximizes the expected return under the worst-possible qualified belief over task groups within an ambiguity set. We rigorously show that GDR-MDP's hierarchical structure improves distributional robustness by adding regularization to the worst possible outcomes. We then develop deep RL algorithms for GDR-MDP for both value-based and policy-based RL methods. Extensive experiments on Box2D control tasks, MuJoCo benchmarks, and Google football platforms show that our algorithms outperform classic robust training algorithms across diverse environments in terms of robustness under belief uncertainties. Demos are available on our project page (https://sites.google.com/view/gdr-rl/home). Copyright © 2023 by the author(s)
DA  - 2023///
PY  - 2023
VL  - 206
SP  - 2677
EP  - 2703
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165176997&partnerID=40&md5=78b2ceb3e076387d4b6e631d9b475265
DB  - Scopus
KW  - Reinforcement learning
KW  - Performance
KW  - Reinforcement learnings
KW  - Robustness (control systems)
KW  - Markov Decision Processes
KW  - Markov processes
KW  - Multi tasks
KW  - Optimal policies
KW  - Latent variable
KW  - Task groups
KW  - Mixture modeling
KW  - Task specifications
KW  - Worst-case robustness
ER  - 

TY  - CHAP
TI  - Impact of Pandemic Over Cognitive IoT for Healthcare Industry: A Market Study
AU  - Bhargava, D.
AU  - Bhargava, A.
T2  - Internet of Things
AB  - The emerging communication and technologies have affected manifolds across all industries and businesses. However, the medical industry and healthcare have embodied changes in patient care, medical innovations, personal care, remote consultation, diagnosis, and clinical trials. We have witnessed a technological transformation in healthcare in terms of remotely accessible, cost-effective solutions for doctors, patients, pharmacists, and hospitals, such as smart wearable Internet of Things (IoT) devices, remote surgery using IoT devices, virtual consultation, remote medical services, intelligent clinics, EMR, and EHR to name a few. The present market study shows the rise in IoT-based diverse application-specific and smart healthcare solutions to combat the present pandemic COVID-19. The IoT provides noninvasive healthcare solutions, real-time patient data acquisition through sensors, and quality of care and remote physiological monitoring of patients. IoT in healthcare market includes components, such as sensor-based medical equipment, applications such as telemedicine, medical imaging, and remote monitoring; and end users like hospitals, doctors, and patients. The market study shows that more than 75% of top-notch companies such as IBM, SAP, Google, Microsoft, and Oracle are ready to use Cognitive IoT-based systems in healthcare, the blend of IoT and artificial intelligence techniques. This chapter includes the concept of cognitive IoT in healthcare and its key drivers, opportunities, challenges, and limitations. The further section presents the market analysis and key market players in cognitive IoT in healthcare. The chapter concludes with the impact of pandemic on cognitive IoT. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
VL  - Part F739
SP  - 183
EP  - 190
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163856484&doi=10.1007%2f978-3-031-08637-3_10&partnerID=40&md5=a440abca5e6150d7c15b2db9b3b0ddb2
DB  - Scopus
KW  - Machine learning
KW  - Data analysis
KW  - Learning systems
KW  - COVID-19
KW  - Diagnosis
KW  - Internet of things
KW  - Internet of Things
KW  - Responsibility
KW  - Machine-learning
KW  - Cognitive systems
KW  - Pandemics
KW  - Cost effectiveness
KW  - Hospitals
KW  - Data acquisition
KW  - Healthcare
KW  - Personal data
KW  - Patient monitoring
KW  - Hospital data processing
KW  - Pandemic
KW  - Cognitive computation
KW  - Cognitive internet of thing
KW  - Cognitive internets
KW  - Cognitive IoT
KW  - Economic analysis
KW  - Economics analysis
KW  - Industry analysis
KW  - Internet of medical thing
KW  - Internet of Medical Things
KW  - Market studies
KW  - Market study
KW  - Massive data
KW  - Responsive AI
KW  - Smart healthcare
KW  - Smart tool
KW  - Smart tools
ER  - 

TY  - CONF
TI  - Supply Chain for Safe & Timely Distribution of Medicines using Blockchain & Machine Learning
AU  - Shah, Y.
AU  - Verma, Y.
AU  - Sharma, U.
AU  - Sampat, A.
AU  - Kulkarni, V.
T2  - Proceedings - 5th International Conference on Smart Systems and Inventive Technology, ICSSIT 2023
AB  - Because fake drugs are so prevalent, researchers, managers, and policymakers are paying close attention to the issue. When fake medications are used, they can harm or even kill the person who is taking them. The majority of the issues with the safety of counterfeit drugs in the supply chain are related to how the drugs are manufactured in the first place. Because it is difficult to track down the right active pharmaceutical ingredients during manufacturing, finding medicines that do not have the right active ingredients can harm or kill patients. Because Blockchain is so advanced, it can be used to track medicines from the manufacturer to the person who takes them. It can also be used to detect counterfeit medications. Blockchain technology can be promising to transform and improve the healthcare industry because it is secure, dependable, and open, and it can store data in real time. Blockchain technology and Machine Learning(ML) will be used in this study to investigate drug safety and ensure timely distribution of medicines. The use of Blockchain technology, proposes a supply chain management system based on a permissioned Blockchain network and role-based authorization. This would prevent people from tampering with the network's data. By ensuring that all item units are transparent, traceable, and consistent, the Blockchain-based decentralized solution will make it easier for people to collaborate and trust one another. By using data from the Blockchain network based machine learning algorithms will be used to predict delays in deliveries and hence help the Supply Chain Managers to take preventive action and save further supply chain expenses.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICSSIT55814.2023.10061049
SP  - 1123
EP  - 1129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150680481&doi=10.1109%2fICSSIT55814.2023.10061049&partnerID=40&md5=9ebfb4ad47ce16bf8e7c8d4ba26e9f30
DB  - Scopus
KW  - Machine learning
KW  - Machine Learning
KW  - Blockchain
KW  - Learning algorithms
KW  - Machine-learning
KW  - Crime
KW  - Network-based
KW  - Block-chain
KW  - Policy makers
KW  - Active ingredients
KW  - Active pharmaceuticals ingredients
KW  - Counterfeit drugs
KW  - Counterfeit Drugs
KW  - Healthcare industry
KW  - Pharmaceutical supply chain management
KW  - Pharmaceutical Supply Chain Management
KW  - Pharmaceutical supply chains
KW  - Supply chain management
ER  - 

TY  - CONF
TI  - Analysis of Regional Safety Index Based on Public Data: Focusing on Suwon City
AU  - Lee, M.-K.
AU  - Jeong, Y.-S.
AU  - Kuc, T.-Y.
T2  - Proceedings - 2023 12th IEEE International Conference on Communication Systems and Network Technologies, CSNT 2023
AB  - The purpose of this paper is to analyze the correlation between the regional safety index, urban space, and time series data, to analyze the causes of vulnerable areas by subdividing the regional safety index, and to derive solutions. Public data was used for analysis, and spatial data such as police stations, security bells, and security facilities, and time-series and spatial composite data such as the number of police reports by time zone and floating population were used. In addition, Suwon, Gyeonggi-do, the city to be analyzed, is a large city with a population of over 1 million. It is located near Seoul and has a very high floating population as there are various landmarks, such as Samsung Electronics headquarters and Suwon Hwaseong, in the city. Therefore, it is an excellent city to analyze multiple characteristics that are difficult to obtain in other cities. To obtain various insights, we analyzed multiple methods, and in particular, techniques such as exploratory data analysis, visualization analysis, and machine learning were used. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/CSNT57126.2023.10134587
SP  - 509
EP  - 513
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162014673&doi=10.1109%2fCSNT57126.2023.10134587&partnerID=40&md5=5a7a92e0ad920867e913f5ab40b4015d
DB  - Scopus
KW  - Machine learning
KW  - Data handling
KW  - Machine-learning
KW  - Data visualization
KW  - Information analysis
KW  - Safety indexes
KW  - Time series
KW  - Time-series data
KW  - Law enforcement
KW  - Population statistics
KW  - Public data
KW  - Correlation analysis
KW  - Floating populations
KW  - Regional safety index
KW  - Space and time
KW  - Spatial data analysis
KW  - Spatial variables measurement
KW  - Urban spaces
ER  - 

TY  - JOUR
TI  - Physics-Constrained Adversarial Training for Neural Networks in Stochastic Power Grids
AU  - Li, W.
AU  - Deka, D.
AU  - Wang, R.
AU  - Paternina, M.R.A.
T2  - IEEE Transactions on Artificial Intelligence
AB  - The growth in distributed energy resources (DERs) is an important step toward solving the global climate crisis. However, many DERs, such as wind and solar power, are random and intermittent, causing the data in power grids to be perturbed with high uncertainty. Such perturbations degrade the performance of data-driven algorithms introduced in power grids for sensing and control. Existing approaches can strengthen machine learning models against well-designed malicious attacks. However, such physics-agnostic efforts fail to ensure the robustness to natural perturbations in power grids, that occur due to varying loads and changes in control inputs. This paper proposes a novel physics-constrained adversarial training method for robustifying neural networks for the crucial problem of locating edge-faults in power grids. Our approach relies on first deriving analytical physical laws that are satisfied by state perturbations in realistic grids, and then using the descriptive sets during adversarial training. Compared to state of the art methods, our perturbation-robust neural networks have higher robust accuracy as well as training efficiency. Also, we demonstrate that the proposed approach achieves a tighter upper bound of robust risks than traditional efforts. The numerical experimental results in the IEEE 68-bus benchmark system validate our adversarial training in two scenarios when loads and control inputs vary randomly. The proposed method shows superior performance in accuracy and efficiency for different perturbed datasets. In addition, we testify the influence of different inputs on the robustness. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TAI.2023.3236377
SP  - 1
EP  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147203039&doi=10.1109%2fTAI.2023.3236377&partnerID=40&md5=f71d4c138fd2b1127d37706a918a5b06
DB  - Scopus
KW  - Machine learning
KW  - Neural networks
KW  - Training
KW  - Perturbation methods
KW  - robustness
KW  - Learning systems
KW  - neural networks
KW  - Machine-learning
KW  - Robustness (control systems)
KW  - Robustness
KW  - Stochastic systems
KW  - Neural-networks
KW  - Electric power system control
KW  - Power grids
KW  - Perturbation method
KW  - Perturbation techniques
KW  - Adversarial training
KW  - Solar energy
KW  - Voltage measurement
KW  - fault location
KW  - natural perturbations
KW  - Natural perturbations
KW  - Physic-constrained
KW  - physics-constrained
ER  - 

TY  - JOUR
TI  - Identifying Road Accident Black Spots using Classical and Modern Approaches
AU  - Karamanlis, I.
AU  - Kokkalis, A.
AU  - Profillidis, V.
AU  - Botzoris, G.
AU  - Galanis, A.
T2  - WSEAS Transactions on Systems
AB  - The utilization of conclusions from the data analysis of road traffic accidents is of high importance for the development of targeted traffic safety measures, which will effectively reduce the rate of road traffic accidents, thus promoting road safety. Considering the problems of time and money, it is not practical to improve road safety in all the places where road traffic accidents occur. Therefore, the process of identifying accident-prone locations, known as black spots, is a cost-effective and efficient way to analyze the causes of road accidents and reduce them. Identifying black spots is an effective strategy to reduce accidents. The core methods that may be used in the process of identifying the black spots of a road network are the sorting, grouping, and accident prediction methods. However, in practice, it is easy to overlook certain factors that significantly contribute to defining and characterizing a spot on the road network as black. Therefore, suggestions to carry out projects required to reduce security risks shall not be based on the above methods. Machine learning algorithms that in recent years have been widely used in the field of predicting a road traffic accident cover these weaknesses. They can effectively classify data sets and make a connection between factors and the severity of events. Machine learning algorithms include classification, regression, clustering, and dimensionality reduction. In this work, a study was conducted on road traffic accidents that took place on the national and provincial network of Northern Greece from 2014 to 2018, with the aim of determining the black spots. The study provided the general public access to a database of black spots on the road network of Northern Greece. At the same time, it created a point of reference for the recognition of the points in question located on the entire road network, and selected a black spot determination model, after having compared specific measures to determine the quality of a model, which resulted from the application of a logistic regression and machine learning algorithms. © 2023 WSEAS Transactions on Systems. All rights reserved.
DA  - 2023///
PY  - 2023
DO  - 10.37394/23202.2023.22.56
VL  - 22
SP  - 556
EP  - 565
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164611017&doi=10.37394%2f23202.2023.22.56&partnerID=40&md5=c3efb49d488d7cda38b1468df8301d00
DB  - Scopus
KW  - machine learning
KW  - road safety
KW  - data set
KW  - binary logistic regression
KW  - Black spot
KW  - traffic accidents
ER  - 

TY  - CONF
TI  - Semantically Processed Sensor Data in Health Care, Legislation Compliant, Ontologies
AU  - D’Souza, O.
AU  - Mukhopadhyay, S.
AU  - Sheng, M.
T2  - Lecture Notes in Electrical Engineering
AB  - Sensor technologies protect life, property and those that are vulnerable, an ontology of most concern to researchers in public health. Detecting risks, such as intrusion and fire, is as crucial as delivering care to the most vulnerable. Today the sophistication of these multi-spectral sensor systems provides much more than “event alarms”, improving the quality of work and life for all. The technology, operational scope and necessary compliance with standards and legislation (the law) make it a challenging environment. We present core concepts in designing sensors and semantically aware systems to enhance security, safety and compliance, especially in assisted living centres, where solutions have evolved to perform in a data-driven domain. The complexity of products, systems and processes ensures that data is always available to analyse events live and forensically. The emergence of machine learning makes sensors “intelligent”, improving the approach to risk management. We present options that bring together legislated processes and technology that facilitate compliance with a data-driven focus for the assisted living community. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-29871-4_16
VL  - 1035 LNEE
SP  - 135
EP  - 148
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159418215&doi=10.1007%2f978-3-031-29871-4_16&partnerID=40&md5=4c39b64c4740c8fedf420e4d940d3fff
DB  - Scopus
KW  - Security
KW  - Machine learning
KW  - Risk management
KW  - Standards
KW  - Ontology
KW  - Machine-learning
KW  - Safety engineering
KW  - Digital storage
KW  - Real- time
KW  - Data driven
KW  - Fire safety
KW  - Healthcare
KW  - fire safety
KW  - Regulatory compliance
KW  - Assisted living
KW  - Data drive
KW  - Data drives
KW  - Legislated compliance
KW  - Machine learning sensor
KW  - Machine Learning sensors
KW  - Ontology's
KW  - real-time
ER  - 

TY  - JOUR
TI  - Robust ranking by ensembling of diverse models and assessment metrics
AU  - Tomal, J.H.
AU  - Welch, W.J.
AU  - Zamar, R.H.
T2  - Journal of Statistical Computation and Simulation
AB  - We propose an ensemble of classification models formed using different assessment metrics. For a given metric, a classifier performs feature selection and combines models based on different subsets of feature variables which we call phalanxes. This first step, which employs the algorithm of phalanx formation, identifies strong and diverse subsets of feature variables. A second phase of ensembling aggregates classifiers across diverse assessment metrics. The proposed method is applied to protein homology data to mine homologous proteins, where the feature variables used for developing classifiers are various measures of similarity scores of proteins, and found robust for ranking both evolutionary close and distant homologous proteins. © 2022 Informa UK Limited, trading as Taylor & Francis Group.
DA  - 2023///
PY  - 2023
DO  - 10.1080/00949655.2022.2093873
VL  - 93
IS  - 1
SP  - 77
EP  - 102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133693327&doi=10.1080%2f00949655.2022.2093873&partnerID=40&md5=3d4125e2aebfe718b2c3daa4b476f510
DB  - Scopus
KW  - Machine learning
KW  - robustness
KW  - data mining
KW  - feature selection
KW  - classification and clustering
ER  - 

TY  - JOUR
TI  - Self-Supervised Monocular Depth Estimation with Self-Reference Distillation and Disparity Offset Refinement
AU  - Liu, Z.
AU  - Li, R.
AU  - Shao, S.
AU  - Wu, X.
AU  - Chen, W.
T2  - IEEE Transactions on Circuits and Systems for Video Technology
AB  - Monocular depth estimation plays a fundamental role in computer vision. Due to the costly acquisition of depth ground truth, self-supervised methods that leverage adjacent frames to establish a supervision signal have emerged as the most promising paradigms. In this work, we propose two novel ideas to improve self-supervised monocular depth estimation: 1) self-reference distillation and 2) disparity offset refinement. Specifically, we use a parameter-optimized model as the teacher updated as the training epochs to provide additional supervision during the training process. The teacher model has the same structure as the student model, with weights inherited from the historical student model. In addition, a multiview check is introduced to filter out the outliers produced by the teacher model. Furthermore, we leverage the contextual consistency between high-level and low-level features to obtain multiscale disparity offsets, which are used to refine the disparity output incrementally by aligning disparity information at different scales. The experimental results on the KITTI and Make3D datasets show that our method outperforms previous state-of-the-art competitors. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TCSVT.2023.3275584
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162872553&doi=10.1109%2fTCSVT.2023.3275584&partnerID=40&md5=6e3fd32d5c4d40244cac0dce4f888d93
DB  - Scopus
KW  - Task analysis
KW  - Training
KW  - Supervised learning
KW  - Job analysis
KW  - Personnel training
KW  - Estimation
KW  - Decoding
KW  - Distillation
KW  - Self-supervised learning
KW  - Bandpass filters
KW  - Multi-views
KW  - Depth Estimation
KW  - Monocular depth estimation
KW  - Three dimensional displays
KW  - Three-dimensional display
KW  - Three-dimensional displays
KW  - Teaching
KW  - Disparity alignment
KW  - Information filter
KW  - Information filters
KW  - Multiview check
KW  - Optical filters
KW  - Self-reference distillation
KW  - Self-references
ER  - 

TY  - CONF
TI  - A Robust Framework for Fixing The Vulnerability of Compressed Distributed Learning
AU  - Chen, Y.
AU  - Wang, B.
AU  - Zhang, Y.
AU  - Kuang, J.
T2  - Proceedings of the 2023 26th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2023
AB  - Nowadays, as a prevailing paradigm for large-scale machine learning, distributed learning has been faced with two challenges, communication bottleneck and limited robustness. For the communication challenge, compression is widely-used as a solution. For the robustness challenge, some robust defence methods have been proposed. However, previous works that simultaneously consider these two challenges are limited. Through an experiment on the w8a dataset, we found that compressed distributed learning with rand-K is vulnerable to poisoning attacks. Therefore, in this paper, we propose a robust compressed distributed framework for distributed learning settings. Experimental evaluations on a9a and w8a datasets have shown the effectiveness of our proposed framework, which markedly decreases the average optimality gap from 1.47E -2 and 2.15E -2 to 3.98E -4 and 4.33E -4 respectively.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/CSCWD57460.2023.10152781
SP  - 733
EP  - 738
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164686727&doi=10.1109%2fCSCWD57460.2023.10152781&partnerID=40&md5=3b3e21af6d20d9c82120e878aeb75a21
DB  - Scopus
KW  - Machine learning
KW  - Machine Learning
KW  - Machine-learning
KW  - Robustness
KW  - Poisoning attacks
KW  - Learning settings
KW  - Experimental evaluation
KW  - Distributed learning
KW  - Average optimality
KW  - Compression
KW  - Distributed framework
KW  - Distributed Learning
KW  - Large-scale machine learning
KW  - Poisoning Attacks
ER  - 

TY  - JOUR
TI  - Distributed and Distribution-Robust Meta Reinforcement Learning (D2-RMRL) for Data Pre-Storage and Routing in Cube Satellite Networks
AU  - Hu, Y.
AU  - Wang, X.
AU  - Saad, W.
T2  - IEEE Journal on Selected Topics in Signal Processing
AB  - In this paper, the problem of data pre-storage and routing in dynamic, resource-constrained cube satellite networks is studied. In such a network, each cube satellite delivers requested data to user clusters under its coverage. A group of ground gateways will route and pre-store certain data to the satellites, such that the ground users can be directly served with the pre-stored data. This pre-storage and routing design problem is formulated as a decentralized Markov decision process (Dec-MDP) in which we seek to find the optimal strategy that maximizes the pre-store hit rate, i.e., the fraction of users being directly served with the pre-stored data. To obtain the optimal strategy, a distributed distribution-robust meta reinforcement learning (D2-RMRL) algorithm is proposed that consists of three key ingredients: value-decomposition for achieving the global optimum in distributed setting with minimum communication overhead, meta learning to obtain the optimal initial to reduce the training time under dynamic conditions, and pre-training to further speed up the meta training procedure. Simulation results show that, using the proposed value decomposition and meta training techniques, the satellite networks can achieve a 31.8% improvement of the pre-store hits and a 40.7% improvement of the convergence speed, compared to a baseline reinforcement learning algorithm. Moreover, the use of the proposed pre-training mechanism helps to shorten the meta-learning procedure by up to 43.7%.  © 2007-2012 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/JSTSP.2022.3232944
VL  - 17
IS  - 1
SP  - 128
EP  - 141
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147208192&doi=10.1109%2fJSTSP.2022.3232944&partnerID=40&md5=afb7c345464bf642b1deabb84b3923be
DB  - Scopus
KW  - Reinforcement learning
KW  - Task analysis
KW  - Learning algorithms
KW  - Markov processes
KW  - Multi agent systems
KW  - Multi-agent reinforcement learning
KW  - Digital storage
KW  - Heuristic algorithms
KW  - Heuristics algorithm
KW  - Satellites
KW  - Metalearning
KW  - Actor critic
KW  - Optimal systems
KW  - meta learning
KW  - multi-agent reinforcement learning
KW  - Routings
KW  - Geometry
KW  - Actor-critic
KW  - cube satellite network
KW  - Cube satellite network
KW  - data pre-storage
KW  - Data pre-storage
KW  - routing
KW  - Satellite communications
KW  - Satellite network
KW  - value decomposition
KW  - Value decomposition
ER  - 

TY  - JOUR
TI  - Robust Incremental Bayesian Learning Based Online Flux Linkage Estimation for PMSM Drives
AU  - Huang, K.
AU  - Feng, G.
AU  - Lai, C.
AU  - Kar, N.C.
T2  - IEEE Transactions on Transportation Electrification
AB  - For the permanent magnet synchronous machine (PMSM), parameter estimation can be greatly affected by the measurement uncertainty, but few efforts are made to reduce the uncertainty level for estimation performance improvement. Therefore, this article proposes an efficient and robust incremental Bayesian learning approach for PMSM parameter estimation. The measurement uncertainty is evaluated to guide the selection of informative measurements, and the estimation uncertainty is provided to indicate the confidence in using the estimated results. Specifically, a Bayesian learning strategy with a layered noise model is proposed for nonlinear flux linkage estimation. The measurement uncertainty level is estimated from the proposed Bayesian learning model, which is utilized to adaptively select the most informative data and delete the noninformative data for parameter estimation. This contributes to improving estimation accuracy and computation efficiency. Moreover, the estimation uncertainty is also determined by the proposed model, which can be used to indicate if the estimated results can be trusted and utilized in practical applications. The proposed approach is evaluated on a laboratory interior PMSM under various operating conditions.  © 2015 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TTE.2022.3190328
VL  - 8
IS  - 4
SP  - 4509
EP  - 4522
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134202819&doi=10.1109%2fTTE.2022.3190328&partnerID=40&md5=56f135ab76b12874835b498ea18c1d37
DB  - Scopus
KW  - Learning systems
KW  - Uncertainty
KW  - Uncertainty analysis
KW  - Parameter estimation
KW  - Data reduction
KW  - Digital storage
KW  - Permanent magnets
KW  - Bayes method
KW  - Bayesian learning
KW  - Couplings
KW  - parameter estimation
KW  - Data selection
KW  - Data Selection
KW  - Flux linkage
KW  - measurement uncertainty
KW  - Measurement uncertainty
KW  - Parameters estimation
KW  - permanent magnet synchronous machine (PMSM)
KW  - Permanent magnets synchronous machines
KW  - robust incremental Bayesian learning
KW  - Robust incremental bayesian learning
ER  - 

TY  - JOUR
TI  - Multi-Modal Noise-Robust DDoS Attack Detection Architecture in Large-Scale Networks Based on Tensor SVD
AU  - Xu, J.
AU  - Li, X.
AU  - Wang, P.
AU  - Jin, X.
AU  - Yao, S.
T2  - IEEE Transactions on Network Science and Engineering
AB  - Distributed Denial of Service (DDoS) attacks consumes the resources of traditional or cloud computing networks, resulting in the network unable to provide normal services. Therefore, accurate detection of DDoS attacks can avoid greater losses and provide an important guarantee for network space security. But with the rapid development of the Internet, the network scale is becoming larger and larger, and the structure is becoming more and more complex. Network data shows large-scale heterogeneous characteristics, which lead to data processing becomes more difficult and the traditional algorithms cannot accurately identify attack traffic. Therefore, how to accurately and efficiently detect DDoS attacks in large-scale networks has become a new challenge. To deal this problem, this paper proposes a novel DDoS attack detection framework. Which has mainly made three contributions: (i) Representation of large-scale heterogeneous network data by tensor; (ii) A multi-modal denoising algorithm based on tensor SVD is proposed; (iii) An efficient anomaly detection architecture suitable for large-scale networks is proposed, which combines (i), (ii) and XGBoost classification model. Experiments show that the framework can achieve a high detection rate of 98.84%, and has the characteristics of well extendable, strong noise-robust and fast detection speed.  © 2013 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TNSE.2022.3205708
VL  - 10
IS  - 1
SP  - 152
EP  - 165
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139386755&doi=10.1109%2fTNSE.2022.3205708&partnerID=40&md5=de4a5bd6056359aae6cb47daa8be6f64
DB  - Scopus
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Learning systems
KW  - Anomaly detection
KW  - Learning algorithms
KW  - E-learning
KW  - Machine-learning
KW  - Network security
KW  - Network architecture
KW  - Heterogeneous networks
KW  - Denial-of-service attack
KW  - Denialof- service attacks
KW  - Distributed computer systems
KW  - Noise robust
KW  - Tensors
KW  - Distributed denial of service
KW  - Data de-noising
KW  - Data denoising
KW  - Large-scale network
KW  - Network anomaly detection
KW  - Noise-Robust
KW  - Tensor SVD
ER  - 

TY  - CONF
TI  - Robust Models of Distance Metric Learning by Interval-Valued Training Data
AU  - Utkin, L.
AU  - Konstantinov, A.
AU  - Muliukha, V.
AU  - Politaeva, N.
T2  - Lecture Notes in Networks and Systems
AB  - Two approaches for developing robust models of the distance metric learning under condition of interval-valued training data are proposed. Both approaches are based on a probabilistic representation of the feature intervals and on solving the minimax optimization problem which is stated for implementing robust decisions. The first approach is based on using the dual form representation of the linear maximization programming problem with probability distributions as optimization variables for computing optimal values of features within intervals. The second approach is based on considering extreme points of a polyhedron produced by the probability distribution constraints. The approaches can be regarded as a framework for developing a set of robust distance metric learning models which can be constructed on the basis of the Mahalanobis distance (linear transformation) as well as of Siamese neural networks (non-linear transformation). © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2023///
PY  - 2023
DO  - 10.1007/978-3-031-20875-1_7
VL  - 460 LNNS
SP  - 65
EP  - 77
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148026725&doi=10.1007%2f978-3-031-20875-1_7&partnerID=40&md5=5b631ac7901c3393eab7571049c92ef4
DB  - Scopus
KW  - Machine learning
KW  - Robust
KW  - Metric learning
KW  - Interval-valued data
ER  - 

TY  - JOUR
TI  - JSMix: a holistic algorithm for learning with label noise
AU  - Wen, Z.
AU  - Xu, H.
AU  - Ying, S.
T2  - Neural Computing and Applications
AB  - The success of deep learning is mainly dependent on large-scale and accurately labeled datasets. However, real-world datasets are marked with much noise. Directly training on datasets with label noise may lead to the overfitting. Recent research is under the spotlight on how to design algorithms that can learn robust models from noisy datasets, via designing the loss function and integrating the idea of Semi-supervised learning (SSL). This paper proposes a robust algorithm for learning with label noise that does not require additional clean data and an auxiliary model. Specifically, on the one hand, Jensen–Shannon (JS) divergence is introduced as a component of the loss function, which measures the distance between the predicted distribution and the noisy label distribution. It can alleviate the overfitting problem caused by the traditional cross entropy loss theoretically and experimentally. On the other hand, a dynamic sample selection mechanism is also proposed. The dataset is divided into the pseudo-clean labeled subset and the pseudo-noisy labeled subset. Two subsets are treated differently to exploit prior information about the data, and then learned by SSL. The dynamic sample selection is performed with the iteration between two subsets and the model parameters, which are different from the conventional training. Considering the label of the pseudo-clean labeled subset is not correct entirely, they are also refined by linear interpolation. Furthermore, we experimentally show that the integration of SSL helps the model divide two subsets more precise and build decision boundaries more explicit. Extensive experimental results on corrupted data from benchmark datasets and the real-world dataset, including CIFAR-10, CIFAR-100, and Clothing1M, demonstrate that our method is superior to many state-of-the-art approaches for learning with label noise. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s00521-022-07770-9
VL  - 35
IS  - 2
SP  - 1519
EP  - 1533
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139177299&doi=10.1007%2fs00521-022-07770-9&partnerID=40&md5=733ca6f7e18f5fbabc4dac91622d3cf8
DB  - Scopus
KW  - Deep learning
KW  - Supervised learning
KW  - Learning algorithms
KW  - Semi-supervised learning
KW  - Loss functions
KW  - Robust loss function
KW  - Iterative methods
KW  - Large dataset
KW  - Set theory
KW  - Large-scales
KW  - Real-world datasets
KW  - Overfitting
KW  - Labeled dataset
KW  - Data with label noise
KW  - Dynamic sample selection
KW  - Jensen-Shannon divergence
KW  - Jensen–Shannon divergence
ER  - 

TY  - CONF
TI  - White-Box Adversarial Policies in Deep Reinforcement Learning
AU  - Casper, S.
AU  - Hadfield-Menell, D.
AU  - Kreiman, G.
T2  - CEUR Workshop Proceedings
AB  - Adversarial examples can be useful for developing safer AI both by identifying vulnerabilities in a model and improving its robustness via adversarial training. In reinforcement learning, adversarial policies can be developed by training an adversarial agent to minimize a target agent's rewards. Prior work has studied black-box attacks where the adversary only sees the state observations and effectively treats the target agent as any other part of the environment. In this work, we study white-box adversarial policies to understand whether an agent's internal state can offer useful information for other agents. We make three contributions. First, we introduce white-box adversarial policies in which an attacker can observe a target agent's internal state at each timestep. Second, we demonstrate that white-box adversarial policies are more effective at finding weaknesses in a target agent, resulting in both faster initial learning and higher asymptotic performance. Third, we show that training against white-box adversarial policies can be used to make learners in single-agent environments more robust to domain shifts. Code is available at this https url. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0). CEUR Workshop Proceedings (CEUR-WS.org)
DA  - 2023///
PY  - 2023
VL  - 3381
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159291476&partnerID=40&md5=46a78213325ce23b249467c4811e2b1b
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Internal state
KW  - Reinforcement learnings
KW  - Black boxes
KW  - Robustness (control systems)
KW  - Robustness
KW  - Adversarial attack
KW  - Adversarial attacks
KW  - White box
KW  - Adversarial training
KW  - HTTP
KW  - Adversarial agent
KW  - State observation
KW  - Time step
ER  - 

TY  - JOUR
TI  - A robust and interpretable machine learning approach using multimodal biological data to predict future pathological tau accumulation
AU  - Giorgio, J.
AU  - Jagust, W.J.
AU  - Baker, S.
AU  - Landau, S.M.
AU  - Tino, P.
AU  - Kourtzi, Z.
T2  - Nature Communications
AB  - The early stages of Alzheimer’s disease (AD) involve interactions between multiple pathophysiological processes. Although these processes are well studied, we still lack robust tools to predict individualised trajectories of disease progression. Here, we employ a robust and interpretable machine learning approach to combine multimodal biological data and predict future pathological tau accumulation. In particular, we use machine learning to quantify interactions between key pathological markers (β-amyloid, medial temporal lobe atrophy, tau and APOE 4) at mildly impaired and asymptomatic stages of AD. Using baseline non-tau markers we derive a prognostic index that: (a) stratifies patients based on future pathological tau accumulation, (b) predicts individualised regional future rate of tau accumulation, and (c) translates predictions from deep phenotyping patient cohorts to cognitively normal individuals. Our results propose a robust approach for fine scale stratification and prognostication with translation impact for clinical trial design targeting the earliest stages of AD. © 2022, The Author(s).
DA  - 2022///
PY  - 2022
DO  - 10.1038/s41467-022-28795-7
VL  - 13
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130786544&doi=10.1038%2fs41467-022-28795-7&partnerID=40&md5=2c5136c0e52ffa5bebb7229b5d75e367
DB  - Scopus
KW  - machine learning
KW  - Machine Learning
KW  - prediction
KW  - female
KW  - human
KW  - Humans
KW  - male
KW  - procedures
KW  - aged
KW  - comparative study
KW  - Article
KW  - disease course
KW  - major clinical study
KW  - predictive model
KW  - pathology
KW  - cohort analysis
KW  - neuroimaging
KW  - nuclear magnetic resonance imaging
KW  - phenotype
KW  - Alzheimer disease
KW  - Alzheimer Disease
KW  - cognitive defect
KW  - Cognitive Dysfunction
KW  - mild cognitive impairment
KW  - neuropsychological test
KW  - positron emission tomography
KW  - biological marker
KW  - Biomarkers
KW  - unclassified drug
KW  - recursive feature elimination
KW  - diagnostic accuracy
KW  - Magnetic Resonance Imaging
KW  - Positron-Emission Tomography
KW  - accumulation
KW  - amyloid beta protein
KW  - Amyloid beta-Peptides
KW  - apolipoprotein
KW  - apolipoprotein E4
KW  - Apolipoprotein E4
KW  - community dwelling person
KW  - disease
KW  - florbetapir
KW  - generalised matrix learning vector quantisation
KW  - learning vector quantisation
KW  - limit of quantitation
KW  - multimodal imaging
KW  - neuropathology
KW  - physiological response
KW  - standardized uptake value ratio
KW  - stratification
KW  - T1 weighted imaging
KW  - tau protein
KW  - tau Proteins
KW  - tracer
ER  - 

TY  - JOUR
TI  - A state-of-the-art review on adversarial machine learning in image classification
AU  - Bajaj, A.
AU  - Vishwakarma, D.K.
T2  - Multimedia Tools and Applications
AB  - Computer vision applications like traffic monitoring, security checks, self-driving cars, medical imaging, etc., rely heavily on machine learning models. It raises an essential growing concern regarding the dependability of machine learning algorithms, which cannot be entirely trusted due to their fragile nature. This leads us to a dire need for systematic analysis of adversarial settings in neural networks. Hence, this article presents a comprehensive study of vulnerabilities, possible attacks such as data poisoning and data access during training, evasion, and oracle attacks at the test time, and their defensive and preventive measures using novel taxonomies. The survey has covered the complete scenario where an adversary can make malicious manipulations and elaborated more on the most potent threat, i.e., test time evasion attack using an adversarial image (maliciously perturbed image). It expounds an intuition behind generating an adversarial image, covering all relevant adversarial attack algorithms and strategies for increasing robustness against adversarial images. The existence and effect of adversarial images, as well as their transferability, are also examined. The article guides the reader with an approach on building new models to enhance their reliability. Additionally, the survey presents the procedures that still demand further exploration with limitations in existing methods, enhancing future research directions. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s11042-023-15883-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161966122&doi=10.1007%2fs11042-023-15883-z&partnerID=40&md5=8e7fe6972be2727f1bfe567219cc9297
DB  - Scopus
KW  - Deep neural networks
KW  - Convolutional neural networks
KW  - Learning systems
KW  - Learning algorithms
KW  - Machine-learning
KW  - Image classification
KW  - Convolutional neural network
KW  - Medical imaging
KW  - Robustness
KW  - Adversarial machine learning
KW  - Attack
KW  - Attacks
KW  - Backdoors
KW  - Deep neural network
KW  - Defense
KW  - Data poisoning
KW  - Adversarial machine learning (AML)
KW  - Backdoor attack
KW  - Backdoor attacks
KW  - Brittle
KW  - Convolutional neural networks (CNN)
KW  - Deep neural networks (DNNs)
KW  - Defences
KW  - Evasion
ER  - 

TY  - JOUR
TI  - Learning from small medical data - Robust semi-supervised cancer prognosis classifier with Bayesian variational autoencoder
AU  - Hsu, T.-C.
AU  - Lin, C.
T2  - Bioinformatics Advances
AB  - Motivation: Cancer is one of the world's leading mortality causes, and its prognosis is hard to predict due to complicated biological interactions among heterogeneous data types. Numerous challenges, such as censorship, high dimensionality and small sample size, prevent researchers from using deep learning models for precise prediction. Results: We propose a robust Semi-supervised Cancer prognosis classifier with bAyesian variational autoeNcoder (SCAN) as a structured machine-learning framework for cancer prognosis prediction. SCAN incorporates semi-supervised learning for predicting 5-year disease-specific survival and overall survival in breast and non-small cell lung cancer (NSCLC) patients, respectively. SCAN achieved significantly better AUROC scores than all existing benchmarks (81.73% for breast cancer; 80.46% for NSCLC), including our previously proposed bimodal neural network classifiers (77.71% for breast cancer; 78.67% for NSCLC). Independent validation results showed that SCAN still achieved better AUROC scores (74.74% for breast; 72.80% for NSCLC) than the bimodal neural network classifiers (64.13% for breast; 67.07% for NSCLC). SCAN is general and can potentially be trained on more patient data. This paves the foundation for personalized medicine for early cancer risk screening. © 2023 The Author(s). Published by Oxford University Press.
DA  - 2023///
PY  - 2023
DO  - 10.1093/bioadv/vbac100
VL  - 3
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150156254&doi=10.1093%2fbioadv%2fvbac100&partnerID=40&md5=41d81c1eb8b97618519fc11178c2cb99
DB  - Scopus
ER  - 

TY  - JOUR
TI  - A Cloud-Edge Collaboration Solution for Distribution Network Reconfiguration Using Multi-Agent Deep Reinforcement Learning
AU  - Gao, H.
AU  - Wang, R.
AU  - He, S.
AU  - Wang, L.
AU  - Liu, J.
AU  - Chen, Z.
T2  - IEEE Transactions on Power Systems
AB  - Network reconfiguration can maintain the optimal operation of distribution network with increasing penetration of distributed generations (DGs). However, network reconfiguration problems may not be solved quickly by traditional methods in large-scale distribution networks. In this context, a cloud-edge collaboration framework based on multi-agent deep reinforcement learning (MADRL) is proposed, where the MADRL model can be trained centrally in the cloud center and decentrally executed in edge servers to reduce the training cost and execution latency of MADRL. In addition, a discrete multi-agent soft actor-critic algorithm (MASAC) is introduced as the basic algorithm to address the non-stationary environment problem in MADRL. Then, online safe learning and offline safe learning are combined for the distribution network reconfiguration task in practice to update the neural networks of MADRL under constraints. Specifically, a novel offline algorithm called multi-agent constraints penalized Q-learning (MACPQ) is proposed to reduce the cost of trial-and-error process of MADRL while allowing agents to pre-train their policies from a historical dataset considering constraints. Meanwhile, a new online MADRL method called primal-dual MASAC is proposed to further improve the performance of agents by directly interacting with the physical distribution network under the safe action exploration. Finally, the superiority of the proposed methods is verified in IEEE 33-bus system and a practical 445-bus system. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TPWRS.2023.3296463
SP  - 1
EP  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165292802&doi=10.1109%2fTPWRS.2023.3296463&partnerID=40&md5=f03c08566e786c66707d861e7167a57a
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Task analysis
KW  - Training
KW  - Job analysis
KW  - Reinforcement learnings
KW  - Multi agent systems
KW  - Costs
KW  - Safe reinforcement learning
KW  - safe reinforcement learning
KW  - Switches
KW  - Multi agent
KW  - multi-agent deep reinforcement learning
KW  - Multi-agent deep reinforcement learning
KW  - Cost reduction
KW  - Collaboration
KW  - Q-learning
KW  - Distribution networks
KW  - Batch reinforcement learning
KW  - cloud-edge collaboration
KW  - Cloud-edge collaboration
KW  - distribution network reconfiguration
KW  - Distribution network reconfiguration
ER  - 

TY  - JOUR
TI  - Robust deep semi-supervised learning with label propagation and differential privacy
AU  - Yan, Z.
AU  - Li, S.
AU  - Duan, Z.
AU  - Zhao, Y.
T2  - Frontiers in Computer Science
AB  - Semi-supervised learning (SSL) methods provide a powerful tool for utilizing abundant unlabeled data to strengthen standard supervised learning. Traditional graph-based SSL methods prevail in classical SSL problems for their intuitional implementation and effective performance. However, they encounter troubles when applying to image classification followed by modern deep learning, since the diffusion algorithms face the curse of dimensionality. In this study, we propose a simple and efficient SSL method, combining a graph-based SSL paradigm with differential privacy. We aim at developing coherent latent feature space of deep neural networks so that the diffusion algorithm in the latent space can give more precise predictions for unlabeled data. Our approach achieves state-of-the-art performance on the Cifar10, Cifar100, and Mini-imagenet benchmark datasets and obtains an error rate of 18.56% on Cifar10 using only 1% of all labels. Furthermore, our approach inherits the benefits of graph-based SSL methods with a simple training process and can be easily combined with any network architecture. Copyright © 2023 Yan, Li, Duan and Zhao.
DA  - 2023///
PY  - 2023
DO  - 10.3389/fcomp.2023.1114186
VL  - 5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161233853&doi=10.3389%2ffcomp.2023.1114186&partnerID=40&md5=2a9293f3fe6b1b657eccfa97e7c06e8d
DB  - Scopus
KW  - robust learning
KW  - deep semi-supervised learning
KW  - differential privacy
KW  - label propagation
KW  - mixup data augmentation
ER  - 

TY  - JOUR
TI  - Active Gamma-Ray Log Pattern Localization With Distributionally Robust Reinforcement Learning
AU  - Zi, Y.
AU  - Fan, L.
AU  - Wu, X.
AU  - Chen, J.
AU  - Wang, S.
AU  - Han, Z.
T2  - IEEE Transactions on Geoscience and Remote Sensing
AB  - Accurately localizing 1-D signal patterns, such as Gamma-ray well-log depth matching, is crucial in the oilfield service industry as it directly affects the quality of oil and gas exploration. However, traditional methods such as well-log curve analysis and pattern hand-picking matching are labor-intensive and heavily rely on human expertise, leading to inconsistent results. Although attempts have been made to automate this process, challenges such as low computational performance, nonrobustness, and nongeneralization remain unsolved. To address these challenges, we have developed a data-driven AI system that learns an active signal pattern localization strategy inspired by human attention. Our artificial intelligence system uses an offline reinforcement learning (RL) framework as its central component, which solves a highly abstracted Markov decision process (MDP) problem via offline training on human-labeled historical data. The RL agent uses top-down reasoning to determine the location of target signal fragments by deforming a bounding window using simple transformation actions. To overcome distribution shifts between logged data and real and ensure generalization, we propose a discrete distributionally robust soft actor-critic (SAC) RL framework (DRSAC-Discrete) to solve the MDP problem under uncertainty. By exploring unfamiliar environments in a restrictive manner, the DRSAC-Discrete algorithm provides a safe solution that can be used when data is limited during the early stage of this industrial application. We evaluated the RL-based localization system on augmented field Gamma-ray well-log datasets, and the results showed promising localization capability. Furthermore, the DRSAC-Discrete algorithm demonstrated relatively robust performance guarantees when facing data shortage.  © 1980-2012 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/TGRS.2023.3278491
VL  - 61
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161010687&doi=10.1109%2fTGRS.2023.3278491&partnerID=40&md5=845be72bc61ffa85fa982c3a2abd8d5d
DB  - Scopus
KW  - Reinforcement learning
KW  - robotics
KW  - Reinforcement learnings
KW  - algorithm
KW  - Uncertainty
KW  - Robustness
KW  - Markov chain
KW  - Markov Decision Processes
KW  - Markov processes
KW  - supervised learning
KW  - Gamma rays
KW  - Localisation
KW  - data set
KW  - pattern recognition
KW  - Distributionally robustness
KW  - gamma radiation
KW  - Gamma ray logs
KW  - gamma-ray log
KW  - Gamma-rays
KW  - Location awareness
KW  - Markov decision processes (MDPs)
KW  - oil field
KW  - Petroleum prospecting
KW  - signal localization
KW  - Signal localization
ER  - 

TY  - CHAP
TI  - Safe deployment of reinforcement learning using deterministic optimization over neural networks
AU  - Burtea, R.-A.
AU  - Tsay, C.
T2  - Computer Aided Chemical Engineering
AB  - Enabling reinforcement learning (RL) to explicitly consider constraints is important for safe deployment in real-world process systems. This work exploits recent developments in deep RL and optimization over trained neural networks to introduce algorithms for safe training and deployment of RL agents. We show how optimization over trained neural-network state-action value functions (i.e., a critic function) can explicitly incorporate constraints and describe two corresponding RL algorithms: the first uses constrained optimization of the critic to give optimal actions for train- ing an actor, while the second guarantees constraint satisfaction by directly implementing actions from optimizing a trained critic model. The two algorithms are tested on a supply chain case study from OR-Gym and are compared against state-of-the-art algorithms TRPO, CPO, and RCPO. © 2023 Elsevier B.V.
DA  - 2023///
PY  - 2023
VL  - 52
SP  - 1643
EP  - 1648
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165109397&doi=10.1016%2fB978-0-443-15274-0.50261-4&partnerID=40&md5=87535a952e53d3db40db451159b3a260
DB  - Scopus
KW  - Constrained reinforcement learning
KW  - Optimization and machine learning toolkit
KW  - Optimization of neural network surrogates
KW  - Supply chain optimization
ER  - 

TY  - CONF
TI  - Improved Sample Complexity Bounds for Distributionally Robust Reinforcement Learning
AU  - Xu, Z.
AU  - Panaganti, K.
AU  - Kalathil, D.
T2  - Proceedings of Machine Learning Research
AB  - We consider the problem of learning a control policy that is robust against the parameter mismatches between the training environment and testing environment. We formulate this as a distributionally robust reinforcement learning (DR-RL) problem where the objective is to learn the policy which maximizes the value function against the worst possible stochastic model of the environment in an uncertainty set. We focus on the tabular episodic learning setting where the algorithm has access to a generative model of the nominal (training) environment around which the uncertainty set is defined. We propose the Robust Phased Value Learning (RPVL) algorithm to solve this problem for the uncertainty sets specified by four different divergences: total variation, chi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm achieves Õ(|S||A|H5) sample complexity, which is uniformly better than the existing results by a factor of |S|, where |S| is number of states, |A| is the number of actions, and H is the horizon length. We also provide the first-ever sample complexity result for the Wasserstein uncertainty set. Finally, we demonstrate the performance of our algorithm using simulation experiments. Copyright © 2023 by the author(s)
DA  - 2023///
PY  - 2023
VL  - 206
SP  - 9728
EP  - 9754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165128474&partnerID=40&md5=90de9728edbfcd03f58b3c9a519673a0
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Uncertainty
KW  - Stochastic models
KW  - Stochastic systems
KW  - Learn+
KW  - Learning problem
KW  - Sample complexity
KW  - Control policy
KW  - Value functions
KW  - Parameter mismatches
KW  - Sample complexity bounds
KW  - Testing environment
ER  - 

TY  - JOUR
TI  - Automatic Surface Analyzation of Bicycle Paths Using Machine Learning – A Multi-Stage Approach
AU  - Taminé, O.
AU  - Baier, J.
AU  - Deyringer, J.
AU  - Alili, B.
AU  - Sartorius, E.
AU  - Demir, M.
AU  - Kauz, N.
T2  - AGIT- Journal fur Angewandte Geoinformatik
AB  - In this paper, a multi-stage method is presented that uses machine learning methods to determine the surface condition of paths used by bicycles. This approach uses a low-threshold acquisition method through smartphone-generated video data for image recognition to automatically detect and classify the surface condition and its state. The results are displayed on digital maps to increase their level of detail. The aim is to improve the safety and comfort of cyclists and to enable better maintenance of the paths. © Wichmann Verlag, VDE VERLAG GMBH · Berlin.
DA  - 2023///
PY  - 2023
DO  - 10.14627/537742012
VL  - 2023
IS  - 9
SP  - 114
EP  - 121
ST  - Automatische Erfassung und Analyse der Oberflächenbeschaffenheit von Radwegen mittels Machine Learning – ein mehrstufiger Ansatz
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164152927&doi=10.14627%2f537742012&partnerID=40&md5=299eb0285180f1f1ab6f829c25df43a3
DB  - Scopus
KW  - Machine Learning
KW  - automatic detection
KW  - bicycle paths
KW  - bicycle safety
KW  - condition analysis
KW  - digital maps
KW  - image recognition
KW  - smartphone-generated video data
KW  - Surface condition
ER  - 

TY  - CONF
TI  - Byzantine-Robust Online and Offline Distributed Reinforcement Learning
AU  - Chen, Y.
AU  - Zhang, X.
AU  - Zhang, K.
AU  - Wang, M.
AU  - Zhu, X.
T2  - Proceedings of Machine Learning Research
AB  - We consider a distributed reinforcement learning setting where multiple agents separately explore the environment and communicate their experiences through a central server. However, αfraction of agents are adversarial and can report arbitrary fake information. Critically, these adversarial agents can collude and their fake data can be of any sizes. We desire to robustly identify a near-optimal policy for the underlying Markov decision process in the presence of these adversarial agents. Our main technical contribution is COW, a novel algorithm for the robust mean estimation from batches problem, that can handle arbitrary batch sizes. Building upon this new estimator, in the offline setting, we design a Byzantine-robust distributed pessimistic value iteration algorithm; in the online setting, we design a Byzantine-robust distributed optimistic value iteration algorithm. Both algorithms obtain near-optimal sample complexities and achieve superior robustness guarantee than prior works. Copyright © 2023 by the author(s)
DA  - 2023///
PY  - 2023
VL  - 206
SP  - 3230
EP  - 3269
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164381268&partnerID=40&md5=f0f263cd3d72d542c157a405a6e611d3
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - E-learning
KW  - Reinforcement learnings
KW  - Markov Decision Processes
KW  - Markov processes
KW  - Multi agent systems
KW  - Iterative methods
KW  - Offline
KW  - Learning settings
KW  - Adversarial agent
KW  - Central servers
KW  - Near-optimal policies
KW  - Multiple agents
KW  - Technical contribution
KW  - Value iteration algorithm
ER  - 

TY  - JOUR
TI  - Residuals-based distributionally robust optimization with covariate information
AU  - Kannan, R.
AU  - Bayraksan, G.
AU  - Luedtke, J.R.
T2  - Mathematical Programming
AB  - We consider data-driven approaches that integrate a machine learning prediction model within distributionally robust optimization (DRO) given limited joint observations of uncertain parameters and covariates. Our framework is flexible in the sense that it can accommodate a variety of regression setups and DRO ambiguity sets. We investigate asymptotic and finite sample properties of solutions obtained using Wasserstein, sample robust optimization, and phi-divergence-based ambiguity sets within our DRO formulations, and explore cross-validation approaches for sizing these ambiguity sets. Through numerical experiments, we validate our theoretical results, study the effectiveness of our approaches for sizing ambiguity sets, and illustrate the benefits of our DRO formulations in the limited data regime even when the prediction model is misspecified. © 2023, Springer-Verlag GmbH Germany, part of Springer Nature and Mathematical Optimization Society.
DA  - 2023///
PY  - 2023
DO  - 10.1007/s10107-023-02014-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172278862&doi=10.1007%2fs10107-023-02014-7&partnerID=40&md5=eba3d8199b3c45b704caa2fbecf9e5ec
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Uncertainty analysis
KW  - Robust optimization
KW  - Distributionally robust optimization
KW  - Stochastic programming
KW  - Sampling
KW  - Data driven
KW  - Convergence rates
KW  - Wasserstein distance
KW  - Covariates
KW  - Convergence rate
KW  - Data-driven stochastic programming
KW  - Large deviations
KW  - Phi divergences
KW  - Phi-divergences
ER  - 

TY  - JOUR
TI  - Boosting Video Object Segmentation via Robust and Efficient Memory Network
AU  - Chen, Y.
AU  - Zhang, D.
AU  - Zheng, Y.
AU  - Yang, Z.
AU  - Wu, E.
AU  - Zhao, H.
T2  - IEEE Transactions on Circuits and Systems for Video Technology
AB  - Recently, memory-based methods have exhibited remarkable performance in Video Object Segmentation (VOS) by employing non-local pixel-wise matching between the query and memory. Nevertheless, these methods suffer from two limitations: 1) Non-local pixel-wise matching can result in the incorrect segmentation of background distractor objects, and 2) memory features with substantial temporal redundancy consume significant computing resources and reduce the inference speed. To address the limitations, we first propose a local attention mechanism to suppress background features, and we introduce a novel training framework based on contrast learning to ensure the network learns reliable and robust pixel-wise correspondence between query and memory. We adaptively determine whether to update the memory based on the variation of foreground objects. Next, we propose a dynamic memory bank, which utilizes a lightweight and differentiable soft modulation gate to determine the number of memory features to remove along the temporal dimension. This allows efficient and flexible management of memory features. Our network achieves competitive results (e.g., 92.1% on DAVIS 2016 val, 87.6%/81.3% on DAVIS 2017 val/test, 87.0% on YouTube-VOS 2018 val) compared with the state-of-the-art methods while maintaining a faster inference speed of 25+FPS. Moreover, our network demonstrates a favorable balance between performance and speed when dealing with the long-time video dataset. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TCSVT.2023.3321977
SP  - 1
EP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174811833&doi=10.1109%2fTCSVT.2023.3321977&partnerID=40&md5=d62df29788f67a2977d2b55824703fd9
DB  - Scopus
KW  - Task analysis
KW  - Feature extraction
KW  - semi-supervised learning
KW  - Training
KW  - robustness
KW  - Supervised learning
KW  - Features extraction
KW  - Job analysis
KW  - Performance
KW  - Image segmentation
KW  - Robustness
KW  - Semi-supervised learning
KW  - Motion compensation
KW  - Pixels
KW  - Redundancy
KW  - redundancy
KW  - Video sequences
KW  - Memory management
KW  - Memory-management
KW  - Object segmentation
KW  - Objects segmentation
KW  - Termination of employment
KW  - Video objects segmentations
ER  - 

TY  - JOUR
TI  - Conformal Predictive Safety Filter for RL Controllers in Dynamic Environments
AU  - Strawn, K.J.
AU  - Ayanian, N.
AU  - Lindemann, L.
T2  - IEEE Robotics and Automation Letters
AB  - The interest in using reinforcement learning (RL) controllers in safety-critical applications such as robot navigation around pedestrians motivates the development of additional safety mechanisms. Running RL-enabled systems among uncertain dynamic agents may result in high counts of collisions and failures to reach the goal. The system could be safer if the pre-trained RL policy was uncertainty-informed. For that reason, we propose <italic>conformal predictive safety filters</italic> that: 1) predict the other agents&#x0027; trajectories, 2) use statistical techniques to provide uncertainty intervals around these predictions, and 3) learn an additional safety filter that closely follows the RL controller but avoids the uncertainty intervals. We use conformal prediction to learn uncertainty-informed predictive safety filters, which make no assumptions about the agents&#x0027; distribution. The framework is modular and outperforms the existing controllers in simulation. We demonstrate our approach with multiple experiments in a collision avoidance gym environment and show that our approach minimizes the number of collisions without making overly conservative predictions. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/LRA.2023.3322644
SP  - 1
EP  - 8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174844462&doi=10.1109%2fLRA.2023.3322644&partnerID=40&md5=07707bbdae1e1e714275089a0239b90c
DB  - Scopus
KW  - Reinforcement learning
KW  - Safety
KW  - Motion planning
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Training
KW  - Collision avoidance
KW  - Motion-planning
KW  - Collisions avoidance
KW  - Reinforcement learnings
KW  - Controllers
KW  - Forecasting
KW  - Pedestrian safety
KW  - Uncertainty
KW  - Learn+
KW  - Reinforcement Learning
KW  - Robot programming
KW  - Bandpass filters
KW  - Conformal predictions
KW  - Learning controllers
KW  - Conformal Prediction
KW  - Predictive safety filter
KW  - Predictive Safety Filter
KW  - Safe motion planning
KW  - Safe Motion Planning
KW  - Uncertainty intervals
ER  - 

TY  - CONF
TI  - The Benefits of Power Regularization in Cooperative Reinforcement Learning
AU  - Li, M.
AU  - Dennis, M.
T2  - Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS
AB  - Cooperative Multi-Agent Reinforcement Learning (MARL) algorithms, trained only to optimize task reward, can lead to a concentration of power where the failure or adversarial intent of a single agent could decimate the reward of every agent in the system. In the context of teams of people, it is often useful to explicitly consider how power is distributed to ensure no person becomes a single point of failure. Here, we argue that explicitly regularizing the concentration of power in cooperative RL systems can result in systems which are more robust to single agent failure, adversarial attacks, and incentive changes of co-players. To this end, we define a practical pairwise measure of power that captures the ability of any co-player to influence the ego agent's reward, and then propose a power-regularized objective which balances task reward and power concentration. Given this new objective, we show that there always exists an equilibrium where every agent is playing a power-regularized best-response balancing power and task reward. Moreover, we present two algorithms for training agents towards this power-regularized objective: Sample Based Power Regularization (SBPR), which injects adversarial data during training; and Power Regularization via Intrinsic Motivation (PRIM), which adds an intrinsic motivation to regulate power to the training objective. Our experiments demonstrate that both algorithms successfully balance task reward and power, leading to lower power behavior than the baseline of task-only reward and avoid catastrophic events in case an agent in the system goes off-policy. © 2023 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.
DA  - 2023///
PY  - 2023
VL  - 2023-May
SP  - 457
EP  - 465
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171277810&partnerID=40&md5=b137712938bf9dc56237e7ab9e1c4760
DB  - Scopus
KW  - Game theory
KW  - Reinforcement learning
KW  - Autonomous agents
KW  - Learning systems
KW  - Learning algorithms
KW  - Motivation
KW  - Fault tolerance
KW  - Multi agent systems
KW  - Fertilizers
KW  - Multi-agent reinforcement learning
KW  - Power
KW  - Multi-Agent Reinforcement Learning
KW  - Single-agent
KW  - Regularisation
KW  - Adversarial robustness
KW  - Adversarial Robustness
KW  - Cooperative multi-agent reinforcement learning
KW  - Cooperative Multi-Agent Reinforcement Learning
KW  - Cooperative reinforcement learning
KW  - Distribution of power
KW  - Distribution of Power
KW  - Fault Tolerance
KW  - Game Theory
KW  - Intrinsic motivation
KW  - Intrinsic Motivation
ER  - 

TY  - JOUR
TI  - Novel Wearable HD-EMG Sensor with Shift-Robust Gesture Recognition using Deep Learning
AU  - Chamberland, F.
AU  - Buteau, E.
AU  - Tam, S.
AU  - Campbell, E.
AU  - Mortazavi, A.
AU  - Scheme, E.
AU  - Fortier, P.
AU  - Boukadoum, M.
AU  - Campeau-Lecours, A.
AU  - Gosselin, B.
T2  - IEEE Transactions on Biomedical Circuits and Systems
AB  - In this work, we present a hardware-software solution to improve the robustness of hand gesture recognition to confounding factors in myoelectric control. The solution includes a novel, full-circumference, flexible, 64-channel high-density electromyography (HD-EMG) sensor called EMaGer. The stretchable, wearable sensor adapts to different forearm sizes while maintaining uniform electrode density around the limb. Leveraging this uniformity, we propose novel array barrel-shifting data augmentation (ABSDA) approach used with a convolutional neural network (CNN), and an anti-aliased CNN (AA-CNN), that provides shift invariance around the limb for improved classification robustness to electrode movement, forearm orientation, and inter-session variability. Signals are sampled from a 4x16 HD-EMG array of electrodes at a frequency of 1 kHz and 16-bit resolution. Using data from 12 able-bodied participants, the approach is tested in response to sensor rotation, forearm rotation, and inter-session scenarios. The proposed ABSDA-CNN method improves inter-session accuracy by 25.67&#x0025; on average across users for 6 gesture classes compared to conventional CNN classification. A comparison with other devices shows that this benefit is enabled by the unique design of the EMaGer array. The AA-CNN yields improvements of up to 63.05&#x0025; accuracy over non-augmented methods when tested with electrode displacements ranging from -45<inline-formula><tex-math notation="LaTeX">$^\circ$</tex-math></inline-formula> to +45<inline-formula><tex-math notation="LaTeX">$^\circ$</tex-math></inline-formula> around the limb. Overall, this paper demonstrates the benefits of co-designing sensor systems, processing methods, and inference algorithms to leverage synergistic and interdependent properties to solve state-of-the-art problems. IEEE
DA  - 2023///
PY  - 2023
DO  - 10.1109/TBCAS.2023.3314053
SP  - 1
EP  - 17
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171793497&doi=10.1109%2fTBCAS.2023.3314053&partnerID=40&md5=e058a3b50465197ac81256ab9fa78dee
DB  - Scopus
KW  - Deep learning
KW  - deep learning
KW  - Artificial intelligence
KW  - Neural networks
KW  - Convolutional neural networks
KW  - Convolution
KW  - Convolutional neural network
KW  - Robustness (control systems)
KW  - Robustness
KW  - Inference engines
KW  - Electrodes
KW  - Electromyography
KW  - Gesture recognition
KW  - Hand gesture recognition
KW  - Hand-gesture recognition
KW  - Palmprint recognition
KW  - Wearable sensors
KW  - electromyography (EMG)
KW  - data augmentation
KW  - Data augmentation
KW  - artificial intelligence (AI)
KW  - biomedical
KW  - Biomedical
KW  - flexible PCB
KW  - Flexible PCB
KW  - Gestures recognition
KW  - hand gesture recognition (HGR)
KW  - HD-EMG
KW  - High-density electromyography
KW  - Muscles
KW  - Polychlorinated biphenyls
KW  - prosthesis control
KW  - Prosthesis control
ER  - 

TY  - JOUR
TI  - Improving Data-Efficiency and Robustness of Medical Imaging Segmentation Using Inpainting-Based Self-Supervised Learning
AU  - Dominic, J.
AU  - Bhaskhar, N.
AU  - Desai, A.D.
AU  - Schmidt, A.
AU  - Rubin, E.
AU  - Gunel, B.
AU  - Gold, G.E.
AU  - Hargreaves, B.A.
AU  - Lenchik, L.
AU  - Boutin, R.
AU  - Chaudhari, A.S.
T2  - Bioengineering
AB  - We systematically evaluate the training methodology and efficacy of two inpainting-based pretext tasks of context prediction and context restoration for medical image segmentation using self-supervised learning (SSL). Multiple versions of self-supervised U-Net models were trained to segment MRI and CT datasets, each using a different combination of design choices and pretext tasks to determine the effect of these design choices on segmentation performance. The optimal design choices were used to train SSL models that were then compared with baseline supervised models for computing clinically-relevant metrics in label-limited scenarios. We observed that SSL pretraining with context restoration using 32 × 32 patches and Poission-disc sampling, transferring only the pretrained encoder weights, and fine-tuning immediately with an initial learning rate of 1 × 10 (Formula presented.) provided the most benefit over supervised learning for MRI and CT tissue segmentation accuracy (p < 0.001). For both datasets and most label-limited scenarios, scaling the size of unlabeled pretraining data resulted in improved segmentation performance. SSL models pretrained with this amount of data outperformed baseline supervised models in the computation of clinically-relevant metrics, especially when the performance of supervised learning was low. Our results demonstrate that SSL pretraining using inpainting-based pretext tasks can help increase the robustness of models in label-limited scenarios and reduce worst-case errors that occur with supervised learning. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/bioengineering10020207
VL  - 10
IS  - 2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149065792&doi=10.3390%2fbioengineering10020207&partnerID=40&md5=2fed220f2f5333ef1dc9f72fac0a244c
DB  - Scopus
KW  - machine learning
KW  - deep learning
KW  - segmentation
KW  - self-supervised learning
KW  - CT
KW  - MRI
ER  - 

TY  - CONF
TI  - RAMRL: Towards Robust On-Ramp Merging via Augmented Multimodal Reinforcement Learning
AU  - Bagwe, G.
AU  - Yuan, X.
AU  - Chen, X.
AU  - Zhang, L.
T2  - Proceedings - 2023 IEEE International Conference on Mobility, Operations, Services and Technologies, MOST 2023
AB  - Despite the success of AI-enabled onboard perception, on-ramp merging has been one of the main challenges for autonomous driving. Due to limited sensing range of onboard sensors, a merging vehicle can hardly observe main road conditions and merge properly. By leveraging the wireless communications between connected and automated vehicles (CAVs), a merging CAV has potential to proactively obtain the intentions of nearby vehicles. However, CAVs can be prone to inaccurate observations, such as the noisy basic safety messages (BSM) and poor quality surveillance images. In this paper, we present a novel approach for Robust on-ramp merge of CAVs via Augmented and Multi-modal Reinforcement Learning, named by RAMRL. Specifically, we formulate the on-ramp merging problem as a Markov decision process (MDP) by taking driving safety, comfort driving behavior, and traffic efficiency into account. To provide reliable merging maneuvers, we simultaneously leverage BSM and surveillance images for multi-modal observation, which is used to learn a policy model through proximal policy optimization (PPO). Moreover, to improve data efficiency and provide better generalization performance, we train the policy model with augmented data (e.g., noisy BSM and noisy surveillance images). Extensive experiments are conducted with Simulation of Urban MObility (SUMO) platform under two typical merging scenarios. Experimental results demonstrate the effectiveness and efficiency of our robust on-ramp merging design. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/MOST57249.2023.00011
SP  - 23
EP  - 33
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169816685&doi=10.1109%2fMOST57249.2023.00011&partnerID=40&md5=eb5f6f48225aa8e61500c5789364e2ab
DB  - Scopus
KW  - Reinforcement learning
KW  - Vehicles
KW  - Automated vehicles
KW  - Reinforcement learnings
KW  - Multi-modal
KW  - Efficiency
KW  - Vehicle to vehicle communications
KW  - Image enhancement
KW  - Markov processes
KW  - Simulation platform
KW  - Policy optimization
KW  - Data augmentation
KW  - Connected and automated vehicle
KW  - Proximal policy optimization
KW  - Safety messages
KW  - Merging
KW  - Multimodal
KW  - On-ramp
KW  - Robust on-ramp merging
ER  - 

TY  - CONF
TI  - Out-of-Distributed Semantic Pruning for Robust Semi-Supervised Learning
AU  - Wang, Y.
AU  - Qiao, P.
AU  - Liu, C.
AU  - Song, G.
AU  - Zheng, X.
AU  - Chen, J.
T2  - Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition
AB  - Recent advances in robust semi-supervised learning (SSL) typically filter out-of-distribution (OOD) information at the sample level. We argue that an overlooked problem of robust SSL is its corrupted information on semantic level, practically limiting the development of the field. In this paper, we take an initial step to explore and propose a unified framework termed OOD Semantic Pruning (OSP), which aims at pruning OOD semantics out from in-distribution (ID) features. Specifically, (i) we propose an aliasing OOD matching module to pair each ID sample with an OOD sample with semantic overlap. (ii) We design a soft orthogonality regularization, which first transforms each ID feature by suppressing its semantic component that is collinear with paired OOD sample. It then forces the predictions before and after soft orthogonality decomposition to be consistent. Being practically simple, our method shows a strong performance in OOD detection and ID classification on challenging benchmarks. In particular, OSP surpasses the previous state-of-the-art by 13.7% on accuracy for ID classification and 5.9% on AUROC for OOD detection on TinyImageNet dataset. The source codes are publicly available at https://github.com/rain305f/OSP. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/CVPR52729.2023.02284
VL  - 2023-June
SP  - 23849
EP  - 23858
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173943999&doi=10.1109%2fCVPR52729.2023.02284&partnerID=40&md5=293eb3822748643d1696dab4705c586c
DB  - Scopus
KW  - detection
KW  - Recognition: Categorization
KW  - retrieval
ER  - 

TY  - CONF
TI  - Robust Route Planning with Distributional Reinforcement Learning in a Stochastic Road Network Environment
AU  - Lin, X.
AU  - Szenher, P.
AU  - Martin, J.D.
AU  - Englot, B.
T2  - 2023 20th International Conference on Ubiquitous Robots, UR 2023
AB  - Route planning is essential to mobile robot navigation problems. In recent years, deep reinforcement learning (DRL) has been applied to learning optimal planning policies in stochastic environments without prior knowledge. However, existing works focus on learning policies that maximize the expected return, the performance of which can vary greatly when the level of stochasticity in the environment is high. In this work, we propose a distributional reinforcement learning based framework that learns return distributions which explicitly reflect environmental stochasticity. Policies based on the second-order stochastic dominance (SSD) relation can be used to make adjustable route decisions according to user preference on performance robustness. Our proposed method is evaluated in a simulated road network environment, and experimental results show that our method is able to plan the shortest routes that minimize stochasticity in travel time when robustness is preferred, while other state-of-the-art DRL methods are agnostic to environmental stochasticity.  © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/UR57808.2023.10202222
SP  - 287
EP  - 294
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169450732&doi=10.1109%2fUR57808.2023.10202222&partnerID=40&md5=72c9c4399bd7c3ab35348145a49b3488
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Route planning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Roads and streets
KW  - Mobile robots
KW  - Stochastic systems
KW  - Robot programming
KW  - Travel time
KW  - Stochastics
KW  - Road network
KW  - Environmental stochasticity
KW  - Mobile Robot Navigation
KW  - Navigation problem
KW  - Network environments
KW  - Optimal planning
KW  - Stochasticity
ER  - 

TY  - CONF
TI  - Distributionally Robust Proximal Policy Optimization for Unit Commitment with Wind Power Uncertainty
AU  - Lu, Y.
AU  - Wang, B.
T2  - 2022 1st International Conference on Cyber-Energy Systems and Intelligent Energy, ICCSIE 2022
AB  - Unit commitment problem plays an essential part in the electricity market. The uncertainty of wind power and power demand increases the difficulty of solving the unit commitment problem. Although the traditional method can effectively solve this problem, the computation time grows exponentially with the increasing scale. To overcome this difficulty, we use deep reinforcement learning (DRL) methods by the means of the formulation of the UC problem as a Markov decision process and propose a DRL-based algorithm to solve the problem. Meanwhile, we use distributionally robust optimization to improve the DRL method robustness. The IEEE 39-bus test case is used to conduct numerical results and demonstrate the method's effectiveness. Finally, we compare it with some existing solutions to verify its effectiveness and superiority. © 2023 IEEE.
DA  - 2023///
PY  - 2023
DO  - 10.1109/ICCSIE55183.2023.10175277
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166385273&doi=10.1109%2fICCSIE55183.2023.10175277&partnerID=40&md5=0a048a651e5a502db3b8455cabf88626
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Markov decision process
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Uncertainty
KW  - Optimization
KW  - Wind power
KW  - Markov Decision Processes
KW  - Markov processes
KW  - Robust optimization
KW  - distributionally robust optimization
KW  - Distributionally robust optimization
KW  - Numerical methods
KW  - deep reinforcement learning
KW  - Policy optimization
KW  - Unit commitment
KW  - Unit Commitment
KW  - Proximal policy optimization
KW  - Unit-commitment problems
ER  - 

TY  - JOUR
TI  - A Novel and Robust Wind Speed Prediction Method Based on Spatial Features of Wind Farm Cluster
AU  - Zhang, M.
AU  - Wang, Y.
AU  - Zhang, H.
AU  - Peng, Z.
AU  - Tang, J.
T2  - Mathematics
AB  - Wind energy has been widely used in recent decades to achieve green and sustainable development. However, wind speed prediction in wind farm clusters remains one of the less studied areas. Spatial features of cluster data of wind speed are not fully exploited in existing work. In addition, missing data, which dramatically deteriorate the forecasting performance, have not been addressed thoroughly. To tackle these tough issues, a new method, termed input set based on wind farm cluster data–deep extreme learning machine (IWC-DELM), is developed herein. This model builds an input set based on IWC, which takes advantage of the historical data of relevant wind farms to utilize the spatial characteristics of wind speed sequences within such wind farm clusters. Finally, wind speed prediction is obtained after the training of DELM, which results in a better performance in forecasting accuracy and training speed. The structure IWC, complete with the multidimensional average method (MDAM), is also beneficial to make up the missing data, thus enhancing data robustness in comparison to the traditional method of the moving average approach (MAA). Experiments are conducted with some real-world data, and the results of gate recurrent unit (GRU), long- and short-term memory (LSTM) and sliced recurrent neural networks (SRNNs) are also taken for comparison. These comparative tests clearly verify the superiority of IWC-DELM, whose accuracy and efficiency both rank at the top among the four candidates. © 2023 by the authors.
DA  - 2023///
PY  - 2023
DO  - 10.3390/math11030499
VL  - 11
IS  - 3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147879334&doi=10.3390%2fmath11030499&partnerID=40&md5=3fc5a22184a62271cd432c40072583a8
DB  - Scopus
KW  - robustness analysis
KW  - deep extreme learning machine
KW  - input set based on wind farm cluster data
KW  - multidimensional average method
KW  - wind farm cluster
KW  - wind speed forecasting
ER  - 

TY  - JOUR
TI  - Unsupervised cross-domain speaker recognition based on distribution alignment and adversarial learning
AU  - Chen, Z.
AU  - Zhao, Q.
AU  - Wang, L.
AU  - Wang, W.
T2  - Shengxue Xuebao/Acta Acustica
AB  - Domain mismatch has become one of the biggest challenges for realistic speaker recognition systems, especially labeled data in the target domain are unavailable. The proposed methods fuse with adversarial learning to extract speaker discriminative features. It reduces domain discrepancy by distribution alignment during the training stage. Consistent performance improvements are achieved under variety of domain mismatch circumstances. For text-dependent tasks, adversarial learning and distribution alignment work together to reduce the equal error rates 11% relatively. As for text-independent tasks, adversarial learning can hardly make contributions while our distribution alignment still achieves a relative 8% improvement. The proposed methods can steadily improve the performance effectively for unsupervised cross-domain speaker recognition. © 2021 Acta Acustica.
DA  - 2021///
PY  - 2021
VL  - 46
IS  - 5
SP  - 767
EP  - 774
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115891162&partnerID=40&md5=b72e8119cda96adcdf6460e2ca179dcf
DB  - Scopus
KW  - Speech recognition
KW  - Labeled data
KW  - Software engineering
KW  - Adversarial learning
KW  - Cross-domain
KW  - Target domain
KW  - Consistent performance
KW  - Dependent tasks
KW  - Discriminative features
KW  - Equal error rate
KW  - Speaker recognition
KW  - Speaker recognition system
ER  - 

TY  - JOUR
TI  - Deep Reinforcement Learning for Scenario-Based Robust Economic Dispatch Strategy in Internet of Energy
AU  - Fang, D.
AU  - Guan, X.
AU  - Hu, B.
AU  - Peng, Y.
AU  - Chen, M.
AU  - Hwang, K.
T2  - IEEE Internet of Things Journal
AB  - Currently, the integration of distributed energy generators through virtual power plants in the Internet of Energy is a mainstream method. The complex structure of virtual power plants and the characteristics of distributed energy make it difficult to solve the economic dispatch problems of virtual power plants. In addition, the load of a virtual power plant is unstable and uncertain and thus requires a robust economic dispatch strategy. Because the selection of the set of uncertain conditions is conservative, the traditional robust economic dispatch strategies cannot effectively reduce the cost of virtual power plants. In addition, the traditional methods for solving robust strategies cannot directly solve nonlinear and nonconvex problems. In this article, we propose a scenario-based robust economic dispatch strategy for virtual power plants, aiming to reduce the operational costs of virtual power plants. First, to reduce the conservatism of the strategy, scenario-based data augmentation is adopted for data generation. Through a generative adversarial network, a large amount of scene data are generated to extend the set of uncertain conditions. The scene data cannot only reduce the conservatism but also can be used in the determination of robust strategies. Second, deep reinforcement learning is adopted for historical data training, directly solving nonlinear and nonconvex problems to obtain a robust economic dispatch strategy. As experiments show, with the accurate generation of scene data, the proposed economic dispatch strategy is robust and effectively reduces the cost of virtual power plants.  © 2014 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/JIOT.2020.3040294
VL  - 8
IS  - 12
SP  - 9654
EP  - 9663
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097126941&doi=10.1109%2fJIOT.2020.3040294&partnerID=40&md5=90aaabb561601cd18dbadfed571ff173
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Deep reinforcement learning
KW  - Data reduction
KW  - Cost reduction
KW  - Scheduling
KW  - Electric load dispatching
KW  - virtual power plant
KW  - Economic Dispatch
KW  - Adversarial networks
KW  - Complex structure
KW  - Distributed energies
KW  - Economic dispatch problems
KW  - Electric power plants
KW  - Internet of Energy
KW  - Nonconvex problem
KW  - robust economic dispatch strategy
KW  - scene data generation
KW  - Uncertain condition
KW  - Virtual power plants
ER  - 

TY  - JOUR
TI  - Using the Robust Principal Component Analysis to Identify Incorrect Aerological Data
AU  - Kozin, A.M.
AU  - Lykov, A.D.
AU  - Vyazankin, I.A.
AU  - Vyazankin, A.S.
T2  - Russian Meteorology and Hydrology
AB  - Abstract: The “Middle Atmosphere” Regional Information and Analytic Center (Central Aerological Observatory) works out algorithms for analyzing the quality of aerological data based on machine learning methods. Different approaches to the data preparation are described, the examples of data that were rejected using standard approaches are given, the ways to develop and improve the quality of aerological information transmitted to the WMO international network are outlined. © 2021, Pleiades Publishing, Ltd.
DA  - 2021///
PY  - 2021
DO  - 10.3103/S1068373921090090
VL  - 46
IS  - 9
SP  - 631
EP  - 639
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121514476&doi=10.3103%2fS1068373921090090&partnerID=40&md5=cb2896f36474acc00be0710334bd2b51
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Machine learning methods
KW  - outliers
KW  - principal component analysis
KW  - Principal component analysis
KW  - Robust principal component analysis
KW  - meteorology
KW  - outlier
KW  - identification method
KW  - aerological data
KW  - Aerological data
KW  - Analytic center
KW  - Data preparation
KW  - Geo-potential heights
KW  - geopotential
KW  - geopotential height
KW  - instrumentation
KW  - International networks
KW  - middle atmosphere
KW  - Middle atmosphere
KW  - Regional information
KW  - Robust principal component analyse
KW  - Robust Principal Component Analysis (RPCA)
ER  - 

TY  - JOUR
TI  - Robust Policy Iteration for Continuous-Time Linear Quadratic Regulation
AU  - Pang, B.
AU  - Bian, T.
AU  - Jiang, Z.-P.
T2  - IEEE Transactions on Automatic Control
AB  - This article studies the robustness of policy iteration in the context of continuous-time infinite-horizon linear quadratic regulator (LQR) problem. It is shown that Kleinman's policy iteration algorithm is small-disturbance input-to-state stable, a property that is stronger than Sontag's local input-to-state stability but weaker than global input-to-state stability. More precisely, whenever the error in each iteration is bounded and small, the solutions of the policy iteration algorithm are also bounded and enter a small neighborhood of the optimal solution of the LQR problem. Based on this result, an off-policy data-driven policy iteration algorithm for the LQR problem is shown to be robust when the system dynamics are subject to small additive unknown bounded disturbances. The theoretical results are validated by a numerical example.  © 1963-2012 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TAC.2021.3085510
VL  - 67
IS  - 1
SP  - 504
EP  - 511
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107357345&doi=10.1109%2fTAC.2021.3085510&partnerID=40&md5=2f5cfa158f9965d50dac8d8740fd6d3c
DB  - Scopus
KW  - Iterative methods
KW  - Continuous time systems
KW  - Policy iteration algorithms
KW  - Linear quadratic regulator
KW  - Input-to-state stability
KW  - Adaptive dynamic programming, adaptive optimal control, data-driven control, policy iteration, reinforcement learning, robustness
KW  - Bounded disturbances
KW  - Infinite horizons
KW  - Input to state stable
KW  - Linear quadratic regulations
KW  - Small disturbances
ER  - 

TY  - JOUR
TI  - Detecting congestive heart failure by extracting multimodal features with synthetic minority oversampling technique (SMOTE) for imbalanced data using robust machine learning techniques
AU  - Hussain, L.
AU  - Lone, K.J.
AU  - Awan, I.A.
AU  - Abbasi, A.A.
AU  - Pirzada, J.-U.-R.
T2  - Waves in Random and Complex Media
AB  - The incidence of congestive heart failure (CHF) is approximately 10 per 1000 for Americans over the age of 65 years. The dynamics of CHF are highly complex, nonlinear, and temporal dynamics. Based on these characteristics, we extracted multimodal features from congestive heart failure (CHF) and normal sinus rhythm (NSR) signals. We performed the synthetic minority over-sampling technique (SMOTE) to increase the number of CHF subjects to balance our train data. The classification between these subjects with original data and SMOTE data was performed using machine learning classifiers such as classification and regression tree (CART), support vector machine linear (SVM-L), Naïve Bayes, neural network, and ensemble classifiers such as random forest (RF), XG boost, averaged neural network (AVNNET). With the original data, the highest performance was obtained using SVM-L with accuracy (94.28%), sensitivity (84.61%), specificity (100%), p-value (0.0002), AUC (0.9605) with 95% CI: 0.9006-1.00. By applying the SMOET, the highest performance was obtained with SVM-L with accuracy (97.14%), sensitivity (92.30%), specificity (100%), p-value (7.99e-06), AUC (0.9650) with 95% CI: 0.8945–1.00. The results reveal that proposed approach with SMOTE improved the detection performance which can be very effective and computationally efficient tool for automatic detection of congestive heart failure patients. © 2020 Informa UK Limited, trading as Taylor & Francis Group.
DA  - 2022///
PY  - 2022
DO  - 10.1080/17455030.2020.1810364
VL  - 32
IS  - 3
SP  - 1079
EP  - 1102
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089785292&doi=10.1080%2f17455030.2020.1810364&partnerID=40&md5=f0c56c6d620557b21ee2364b467bbbf0
DB  - Scopus
KW  - Decision trees
KW  - Neural networks
KW  - Support vector machines
KW  - Learning systems
KW  - Classification (of information)
KW  - support vector machine
KW  - Machine learning techniques
KW  - Support vector regression
KW  - decision tree
KW  - Heart
KW  - Computationally efficient
KW  - Cardiology
KW  - Classification and regression tree
KW  - Detection performance
KW  - Ensemble classifiers
KW  - Synthetic minority over-sampling techniques
KW  - Congestive heart failure
KW  - Congestive heart failures
KW  - multimodal features
KW  - normal sinus rhythm
KW  - Normal sinus rhythm
ER  - 

TY  - CONF
TI  - GARFIELD: System Support for Byzantine Machine Learning (Regular Paper)
AU  - Guerraoui, R.
AU  - Guirguis, A.
AU  - Plassmann, J.
AU  - Ragot, A.
AU  - Rouault, S.
T2  - Proceedings - 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks, DSN 2021
AB  - We present GARFIELD, a library to transparently make machine learning (ML) applications, initially built with popular (but fragile) frameworks, e.g., TensorFlow and PyTorch, Byzantine-resilient. GARFIELD relies on a novel object-oriented design, reducing the coding effort, and addressing the vulnerability of the shared-graph architecture followed by classical ML frameworks. GARFIELD encompasses various communication patterns and supports computations on CPUs and GPUs, allowing addressing the general question of the practical cost of Byzantine resilience in ML applications. We report on the usage of GARFIELD on three main ML architectures: (a) a single server with multiple workers, (b) several servers and workers, and (c) peer-to-peer settings. Using GARFIELD, we highlight interesting facts about the cost of Byzantine resilience. In particular, (a) Byzantine resilience, unlike crash resilience, induces an accuracy loss, (b) the throughput overhead comes more from communication than from robust aggregation, and (c) tolerating Byzantine servers costs more than tolerating Byzantine workers.  © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/DSN48987.2021.00021
SP  - 39
EP  - 51
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114850990&doi=10.1109%2fDSN48987.2021.00021&partnerID=40&md5=153356dcc68b65a31c2157ac6d56a7d2
DB  - Scopus
KW  - Machine learning
KW  - Network architecture
KW  - Program processors
KW  - Robust aggregation
KW  - Byzantine Fault Tolerance
KW  - Peer to peer
KW  - Accuracy loss
KW  - Communication pattern
KW  - Distributed Machine Learning
KW  - Object oriented design
KW  - Robust Machine Learning
KW  - Single server
KW  - System supports
ER  - 

TY  - CHAP
TI  - Clustering Methods for Microarray Data Sets
AU  - Agapito, G.
AU  - Fedele, G.
T2  - Methods in Molecular Biology
AB  - Microarrays are experimental methods that can provide information about gene expression and SNP data that hold great potential for new understanding, driving advances in functional genomics and clinical and molecular biology. Cluster analysis is used to analyze data that are not a priori to contain any specific subgroup. The goal is to use the data itself to recognize meaningful and informative subgroups. Also, cluster analysis helps data reduction purposes, exposes hidden patterns, and generates hypotheses regarding the relationship between genes and phenotypes. This chapter outlines a collection of cluster methods suitable for the analysis of microarray data sets. © 2022, The Author(s), under exclusive license to Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2022///
PY  - 2022
VL  - 2401
SP  - 249
EP  - 261
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121538699&doi=10.1007%2f978-1-0716-1839-4_16&partnerID=40&md5=1f3c64f387472ea55b1c1f375431f410
DB  - Scopus
KW  - Data analysis
KW  - Algorithms
KW  - algorithm
KW  - learning
KW  - cluster analysis
KW  - Sequence alignment
KW  - Unsupervised learning
KW  - data analysis
KW  - sequence alignment
KW  - phenotype
KW  - DNA microarray
KW  - gene expression
KW  - Oligonucleotide Array Sequence Analysis
KW  - microarray analysis
KW  - Microarray Analysis
KW  - single nucleotide polymorphism
KW  - Genomics
KW  - genomics
KW  - Cluster Analysis
KW  - Gene Expression Profiling
KW  - functional genomics
KW  - Edit distance
KW  - Gene Expression
KW  - gene expression profiling
KW  - Microarray
KW  - Multiparameterized edit distance
ER  - 

TY  - JOUR
TI  - Distributed Imitation-Orientated Deep Reinforcement Learning Method for Optimal PEMFC Output Voltage Control
AU  - Li, J.
AU  - Li, Y.
AU  - Yu, T.
T2  - Frontiers in Energy Research
AB  - In order to improve the stability of proton exchange membrane fuel cell (PEMFC) output voltage, a data-driven output voltage control strategy based on regulation of the duty cycle of the DC-DC converter is proposed in this paper. In detail, an imitation-oriented twin delay deep deterministic (IO-TD3) policy gradient algorithm which offers a more robust voltage control strategy is demonstrated. This proposed output voltage control method is a distributed deep reinforcement learning training framework, the design of which is guided by the pedagogic concept of imitation learning. The effectiveness of the proposed control strategy is experimentally demonstrated. © Copyright © 2021 Li, Li and Yu.
DA  - 2021///
PY  - 2021
DO  - 10.3389/fenrg.2021.741101
VL  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117140120&doi=10.3389%2ffenrg.2021.741101&partnerID=40&md5=f2ae4fa93a4fbb28c7c7490a07749448
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - robustness
KW  - Robustness
KW  - Reinforcement learning method
KW  - DC-DC converters
KW  - Voltage control
KW  - Data driven
KW  - Deterministics
KW  - Proton exchange membrane fuel cells (PEMFC)
KW  - Proton-exchange membranes fuel cells
KW  - DC-DC converter
KW  - distributed deep reinforcement learning
KW  - Distributed deep reinforcement learning
KW  - Duty-cycle
KW  - output voltage control
KW  - Output voltage control
KW  - Output voltages
KW  - proton exchange membrane fuel cell
KW  - Voltage control strategies
ER  - 

TY  - JOUR
TI  - Instance weighting through data imprecisiation
AU  - Lienen, J.
AU  - Hüllermeier, E.
T2  - International Journal of Approximate Reasoning
AB  - In machine learning, instance weighting is commonly used to control the influence of individual data points in a learning process. The general idea is to improve results (e.g., the accuracy of a predictor) by restricting the influence of training examples that do not appear to be representative and may bias the learner in an undesirable way. The simplest and most common approach is to modulate the influence of each data point through multiplicative scaling. In this paper, we elaborate on the idea of instance weighting through data imprecisiation as a viable alternative to existing methods, and formalize this approach within the framework of superset learning. Roughly speaking, the idea is to reduce the influence of training examples by turning a precise data point into an imprecise observation. Within the framework of optimistic superset learning, a generic approach to superset learning, this effectively comes down to modifying an underlying loss function on a per-instance basis. We illustrate our approach for the case of binary classification with support vector machines, showing that it compares favorably with existing approaches to instance weighting in support vector machines. In a further case study, we demonstrate the usefulness of instance weighting through data imprecisiation for the practical problem of depth estimation in monocular images. © 2021 Elsevier Inc.
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.ijar.2021.04.002
VL  - 134
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104286036&doi=10.1016%2fj.ijar.2021.04.002&partnerID=40&md5=d650571dc61f80ed41a880be1f80f4b9
DB  - Scopus
KW  - Support vector machines
KW  - Learning systems
KW  - Robustness
KW  - Weakly supervised learning
KW  - Depth Estimation
KW  - Monocular depth estimation
KW  - Training example
KW  - Learning process
KW  - Binary classification
KW  - Data imprecisiation
KW  - Generic approach
KW  - Instance weighting
KW  - Monocular image
KW  - Practical problems
KW  - Superset learning
ER  - 

TY  - JOUR
TI  - Combined i-Vector and Extreme Learning Machine Approach for Robust Speaker Identification and Evaluation with SITW 2016, NIST 2008, TIMIT Databases
AU  - Al-Kaltakchi, M.T.S.
AU  - Abdullah, M.A.M.
AU  - Woo, W.L.
AU  - Dlay, S.S.
T2  - Circuits, Systems, and Signal Processing
AB  - In this article, a novel combined i-vector and an Extreme Learning Machine (ELM) is proposed for speaker identification. The ELM is chosen because it is fast to train and has a universal approximator property. Four combinations of features based on Mel Frequency Cepstral Coefficient and Power Normalized Cepstral Coefficient are used. Besides, seven fusion methods are exploited. The system is evaluated with three different databases, namely: the SITW 2006, NIST 2008, and the TIMIT database. This work employs the 2016 SITW database for the first time for speaker identification using the integration between the ELM and i-vector approach. From each database, 120 speakers with 1200 speech utterances are used (overall 360 speakers with 3600 speech utterances). Furthermore, comprehensive evaluations are exploited with a wide range of realistic background noise types (Stationary noise AWGN and Non-Stationary Noise types) with the handset effect. The proposed system is compared with the Gaussian Mixture Model-Universal Background Model (GMM-UBM) and other states of the art approaches. The results show that the i-vector method outperforms the GMM-UBM approach and other state- of-the-art methods under specific conditions, and that fusion techniques can be used to improve robustness to noise and handset effects. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2021///
PY  - 2021
DO  - 10.1007/s00034-021-01697-7
VL  - 40
IS  - 10
SP  - 4903
EP  - 4923
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103186750&doi=10.1007%2fs00034-021-01697-7&partnerID=40&md5=deed233995db9503166944cf80f71c70
DB  - Scopus
KW  - Machine learning
KW  - Speech recognition
KW  - Telephone sets
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - Vectors
KW  - Database systems
KW  - State-of-the-art methods
KW  - Gaussian distribution
KW  - Additive Gaussian noise
KW  - Comprehensive evaluation
KW  - Gaussian mixture model-universal background models
KW  - Loudspeakers
KW  - Mel frequency cepstral co-efficient
KW  - Non-stationary Noise
KW  - Robust speaker identification
KW  - Speaker identification
KW  - Text independent speaker identification
KW  - TIMIT database
KW  - Universal approximators
ER  - 

TY  - JOUR
TI  - Why Does Regularization Help with Mitigating Poisoning Attacks?
AU  - Farokhi, F.
T2  - Neural Processing Letters
AB  - We use distributionally-robust optimization for machine learning to mitigate the effect of data poisoning attacks. We provide performance guarantees for the trained model on the original data (not including the poison records) by training the model for the worst-case distribution on a neighbourhood around the empirical distribution (extracted from the training dataset corrupted by a poisoning attack) defined using the Wasserstein distance. We relax the distributionally-robust machine learning problem by finding an upper bound for the worst-case fitness based on the empirical sampled-averaged fitness and the Lipschitz-constant of the fitness function (on the data for given model parameters) as regularizer. For regression models, we prove that this regularizer is equal to the dual norm of the model parameters. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2021///
PY  - 2021
DO  - 10.1007/s11063-021-10539-1
VL  - 53
IS  - 4
SP  - 2933
EP  - 2945
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106470386&doi=10.1007%2fs11063-021-10539-1&partnerID=40&md5=4921f632dd6c858407e8bcf514de8ba0
DB  - Scopus
KW  - Machine learning
KW  - Regression analysis
KW  - Optimization
KW  - Robust optimization
KW  - Health
KW  - Adversarial machine learning
KW  - Poisoning attacks
KW  - Wasserstein distance
KW  - Performance guarantees
KW  - Fitness functions
KW  - Distributionally-robust optimization
KW  - Empirical distributions
KW  - Lipschitz constant
KW  - Machine learning problem
ER  - 

TY  - JOUR
TI  - Equidistant and Uniform Data Augmentation for 3D Objects
AU  - Morozov, A.
AU  - Zgyatti, D.
AU  - Popov, P.
T2  - IEEE Access
AB  - Data augmentation is commonly used to increase the size and diversity of the datasets in machine learning. It is of particular importance to evaluate the robustness of the existing machine learning methods. With progress in geometrical and 3D machine learning, many methods exist to augment a 3D object, from the generation of random orientations to exploring different perspectives of an object. In high-precision applications, the machine learning model must be robust with respect to the small perturbations of the input object. Therefore, there is a need for 3D data augmentation tools that consider the distribution of distance metrics between the original and augmented objects. Here we present Eurecon, the first 3D data augmentation approach with spatial control over the augmented samples. It generates objects uniformly distributed over a sphere with a user-defined radius, which is a distance with respect to the original object. Eurecon is applicable to both point cloud and polygon mesh representations of the 3D objects, as demonstrated on the ModelNet dataset. The method is particularly useful in assessing and improving the machine learning models' robustness with respect to the transformations of a small magnitude. We demonstrated the superior performance of a point cloud-based model (PointNet++) and a mesh-based model (MeshNet) when trained on datasets augmented with Eurecon, compared to non-augmented and randomly augmented models. Eurecon is computationally efficient, taking 0.1 seconds to generate 1, 000 samples of an object of 1, 000 3D points. Eurecon works with the most common 3D file formats including point cloud and polygon mesh formats. © 2013 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2021.3138162
VL  - 10
SP  - 3766
EP  - 3774
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122084699&doi=10.1109%2fACCESS.2021.3138162&partnerID=40&md5=5eec06c4e4c157296231d62c8ba75a40
DB  - Scopus
KW  - Machine learning
KW  - Task analysis
KW  - Trustworthy AI
KW  - Job analysis
KW  - Machine-learning
KW  - Data structures
KW  - Computational modelling
KW  - Point cloud compression
KW  - Point-clouds
KW  - Solid modelling
KW  - Robust machine learning
KW  - Data augmentation
KW  - Three dimensional displays
KW  - Three-dimensional display
KW  - 3d machine learning
KW  - 3D machine learning
KW  - Mesh generation
ER  - 

TY  - CONF
TI  - Are We Training with The Right Data? Evaluating Collective Confidence in Training Data using Dempster Shafer Theory
AU  - Dey, S.
AU  - Lee, S.-W.
T2  - Proceedings - International Conference on Software Engineering
AB  - The latest trend of incorporating various data-centric machine learning (ML) models in software-intensive systems has posed new challenges in the quality assurance practice of software engineering, especially in a high-risk environment. ML experts are now focusing on explaining ML models to assure the safe behavior of ML-based systems. However, not enough attention has been paid to explain the inherent uncertainty of the training data. The current practice of ML-based system engineering lacks transparency in the systematic fitness assessment process of the training data before engaging in the rigorous ML model training. We propose a method of assessing the collective confidence in the quality of a training dataset by using Dempster Shafer theory and its modified combination rule (Yager's rule). With the example of training datasets for pedestrian detection of autonomous vehicles, we demonstrate how the proposed approach can be used by the stakeholders with diverse expertise to combine their beliefs in the quality arguments and evidences about the data. Our results open up a scope of future research on data requirements engineering that can facilitate evidence-based data assurance for ML-based safety-critical systems.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICSE-NIER55298.2022.9793521
SP  - 11
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132965104&doi=10.1109%2fICSE-NIER55298.2022.9793521&partnerID=40&md5=6120ec27543790dfe983633fa67ffc93
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Training data
KW  - Machine-learning
KW  - safety
KW  - Machine learning models
KW  - Safety engineering
KW  - Data centric
KW  - Software engineering
KW  - Requirements engineering
KW  - Training dataset
KW  - Quality assurance
KW  - data uncertainty
KW  - Data uncertainty
KW  - Software intensive systems
KW  - Dempster Shafer theory
KW  - Dempster-Shafer theory
KW  - High risk environment
KW  - Quality assurance practices
ER  - 

TY  - CONF
TI  - Discovering the rationale of decisions: Towards a method for aligning learning and reasoning
AU  - Steging, C.
AU  - Renooij, S.
AU  - Verheij, B.
T2  - Proceedings of the 18th International Conference on Artificial Intelligence and Law, ICAIL 2021
AB  - In AI and law, systems that are designed for decision support should be explainable when pursuing justice. In order for these systems to be fair and responsible, they should make correct decisions and make them using a sound and transparent rationale. In this paper, we introduce a knowledge-driven method for model-agnostic rationale evaluation using dedicated test cases, similar to unit-testing in professional software development. We apply this new quantitative human-in-the-loop method in a machine learning experiment aimed at extracting known knowledge structures from artificial datasets from a real-life legal setting. We show that our method allows us to analyze the rationale of black box machine learning systems by assessing which rationale elements are learned or not. Furthermore, we show that the rationale can be adjusted using tailor-made training data based on the results of the rationale evaluation.  © 2021 Owner/Author.
DA  - 2021///
PY  - 2021
DO  - 10.1145/3462757.3466059
SP  - 235
EP  - 239
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108063967&doi=10.1145%2f3462757.3466059&partnerID=40&md5=c7151097ba144ff38a5b1cbbbe6f5bcc
DB  - Scopus
KW  - machine learning
KW  - explainable AI
KW  - Machine learning
KW  - Training data
KW  - responsible AI
KW  - Decision support systems
KW  - Turing machines
KW  - Software design
KW  - Software testing
KW  - Decision supports
KW  - Human-in-the-loop
KW  - Artificial datasets
KW  - Knowledge driven methods
KW  - Knowledge structures
KW  - learning knowledge from data
KW  - Professional software
KW  - Unit testing
ER  - 

TY  - JOUR
TI  - Distributed Robust Process Monitoring Based on Optimized Denoising Autoencoder with Reinforcement Learning
AU  - Chen, S.
AU  - Jiang, Q.
T2  - IEEE Transactions on Instrumentation and Measurement
AB  - Global monitoring for complex large-scale chemical processes is often challenging because of complex correlations among variables. This article proposes an optimized denoising autoencoder (DAE)-based distributed monitoring method to achieve efficient and robust monitoring of multiunit, nonlinear processes. First, a process is decomposed into multiple units, and then stacked DAE is used to extract the robust features of each unit and represent variable correlations within each unit. Second, deep regression neural networks are established between a local unit and its neighboring units to represent the correlations among units. A reinforcement learning-based neural architecture search method is proposed to avoid the tedious manual tuning process and obtain a high-performance neural network. Finally, a numerical simulation example, the Tennessee-Eastman benchmark process, and a laboratory-scale distillation process are used to verify the effectiveness of the proposed method.  © 1963-2012 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/TIM.2022.3147887
VL  - 71
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124204080&doi=10.1109%2fTIM.2022.3147887&partnerID=40&md5=c3dbf5d152e9bd9e27304a2573e1ae2b
DB  - Scopus
KW  - Reinforcement learning
KW  - Process control
KW  - Neural networks
KW  - Features extraction
KW  - Optimisations
KW  - Complex networks
KW  - Process monitoring
KW  - Numerical methods
KW  - Distillation
KW  - De-noising
KW  - Noise abatement
KW  - Q-learning
KW  - Auto encoders
KW  - Denoising autoencoder
KW  - Correlation
KW  - Denoising autoencoder (DAE)
KW  - distributed monitoring
KW  - Distributed monitoring
KW  - Multi-unit
KW  - Multi-unit process
KW  - multiunit process
KW  - robust monitoring
KW  - Robust monitoring
ER  - 

TY  - CONF
TI  - Robust reinforcement learning for stochastic linear quadratic control with multiplicative noise
AU  - Pang, B.
AU  - Jiang, Z.-P.
T2  - IFAC-PapersOnLine
AB  - This paper studies the robustness of reinforcement learning for discrete-time linear stochastic systems with multiplicative noise evolving in continuous state and action spaces. As one of the popular methods in reinforcement learning, the robustness of policy iteration is a longstanding open issue for the stochastic linear quadratic regulator (LQR) problem with multiplicative noise. A solution in the spirit of small-disturbance input-to-state stability is given, guaranteeing that the solutions of the policy iteration algorithm are bounded and enter a small neighborhood of the optimal solution, whenever the error in each iteration is bounded and small. In addition, a novel off-policy multiple-trajectory optimistic least-squares policy iteration algorithm is proposed, to learn a near-optimal solution of the stochastic LQR problem directly from online input/state data, without explicitly identifying the system matrices. The efficacy of the proposed algorithm is supported by rigorous convergence analysis and numerical results on a second-order example. © 2021 The Authors.
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.ifacol.2021.08.365
VL  - 54
SP  - 240
EP  - 243
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118105883&doi=10.1016%2fj.ifacol.2021.08.365&partnerID=40&md5=c253dee8fdcf0330c73335bcc6f166d7
DB  - Scopus
KW  - Reinforcement learning
KW  - Robustness (control systems)
KW  - Stochastic systems
KW  - Iterative methods
KW  - Optimal control systems
KW  - Continuous time systems
KW  - Stochastics
KW  - Policy iteration algorithms
KW  - Reinforcement learning control
KW  - Stochastic control systems
KW  - Robustness analysis
KW  - Stochastic optimal control problem
KW  - Input-to-state stability
KW  - Linear control systems
KW  - Data based controls
KW  - Data-based control
KW  - Linear quadratic regulator problems
KW  - Multiplicative noise
KW  - Phase noise
KW  - Stochastic linear quadratic control
KW  - Stochastic optimal control problems
ER  - 

TY  - JOUR
TI  - A wavelet-outlier robust extreme learning machine for rainfall forecasting in Ardabil City, Iran
AU  - Esmaeili, F.
AU  - Shabanlou, S.
AU  - Saadat, M.
T2  - Earth Science Informatics
AB  - In this paper, the monthly long-term precipitation of the city of Ardabil from 1976 to 2020 is simulated by a modern hybrid learning machine. To this end, the Wavelet and Outlier Robust Extreme Learning Machine (ORELM) models are integrated to produce a hybrid model called “Wavelet-Outlier Robust Extreme Learning Machine (WORELM)”. First, the observed data are normalized, and the best normalization coefficients for the study are acquired. About 70% of the observed data are employed to train the artificial intelligence models and the remaining (i.e., 30%) to test them. After that, the optimal mother wavelet and the best decomposition level of the wavelet model are computed. Then, the optimal number of the hidden layer neurons and the best activation function of the ORELM model is chosen by performing a trial and error procedure. In this study, the regularization parameter of the ORELM model is also optimized. Moreover, using the autocorrelation function (ACF), the most influencing lags of the time-series data are detected, and 14 WORELM models are developed. By analyzing the WORELM models, the best model and the effective lags of the time-series data are introduced. The outcomes of the hybrid WORELM model are finally compared with other machine learning (ML) algorithms to prove the superiority of the WORELM model. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.
DA  - 2021///
PY  - 2021
DO  - 10.1007/s12145-021-00681-8
VL  - 14
IS  - 4
SP  - 2087
EP  - 2100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112259703&doi=10.1007%2fs12145-021-00681-8&partnerID=40&md5=5fda80570bf5a1b8f701b3b20c28f498
DB  - Scopus
KW  - machine learning
KW  - artificial intelligence
KW  - Simulation
KW  - Outlier robust extreme learning machine
KW  - Iran
KW  - wavelet analysis
KW  - forecasting method
KW  - Time series data
KW  - Ardabil
KW  - Ardabil City
KW  - long-term change
KW  - precipitation intensity
KW  - rainfall
KW  - Rainfall
KW  - Wavelet
ER  - 

TY  - CHAP
TI  - The Extraction of Automated Vehicles Traffic Accident Factors and Scenarios Using Real-World Data
AU  - Kang, M.H.
AU  - Song, J.
AU  - Hwang, K.
T2  - Lecture Notes on Data Engineering and Communications Technologies
AB  - As automated vehicles (AVs) approach commercialization, the fact that the SAFETY problem becomes more concentrated is not controversial. Depending on this issue, the scenarios research that can ensure safety and are related to vehicle safety assessments are essential. In this paper, based on ‘report of traffic collision involving an AVs’ provided by California DMV (Department of Motor Vehicles), we extract the major factors for identifying AVs traffic accidents to derive basic AVs traffic accident scenarios by employing the random forest, one of the machine learning. As a result, we have found the importance of the pre-collision movement of neighboring vehicles to AVs and inferred that they are related to collision time (TTC). Based on these factors, we derived scenarios and confirm that AVs rear-end collisions of neighboring vehicles usually occur when AVs are ahead in passing, changing lanes, and merge situations. While most accident determinants and scenarios are expected to be similar to those between human driving vehicles (HVs), AVs are expected to reduce accident rates because ‘AVs do not cause accidents.’ © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
DA  - 2022///
PY  - 2022
VL  - 114
SP  - 1
EP  - 15
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133693457&doi=10.1007%2f978-981-16-9416-5_1&partnerID=40&md5=c465a2337b0bdb7e2b24cce490975ae2
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Automation
KW  - Vehicle safety
KW  - Accidents
KW  - Automated vehicle
KW  - Automated vehicles
KW  - Machine-learning
KW  - Motor transportation
KW  - Real-world
KW  - Accident scenarios
KW  - Road safety
KW  - Accident factors
KW  - Real data sets
KW  - Real datasets
KW  - Traffic accident
KW  - Traffic scenario
KW  - Vehicle approaches
KW  - Vehicle traffic
ER  - 

TY  - JOUR
TI  - Applied Machine Learning for Simulated Reprocessing Safeguards: Unsupervised Networks
AU  - Shoman, N.
AU  - Cipiti, B.
AU  - Grimes, T.
AU  - Wilson, B.
AU  - Gladen, R.
T2  - ESARDA Bulletin
AB  - A goal of the International Atomic Energy Agency (IAEA) is to deter the spread of nuclear weapons through detection of nuclear material and technology misuse. Detecting diversion of nuclear material from large bulk handling facilities, such as a reprocessing plant, is a goal that can prove to be both challenging and resource intensive as it often requires destructive analysis of numerous samples taken from various locations across the facility. The IAEA has sought out methods to develop an integrated system of instrumentation and data processing to reduce this burden. The goal of this work is to leverage machine learning (ML) methods to improve the effectiveness and efficiency of safeguards by utilizing higher uncertainty measurements, such as process monitoring and Non-Destructive Assay measurements, which are not extensively used in traditional safeguards methods. This work is part of a series of two documents that consider the use of ML to improve one aspect of safeguards, namely nuclear material accountancy. This part considers unsupervised networks that are used to detect anomalous behavior that could be indicative of material loss. The unsupervised approach is shown to exceed traditional methodologies but only after several practical barriers have been accounted for and resolved. © 2021, Publications Office of the European Union. All rights reserved.
DA  - 2021///
PY  - 2021
DO  - 10.3011/ESARDA.IJNSNP.2021.8
VL  - 2021
IS  - 63 Special issue
SP  - 15
EP  - 29
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125478747&doi=10.3011%2fESARDA.IJNSNP.2021.8&partnerID=40&md5=56356539e408235ba6a203b6c0393ab9
DB  - Scopus
KW  - Machine learning
KW  - Data science
KW  - Nuclear material accountancy
KW  - Safeguards
KW  - Reprocessing
ER  - 

TY  - JOUR
TI  - Robust principal component analysis-based prediction of protein-protein interaction hot spots
AU  - Sitani, D.
AU  - Giorgetti, A.
AU  - Alfonso-Prieto, M.
AU  - Carloni, P.
T2  - Proteins: Structure, Function and Bioinformatics
AB  - Proteins often exert their function by binding to other cellular partners. The hot spots are key residues for protein-protein binding. Their identification may shed light on the impact of disease associated mutations on protein complexes and help design protein-protein interaction inhibitors for therapy. Unfortunately, current machine learning methods to predict hot spots, suffer from limitations caused by gross errors in the data matrices. Here, we present a novel data pre-processing pipeline that overcomes this problem by recovering a low rank matrix with reduced noise using Robust Principal Component Analysis. Application to existing databases shows the predictive power of the method. © 2021 The Authors. Proteins: Structure, Function, and Bioinformatics published by Wiley Periodicals LLC.
DA  - 2021///
PY  - 2021
DO  - 10.1002/prot.26047
VL  - 89
IS  - 6
SP  - 639
EP  - 647
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100144133&doi=10.1002%2fprot.26047&partnerID=40&md5=a01528f52b26983f27a94900012cee42
DB  - Scopus
KW  - machine learning
KW  - Machine Learning
KW  - prediction
KW  - human
KW  - Humans
KW  - biology
KW  - Computational Biology
KW  - procedures
KW  - Article
KW  - priority journal
KW  - receiver operating characteristic
KW  - metabolism
KW  - protein analysis
KW  - Protein Interaction Mapping
KW  - protein protein interaction
KW  - Proteins
KW  - chemistry
KW  - principal component analysis
KW  - Principal Component Analysis
KW  - protein
KW  - feature selection
KW  - molecular model
KW  - area under the curve
KW  - classification algorithm
KW  - binding site
KW  - Binding Sites
KW  - protein binding
KW  - Protein Binding
KW  - ROC Curve
KW  - Models, Molecular
KW  - Databases, Protein
KW  - protein database
KW  - validation study
KW  - imbalanced datasets
KW  - F1-score
KW  - hot spot residues
KW  - noiseless data matrices
KW  - protein domain
KW  - Protein Interaction Domains and Motifs
KW  - protein-protein interactions
KW  - robust PCA (principal component analysis)
ER  - 

TY  - JOUR
TI  - Dropout-Based Robust Self-Supervised Deep Learning for Seismic Data Denoising
AU  - Chen, G.
AU  - Liu, Y.
AU  - Zhang, M.
AU  - Zhang, H.
T2  - IEEE Geoscience and Remote Sensing Letters
AB  - Incoherent noise suppression is an indispensable step in seismic data processing. Recently, deep learning (DL) methods have gained commendable success in seismic data denoising, one of which is the supervised DL denoising method using clean data as the training label, whereas the cost of obtaining clean data is high. We investigate a robust self-supervised DL denoising method without using clean data. Bernoulli-sampled training pairs of the raw noisy data produced by the dropout layer are served to train the NN, and a Monte Carlo (MC) self-integrated technique results in further improving the denoising quality of the trained NN during the testing. Compared with the f-x deconvolution (FXDECON), deep image prior (DIP), and sparse autoencoder (SAE) methods via synthetic and real data examples, the proposed method outperforms these methods for enhancing the signal-to-noise ratio (SNR) and reducing the signal loss.  © 2004-2012 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/LGRS.2022.3167999
VL  - 19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128689935&doi=10.1109%2fLGRS.2022.3167999&partnerID=40&md5=8054844312c7add0f0e2520ec1d3e0c3
DB  - Scopus
KW  - Deep learning
KW  - Neural networks
KW  - Signal to noise ratio
KW  - Data handling
KW  - Image enhancement
KW  - data processing
KW  - supervised learning
KW  - Noise measurements
KW  - Monte Carlo methods
KW  - De-noising
KW  - Seismic response
KW  - Denoising
KW  - Denoising methods
KW  - dropout
KW  - Dropout
KW  - Electronic Packaging
KW  - Electronics packaging
KW  - Incoherent noise
KW  - Monte Carlo (MC) self-ensemble
KW  - Monte Carlo analysis
KW  - Monte carlo self-ensemble
KW  - Noise suppression
KW  - seismic
KW  - seismic data
KW  - Seismic data processing
KW  - seismic noise
KW  - Seismic waves
KW  - Self-supervised deep learning
KW  - self-supervised deep learning (DL)
ER  - 

TY  - CONF
TI  - MLOps - Definitions, Tools and Challenges
AU  - Symeonidis, G.
AU  - Nerantzis, E.
AU  - Kazakis, A.
AU  - Papakostas, G.A.
T2  - 2022 IEEE 12th Annual Computing and Communication Workshop and Conference, CCWC 2022
AB  - This paper is an concentrated overview of the Machine Learning Operations (MLOps) area. Our aim is to define the operation and the components of such systems by highlighting the current problems and trends. In this context we present the different tools and their usefulness in order to provide the corresponding guidelines. Moreover, the connection between MLOps and AutoML (Automated Machine Learning) is identified and how this combination could work is proposed. The novelty of our approach relies on the combination of state-of-the-art topics such as AutoML, exlainability and sustain-ability in order to overcome the current challenges in MLOps identifying them not only as the answer for the incorporation of ML models in production but also as a possible tool for efficient, robust and accurate machine learning models. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/CCWC54503.2022.9720902
SP  - 453
EP  - 460
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127618362&doi=10.1109%2fCCWC54503.2022.9720902&partnerID=40&md5=1808f7af8749bd84c70c8a6f7cf051c1
DB  - Scopus
KW  - Explainability
KW  - Machine learning
KW  - Fairness
KW  - Machine-learning
KW  - Automated machines
KW  - Robustness
KW  - Monitoring
KW  - Sustainability
KW  - MLOps
KW  - Automated machine learning
KW  - AutoML
KW  - Deployment
KW  - Machine learning operation
KW  - Re-training
ER  - 

TY  - JOUR
TI  - Clinically Relevant Sound-Based Features in COVID-19 Identification: Robustness Assessment With a Data-Centric Machine Learning Pipeline
AU  - Matias, P.
AU  - Costa, J.
AU  - Carreiro, A.V.
AU  - Gamboa, H.
AU  - Sousa, I.
AU  - Gomez, P.
AU  - Sousa, J.
AU  - Neuparth, N.
AU  - Carreiro-Martins, P.
AU  - Soares, F.
T2  - IEEE Access
AB  - As long as the COVID-19 pandemic is still active in most countries worldwide, rapid diagnostic continues to be crucial to mitigate the impact of seasonal infection waves. Commercialized rapid antigen self-tests proved they cannot handle the most demanding periods, lacking availability and leading to cost rises. Thus, developing a non-invasive, costless, and more decentralized technology capable of giving people feedback about the COVID-19 infection probability would fill these gaps. This paper explores a sound-based analysis of vocal and respiratory audio data to achieve that objective. This work presents a modular data-centric Machine Learning pipeline for COVID-19 identification from voice and respiratory audio samples. Signals are processed to extract and classify relevant segments that contain informative events, such as coughing or breathing. Temporal, amplitude, spectral, cepstral, and phonetic features are extracted from audio along with available metadata for COVID-19 identification. Audio augmentation and data balancing techniques are used to mitigate class disproportionality. The open-access Coswara and COVID-19 Sounds datasets were used to test the performance of the proposed architecture. Obtained sensitivity scores ranged from 60.00% to 80.00% in Coswara and from 51.43% to 77.14% in COVID-19 Sounds. Although previous works report higher accuracy on COVID-19 detection, this research focused on a data-centric approach by validating the quality of the samples, segmenting the speech events, and exploring interpretable features with physiological meaning. As the pandemic evolves, its lessons must endure, and pipelines such as the proposed one will help prepare new stages where quick and easy disease identification is essential.  © 2013 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3211295
VL  - 10
SP  - 105149
EP  - 105168
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139829418&doi=10.1109%2fACCESS.2022.3211295&partnerID=40&md5=3837ea2475e770f3305d1fc9e0dfc818
DB  - Scopus
KW  - machine learning
KW  - Feature extraction
KW  - Signal processing
KW  - Speech recognition
KW  - signal processing
KW  - Pipelines
KW  - Learning systems
KW  - COVID-19
KW  - Diagnosis
KW  - Features extraction
KW  - Machine-learning
KW  - Lung
KW  - Extraction
KW  - feature extraction
KW  - Data centric
KW  - speech
KW  - Signal-processing
KW  - Pandemic
KW  - data-centric
KW  - Larynx
KW  - Respiratory system
KW  - vocal tract
KW  - Vocal-tracts
ER  - 

TY  - CONF
TI  - Embracing Risk in Reinforcement Learning: The Connection between Risk-Sensitive Exponential and Distributionally Robust Criteria
AU  - Noorani, E.
AU  - Baras, J.S.
T2  - Proceedings of the American Control Conference
AB  - We explore the relation between the risk-sensitive exponential (exponential of total cost) and Distributionally Robust Reinforcement Learning objectives, and in doing so, we unify some of the popular Reinforcement Learning algorithms. Such equivalence (I) allows to understand a number of well-known Reinforcement Learning algorithms from a risk minimization perspective and (II) establishes the robustness properties of risk-sensitive exponential objective in the Reinforcement Learning context, which in turn provides a theoretical justification for the robust performance of risk-sensitive Reinforcement Learning algorithms in the literature. The robustness of exponential criteria motivates risk-sensitizing current risk-neutral Reinforcement Learning algorithms using such criteria.  © 2022 American Automatic Control Council.
DA  - 2022///
PY  - 2022
DO  - 10.23919/ACC53348.2022.9867841
VL  - 2022-June
SP  - 2703
EP  - 2708
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136260457&doi=10.23919%2fACC53348.2022.9867841&partnerID=40&md5=347ba7f8d2c690bdd7ad34cc2c71ded9
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - 'current
KW  - Reinforcement learning algorithms
KW  - Robust performance
KW  - Learning objectives
KW  - Robustness properties
KW  - Exponentials
KW  - Learning context
KW  - Risk minimization
KW  - Robust criteria
ER  - 

TY  - CONF
TI  - Learning the Robust and Structured Control of Unknown Linear Systems
AU  - Mukherjee, S.
AU  - Vu, T.L.
T2  - Proceedings of the American Control Conference
AB  - In many control systems in practice, the control input is subject to some specific structure and affected by noise. Designing control laws to stabilize these systems is challenging, especially when the system model is uncertain. This paper will solve this problem for linear systems with unknown system state matrix. First, a model-based framework is formulated to embed the structural control constraint and input noise into the linear quadratic regulator (LQR) setting to find the stabilizing control. Then, this model-based LQR setting is transformed into a data-based learning framework, robust structured reinforcement learning (RSRL), to cope with the unknown system state matrix. As a result, the data-based control can stabilize the unknown system with input noise, while obeying the structural constraint. Theoretical results will be validated on a multi-agent network with 6 agents.  © 2022 American Automatic Control Council.
DA  - 2022///
PY  - 2022
DO  - 10.23919/ACC53348.2022.9867500
VL  - 2022-June
SP  - 4758
EP  - 4763
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138493877&doi=10.23919%2fACC53348.2022.9867500&partnerID=40&md5=299c03f1c3aa74b4ae23d438ae99640d
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Adaptive control systems
KW  - Multi agent systems
KW  - Control theory
KW  - Matrix algebra
KW  - Distributed parameter control systems
KW  - Distributed-control
KW  - Reinforcement Learning
KW  - Robust learning
KW  - Linear systems
KW  - Linear quadratic regulator
KW  - Linear quadratic
KW  - Quadratic regulators
KW  - Control inputs
KW  - Distributed Control
KW  - Linear Quadratic Regulator
KW  - Robust Learning
KW  - Stability guarantee
KW  - Stability Guarantee
KW  - Structural dynamics
KW  - Structured learning
KW  - Structured Learning
KW  - System state
ER  - 

TY  - JOUR
TI  - Human Induction in Machine Learning
AU  - Spelda, P.
AU  - Stritecky, V.
T2  - ACM Computing Surveys
AB  - As our epistemic ambitions grow, the common and scientific endeavours are becoming increasingly dependent on Machine Learning (ML). The field rests on a single experimental paradigm, which consists of splitting the available data into a training and testing set and using the latter to measure how well the trained ML model generalises to unseen samples. If the model reaches acceptable accuracy, then an a posteriori contract comes into effect between humans and the model, supposedly allowing its deployment to target environments. Yet the latter part of the contract depends on human inductive predictions or generalisations, which infer a uniformity between the trained ML model and the targets. The article asks how we justify the contract between human and machine learning. It is argued that the justification becomes a pressing issue when we use ML to reach "elsewhere"in space and time or deploy ML models in non-benign environments. The article argues that the only viable version of the contract can be based on optimality (instead of on reliability, which cannot be justified without circularity) and aligns this position with Schurz's optimality justification. It is shown that when dealing with inaccessible/unstable ground-Truths ("elsewhere"and non-benign targets), the optimality justification undergoes a slight change, which should reflect critically on our epistemic ambitions. Therefore, the study of ML robustness should involve not only heuristics that lead to acceptable accuracies on testing sets. The justification of human inductive predictions or generalisations about the uniformity between ML models and targets should be included as well. Without it, the assumptions about inductive risk minimisation in ML are not addressed in full. © 2021 ACM.
DA  - 2021///
PY  - 2021
DO  - 10.1145/3444691
VL  - 54
IS  - 3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108104372&doi=10.1145%2f3444691&partnerID=40&md5=adcbe6612203735455c7188014921f18
DB  - Scopus
KW  - Machine learning
KW  - Ground truth
KW  - robustness
KW  - Risk perception
KW  - Training and testing
KW  - Optimization
KW  - Optimality
KW  - On-machines
KW  - Well testing
KW  - Space and time
KW  - distribution shifts
KW  - empirical risk minimisation
KW  - epistemic justification of human-machine contracts
KW  - epistemology of machine learning
KW  - Inductive reasoning
KW  - invariant risk minimisation
KW  - Posteriori
KW  - Risk minimisation
KW  - Testing sets
ER  - 

TY  - CONF
TI  - Data Efficient Safe Reinforcement Learning
AU  - Padakandla, S.
AU  - Prabuchandran, J.K.
AU  - Ganguly, S.
AU  - Bhatnagar, S.
T2  - Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics
AB  - Applying reinforcement learning (RL) methods for real world applications pose multiple challenges - the foremost being safety of the system controlled by the learning agent and the learning efficiency. An RL agent learns to control a system by exploring the available actions in various operating states. In some states, when the RL agent exercises an exploratory action, the system may enter unsafe operation, which can lead to safety hazards both for the system as well as for humans supervising the system. RL algorithms thus must learn to control the system respecting safety. In this work, we formulate the safe RL problem in the constrained off-policy setting that facilitates safe exploration by the RL agent. We then develop a sample efficient algorithm utilizing the cross-entropy method. The proposed algorithm's safety performance is evaluated numerically on benchmark RL problems.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/SMC53654.2022.9945313
VL  - 2022-October
SP  - 1167
EP  - 1172
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142744574&doi=10.1109%2fSMC53654.2022.9945313&partnerID=40&md5=ed0651e0aa3cca35216d69eb12c1ffb7
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Real-world
KW  - Safety engineering
KW  - Benchmarking
KW  - Learning agents
KW  - Learn+
KW  - Reinforcement learning method
KW  - Learning problem
KW  - Safe exploration
KW  - Off-policy
KW  - Constrained reinforcement learning
KW  - Constrained RL
KW  - Off-Policy
ER  - 

TY  - CONF
TI  - Decoupled Adversarial Contrastive Learning for Self-supervised Adversarial Robustness
AU  - Zhang, C.
AU  - Zhang, K.
AU  - Zhang, C.
AU  - Niu, A.
AU  - Feng, J.
AU  - Yoo, C.D.
AU  - Kweon, I.S.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Adversarial training (AT) for robust representation learning and self-supervised learning (SSL) for unsupervised representation learning are two active research fields. Integrating AT into SSL, multiple prior works have accomplished a highly significant yet challenging task: learning robust representation without labels. A widely used framework is adversarial contrastive learning which couples AT and SSL, and thus constitutes a very complex optimization problem. Inspired by the divide-and-conquer philosophy, we conjecture that it might be simplified as well as improved by solving two sub-problems: non-robust SSL and pseudo-supervised AT. This motivation shifts the focus of the task from seeking an optimal integrating strategy for a coupled problem to finding sub-solutions for sub-problems. With this said, this work discards prior practices of directly introducing AT to SSL frameworks and proposed a two-stage framework termed Decoupled Adversarial Contrastive Learning (DeACL). Extensive experimental results demonstrate that our DeACL achieves SOTA self-supervised adversarial robustness while significantly reducing the training time, which validates its effectiveness and efficiency. Moreover, our DeACL constitutes a more explainable solution, and its success also bridges the gap with semi-supervised AT for exploiting unlabeled samples for robust representation learning. The code is publicly accessible at https://github.com/pantheon5100/DeACL. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-20056-4_42
VL  - 13690 LNCS
SP  - 725
EP  - 742
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144544122&doi=10.1007%2f978-3-031-20056-4_42&partnerID=40&md5=31ca03190c46bbcd6067a473f7dbb3a8
DB  - Scopus
KW  - Supervised learning
KW  - Optimization
KW  - Self-supervised learning
KW  - Research fields
KW  - Adversarial training
KW  - Sub-problems
KW  - Adversarial robustness
KW  - Adversarial contrastive learning
KW  - Complex optimization problems
KW  - Coupled problems
KW  - Divide-and-conquer
KW  - Task learning
ER  - 

TY  - CHAP
TI  - Data-Driven Adaptive Robust Unit Commitment Assisted by Machine Learning Techniques
AU  - Zhao, N.
AU  - You, F.
T2  - Computer Aided Chemical Engineering
AB  - In this paper, we propose a novel robust unit commitment (UC) framework with data- driven disjunctive uncertainty sets for volatile wind power outputs, assisted by machine learning techniques. To flexibly identify the uncertainty space for wind power forecast error data with disjunctive structures, the uncertainty data are grouped using K-means and density-based spatial clustering of applications with noise. The disjunctive uncertainty sets are constructed accordingly as the union of multiple basic uncertainty sets, including conventional uncertainty sets, and data-driven uncertainty sets using Dirichlet process mixture model, principal component analysis coupled with kernel density estimation, and support vector clustering. The problem is formulated into a two- stage robust UC model with data-driven disjunctive uncertainty sets and with a multi- level optimization structure. To facilitate the solution process, a decomposition-based optimization algorithm is developed. The effectiveness of the proposed framework is illustrated using a case study based on the IEEE 39-bus system. © 2022 Elsevier B.V.
DA  - 2022///
PY  - 2022
VL  - 49
SP  - 1165
EP  - 1170
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136292438&doi=10.1016%2fB978-0-323-85159-6.50194-9&partnerID=40&md5=a454972220be070395c424b0e50edbe2
DB  - Scopus
KW  - machine learning
KW  - robust optimization
KW  - Unit commitment
KW  - disjunction
ER  - 

TY  - CONF
TI  - Robust Reinforcement Learning using Offline Data
AU  - Panaganti, K.
AU  - Xu, Z.
AU  - Kalathil, D.
AU  - Ghavamzadeh, M.
T2  - Advances in Neural Information Processing Systems
AB  - The goal of robust reinforcement learning (RL) is to learn a policy that is robust against the uncertainty in model parameters. Parameter uncertainty commonly occurs in many real-world RL applications due to simulator modeling errors, changes in the real-world system dynamics over time, and adversarial disturbances. Robust RL is typically formulated as a max-min problem, where the objective is to learn the policy that maximizes the value against the worst possible models that lie in an uncertainty set. In this work, we propose a robust RL algorithm called Robust Fitted Q-Iteration (RFQI), which uses only an offline dataset to learn the optimal robust policy. Robust RL with offline data is significantly more challenging than its non-robust counterpart because of the minimization over all models present in the robust Bellman operator. This poses challenges in offline data collection, optimization over the models, and unbiased estimation. In this work, we propose a systematic approach to overcome these challenges, resulting in our RFQI algorithm. We prove that RFQI learns a near-optimal robust policy under standard assumptions and demonstrate its superior performance on standard benchmark problems. © 2022 Neural information processing systems foundation. All rights reserved.
DA  - 2022///
PY  - 2022
VL  - 35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143683086&partnerID=40&md5=12385a40ddb4c145a75af7e617b994dc
DB  - Scopus
KW  - Reinforcement learning
KW  - Reinforcement learnings
KW  - Uncertainty
KW  - Real-world
KW  - Real-world system
KW  - Uncertainty analysis
KW  - Benchmarking
KW  - Iterative methods
KW  - Learn+
KW  - Model errors
KW  - Parameter uncertainty
KW  - Simulator models
KW  - Modeling parameters
KW  - Offline data
ER  - 

TY  - CONF
TI  - Robust On-Policy Sampling for Data-Efficient Policy Evaluation in Reinforcement Learning
AU  - Zhong, R.
AU  - Zhang, D.
AU  - Schäfer, L.
AU  - Albrecht, S.V.
AU  - Hanna, J.P.
T2  - Advances in Neural Information Processing Systems
AB  - Reinforcement learning (RL) algorithms are often categorized as either on-policy or off-policy depending on whether they use data from a target policy of interest or from a different behavior policy. In this paper, we study a subtle distinction between on-policy data and on-policy sampling in the context of the RL sub-problem of policy evaluation. We observe that on-policy sampling may fail to match the expected distribution of on-policy data after observing only a finite number of trajectories and this failure hinders data-efficient policy evaluation. Towards improved data-efficiency, we show how non-i.i.d., off-policy sampling can produce data that more closely matches the expected on-policy data distribution and consequently increases the accuracy of the Monte Carlo estimator for policy evaluation. We introduce a method called Robust On-Policy Sampling and demonstrate theoretically and empirically that it produces data that converges faster to the expected on-policy distribution compared to on-policy sampling. Empirically, we show that this faster convergence leads to lower mean squared error policy value estimates. © 2022 Neural information processing systems foundation. All rights reserved.
DA  - 2022///
PY  - 2022
VL  - 35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153052489&partnerID=40&md5=7547e8830c2829f91674775a009e2f91
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Mean square error
KW  - Reinforcement learning algorithms
KW  - Sub-problems
KW  - Data distribution
KW  - Finite number
KW  - Policy distribution
KW  - Behavior policy
KW  - Policy evaluation
KW  - Fast convergence
KW  - Monte Carlo Estimators
ER  - 

TY  - JOUR
TI  - Multiexpert Adversarial Regularization for Robust and Data-Efficient Deep Supervised Learning
AU  - Gholami, B.
AU  - Liu, Q.
AU  - El-Khamy, M.
AU  - Lee, J.
T2  - IEEE Access
AB  - Deep neural networks (DNNs) can achieve high accuracy when there is abundant training data that has the same distribution as the test data. In practical applications, data deficiency is often a concern. For classification tasks, the lack of enough labeled images in the training set often results in overfitting. Another issue is the mismatch between the training and the test domains, which results in poor model performance. This calls for the need to have robust and data efficient deep learning models. In this work, we propose a deep learning approach called Multi-Expert Adversarial Regularization learning (MEAR) with limited computational overhead to improve the generalization and robustness of deep supervised learning models. The MEAR framework appends multiple classifier heads (experts) to the feature extractor of the legacy model. MEAR aims to learn the feature extractor in an adversarial fashion by leveraging complementary information from the individual experts as well as the ensemble of the experts to be more robust for an unseen test domain. We train state-of-the-art networks with MEAR for two important computer vision tasks, image classification and semantic segmentation. We compare MEAR to a variety of baselines on multiple benchmarks. We show that MEAR is competitive with other methods and more successful at learning robust features. © 2013 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ACCESS.2022.3196780
VL  - 10
SP  - 85080
EP  - 85094
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136107917&doi=10.1109%2fACCESS.2022.3196780&partnerID=40&md5=5dff15387da09a3c425c359284ad6896
DB  - Scopus
KW  - Ensemble methods
KW  - Semantics
KW  - Task analysis
KW  - Predictive models
KW  - Deep neural networks
KW  - Supervised learning
KW  - Features extraction
KW  - Job analysis
KW  - Image classification
KW  - Classification (of information)
KW  - Efficient learning
KW  - Semantic Segmentation
KW  - Images classification
KW  - Images segmentations
KW  - Robustness
KW  - Computational modelling
KW  - Robust learning
KW  - image segmentation
KW  - Adversarial learning
KW  - robust learning
KW  - adversarial learning
KW  - data efficient learning
KW  - Data efficient learning
KW  - ensemble methods
ER  - 

TY  - CONF
TI  - Learning to Infer from Unlabeled Data: A Semi-Supervised Learning Approach for Robust Natural Language Inference
AU  - Sadat, M.
AU  - Caragea, C.
T2  - Findings of the Association for Computational Linguistics: EMNLP 2022
AB  - Natural Language Inference (NLI) or Recognizing Textual Entailment (RTE) aims at predicting the relation between a pair of sentences (premise and hypothesis) as entailment, contradiction or semantic independence. Although deep learning models have shown promising performance for NLI in recent years, they rely on large scale expensive human-annotated datasets. Semi-supervised learning (SSL) is a popular technique for reducing the reliance on human annotation by leveraging unlabeled data for training. However, despite its substantial success on single sentence classification tasks where the challenge in making use of unlabeled data is to assign “good enough” pseudo-labels, for NLI tasks, the nature of unlabeled data is more complex: one of the sentences in the pair (usually the hypothesis) along with the class label are missing from the data and require human annotations, which makes SSL for NLI more challenging. In this paper, we propose a novel way to incorporate unlabeled data in SSL for NLI where we use a conditional language model, BART to generate the hypotheses for the unlabeled sentences (used as premises). Our experiments show that our SSL framework successfully exploits unlabeled data and substantially improves the performance of four NLI datasets in low-resource settings. We release our code at: https://github.com/msadat3/SSL_for_NLI. © 2022 Association for Computational Linguistics.
DA  - 2022///
PY  - 2022
SP  - 4792
EP  - 4805
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149815700&partnerID=40&md5=db618b39411d0cd5dadc7b95707e08e0
DB  - Scopus
KW  - Deep learning
KW  - Semantics
KW  - Learning systems
KW  - Performance
KW  - Classification (of information)
KW  - Learning models
KW  - Natural language processing systems
KW  - Semi-supervised learning
KW  - Supervised learning approaches
KW  - Large dataset
KW  - Natural languages
KW  - Computational linguistics
KW  - Unlabeled data
KW  - Large-scales
KW  - Human annotations
KW  - Language inference
KW  - Recognizing textual entailments
ER  - 

TY  - CONF
TI  - SELF-SUPERVISED LEARNING IS MORE ROBUST TO DATASET IMBALANCE
AU  - Liu, H.
AU  - HaoChen, J.Z.
AU  - Gaidon, A.
AU  - Ma, T.
T2  - ICLR 2022 - 10th International Conference on Learning Representations
AB  - Self-supervised learning (SSL) is a scalable way to learn general visual representations since it learns without labels. However, large-scale unlabeled datasets in the wild often have long-tailed label distributions, where we know little about the behavior of SSL. In this work, we systematically investigate self-supervised learning under dataset imbalance. First, we find out via extensive experiments that off-the-shelf self-supervised representations are already more robust to class imbalance than supervised representations. The performance gap between balanced and imbalanced pre-training with SSL is significantly smaller than the gap with supervised learning, across sample sizes, for both in-domain and, especially, out-of-domain evaluation. Second, towards understanding the robustness of SSL, we hypothesize that SSL learns richer features from frequent data: it may learn label-irrelevant-but-transferable features that help classify the rare classes and downstream tasks. In contrast, supervised learning has no incentive to learn features irrelevant to the labels from frequent examples. We validate this hypothesis with semi-synthetic experiments and theoretical analyses on a simplified setting. Third, inspired by the theoretical insights, we devise a re-weighted regularization technique that consistently improves the SSL representation quality on imbalanced datasets with several evaluation criteria, closing the small gap between balanced and imbalanced datasets with the same number of examples. © 2022 ICLR 2022 - 10th International Conference on Learning Representationss. All rights reserved.
DA  - 2022///
PY  - 2022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138604585&partnerID=40&md5=be3dffdc3ea75d22c874afb7eec7e06d
DB  - Scopus
KW  - Supervised learning
KW  - Quality control
KW  - Imbalanced dataset
KW  - Learn+
KW  - Large dataset
KW  - Pre-training
KW  - Class imbalance
KW  - Large-scales
KW  - Visual representations
KW  - Rich features
KW  - Label distribution
KW  - Performance gaps
KW  - Sample sizes
ER  - 

TY  - CHAP
TI  - Stochastic optimization of industrial grinding operation through data-driven robust optimization
AU  - Pantula, P.D.
AU  - Miriyala, S.S.
AU  - Mitra, K.
T2  - Statistical Modeling in Machine Learning: Concepts and Applications
AB  - While modeling the industrial grinding circuits (IGCs), the presence of uncertain process parameters intensifies the level of difficulty, especially when the objectives aimed to be optimized are conflicting. In this chapter, considering various sources of uncertainties, a three objective IGC stochastic optimization problem is solved by means of robust optimization (RO) approach. Conventionally, researchers adopted specific geometric shape based uncertainty sets like box, diamond, and so on, for generating samples from the uncertain variable space. Nonetheless, in real scenarios, since the uncertain parameter data may be sparse and might not necessarily follow any distribution, the existing uncertainty sets may lead to conservative solutions. Thus, a new data based sampling technique for RO is presented, which utilizes unsupervised machine learning and novel generative modeling framework for identifying the intended space more accurately and sampling in the desired regions of uncertainty. An industrial grinding circuit, consisting of three decision variables, 10 parameters that depict the uncertainties in the model and feed stream and three conflicting objectives based on productivity, quality and energy savings in the process, is used to demonstrate the effectiveness of the novel framework followed by comparison studies. © 2023 Elsevier Inc. All rights reserved.
DA  - 2022///
PY  - 2022
SP  - 249
EP  - 267
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150572342&doi=10.1016%2fB978-0-323-91776-6.00012-9&partnerID=40&md5=7b3e69046d8114ba415eecfb80f9c3cb
DB  - Scopus
KW  - Machine learning
KW  - Robust optimization
KW  - Data-driven sampling
KW  - Industrial grinding circuit
KW  - Multiobjective optimization under uncertainty
KW  - Uncertainty sets
ER  - 

TY  - CONF
TI  - Role of Artificial Intelligence Techniques in Active Safety using Image Processing for Autonomous Driving Vehicles
AU  - Moga, D.
AU  - Filip, I.
T2  - SACI 2022 - IEEE 16th International Symposium on Applied Computational Intelligence and Informatics, Proceedings
AB  - This paper presents a study on the importance of using Artificial Intelligence methods in developing self-driving vehicles. Advances in Artificial Intelligence are one of the key enablers of the Autonomous Vehicles development. There are several ways to increase the level of autonomy of a vehicle and make it capable to avoid or prevent crashes. Advanced Driver Assistance Systems will help autonomous vehicles become a reality. Image processing of various traffic scenarios can be drastically improved by the use of the superior degrees of computer processing and computer vision techniques. With the help of convolutional neural networks (CNNs), not only that a single object can be detected and tracked in a sequence, but all relevant objects can be detected and classified for further processing. CNN s, the current state-of-the art for efficiently implementing deep neural networks for vision, are more efficient because they reuse a lot of weights across the image. Also, an introduction in synthetic data generation field is presented as a way to overcome the lack of labeled datasets for training networks.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/SACI55618.2022.9919513
SP  - 253
EP  - 258
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141693732&doi=10.1109%2fSACI55618.2022.9919513&partnerID=40&md5=e5542d72756a8954a84871ac27b8e1bc
DB  - Scopus
KW  - machine learning
KW  - Autonomous vehicles
KW  - artificial intelligence
KW  - Accidents
KW  - Deep neural networks
KW  - Convolutional neural networks
KW  - Autonomous driving
KW  - autonomous driving
KW  - Advanced driver assistance systems
KW  - Autonomous Vehicles
KW  - Automobile drivers
KW  - Machine-learning
KW  - Object detection
KW  - Self drivings
KW  - Convolutional neural network
KW  - Artificial intelligence techniques
KW  - Image enhancement
KW  - image processing
KW  - Images processing
KW  - Artificial intelligence methods
KW  - Active safety
KW  - active safety
KW  - Synthetic data generations
KW  - synthetic data generation
ER  - 

TY  - CONF
TI  - Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training
AU  - Huang, P.
AU  - Xu, M.
AU  - Fang, F.
AU  - Zhao, D.
T2  - IJCAI International Joint Conference on Artificial Intelligence
AB  - Robust Reinforcement Learning (RL) focuses on improving performances under model errors or adversarial attacks, which facilitates the real-life deployment of RL agents. Robust Adversarial Reinforcement Learning (RARL) is one of the most popular frameworks for robust RL. However, most of the existing literature models RARL as a zero-sum simultaneous game with Nash equilibrium as the solution concept, which could overlook the sequential nature of RL deployments, produce overly conservative agents, and induce training instability. In this paper, we introduce a novel sequential formulation of robust RL - a general-sum Stackelberg game model called RRL-Stack - to formalize the sequential nature and provide extra flexibility for robust training. We develop the Stackelberg Policy Gradient algorithm to solve RRL-Stack, leveraging the Stackelberg learning dynamics by considering the adversary's response. Our method generates challenging yet solvable adversarial environments which benefit RL agents' robust learning. Our algorithm demonstrates better training stability and robustness against different testing conditions in the single-agent robotics control and multi-agent highway merging tasks. © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved.
DA  - 2022///
PY  - 2022
SP  - 3099
EP  - 3106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137863569&partnerID=40&md5=02ead14a4135fb066e8122a6c4ae2b56
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Multi agent systems
KW  - Model errors
KW  - Nash equilibria
KW  - Improving performance
KW  - Literature models
KW  - Solution concepts
KW  - Stackelberg
KW  - Stackelberg Games
KW  - Zero sums
ER  - 

TY  - JOUR
TI  - Robustness enhancement of machine fault diagnostic models for railway applications through data augmentation
AU  - Shi, D.
AU  - Ye, Y.
AU  - Gillwald, M.
AU  - Hecht, M.
T2  - Mechanical Systems and Signal Processing
AB  - The performance of machine learning based machine fault diagnosis (MFD) models could be impaired due to operating condition variations encountered in the real-world industrial environment, such as variations of operating speeds and loads. One major reason for this robustness problem is a lack of adequate training data, especially faulty data, measured in various operating conditions. To cover this gap, we propose a novel data augmentation framework for robustness enhancement in railway MFD applications. First, multibody dynamic simulation (MBS) for physical modeling is applied to simulate arbitrary faulty and operating conditions. Second, fast weighted feature-space averaging (FWFSA) as a new data augmentation technique is developed to augment the simulated faulty data, producing infinite reality-augmented simulation data. The proposed MBS-FWFSA can fit in arbitrary MFD algorithms and transfer-learning settings with minimal effort. Moreover, an in-depth empirical study has been carried out to investigate the causality between condition variations and robustness. A new metric has been defined to evaluate robustness. The experiments also revealed the effect of the proposed MBS-FWFSA and its outperformance against several state-of-the-art augmentation methods. The code and data used in this paper have been shared in our GitHub repository: https://github.com/quickhdsdc/Robustness-Enhancement-of-Machine-Fault-Diagnostic-Models. © 2021 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.ymssp.2021.108217
VL  - 164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111801223&doi=10.1016%2fj.ymssp.2021.108217&partnerID=40&md5=6834f50951bd13f0fff94700893c96cb
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Railroads
KW  - Robustness (control systems)
KW  - Robustness
KW  - Failure analysis
KW  - Fault detection
KW  - Machine fault diagnosis
KW  - Covariate shift
KW  - Covariate shifts
KW  - Data augmentation
KW  - Feature space
KW  - Operating condition
KW  - Multi-body dynamic simulation
KW  - Space averaging
KW  - Weighted features
ER  - 

TY  - CONF
TI  - Robust Distributed MISO Beamforming Using Multi-Agent Deep Reinforcement Learning
AU  - Jia, H.
AU  - He, Z.-Q.
AU  - Rui, H.
AU  - Lin, W.
T2  - 2022 14th International Conference on Communication Software and Networks, ICCSN 2022
AB  - Sum-rate maximizing beamforming with base station (BS) power constraints is an important task for interference management in multicell multiple-input-single-output (MISO) down-link systems. This work considers a distributed implementation for multicell MISO beamforming in the presence of imperfect channel state information (CSI), based on multi-agent deep reinforcement learning. In particular, we develop a multi-agent deep deterministic policy gradient (MADDPG) based algorithm. Specifically, each BS as an agent is provided with an independent DDPG network with convolutional neural network structure, which can learn to choose the beam direction and allocate power for multiple users via a limited information exchange protocol. To achieve robustness against CSI errors, we design a robust reward function based on the averaged data rate and the interference penalty generated by each BS. Simulation results demonstrate the effectiveness of the proposed MADDPG algorithm under large CSI errors. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICCSN55126.2022.9817604
SP  - 197
EP  - 201
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135421661&doi=10.1109%2fICCSN55126.2022.9817604&partnerID=40&md5=d36183546e0a45361104316d6e93c7ea
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Convolutional neural networks
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Multi agent systems
KW  - Multi agent
KW  - Deterministics
KW  - Policy gradient
KW  - Channel state information
KW  - Beamforming
KW  - Gradient algorithm
KW  - deep deterministic policy gradient algorithm
KW  - Deep deterministic policy gradient algorithm
KW  - distributed multicell beamforming
KW  - Distributed multicell beamforming
KW  - Multi-Cell Beamforming
KW  - Multiple inputs single outputs
ER  - 

TY  - CONF
TI  - Unsupervised Anomaly Detection for IoT Data based on Robust Adversarial Learning
AU  - Qiao, Y.
AU  - Zhang, B.
AU  - Zhang, Z.
T2  - Proceedings - 24th IEEE International Conference on High Performance Computing and Communications, 8th IEEE International Conference on Data Science and Systems, 20th IEEE International Conference on Smart City and 8th IEEE International Conference on Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2022
AB  - Anomaly detection based on Generative Adversarial Networks (GANs) has been demonstrated its superiority on in imaging area. However, most existing GAN-based methods require noise-free datasets to accurately train the network, whereas neither collecting an absolute clean dataset or labeling the anomalies in the dataset are quite difficult for Internet of Things (IoT) applications due to the harsh environment and the high dimensionality of the data. In this paper, we propose a robust GAN-based model for anomaly detection in IoT, which can accurately learn the data pattern unsupervisedly even with polluted training data. The new model adopts the framework of Bidirectional GAN (BiGAN) to enable an efficient representation mapping, and integrates the mechanism of Robust Principal Component Analysis (RPCA) to rule out the noises of data from the training set. To improve its performance, a new objective function and scoring function are elaborately designed, while a proximal method and Alternating Direction Method of Multiplier (ADMM) are incorporated into the training process. Comparing our method with four state-of-the-art anomaly detection methods, the experimental results strongly confirm the superiority of our method with polluted IoT datasets.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00343
SP  - 2324
EP  - 2330
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152228278&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys57074.2022.00343&partnerID=40&md5=3c3484f1e391558e5f39bdb22245e5a1
DB  - Scopus
KW  - Anomaly detection
KW  - Internet of things
KW  - Labelings
KW  - Principal component analysis
KW  - Unsupervised anomaly detection
KW  - Robust principal component analysis
KW  - Alternating directions method of multipliers
KW  - Adversarial learning
KW  - Generative adversarial networks
KW  - Network-based
KW  - Network-based modeling
KW  - robust principal component analysis
KW  - generative adversarial network
KW  - alternating direction method of multiplier
KW  - Harsh environment
KW  - High dimensionality
ER  - 

TY  - CONF
TI  - Curriculum Adversarial Training for Robust Reinforcement Learning
AU  - Sheng, J.
AU  - Zhai, P.
AU  - Dong, Z.
AU  - Kang, X.
AU  - Chen, C.
AU  - Zhang, L.
T2  - Proceedings of the International Joint Conference on Neural Networks
AB  - Reinforcement learning with adversarial training is currently a key method for improving the robustness of DRL. However, in adversarial training, especially for unstable or disturbance-sensitive systems, the adversary always learns the policy significantly faster than the DRL agent and thus easily generates powerful perturbations. The agent cannot effectively adapt to the overly powerful adversary, which leads to unstable training and even failure to learn the robust policy. In this work, we propose a novel adversarial training method, called Curriculum Adversarial Training, inspired by the idea of curriculum learning. The method dynamically adjusts the strength of the adversary through natural curriculum learning for progressive adversarial training. Thus, the DRL system considers to reasonable learning rules, and the agent faces a suitable learning process. Furthermore, we adopt an advanced action space perturbation method with a most attractive ability as the adversary during training. The proposed method is compared with popular baseline methods through MuJoCo tasks. Experimental results show that our method can improve the robustness of the policy significantly and adapt to uncertain environment effectively. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/IJCNN55064.2022.9892908
VL  - 2022-July
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140713482&doi=10.1109%2fIJCNN55064.2022.9892908&partnerID=40&md5=c94a204323f7a23ca716361e53ff6655
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Deep Reinforcement Learning
KW  - Robustness
KW  - Learn+
KW  - Perturbation techniques
KW  - Training methods
KW  - Curricula
KW  - Adversarial training
KW  - Adversarial Training
KW  - Learning process
KW  - Curriculum learning
KW  - Curriculum Learning
KW  - Learning rules
KW  - Sensitive systems
ER  - 

TY  - JOUR
TI  - Deep Reinforcement Learning-Based Robust Protection in DER-Rich Distribution Grids
AU  - Wu, D.
AU  - Kalathil, D.
AU  - Begovic, M.M.
AU  - Ding, K.Q.
AU  - Xie, L.
T2  - IEEE Open Access Journal of Power and Energy
AB  - This paper introduces a new framework of deep reinforcement learning based protective relay design in power distribution systems with many distributed energy resources (DERs). With increasing penetration of power electronically-interfaced resources, conventional overcurrent relays' performance is rendered less effective due to the two-way uncertainties in power flow patterns. In this paper, a machine learning-based protective relay that is designed for adaptively deciding the threshold for relay action is proposed. The particular algorithm used is an Long Short-Term Memory (LSTM) enhanced deep neural network that is highly accurate, communication-free and easy to implement. The proposed relay design is tested in OpenDSS simulation on the IEEE 34-node test feeder and a collection of large synthetic feeders in Austin, Texas area. By designing adaptability upfront, the proposed relay is shown to substantially improve the performance of relay in terms of failure rate, robustness, and response speed, in particular in scenarios with high level of distributed energy resources.  © 2020 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/OAJPE.2022.3161904
VL  - 9
SP  - 537
EP  - 548
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136526883&doi=10.1109%2fOAJPE.2022.3161904&partnerID=40&md5=4691e6987a5cb7354a82ded40f07c89a
DB  - Scopus
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - reinforcement learning
KW  - Performance
KW  - Reinforcement learnings
KW  - Long short-term memory
KW  - Failure analysis
KW  - Distributed Energy Resources
KW  - Electric load flow
KW  - Power
KW  - Electric power distribution
KW  - Energy resources
KW  - Electric power system protection
KW  - Power-distribution system
KW  - Distribution grid
KW  - Electronically interfaced
KW  - Power distribution systems
KW  - Protective relay design
KW  - protective relaying
KW  - Protective relaying
KW  - Relay protection
KW  - Resource-Rich
ER  - 

TY  - JOUR
TI  - Identification of Triple Negative Breast Cancer Genes Using Rough Set Based Feature Selection Algorithm & Ensemble Classifier
AU  - Patil, S.
AU  - Balmuri, K.R.
AU  - Frnda, J.
AU  - Parameshachari, B.D.
AU  - Konda, S.
AU  - Nedoma, J.
T2  - Human-centric Computing and Information Sciences
AB  - In recent decades, microarray datasets have played an important role in triple negative breast cancer (TNBC) detection. Microarray data classification is a challenging process due to the presence of numerous redundant and irrelevant features. Therefore, feature selection becomes irreplaceable in this research field that eliminates non-required feature vectors from the system. The selection of an optimal number of features significantly reduces the NP hard problem, so a rough set-based feature selection algorithm is used in this manuscript for selecting the optimal feature values. Initially, the datasets related to TNBC are acquired from gene expression omnibuses like GSE45827, GSE76275, GSE65194, GSE3744, GSE21653, and GSE7904. Then, a robust multi-array average technique is used for eliminating the outlier samples of TNBC/non-TNBC which helps in enhancing classification performance. Further, the pre-processed microarray data are fed to a rough set theory for optimal gene selection, and then the selected genes are given as the inputs to the ensemble classification technique for classifying low-risk genes (non-TNBC) and high-risk genes (TNBC). The experimental evaluation showed that the ensemble-based rough set model obtained a mean accuracy of 97.24%, which is superior related to other comparative machine learning techniques. © 2022, Human-centric Computing and Information Sciences. All Rights Reserved.
DA  - 2022///
PY  - 2022
DO  - 10.22967/HCIS.2022.12.054
VL  - 12
IS  - 54
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146302148&doi=10.22967%2fHCIS.2022.12.054&partnerID=40&md5=6eb398abd6d74f3d574f71595d009f6d
DB  - Scopus
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Optimization
KW  - Gene expression
KW  - Ensemble classifier
KW  - Ensemble-classifier
KW  - Machine learning techniques
KW  - Feature Selection
KW  - Computational complexity
KW  - Rough set theory
KW  - Diseases
KW  - Feature selection algorithm
KW  - Triple-negative breast cancers
KW  - Cancer genes
KW  - Machine-learning technique
KW  - Microarray data
KW  - Microarray dataset
KW  - Microarrays data
KW  - Multi arrays
KW  - Robust multi-array average technique
KW  - Rough-set based
KW  - Triple negative breast cancer
ER  - 

TY  - CONF
TI  - Detection of ADR on Covid Vaccine Safety Data
AU  - Gangaramani, N.
AU  - Kulkarni, S.
AU  - Lotya, S.
AU  - Khedkar, S.
AU  - Ahuja, A.
AU  - Rajadhyax, D.
T2  - 2022 International Conference on Data Science, Agents and Artificial Intelligence, ICDSAAI 2022
AB  - Due to pandemic vaccines are developed at a rapid pace. There is a requirement to ensure proper post-market pharmacovigilance. The proposed model will help speed up this process by classifying the Adverse Drug Reactions (ADRs) of the vaccines based on the severity. This will help vaccine manufacturers take necessary and timely action. The model will input the patient data (such as symptoms, vaccination details, and patient health details), which will be preprocessed and cleaned. The ADR will then be classified as a minor, major, or deadly reaction. The system made use of Count Vectors (CV), Word TF-IDF, N-gram TFIDF, and Character TF-IDF feature with Naive Bayes, Random Forest, Logistic Regression, Gradient Boost, and Adaboost machine learning classifiers. Using Random Forest with word-level TF-IDF comparatively a higher accuracy of 93.83% and an F1 score of 0.92 was achieved.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICDSAAI55433.2022.10028914
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148487938&doi=10.1109%2fICDSAAI55433.2022.10028914&partnerID=40&md5=f56b68459199f667671f2c1456c15f9a
DB  - Scopus
KW  - Explainable AI
KW  - Machine learning
KW  - Machine Learning
KW  - Machine-learning
KW  - Adaptive boosting
KW  - Pharmacovigilance
KW  - Random forests
KW  - Adverse drug reactions
KW  - Vaccines
KW  - Embeddings
KW  - Safety data
KW  - Word embedding
KW  - Hospital data processing
KW  - Adverse Drug Reactions
KW  - classification of ADR
KW  - Classification of adverse drug reaction
KW  - Covid vaccine safety data
KW  - Covid Vaccine safety data
KW  - Vaccine safety
KW  - Word Embedding
ER  - 

TY  - JOUR
TI  - Two-stage robust optimization approach for flexible oxygen distribution under uncertainty in integrated iron and steel plants
AU  - Jiang, S.-L.
AU  - Peng, G.
AU  - Bogle, I.D.L.
AU  - Zheng, Z.
T2  - Applied Energy
AB  - Optimal oxygen distribution is one of the most important energy management problems in the modern iron and steel industry. Normally, the supply of the energy generation system is determined by the energy demand of manufacturing processes. However, the balance between supply and demand fluctuates frequently, owing to the uncertainty arising in manufacturing processes. In this study, we developed an optimal oxygen distribution strategy considering uncertain demands and proposed a two-stage robust optimization (TSRO) model with a budget-based uncertainty set that protects the initial distribution decisions with low conservativeness. The main goal of the TSRO model is to make “wait-and-see” decisions, maximizing energy profits, and make “here-and-now” decisions, minimizing operational stability and surplus/shortage penalty. To represent the uncertainty set of energy demands, we developed (1) a Gaussian process-based time-series model to forecast the demand intervals for continuous processes, and (2) a capacity-constrained scheduling model to generate multi-scenario demands for discrete processes. We performed extensive computational studies on TSRO and its components using well-synthesized instances from historical data. The results of model validation and analysis are promising and demonstrate that our approach is well adapted to solving industrial cases under uncertainty. © 2021 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.apenergy.2021.118022
VL  - 306
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118946464&doi=10.1016%2fj.apenergy.2021.118022&partnerID=40&md5=27c274f97f3f993a7e90c673d88f50bd
DB  - Scopus
KW  - Machine learning
KW  - Uncertainty
KW  - Economics
KW  - Manufacture
KW  - Uncertainty analysis
KW  - Optimization
KW  - optimization
KW  - Robust optimization
KW  - oxygen
KW  - Energy management
KW  - Scheduling
KW  - model validation
KW  - Budget control
KW  - Robust optimization models
KW  - Manufacturing process
KW  - Optimization approach
KW  - Oxygen
KW  - Steelmaking
KW  - steel
KW  - Energy demands
KW  - Demand forecasting
KW  - demand-side management
KW  - iron
KW  - Iron and steel industry
KW  - Management problems
KW  - Oxygen distribution
KW  - Process scheduling
ER  - 

TY  - CONF
TI  - A Semi-supervised Deep Learning Model with Consistency Regularization of Augmented Samples for Imbalanced Fault Detection
AU  - Chen, H.
AU  - Han, J.
AU  - Lv, X.
AU  - Wu, Z.
AU  - Guo, H.
AU  - Zhan, Z.
T2  - 13th International Conference on Reliability, Maintainability, and Safety: Reliability and Safety of Intelligent Systems, ICRMS 2022
AB  - With increasing requirements on reliability, maintainability and safety in modern ICT systems, fault detection, as an indispensable part of AIOps, has become essential in cloud computing or communication network environments. However, due to the lack of effective labels and class imbalance on faulty samples, fault detection performance based on the common classification model can't meet the system's operational requirements. Some recent approaches of SSL propose a consistency regularization loss to solve the problem of insufficient labels. However, these approaches are mainly for images based on artificial data augmentations but not feasible for all data types, and class-imbalance problem is not considered simultaneously. So, we propose a semi-supervised method for imbalanced fault detection with few labels, called SSLCR-IFD. In the method, we use a semi-supervised deep classifier based on consistency loss to solve the lack of labels, in which two sample augmentation methods based on clustering and GAN are used. Furthermore, a selective pseudo-labeling self-training strategy is proposed to solve the class-imbalance problem. Compared with the standard data augmentation, our methods alleviates the need for domain knowledge and can be used on multiple types of tasks. Finally, experiment results show that our method outperforms the baseline methods on two different AIOps tasks.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICRMS55680.2022.9944609
SP  - 290
EP  - 295
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143065667&doi=10.1109%2fICRMS55680.2022.9944609&partnerID=40&md5=ca3844b36ae721b2f47955e2b0fcbc65
DB  - Scopus
KW  - Deep learning
KW  - semi-supervised learning
KW  - Learning systems
KW  - Supervised learning
KW  - Semi-supervised learning
KW  - Fault detection
KW  - Faults detection
KW  - Semi-supervised
KW  - Distributed computer systems
KW  - Reliability and safeties
KW  - data augmentation
KW  - Data augmentation
KW  - Domain Knowledge
KW  - Regularisation
KW  - Class imbalance
KW  - Consistency regularization
KW  - Artificial intelligence in reliability and safety
KW  - Class imbalance problems
KW  - class-imbalance
KW  - consistency regularization
ER  - 

TY  - CONF
TI  - Topological Machine Learning Data Analysis for the Extraction of Robust Geometric Information
AU  - Latha, B.A.
AU  - Jagan, S.
AU  - Ajitha, G.
AU  - Radhakrishna, D.
AU  - Hemavathi, S.
AU  - Rajavelu, S.
T2  - Lecture Notes in Networks and Systems
AB  - An increasing demand exists for innovative data analysis methods in a world where various data are generated by complicated data collecting processes. Several hierarchical data sets with high-dimensional data are the focus of this research. If a data set has complex samples, we assume that every sample has an irregular structure that can be represented in the form of an unordered graph. Topological data analysis (TDA) and geometric manifold learning are combined in this study, which add a significant amount of originality. However, topology gives both global and local descriptors, whereas topology is a different approach. We provide a method for combining these two features to create an understandable visual representation of hierarchical data sets. An entirely new metric for quantitative structural analysis at the sample level was devised with the aid of manifold learning. When working with huge data sets, TDA is often utilised to extract structural and qualitative information. A set of hyper-spectral photos and simulated data show how well this approach works and how widely applicable it is. Here, we show that the hierarchical structure of hyper-spectral images is optimum. Our new method also produces better classification results than current best practices, as demonstrated by our experiments. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-981-19-1559-8_17
VL  - 446
SP  - 167
EP  - 177
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135060121&doi=10.1007%2f978-981-19-1559-8_17&partnerID=40&md5=26329322b47b5593fcc3b16fe626b5bc
DB  - Scopus
KW  - Hierarchical data sets
KW  - Hyper-spectral images
KW  - Qualitative structural information
KW  - Topological data analysis
ER  - 

TY  - CONF
TI  - How Out-of-Distribution Data Hurts Semi-Supervised Learning
AU  - Zhao, X.
AU  - Krishnateja, K.
AU  - Iyer, R.
AU  - Chen, F.
T2  - Proceedings - IEEE International Conference on Data Mining, ICDM
AB  - Recent semi-supervised learning algorithms have demonstrated greater success with higher overall performance due to the use of better-unlabeled data representations. Nonetheless, recent research suggests that the performance of the SSL algorithm can be degraded when the unlabeled set contains out-of-distribution examples (OODs). This work addresses the following research question: How do out-of-distribution (OOD) data adversely affect semi-supervised learning algorithms? To answer this question, we investigate the critical causes of OOD's negative effect on SSL algorithms. In particular, we found that 1) certain kinds of OOD data instances that are close to the decision boundary have a more significant impact on performance than those that are further away, and 2) Batch Normalization (BN), a popular module, may degrade rather than improve performance when the unlabeled set contains OODs. To address these challenges, we developed a unified weighted robust SSL framework that can be easily extended to many existing SSL algorithms and improve their robustness against OODs. Having identified the limitations of low-order approximations in bi-level optimization, we developed an efficient bi-level optimization algorithm that could accommodate high-order approximations of the objective and could scale to a large number of inner optimization steps to learn a massive number of weight parameters. Furthermore, we conduct a theoretical analysis of the impact of faraway OODs in the BN step and propose a weighted batch normalization (WBN) procedure that uses the weights estimated by the bi-level optimization problem in the BN step. Additionally, we discuss the connection between our approach and low-order approximation techniques. Our extensive experiments on synthetic and real-world datasets demonstrate that our proposed approach significantly enhances the robustness of four representative SSL algorithms against OODs compared to four state-of-the-art robust SSL strategies.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICDM54844.2022.00087
VL  - 2022-November
SP  - 763
EP  - 772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147729327&doi=10.1109%2fICDM54844.2022.00087&partnerID=40&md5=f24dffc4d1dadf094b61c5199c3fd3be
DB  - Scopus
KW  - Supervised learning
KW  - Learning algorithms
KW  - Performance
KW  - Recent researches
KW  - Optimization
KW  - Semi-supervised learning
KW  - Robust
KW  - Approximation algorithms
KW  - Unlabeled data
KW  - Bi-level optimization
KW  - robust
KW  - Data representations
KW  - Normalisation
KW  - bi level optimization
KW  - Low order approximation
KW  - Out of distribution
KW  - Out of Distribution
KW  - Semi Supervised Learning
ER  - 

TY  - JOUR
TI  - Growth of Artificial Intelligence in Pharma Manufacturing Lonza describes how artificial intelligence, machine learning, and big data are improving safety, quality, and sustainability - All while lowering costs
AU  - Rosenberger, S.
T2  - Genetic Engineering and Biotechnology News
DA  - 2022///
PY  - 2022
DO  - 10.1089/gen.43.01.12
VL  - 43
IS  - 1
SP  - 34
EP  - 36
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147298574&doi=10.1089%2fgen.43.01.12&partnerID=40&md5=19b88aaa5d10352c927d33c5c7806123
DB  - Scopus
ER  - 

TY  - BOOK
TI  - Logic-Driven Traffic Big Data Analytics: Methodology and Applications for Planning
AU  - Zhong, S.
AU  - Sun, D.J.
T2  - Logic-Driven Traffic Big Data Analytics: Methodology and Applications for Planning
AB  - This book starts from the relationship between urban built environment and travel behavior and focuses on analyzing the origin of traffic phenomena behind the data through multi-source traffic big data, which makes the book unique and different from the previous data-driven traffic big data analysis literature. This book focuses on understanding, estimating, predicting, and optimizing mobility patterns. Readers can find multi-source traffic big data processing methods, related statistical analysis models, and practical case applications from this book. This book bridges the gap between traffic big data, statistical analysis models, and mobility pattern analysis with a systematic investigation of traffic big data’s impact on mobility patterns and urban planning. © he Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.
DA  - 2022///
PY  - 2022
SP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151097193&doi=10.1007%2f978-981-16-8016-8&partnerID=40&md5=16ec4c731cc34f909bbc9ad5465ccdf0
DB  - Scopus
KW  - Machine Learning
KW  - Traffic Safety
KW  - Statistical Analysis
KW  - Built Environment and Travel Behavior
KW  - Multi-source Big Data
KW  - Policy Optimization
KW  - Traffic Big Data
KW  - Transportation Planning
KW  - Travel Demand and Pattern Analysis
KW  - Urban Planning
ER  - 

TY  - CONF
TI  - Anatomy-Aware Self-Supervised Learning for Aligned Multi-Modal Medical Data
AU  - Hu, H.
AU  - Lin, T.
AU  - Guo, Y.
AU  - Li, C.
AU  - Wu, R.
AU  - Xu, Y.
T2  - BMVC 2022 - 33rd British Machine Vision Conference Proceedings
AB  - Consistency of anatomical structure naturally exists among medical images from multiple modalities, which provides powerful supervisory signals to self-supervised learning on aligned multi-modal medical images. However, it would lose efficacy due to modality-specific attributes when directly applying current pixel-wise or region-wise contrastive learning methods to pull aligned multi-modal data together in embedding space. To address this issue, we propose a novel anatomy-aware self-supervised learning framework, which represents anatomical structure in each modality using spatial similarity distribution between image patches, to alleviate the ill effects of modality-specific attributes and obtain a modality-consistent representation of anatomical structure. Significantly, we construct a correlation matrix to represent spatial similarity distribution and design a consistency loss to align the distributions across modalities to maintain anatomical consistency. Furthermore, we integrate it with instance-level discrimination into a unified contrastive framework, where the learned features are augmentation-invariant and modality-consistent. Extensive experiments on two medical datasets for the diagnosis of breast cancer and retinal diseases demonstrate that our proposed method achieves superior performance to current related work. © 2022. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.
DA  - 2022///
PY  - 2022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170491836&partnerID=40&md5=306d1a5d2b438bdff1f423737843408b
DB  - Scopus
KW  - Learning systems
KW  - Supervised learning
KW  - Diagnosis
KW  - Computer vision
KW  - 'current
KW  - Multi-modal
KW  - Medical imaging
KW  - Learning methods
KW  - Embeddings
KW  - Modal analysis
KW  - Multi-modal data
KW  - Anatomical structures
KW  - Medical data
KW  - Multiple modalities
KW  - Similarity distribution
KW  - Spatial similarity
ER  - 

TY  - CONF
TI  - Safety Gear Compliance Detection Using Data Augmentation-Assisted Transfer Learning in Construction Work Environment
AU  - Reyes, R.C.
AU  - Sevilla, R.V.
AU  - Zapanta, G.S.
AU  - Merin, J.V.
AU  - Maaliw, R.R.
AU  - Ferrer Santiago, A.
T2  - 2022 IEEE International Conference on Electronics, Computing and Communication Technologies, CONECCT 2022
AB  - The study provides a practical solution to the concern of detecting safety gear compliance in construction. This is imperative given that safety in the construction work environment is one of the greatest global concerns, and advancements in deep learning algorithms, especially in the area of machine learning and database management, enable the possibility to address this challenge in construction. This study developed a framework to recognize construction personnel's safety compliance with PPE, which is designed to be implemented into an organization's operational procedure. The Convolutional Neural Network model was constructed by employing machine learning to a basic version of the YOLOv3 deep learning model for the study. On the testing data, the detection method generated an F1 score of 0.9299, with a mean precision-recall rate of 92.99 %. The purpose of this study is to testify to the viability and applicability of machine vision-based methodologies for automated safety-related compliance processes on construction sites.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/CONECCT55679.2022.9865757
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138291112&doi=10.1109%2fCONECCT55679.2022.9865757&partnerID=40&md5=6f272d641dffa331dfe77708cfaa9754
DB  - Scopus
KW  - machine learning
KW  - Deep learning
KW  - Convolutional neural networks
KW  - Learning systems
KW  - Learning algorithms
KW  - Machine-learning
KW  - Object recognition
KW  - Construction equipment
KW  - and object recognition
KW  - And object recognition
KW  - image database
KW  - Image database
KW  - Objects recognition
KW  - Personal protection equipment
KW  - Personal protection equipment (PPE)
KW  - Personal protection equipments
KW  - protective gear
KW  - Protective gear
KW  - Work sites
KW  - worksite safety
KW  - Worksite safety
KW  - You only look once
KW  - You Only Look Once (YOLO)
ER  - 

TY  - CONF
TI  - Data Mining and Machine Learning Methods for Robust Reliability Predictions on Automotive Components
AU  - Bonato, M.
AU  - Krishnamoorthy, M.
AU  - Goge, P.
T2  - Proceedings - Annual Reliability and Maintainability Symposium
AB  - The ability to deliver fast and accurate reliability predictions is a key factor in order to accelerate the design validation phase during product development.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/RAMS51457.2022.9893998
VL  - 2022-January
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139058352&doi=10.1109%2fRAMS51457.2022.9893998&partnerID=40&md5=351bbab6e3145d5a3d4f4c83f6dfc73b
DB  - Scopus
KW  - machine learning
KW  - big data
KW  - Data mining
KW  - Learning systems
KW  - Natural language processing
KW  - Machine-learning
KW  - Forecasting
KW  - Machine learning methods
KW  - Big data
KW  - Machine components
KW  - Reliability
KW  - Product design
KW  - Language processing
KW  - Natural languages
KW  - natural language processing
KW  - Key factors
KW  - Automotive component
KW  - Design validation
KW  - Reliability prediction
KW  - reliability predictions
KW  - Robust reliability
ER  - 

TY  - CONF
TI  - Robust Unsupervised Domain Adaptation from A Corrupted Source
AU  - Yu, S.
AU  - Zhu, Z.
AU  - Liu, B.
AU  - Jain, A.K.
AU  - Zhou, J.
T2  - Proceedings - IEEE International Conference on Data Mining, ICDM
AB  - Unsupervised Domain Adaptation (UDA) provides a promising solution for learning without supervision, which transfers knowledge from relevant source domains with accessible labeled training data. Existing UDA solutions hinge on clean training data with a short-tail distribution from the source domain, which can be fragile when the source domain data is corrupted either inherently or via adversarial attacks. In this work, we propose an effective framework to address the challenges of UDA from corrupted source domains in a principled manner. Specifically, we perform knowledge ensemble from multiple domain-invariant models that are learned on random partitions of training data. To further address the distribution shift from the source to the target domain, we refine each of the learned models via mutual information maximization, which adaptively obtains the predictive information of the target domain with high confidence. Extensive empirical studies demonstrate that the proposed approach is robust against various types of poisoned data attacks while achieving high asymptotic performance on the target domain.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICDM54844.2022.00171
VL  - 2022-November
SP  - 1299
EP  - 1304
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147729954&doi=10.1109%2fICDM54844.2022.00171&partnerID=40&md5=556ad39d51119f2913db0a36ef016d76
DB  - Scopus
KW  - Training data
KW  - Robust learning
KW  - Domain adaptation
KW  - Unsupervised domain adaptation
KW  - Multiple domains
KW  - Labeled training data
KW  - Target domain
KW  - Robust Learning
KW  - Data attacks
KW  - Poison data attack
KW  - Poison Data Attack
KW  - Tail distribution
KW  - Unsupervised Domain Adaptation
ER  - 

TY  - CONF
TI  - Improving Robustness of Deep Reinforcement Learning Agents: Environment Attack based on the Critic Network
AU  - Schott, L.
AU  - Hajri, H.
AU  - Lamprier, S.
T2  - Proceedings of the International Joint Conference on Neural Networks
AB  - To improve robustness of deep reinforcement learning agents, a line of recent works focus on producing disturbances of the dynamics of the environment. Existing approaches of the literature to generate such disturbances are environment adversarial reinforcement learning methods. These methods set the problem as a two-player game between the protagonist agent, which learns to perform a task in an environment, and the adversary agent, which learns to disturb the dynamics of the considered environment to make the protagonist agent fail. Alternatively, we propose to build on gradient-based adversarial attacks, usually used for classification tasks for instance, that we apply on the critic network of the protagonist to identify efficient disturbances of the dynamics of the environment. Rather than training an adversary agent, which usually reveals as very complex and unstable, we leverage the knowledge of the critic network of the protagonist, to dynamically increase the complexity of the task at each step of the learning process. We show that our method, while being faster and lighter, leads to significantly better improvements in robustness of the policy than existing methods of the literature. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/IJCNN55064.2022.9892901
VL  - 2022-July
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140781892&doi=10.1109%2fIJCNN55064.2022.9892901&partnerID=40&md5=3c7ba77dfe5886c14307e437ac8d50a3
DB  - Scopus
KW  - Intelligent agents
KW  - Deep learning
KW  - Game theory
KW  - Reinforcement learning
KW  - Autonomous agents
KW  - Learning systems
KW  - Learning algorithms
KW  - Deep reinforcement learning
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Deep Reinforcement Learning
KW  - Complex networks
KW  - Robustness
KW  - Multi agent systems
KW  - Learn+
KW  - Reinforcement learning method
KW  - Dynamics
KW  - Knowledge management
KW  - Adversarial training
KW  - Adversarial Training
KW  - Gradient based
KW  - Critic network
KW  - Two-player games
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning Based Autonomous Control Approach for Power System Topology Optimization
AU  - Han, X.
AU  - Hao, Y.
AU  - Chong, Z.
AU  - Ma, S.
AU  - Mu, C.
T2  - Chinese Control Conference, CCC
AB  - With the rapid development of modern power systems, the penetration rates of power electronic equipment and renewable energy are increasing, which bring challenges to stable operation. Due to the strong randomness and uncertainty, the conventional method based on mathematical model can not control modern power systems. So in this paper, a deep reinforcement learning (DRL) based method is proposed to realize the stable autonomous control of power systems. Specific, soft actor-critic (SAC) is used to reroute power flow in transmission lines via autonomous topology optimization control. Besides, to solve huge action space in topology switching and the vulnerability of DRL agents in power systems, a pre-trained scheme based on imitation learning (IL) is presented to use in SAC. Simulations on the IEEE 118-bus system for topology optimization are carried out under random perturbations and common adversarial perturbations to validate the effectiveness and robustness of the proposed methods. The results show that our methods have outstanding performance.  © 2022 Technical Committee on Control Theory, Chinese Association of Automation.
DA  - 2022///
PY  - 2022
DO  - 10.23919/CCC55666.2022.9902073
VL  - 2022-July
SP  - 6041
EP  - 6046
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140445623&doi=10.23919%2fCCC55666.2022.9902073&partnerID=40&md5=94c0e92b2ac886b619fad19083b3abc6
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - robustness
KW  - Learning systems
KW  - Deep reinforcement learning
KW  - Reinforcement learnings
KW  - Autonomous control
KW  - Robustness (control systems)
KW  - Robustness
KW  - Electric load flow
KW  - Power
KW  - Renewable energy resources
KW  - Electric power transmission
KW  - Power control
KW  - Topology
KW  - Control approach
KW  - Actor critic
KW  - Soft actor-critic
KW  - pre-trained scheme
KW  - Pre-trained scheme
KW  - soft actor-critic
KW  - Topology optimisation
KW  - topology optimization
ER  - 

TY  - CONF
TI  - Adversarial Training for Robust Insider Threat Detection
AU  - Gayathri, R.G.
AU  - Sajjanhar, A.
AU  - Xiang, Y.
T2  - Proceedings of the International Joint Conference on Neural Networks
AB  - Insider threat analysis techniques based on machine learning provide convenient and effective automated detection of internally generated cyberattacks. When data are manipulated by adding slight perturbations, the threat intelligence models result in misclassifications of highly skewed class distribution with rare occurrences of events in insider threats. This paper proposes a generative model WGAN-GP conditioned by the class labels, referred to as CWGAN-GP, for insider threat analysis to create synthetic data samples for the rare malicious activities and shows that it generalizes well across different learning algorithms. Further, the robustness of the supervised algorithms to unknown inputs have not been investigated in any other works. This study explores how the synthetically created adversarial samples can increase the robustness of supervised models using adversarial training. We use a target classifier as threat model to generate one-step and iterative adversarial samples and perform a non-targeted test-time attack on the classifiers. We evaluate the robustness of various learning models against synthetic data from other data generation methods and demonstrate that the adversarial training using data generated from CWGAN-GP is less susceptible to adversarial attacks on insider threat classifiers using multiple versions of benchmark CMU CERT data set. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/IJCNN55064.2022.9892059
VL  - 2022-July
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140798784&doi=10.1109%2fIJCNN55064.2022.9892059&partnerID=40&md5=c1d93de60bd1bfea942b4357011e2f37
DB  - Scopus
KW  - Machine learning
KW  - Learning algorithms
KW  - Machine-learning
KW  - Classification (of information)
KW  - Iterative methods
KW  - Adversarial attack
KW  - adversarial machine learning
KW  - Adversarial machine learning
KW  - Cybersecurity
KW  - Synthetic data
KW  - adversarial attacks
KW  - adversarial training
KW  - Adversarial training
KW  - Analysis techniques
KW  - insider threat
KW  - Insider Threat
KW  - Insider threat detections
KW  - robust classifier
KW  - Robust classifier
KW  - Threats analysis
ER  - 

TY  - CONF
TI  - Learning to Robustly Aggregate Labeling Functions for Semi-supervised Data Programming
AU  - Maheshwari, A.
AU  - Killamsetty, K.
AU  - Ramakrishnan, G.
AU  - Iyer, R.
AU  - Danilevsky, M.
AU  - Popa, L.
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
AB  - A critical bottleneck in supervised machine learning is the need for large amounts of labeled data which is expensive and time-consuming to obtain. Although a small amount of labeled data cannot be used to train a model, it can be used effectively for the generation of human-interpretable labeling functions (LFs). These LFs, in turn, have been used to generate a large amount of additional noisy labeled data in a paradigm that is now commonly referred to as data programming. Previous methods of generating LFs do not attempt to use the given labeled data further to train a model, thus missing opportunities for improving performance. Additionally, since the LFs are generated automatically, they are likely to be noisy, and naively aggregating these LFs can lead to suboptimal results. In this work, we propose an LF-based bi-level optimization framework WISDOM to solve these two critical limitations. WISDOM learns a joint model on the (same) labeled dataset used for LF induction along with any unlabeled data in a semi-supervised manner, and more critically, reweighs each LF according to its goodness, influencing its contribution to the semi-supervised loss using a robust bi-level optimization algorithm. We show that WISDOM significantly outperforms prior approaches on several text classification datasets. The source code can be found at https://github.com/ayushbits/robust-aggregate-lfs. © 2022 Association for Computational Linguistics.
DA  - 2022///
PY  - 2022
SP  - 1188
EP  - 1202
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141720641&partnerID=40&md5=d8b6ef5995be9acfde684474b37991ce
DB  - Scopus
KW  - Supervised learning
KW  - Classification (of information)
KW  - Supervised machine learning
KW  - Text processing
KW  - Learn+
KW  - Labeled data
KW  - Semi-supervised
KW  - Computational linguistics
KW  - Bi-level optimization
KW  - Large amounts
KW  - Optimization framework
KW  - Improving performance
KW  - Joint models
KW  - Labeling functions
ER  - 

TY  - CONF
TI  - Safe Exploration of Reinforcement Learning with Data-Driven Control Barrier Function
AU  - Zhang, C.
AU  - Wang, S.
AU  - Meng, S.
AU  - Kan, Z.
T2  - Proceedings - 2022 Chinese Automation Congress, CAC 2022
AB  - Reinforcement learning relies on exploration and exploitation to find optimal policies. However, unconstrained exploration might lead to unsafe actions that jeopardize the system safety. To address this issue, this work presents a RL-based framework that integrates model-based CBF to ensure safe exploration during learning. Rather than synthesizing CBF by hand for complex dynamic systems, we exploit data-driven methods to learn CBFs from collected demonstrations of safe and desirable behavior. Unlike prior works that restrict on off-line collected expert demonstrations to train CBF, the CBF in this work is learned not only from preliminary expert demonstrations, but also from the on-line generated data at runtime, resulting in improved adaptation to complex environments. Numerical simulations and physical experiments using Crazyflie quadrotors are carried out to demonstrate the effectiveness of the developed safe RL framework. The experiment video is available at https://youtu.be/uscl-BQsLRo.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/CAC57257.2022.10055848
VL  - 2022-January
SP  - 1008
EP  - 1013
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151260782&doi=10.1109%2fCAC57257.2022.10055848&partnerID=40&md5=64dfa52abc3cdbb1eb34efd46c3e92f3
DB  - Scopus
KW  - Reinforcement learning
KW  - reinforcement learning
KW  - Reinforcement learnings
KW  - Barriers functions
KW  - Control barriers
KW  - System safety
KW  - Unmanned aerial vehicles (UAV)
KW  - Control barrier function
KW  - Data driven
KW  - Optimal policies
KW  - shield
KW  - Shield
KW  - Data-driven control
KW  - Demonstrations
KW  - data-driven
KW  - Exploration and exploitation
ER  - 

TY  - CONF
TI  - Robust Topology Identification in Distribution Networks Enabled by Latent Low-Rank and Sparse Embedding Feature Extraction
AU  - Jafarian, M.
AU  - Keane, A.
T2  - SEST 2022 - 5th International Conference on Smart Energy Systems and Technologies
AB  - Due to the insufficiency of measurement devices, the topology of distribution networks is not monitored. Recently, the application of machine learning approaches has been examined for identifying the network topology based on the available information in the network, including measurements and pseudo-measurements. Most of these approaches, however, cannot efficiently handle numerous inputs. Consequently, some of the contributing variables have been excluded from the explanatory variables of the applied machine learning approach. In this paper, a latent low-rank and sparse embedding (LLRSE) model is applied to extract a set of representative features with a much lower dimension, from the contributing variables. The extracted features are then considered as the inputs to a deep neural network (DNN) applied as the topology identifier. This reduction in dimension allows the DNN to exploit all available information. The LLRSE model also effectively deals with the uncertainty in data and provides robustness against measurement errors. Results on the IEEE 123-node test feeder demonstrate that by employing the LLRSE model, the performance of the applied DNN significantly improves. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/SEST53650.2022.9898462
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140835890&doi=10.1109%2fSEST53650.2022.9898462&partnerID=40&md5=1e5054d641c4d43910cec47dec13ca97
DB  - Scopus
KW  - Feature extraction
KW  - Deep neural networks
KW  - Features extraction
KW  - Extraction
KW  - Uncertainty analysis
KW  - Robust
KW  - Machine learning approaches
KW  - feature extraction
KW  - Applied machine learning
KW  - Network topology
KW  - Topology
KW  - Embeddings
KW  - robust
KW  - Explanatory variables
KW  - distribution networks
KW  - machine learning approaches
KW  - Measurement device
KW  - Pseudo measurements
KW  - topology identification
KW  - Topology identification
ER  - 

TY  - CONF
TI  - Distributed Multi-Agent Deep Reinforcement Learning for Robust Coordination against Noise
AU  - Motokawa, Y.
AU  - Sugawara, T.
T2  - Proceedings of the International Joint Conference on Neural Networks
AB  - In multi-agent systems, noise reduction techniques are considerable for improving the overall system reliability as agents are required to rely on limited environmental information to develop cooperative and coordinated behaviors with the surrounding agents. However, previous studies have often applied centralized noise reduction methods to build robust and versatile coordination in noisy multi-agent environments, while distributed and decentralized autonomous agents are more plausible for real-world application. In this paper, we introduce a distributed attentional actor architecture model for a multi-agent system (DA3-X), using which we demonstrate that agents with DA3-X can selectively learn the noisy environment and behave cooperatively. We experimentally evaluate the effectiveness of DA3-X by comparing learning methods with and without DA3-X and show that agents with DA3-X can achieve better performance than baseline agents. Furthermore, we visualize heatmaps of attentional weights from the DA3-X to analyze how the decision-making process and coordinated behavior are influenced by noise. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/IJCNN55064.2022.9892253
VL  - 2022-July
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140784231&doi=10.1109%2fIJCNN55064.2022.9892253&partnerID=40&md5=bbbe0e8c9ed49dd82a27932e6dcb977a
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Decision making
KW  - Noise reduction
KW  - Autonomous agents
KW  - Learning systems
KW  - Attention mechanism
KW  - Coordination
KW  - Behavioral research
KW  - Reinforcement learnings
KW  - Attention mechanisms
KW  - Multi agent systems
KW  - Multi agent
KW  - Multi-agent deep reinforcement learning
KW  - Noise abatement
KW  - Distributed systems
KW  - Cooperation
KW  - Alter-exploration problem
KW  - Coordinated behavior
KW  - Distributed system
KW  - Noise reduction technique
ER  - 

TY  - CONF
TI  - Efficient Adversarial Training without Attacking: Worst-Case-Aware Robust Reinforcement Learning
AU  - Liang, Y.
AU  - Sun, Y.
AU  - Zheng, R.
AU  - Huang, F.
T2  - Advances in Neural Information Processing Systems
AB  - Recent studies reveal that a well-trained deep reinforcement learning (RL) policy can be particularly vulnerable to adversarial perturbations on input observations. Therefore, it is crucial to train RL agents that are robust against any attacks with a bounded budget. Existing robust training methods in deep RL either treat correlated steps separately, ignoring the robustness of long-term rewards, or train the agents and RL-based attacker together, doubling the computational burden and sample complexity of the training process. In this work, we propose a strong and efficient robust training framework for RL, named Worst-case-aware Robust RL (WocaR-RL), that directly estimates and optimizes the worst-case reward of a policy under bounded ℓp attacks without requiring extra samples for learning an attacker. Experiments on multiple environments show that WocaR-RL achieves state-of-the-art performance under various strong attacks, and obtains significantly higher training efficiency than prior state-of-the-art robust training methods. The code of this work is available at https://github.com/umd-huang-lab/WocaR-RL. © 2022 Neural information processing systems foundation. All rights reserved.
DA  - 2022///
PY  - 2022
VL  - 35
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150009921&partnerID=40&md5=f780a63268f2da04aa1b18bf9fc5d208
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Sample complexity
KW  - Training methods
KW  - Training process
KW  - Computational burden
KW  - Budget control
KW  - Learning policy
KW  - Agent learning
KW  - Doublings
KW  - Robust trainings
ER  - 

TY  - JOUR
TI  - Error Loss Networks
AU  - Chen, B.
AU  - Zheng, Y.
AU  - Ren, P.
T2  - IEEE Transactions on Neural Networks and Learning Systems
AB  - A novel model called error loss network (ELN) is proposed to build an error loss function for supervised learning. The ELN is similar in structure to a radial basis function (RBF) neural network, but its input is an error sample and output is a loss corresponding to that error sample. That means the nonlinear input&#x2013;output mapper of the ELN creates an error loss function. The proposed ELN provides a unified model for a large class of error loss functions, which includes some information-theoretic learning (ITL) loss functions as special cases. The activation function, weight parameters, and network size of the ELN can be predetermined or learned from the error samples. On this basis, we propose a new machine learning paradigm where the learning process is divided into two stages: first, learning a loss function using an ELN; second, using the learned loss function to continue to perform the learning. Experimental results are presented to demonstrate the desirable performance of the new method. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TNNLS.2022.3202989
SP  - 1
EP  - 13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139420329&doi=10.1109%2fTNNLS.2022.3202989&partnerID=40&md5=6ecd9844783abc1fe29380998e62f0a4
DB  - Scopus
KW  - Machine learning
KW  - Information theory
KW  - Neural networks
KW  - Training
KW  - Supervised learning
KW  - Learning algorithms
KW  - Machine-learning
KW  - Robustness
KW  - supervised learning
KW  - Errors
KW  - Neural-networks
KW  - Entropy
KW  - Radial basis function networks
KW  - Kernel
KW  - Functions
KW  - Base function
KW  - Error loss
KW  - Error loss network
KW  - error loss networks (ELNs)
KW  - Heat conduction
KW  - Loss networks
KW  - Radial base function
KW  - Radial basis
KW  - radial basis functions (RBFs)
ER  - 

TY  - CONF
TI  - Exploring Self-supervised Capsule Networks for Improved Classification with Data Scarcity
AU  - Wittscher, L.
AU  - Pigorsch, C.
T2  - Lecture Notes in Networks and Systems
AB  - While Capsule Networks overcome many shortcomings of Convolutional Neural Networks by taking spatial hierarchies between features into consideration and providing a new approach to routing between layers, they are sensible towards overfitting. Self-supervised training improves the semantic understanding of a network significantly and improves generalization without requiring additional images. Therefore, self-supervised Capsule Networks are a promising approach to improve learning under data scarcity, which makes the combination interesting for a huge variety of applications. Our approach improves test accuracy by up to 11.7% for small data sets and by up to 11.5% for small and imbalanced data sets. Furthermore, we explore the synergies and characteristics of this innovative method combination and give a general overview on the possibilities of self-supervised Capsule Networks. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-12413-6_4
VL  - 514 LNNS
SP  - 36
EP  - 50
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135841517&doi=10.1007%2f978-3-031-12413-6_4&partnerID=40&md5=26d4393a9cf751016d2f951654b62472
DB  - Scopus
KW  - Self-supervised learning
KW  - Data imbalance
KW  - Capsule Network
KW  - Data scarcity
KW  - Robust neural networks
ER  - 

TY  - CONF
TI  - Leveraging Data Pathways for Next Generation Safety Monitoring of Medicines and Vaccines
AU  - Painter, J.L.
AU  - Girard, L.
AU  - Glaser, M.
AU  - Bate, A.
T2  - Proceedings - 2022 International Conference on Computational Science and Computational Intelligence, CSCI 2022
AB  - Safety evaluation of medicines and vaccines is criti-cal to ensure patient safety and maintain confidence in treatment and disease prevention strategies. Leveraging data pathways for next generation pharmacovigilance (PV) requires the creation of new platforms that seamlessly integrate both structured and unstructured data. Here, we describe the design of a novel data environment that provides enhanced data mining, information retrieval, and data governance to improve PV processes and activities. The goal of which is to further inform the knowledge of potential safety issues during the life cycle of medicines, from routine healthcare delivery to informing future drug and vaccine development. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/CSCI58124.2022.00282
SP  - 1570
EP  - 1576
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171997258&doi=10.1109%2fCSCI58124.2022.00282&partnerID=40&md5=7c0c6333ffc74a7fb9c86f3b9c45b137
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Data mining
KW  - Machine-learning
KW  - drug safety
KW  - Drug safety
KW  - pharmacovigilance
KW  - Pharmacovigilance
KW  - Patient safety
KW  - Patient treatment
KW  - Life cycle
KW  - Vaccines
KW  - Heterogeneous data
KW  - Safety monitoring
KW  - Safety evaluations
KW  - heterogeneous data
KW  - Vaccine safety
KW  - Disease prevention
KW  - Prevention strategies
KW  - vaccine safety
ER  - 

TY  - CONF
TI  - A Detailed View on industrial Safety and Health Analytics using Machine Learning Hybrid Ensemble Techniques
AU  - Rathor, K.
AU  - Lenka, S.
AU  - Pandya, K.A.
AU  - Gokulakrishna, B.S.
AU  - Ananthan, S.S.
AU  - Khan, Z.T.
T2  - International Conference on Edge Computing and Applications, ICECAA 2022 - Proceedings
AB  - Industrial work environments are hazardous. Manufacturing facilities contain moving parts equipment, hazardous tools, and ergonomic risks. Falls, moving cars, and large materials are frequent occurrences at construction sites. Forklift traffic, lifting concerns, and even slip and fall dangers are common in warehouses. Even if accidents do occur, there are still things you can do to prevent them. In order to prevent illness and injury in the workplace, employees' training is essential. According to research, most workplace changes and improvements require practical, small-group training for the safety of the workers that are working in that industry.In all industries, industrial safety and health should be given top priority by all firms. Accidents have typically been attributed to dangerous conduct, hazardous physical working circumstances, or malfunctioning technical systems. Industrial safety is a branch of safety science that attempts to provide businesses with a risk-free, hygienic workplace.The main aim of the paper is to predict if the industry measures are safer for the workers or not with the help of hybrid ensemble techniques. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICECAA55415.2022.9936474
SP  - 1166
EP  - 1169
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142696762&doi=10.1109%2fICECAA55415.2022.9936474&partnerID=40&md5=54058c904cd7e1bd5a8d0e30fc582c1c
DB  - Scopus
KW  - Machine learning
KW  - Risk management
KW  - Accidents
KW  - Machine Learning
KW  - Accident prevention
KW  - Machine-learning
KW  - Personnel training
KW  - Health
KW  - Hazards
KW  - Occupational risks
KW  - Workers'
KW  - Construction sites
KW  - Data Science
KW  - Work environments
KW  - Moving parts
KW  - Safety and healths
KW  - Ensemble techniques
KW  - Ensemble Techniques
KW  - Hybrid techniques
KW  - Hybrid Techniques
KW  - Industrial safety and health analytic
KW  - Industrial Safety and Health Analytics
KW  - Manufacturing facility
ER  - 

TY  - CONF
TI  - Adversarial Training With Channel Attention Regularization
AU  - Cho, S.
AU  - Byun, J.
AU  - Kwon, M.-J.
AU  - Kim, Y.
AU  - Kim, C.
T2  - Proceedings - International Conference on Image Processing, ICIP
AB  - Adversarial attack shows that deep neural networks (DNNs) are highly vulnerable to small perturbation. Currently, one of the most effective ways to defend against adversarial attacks is adversarial training, which generates adversarial examples during training and induces the models to classify them correctly. To further increase robustness, various techniques such as exploiting additional unlabeled data and novel training loss have been proposed. In this paper, we propose a novel regularization method that exploits latent features, which can be easily combined with existing approaches. We discover that particular channels are more sensitive to adversarial perturbation, motivating us to propose regularizing these channels. Specifically, we attach a channel attention module for adjusting sensitivity of each channel by reducing the difference between the latent feature of the natural image and that of the adversarial image, which we call Channel Attention Regularization (CAR). CAR can be combined with the existing adversarial training framework, showing that it improves the robustness of state-of-the-art defense models. Experiments on various existing adversarial training methods against diverse attacks show the effectiveness of our methods. Codes are available at https://github.com/sgmath12/Adversarial-Training-CAR. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICIP46576.2022.9897754
SP  - 2996
EP  - 3000
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146701970&doi=10.1109%2fICIP46576.2022.9897754&partnerID=40&md5=5bfdee444f7399d1ed29bce966f3d6f0
DB  - Scopus
KW  - Deep neural networks
KW  - Machine-learning
KW  - Computer vision
KW  - Robustness
KW  - Adversarial machine learning
KW  - Adversarial training
KW  - Unlabeled data
KW  - Regularisation
KW  - Regularization methods
KW  - Natural images
KW  - Small perturbations
KW  - Feature regularization
ER  - 

TY  - CONF
TI  - The Effect of Network Environment on Traffic Classification
AU  - Khesal, A.R.
AU  - Teimouri, M.
T2  - 2022 12th International Conference on Computer and Knowledge Engineering, ICCKE 2022
AB  - One of the challenges of network traffic classification and mobile app identification is model generalization. The accuracy and efficiency of classification models are strongly influenced by the network environment and user behavior. By changing the network environmental parameters such as mobile type or app version, the accuracy of the trained classification model may be reduced. In this paper, we investigate 'how different network environments can affect the performance of a classification model?' and To this end, we have collected a dataset of 60 popular apps in Iran using different network environments. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICCKE57176.2022.9960138
SP  - 59
EP  - 64
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143786141&doi=10.1109%2fICCKE57176.2022.9960138&partnerID=40&md5=56e84a905131194ba2a9c6b0d12e5255
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Behavioral research
KW  - Machine-learning
KW  - Classification (of information)
KW  - Classification models
KW  - Network traffic
KW  - feature engineering
KW  - Cross validation
KW  - Feature engineerings
KW  - cross-validation
KW  - Traffic classification
KW  - Network environments
KW  - Network traffic classification
KW  - network traffic dataset
KW  - Network traffic dataset
KW  - Robust traffic classification
KW  - Telecommunication traffic
ER  - 

TY  - CONF
TI  - Training and Transferring Safe Policies in Reinforcement Learning
AU  - Yang, Q.
AU  - Simão, T.D.
AU  - Jansen, N.
AU  - Tindemans, S.H.
AU  - Spaan, M.T.J.
T2  - ALA 2022 - Adaptive and Learning Agents Workshop at AAMAS 2022
AB  - Safety is critical to broadening the application of reinforcement learning (RL). Often, RL agents are trained in a controlled environment, such as a laboratory, before being deployed in the real world. However, the target reward might be unknown prior to deployment. Reward-free RL addresses this problem by training an agent without the reward to adapt quickly once the reward is revealed. We consider the constrained reward-free setting, where an agent (the guide) learns to explore safely without the reward signal. This agent is trained in a controlled environment, which allows unsafe interactions and still provides the safety signal. After the target task is revealed, safety violations are not allowed anymore. Thus, the guide is leveraged to compose a safe sampling policy. Drawing from transfer learning, we also regularize a target policy (the student) towards the guide while the student is unreliable and gradually eliminate the influence from the guide as training progresses. The empirical analysis shows that this method can achieve safe transfer learning and helps the student solve the target task faster. © 2022 ALA 2022 - Adaptive and Learning Agents Workshop at AAMAS 2022. All rights reserved.
DA  - 2022///
PY  - 2022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168254751&partnerID=40&md5=69ee98d03db848dbd74b02d5ad5311a6
DB  - Scopus
KW  - Intelligent agents
KW  - Reinforcement learning
KW  - Transfer learning
KW  - Reinforcement learning agent
KW  - Reinforcement learnings
KW  - Real-world
KW  - Learn+
KW  - Safety violations
KW  - Students
KW  - Empirical analysis
KW  - Controlled environment
ER  - 

TY  - JOUR
TI  - Cycle Consistency Based Pseudo Label and Fine Alignment for Unsupervised Domain Adaptation
AU  - Zhang, H.
AU  - Tang, J.
AU  - Cao, Y.
AU  - Chen, Y.
AU  - Wang, Y.
AU  - Wu, Q.M.J.
T2  - IEEE Transactions on Multimedia
AB  - Unsupervised Domain Adaptation (UDA) aims to transfer knowledge from a well-labeled source domain to an unlabeled target domain with a correlative distribution. Numerous existing approaches process this hard nut by directly matching the marginal distribution between two domains, which confront the obstacle of rough alignment and blurred decision boundary. Recent advances in UDA introduce target pseudo-label and subdomain adaptation to reduce misalignment and distribution discrepancy. Whereas, they frequently ignore that the production of target pseudo-label is so dependent on the source-trained classifier, which without reasonable restriction to discriminate generated pseudo-label is whether confident. Meanwhile, many methods in the subdomain alignment metric ignore exploring the potential distribution discrepancy between same-class samples of the intra-domain. To address these two issues simultaneously, this paper proposes a Cycle Consistency based Pseudo Label and Fine Alignment (CCPLFA) approach for UDA. In particular, firstly, a novel cycle-consistency based pseudo label module is designed, which is a simple yet effective way to alleviate the noise of pseudo labels and improve their semantic correctness. Secondly, we develop a Fine-Alignment distribution matching metric. Which can maximize the feature distribution density of intra-class cross-domains and not overlook the distribution structure of the global aspect. Comprehensive experiment results on four benchmarks demonstrate the capability of plug and play and the well generalization performance of our proposed method. IEEE
DA  - 2022///
PY  - 2022
DO  - 10.1109/TMM.2022.3233306
SP  - 1
EP  - 14
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146237431&doi=10.1109%2fTMM.2022.3233306&partnerID=40&md5=4d2087c289f28bef237182c8bec59b85
DB  - Scopus
KW  - Semantics
KW  - Task analysis
KW  - Measurement
KW  - Training
KW  - Supervised learning
KW  - Job analysis
KW  - Optimisations
KW  - Benchmarking
KW  - Optimization
KW  - Alignment
KW  - Domain adaptation
KW  - Technological innovation
KW  - Matchings
KW  - Target domain
KW  - Cycle-consistency
KW  - Distribution fine-alignment
KW  - Pseudo label
KW  - Subdomain
ER  - 

TY  - CONF
TI  - Road Crash Data Analysis and Prediction Using Machine Learning Algorithms
AU  - Bagga, A.
AU  - Srivastava, S.
AU  - Shekhawat, R.S.
T2  - Proceedings of 4th International Conference on Cybernetics, Cognition and Machine Learning Applications, ICCCMLA 2022
AB  - Road crashes have emerged as a major global health issue. The vulnerable road users prone to crashes involve pedestrians, cyclists, and two-wheeler riders. Magnitude of the problem is high in the developing nations. The Government stakeholders and other institutions are working tirelessly to improve the situation. In addition to the efforts of the concerned agencies in ensuring road safety, the role of educational institutions cannot be overlooked. At present, the status of research conducted in the field of road safety in low and middle-income group countries is very insignificant. In this context, the work proposed through this paper presents an overview of application of Machine Learning Classification Algorithms for analysing traffic crash data. The paper applies a set of Machine Learning Classification Algorithms to ascertain the accuracy obtained by applying the technique on a given set of data. This paper uses classification methods such as AdaBoost Classifier and Decision Tree Classifier on multiple set of features of a road crash dataset. The application of both the algorithms obtained different results when applied to distinct set of features and in aggregation the Decision Tree Classifier performed better than the AdaBoost Classifier. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICCCMLA56841.2022.9989171
SP  - 316
EP  - 322
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146320180&doi=10.1109%2fICCCMLA56841.2022.9989171&partnerID=40&md5=0280da4cc4ad486b8f24a45131e37bf3
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Accidents
KW  - Machine Learning
KW  - Data handling
KW  - Accident prevention
KW  - Machine-learning
KW  - Classification (of information)
KW  - Roads and streets
KW  - Motor transportation
KW  - Adaptive boosting
KW  - Classification algorithm
KW  - Road safety
KW  - Road Safety
KW  - Machine learning classification
KW  - Classification technique
KW  - Road crash
KW  - Ada boost classifiers
KW  - Classification technique.
KW  - Classification Techniques.
KW  - Crash data
KW  - Crash data analyse
KW  - Crash Data Analysis
ER  - 

TY  - CHAP
TI  - Current Trends, Machine Learning, and Food Safety Data Governance
AU  - Sapienza, S.
T2  - Law, Governance and Technology Series
AB  - This Chapter shifts from the normative perspective adopted in the previous sections to a broader and inclusive approach encompassing governance issues. In particular, emerging concerns are related to the increasingly growing use of artificial intelligence algorithms in the context of food safety risk assessment, and revolve around topics such as algorithmic transparency, fairness, and explainability. Following an introduction to these topics, the discussion is contextualised to the domain at stake by examining the consequences of the use of machine learning and artificial intelligence algorithms in food safety risk assessment from an ethical and legal point of view. A closer look to the forthcoming EU Data Governance Act provides insights on the use of such computational approaches in the public decison-making and, in particular, in matters related to food safety. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
VL  - 52
SP  - 123
EP  - 160
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140714138&doi=10.1007%2f978-3-031-09367-8_4&partnerID=40&md5=7a1be37b17fa0f4319a8989ff9cf2c0b
DB  - Scopus
ER  - 

TY  - CONF
TI  - Minimax Regret Optimization for Robust Machine Learning under Distribution Shift
AU  - Agarwal, A.
AU  - Zhang, T.
T2  - Proceedings of Machine Learning Research
AB  - In this paper, we consider learning scenarios where the learned model is evaluated under an unknown test distribution which potentially differs from the training distribution (i.e. distribution shift). The learner has access to a family of weight functions such that the test distribution is a reweighting of the training distribution under one of these functions, a setting typically studied under the name of Distributionally Robust Optimization (DRO). We consider the problem of deriving regret bounds in the classical learning theory setting, and require that the resulting regret bounds hold uniformly for all potential test distributions. We show that the DRO formulation does not guarantee uniformly small regret under distribution shift. We instead propose an alternative method called Minimax Regret Optimization (MRO), and show that under suitable conditions, this method achieves uniformly low regret across all test distributions. We also adapt our technique to have strong guarantees when the test distributions are heterogeneous in their similarity to the training data. Given the widespead optimization of worst case risks in current approaches to robust machine learning, we believe that MRO can be an attractive framework to address a broad range of distribution shift scenarios. © 2022 A. Agarwal & T. Zhang.
DA  - 2022///
PY  - 2022
VL  - 178
SP  - 2704
EP  - 2729
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164746457&partnerID=40&md5=d36a25ae5eb33f167e114416f1807029
DB  - Scopus
KW  - Machine learning
KW  - covariate shift
KW  - Machine-learning
KW  - Risk perception
KW  - Optimization
KW  - Robust optimization
KW  - Robust learning
KW  - Covariate shifts
KW  - Regret bounds
KW  - Distributionally robust learning
KW  - Learning scenarios
KW  - Distribution shift
KW  - distributionally robust learning
KW  - Minimax regret optimization
KW  - Weight functions
ER  - 

TY  - CONF
TI  - Stability Via Adversarial Training of Neural Network Stochastic Control of Mean-Field Type
AU  - Barreiro-Gomez, J.
AU  - Choutri, S.E.
AU  - Djehiche, B.
T2  - Proceedings of the IEEE Conference on Decision and Control
AB  - In this paper, we present an approach to neural network mean-field-type control and its stochastic stability analysis by means of adversarial inputs (aka adversarial attacks). This is a class of data-driven mean-field-type control where the distribution of the variables such as the system states and control inputs are incorporated into the problem. Besides, we present a methodology to validate the feasibility of the approximations of the solutions via neural networks and evaluate their stability. Moreover, we enhance the stability by enlarging the training set with adversarial inputs to obtain a more robust neural network. Finally, a worked-out example based on the linear-quadratic mean-field type control problem (LQ-MTC) is presented to illustrate our methodology. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/CDC51059.2022.9993216
VL  - 2022-December
SP  - 7547
EP  - 7552
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146987197&doi=10.1109%2fCDC51059.2022.9993216&partnerID=40&md5=67935b69f00cfa40afc8f1b345d937d4
DB  - Scopus
KW  - Neural networks
KW  - robustness
KW  - Supervised learning
KW  - Robustness (control systems)
KW  - Robustness
KW  - Supervised machine learning
KW  - supervised machine learning
KW  - Stochastic systems
KW  - Neural-networks
KW  - Data driven
KW  - Stability
KW  - Stability analyze
KW  - adversarial training
KW  - Mean-field
KW  - Adversarial training
KW  - Data-driven control
KW  - data-driven control
KW  - stability
KW  - Stochastic stability
KW  - Stochastic control
ER  - 

TY  - CONF
TI  - Data-Driven Robust Multi-Agent Reinforcement Learning
AU  - Wang, Y.
AU  - Wang, Y.
AU  - Zhou, Y.
AU  - Velasquez, A.
AU  - Zou, S.
T2  - IEEE International Workshop on Machine Learning for Signal Processing, MLSP
AB  - Multi-agent reinforcement learning (MARL) in the collaborative setting aims to find a joint policy that maximizes the accumulated reward averaged over all the agents. In this paper, we focus on MARL under model uncertainty, where the transition kernel is assumed to be in an uncertainty set, and the goal is to optimize the worst-case performance over the uncertainty set. We investigate the model-free setting, where the uncertain set centers around an unknown Markov decision process from which a single sample trajectory can be obtained sequentially. We develop a robust multi-agent Q-learning algorithm, which is model-free and fully decentralized. We theoretically prove that the proposed algorithm converges to the minimax robust policy, and further characterize its sample complexity. Our algorithm, comparing to the vanilla multi-agent Q-learning, offers provable robustness under model uncertainty without incurring additional computational and memory cost.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/MLSP55214.2022.9943500
VL  - 2022-August
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142763167&doi=10.1109%2fMLSP55214.2022.9943500&partnerID=40&md5=d95526b627560183e68f0e84ebf1a926
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Uncertainty
KW  - Uncertainty analysis
KW  - Markov processes
KW  - Multi agent systems
KW  - Fertilizers
KW  - Multi-agent reinforcement learning
KW  - Modeling uncertainties
KW  - Model free
KW  - Sample complexity
KW  - Data driven
KW  - Computational complexity
KW  - Robust MDP
KW  - model-free
KW  - Distributionally robust
KW  - finite-time analysis
KW  - Finite-time analysis
KW  - Multi-agent Q-learning
KW  - robust MDP
KW  - sample complexity
ER  - 

TY  - JOUR
TI  - Robust biomarker screening from gene expression data by stable machine learning-recursive feature elimination methods
AU  - Li, L.
AU  - Ching, W.-K.
AU  - Liu, Z.-P.
T2  - Computational Biology and Chemistry
AB  - Recently, identifying robust biomarkers or signatures from gene expression profiling data has attracted much attention in computational biomedicine. The successful discovery of biomarkers for complex diseases such as spontaneous preterm birth (SPTB) and high-grade serous ovarian cancer (HGSOC) will be beneficial to reduce the risk of preterm birth and ovarian cancer among women for early detection and intervention. In this paper, we propose a stable machine learning-recursive feature elimination (StabML-RFE for short) strategy for screening robust biomarkers from high-throughput gene expression data. We employ eight popular machine learning methods, namely AdaBoost (AB), Decision Tree (DT), Gradient Boosted Decision Trees (GBDT), Naive Bayes (NB), Neural Network (NNET), Random Forest (RF), Support Vector Machine (SVM) and XGBoost (XGB), to train on all feature genes of training data, apply recursive feature elimination (RFE) to remove the least important features sequentially, and obtain eight gene subsets with feature importance ranking. Then we select the top-ranking features in each ranked subset as the optimal feature subset. We establish a stability metric aggregated with classification performance on test data to assess the robustness of the eight different feature selection techniques. Finally, StabML-RFE chooses the high-frequent features in the subsets of the combination with maximum stability value as robust biomarkers. Particularly, we verify the screened biomarkers not only via internal validation, functional enrichment analysis and literature check, but also via external validation on two real-world SPTB and HGSOC datasets respectively. Obviously, the proposed StabML-RFE biomarker discovery pipeline easily serves as a model for identifying diagnostic biomarkers for other complex diseases from omics data. The source code and data can be found at https://github.com/zpliulab/StabML-RFE. © 2022 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.compbiolchem.2022.107747
VL  - 100
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135898893&doi=10.1016%2fj.compbiolchem.2022.107747&partnerID=40&md5=e62ed150bdcaac4b1ce02838bc3eee9c
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Support vector machines
KW  - Learning systems
KW  - Diagnosis
KW  - Machine-learning
KW  - Complex networks
KW  - Adaptive boosting
KW  - Gene expression
KW  - Feature Selection
KW  - Features selection
KW  - Set theory
KW  - Diseases
KW  - Biomarkers
KW  - Recursive feature elimination
KW  - Bio-marker discovery
KW  - High grades
KW  - High-grade serous ovarian cancer
KW  - Ovarian cancers
KW  - Preterm birth
KW  - Robust biomarker discovery
KW  - Spontaneous preterm birth
KW  - Stable feature selection
ER  - 

TY  - CONF
TI  - The Role of Randomization in Trustworthy Machine Learning
AU  - Papernot, N.
T2  - MTD 2022 - Proceedings of the 9th ACM Workshop on Moving Target Defense, co-located with CCS 2022
AB  - Machine learning has been perhaps this decade's most significant technological development, with the prospect of becoming a general-purpose technology. Applications range from autonomous driving to assisting with court decisions. In many of these settings, the worst-case performance of machine learning is critical. Yet, the predictions of machine learning often appear fragile, with no hint as to the reasoning behind them-and may be dangerously wrong. This situation is in large part due to the absence of security considerations in the design of machine learning algorithms. This is unacceptable: society must be able to trust and hold machine learning accountable. One direction that has been proposed to develop more trustworthy ML algorithms is the introduction of randomization. In this keynote, we contrast the success of randomized algorithms for privacy-preserving learning with failed applications of randomization to develop more robust machine learning models. From this comparison, we identify best practices for the research community, moving forward, as it continues to research the role of randomization in trustworthy machine learning.  © 2022 Owner/Author.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3560828.3564001
SP  - 23
EP  - 24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144823167&doi=10.1145%2f3560828.3564001&partnerID=40&md5=ac6b21e03e9f33a65cb733fd3a77723a
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Autonomous driving
KW  - trustworthy
KW  - Learning algorithms
KW  - Machine-learning
KW  - safety
KW  - Worst-case performance
KW  - Security systems
KW  - Engineering education
KW  - Random processes
KW  - Randomisation
KW  - Privacy-preserving techniques
KW  - Application range
KW  - computer security
KW  - Court decisions
KW  - data privacy
KW  - General purpose technologies
KW  - Large parts
KW  - Technological development
KW  - Trustworthy
ER  - 

TY  - JOUR
TI  - Genuinely distributed Byzantine machine learning
AU  - El-Mhamdi, E.-M.
AU  - Guerraoui, R.
AU  - Guirguis, A.
AU  - Hoang, L.-N.
AU  - Rouault, S.
T2  - Distributed Computing
AB  - Machine learning (ML) solutions are nowadays distributed, according to the so-called server/worker architecture. One server holds the model parameters while several workers train the model. Clearly, such architecture is prone to various types of component failures, which can be all encompassed within the spectrum of a Byzantine behavior. Several approaches have been proposed recently to tolerate Byzantine workers. Yet all require trusting a central parameter server. We initiate in this paper the study of the “general” Byzantine-resilient distributed machine learning problem where no individual component is trusted. In particular, we distribute the parameter server computation on several nodes. We show that this problem can be solved in an asynchronous system, despite the presence of 13 Byzantine parameter servers (i.e., nps> 3 fps+ 1) and 13 Byzantine workers (i.e., nw> 3 fw), which is asymptotically optimal. We present a new algorithm, ByzSGD, which solves the general Byzantine-resilient distributed machine learning problem by relying on three major schemes. The first, scatter/gather, is a communication scheme whose goal is to bound the maximum drift among models on correct servers. The second, distributed median contraction (DMC), leverages the geometric properties of the median in high dimensional spaces to bring parameters within the correct servers back close to each other, ensuring safe and lively learning. The third, Minimum-diameter averaging (MDA), is a statistically-robust gradient aggregation rule whose goal is to tolerate Byzantine workers. MDA requires a loose bound on the variance of non-Byzantine gradient estimates, compared to existing alternatives [e.g., Krum (Blanchard et al., in: Neural information processing systems, pp 118-128, 2017)]. Interestingly, ByzSGD ensures Byzantine resilience without adding communication rounds (on a normal path), compared to vanilla non-Byzantine alternatives. ByzSGD requires, however, a larger number of messages which, we show, can be reduced if we assume synchrony. We implemented ByzSGD on top of both TensorFlow and PyTorch, and we report on our evaluation results. In particular, we show that ByzSGD guarantees convergence with around 32% overhead compared to vanilla SGD. Furthermore, we show that ByzSGD’s throughput overhead is 24–176% in the synchronous case and 28–220% in the asynchronous case. © 2022, The Author(s).
DA  - 2022///
PY  - 2022
DO  - 10.1007/s00446-022-00427-9
VL  - 35
IS  - 4
SP  - 305
EP  - 331
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130717809&doi=10.1007%2fs00446-022-00427-9&partnerID=40&md5=a407f153defb4373dcb1cc54515c8399
DB  - Scopus
KW  - Machine learning
KW  - Software architecture
KW  - Fault tolerance
KW  - Parameter estimation
KW  - Workers'
KW  - Robust machine learning
KW  - Spectra's
KW  - Distributed machine learning
KW  - Modeling parameters
KW  - Byzantine fault tolerance
KW  - Machine learning problem
KW  - Byzantine parameter server
KW  - Byzantine parameter servers
KW  - Component failures
KW  - Minimum diameters
ER  - 

TY  - JOUR
TI  - Probabilistic machine learning based soft-sensors for product quality prediction in batch processes
AU  - Mowbray, M.
AU  - Kay, H.
AU  - Kay, S.
AU  - Caetano, P.C.
AU  - Hicks, A.
AU  - Mendoza, C.
AU  - Lane, A.
AU  - Martin, P.
AU  - Zhang, D.
T2  - Chemometrics and Intelligent Laboratory Systems
AB  - The major promise of the 4th industrial revolution is encompassed by the utilization of real-time process data to inform operational decision-making. Research focus relating to the monitoring of batch process end product qualities has typically been dominated by the use of latent variable models. In this work, we combined latent variable modeling with probabilistic machine learning methods to construct novel soft-sensors, which are able to synchronously capture nonlinearities expressed within process data, as well as identify accurate uncertainty estimates for predictions. Specifically, we explored the combination of multiway projection to latent structures (MPLS) with Gaussian processes (GPs), Bayesian neural networks (BNNs) and heteroscedastic noise neural networks (HNNs). We demonstrated performance of the soft-sensors for industrial batch process quality control, which involves estimating the end viscosity of different variants of a non-newtonian liquid product manufactured over different periods. Through experimental validation, it is concluded that the use of the MPLS-HNN soft-sensor provides particular promise for industrial batch process monitoring given its high accuracy and reliability, as well as ease for practical implementation. © 2022 The Authors
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.chemolab.2022.104616
VL  - 228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134848803&doi=10.1016%2fj.chemolab.2022.104616&partnerID=40&md5=e752b0991b45b40e555f026c45fcfdd9
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Bayesian network
KW  - reliability
KW  - prediction
KW  - structural equation modeling
KW  - uncertainty
KW  - Data analytics
KW  - controlled study
KW  - Article
KW  - Quality control
KW  - Process monitoring
KW  - Uncertainty estimation
KW  - Gaussian process
KW  - measurement accuracy
KW  - validation process
KW  - batch process
KW  - heteroscedastic noise neural network
KW  - multiway projection to latent structure
KW  - product quality
KW  - Robust soft-sensor
KW  - viscosity
ER  - 

TY  - JOUR
TI  - A hybrid machine learning-optimization approach to pricing and train formation problem under demand uncertainty
AU  - Yousefi, A.
AU  - Pishvaee, M.S.
T2  - RAIRO - Operations Research
AB  - Due to the complexity of pricing in the service industry, it is important to provide an efficient pricing framework for real-life and large-sized applications. To this end, we combined an optimization approach with a regression-based machine learning method to provide a reliable and efficient framework for integrated pricing and train formation problem under hybrid uncertainty. To do so, firstly, a regression-based machine learning model is applied to forecast the ticket price of the passenger railway, and then, the obtained price in is used as the input of a train formation optimization model. Further, in order to deal with the hybrid uncertainty of demand parameters, a robust fuzzy stochastic programming model is proposed. Finally, a real transportation network from the Iran railway is applied to demonstrate the efficiency of the proposed model. The analysis of numerical results indicated that the proposed framework is able to state the optimal price with less complexity in comparison to traditional models.  © The authors. Published by EDP Sciences, ROADEF, SMAI 2022.
DA  - 2022///
PY  - 2022
DO  - 10.1051/ro/2022052
VL  - 56
IS  - 3
SP  - 1429
EP  - 1451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132108897&doi=10.1051%2fro%2f2022052&partnerID=40&md5=d7042096f6262b81543cc59d7f046846
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Regression analysis
KW  - Uncertainty
KW  - Railroads
KW  - Complex networks
KW  - Costs
KW  - Stochastic models
KW  - Stochastic systems
KW  - Stochastic programming
KW  - Railroad transportation
KW  - Hybrid machine learning
KW  - Learning optimizations
KW  - Regression-based machine learning
KW  - Optimization approach
KW  - Hybrid uncertainty
KW  - Pricing
KW  - Robust fuzzy
KW  - Robust fuzzy stochastic programming
KW  - Train formation problem
ER  - 

TY  - JOUR
TI  - Understanding Machine Learning Practitioners' Data Documentation Perceptions, Needs, Challenges, and Desiderata
AU  - Heger, A.K.
AU  - Marquis, L.B.
AU  - Vorvoreanu, M.
AU  - Wallach, H.
AU  - Wortman Vaughan, J.
T2  - Proceedings of the ACM on Human-Computer Interaction
AB  - Data is central to the development and evaluation of machine learning (ML) models. However, the use of problematic or inappropriate datasets can result in harms when the resulting models are deployed. To encourage responsible AI practice through more deliberate reflection on datasets and transparency around the processes by which they are created, researchers and practitioners have begun to advocate for increased data documentation and have proposed several data documentation frameworks. However, there is little research on whether these data documentation frameworks meet the needs of ML practitioners, who both create and consume datasets. To address this gap, we set out to understand ML practitioners' data documentation perceptions, needs, challenges, and desiderata, with the ultimate goal of deriving design requirements that can inform future data documentation frameworks. We conducted a series of semi-structured interviews with 14 ML practitioners at a single large, international technology company. We had them answer a list of questions taken from datasheets for datasets∼\citegebru2018datasheets. Our findings show that current approaches to data documentation are largely ad hoc and myopic in nature. Participants expressed needs for data documentation frameworks to be adaptable to their contexts, integrated into their existing tools and workflows, and automated wherever possible. Despite the fact that data documentation frameworks are often motivated from the perspective of responsible AI, participants did not make the connection between the questions that they were asked to answer and their responsible AI implications. In addition, participants often had difficulties prioritizing the needs of dataset consumers and providing information that someone unfamiliar with their datasets might need to know. Based on these findings, we derive seven design requirements for future data documentation frameworks such as more actionable guidance on how the characteristics of datasets might result in harms and how these harms might be mitigated, more explicit prompts for reflection, automated adaptation to different contexts, and integration into ML practitioners' existing tools and workflows.  © 2022 ACM.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3555760
VL  - 6
IS  - 2 CSCW
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146492240&doi=10.1145%2f3555760&partnerID=40&md5=fbcfe6855cbcabc412349af0471a95e3
DB  - Scopus
KW  - machine learning
KW  - responsible AI
KW  - Machine-learning
KW  - Machine learning models
KW  - Responsible AI
KW  - documentation
KW  - Documentation
KW  - Work-flows
KW  - Dataset
KW  - datasets
KW  - Data documentation
KW  - International technology
KW  - Semi structured interviews
KW  - Technology companies
ER  - 

TY  - CONF
TI  - Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation
AU  - Wang, H.
AU  - Huang, Z.
AU  - Wu, X.
AU  - Xing, E.
T2  - Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
AB  - Data augmentation has been proven to be an effective technique for developing machine learning models that are robust to known classes of distributional shifts (e.g., rotations of images), and alignment regularization is a technique often used together with data augmentation to further help the model learn representations invariant to the shifts used to augment the data. In this paper, motivated by a proliferation of options of alignment regularizations, we seek to evaluate the performances of several popular design choices along the dimensions of robustness and invariance, for which we introduce a new test procedure. Our synthetic experiment results speak to the benefits of squared "2 norm regularization. Further, we also formally analyze the behavior of alignment regularization to complement our empirical study under assumptions we consider realistic. Finally, we test this simple technique we identify (worst-case data augmentation with squared "2 norm alignment regularization) and show that the benefits of this method outrun those of the specially designed methods. We also release a software package in both TensorFlow and PyTorch for users to use the method with a couple of lines at https://github.com/jyanln/AlignReg.  © 2022 Owner/Author.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3534678.3539438
SP  - 1846
EP  - 1856
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137145889&doi=10.1145%2f3534678.3539438&partnerID=40&md5=ee29243ec5958682d44789213dc6ab47
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Testing
KW  - robustness
KW  - trustworthy
KW  - Performance
KW  - Machine-learning
KW  - Machine learning models
KW  - Robustness
KW  - Learn+
KW  - Test procedures
KW  - Alignment
KW  - data augmentation
KW  - Data augmentation
KW  - Regularisation
KW  - Trustworthy
KW  - Invariant representation
ER  - 

TY  - JOUR
TI  - A Neural Controller for Induction Motors: Fractional-Order Stability Analysis and Online Learning Algorithm
AU  - Sabzalian, M.H.
AU  - Alattas, K.A.
AU  - El-Sousy, F.F.M.
AU  - Mohammadzadeh, A.
AU  - Mobayen, S.
AU  - Vu, M.T.
AU  - Aredes, M.
T2  - Mathematics
AB  - In this study, an intelligent control scheme is developed for induction motors (IMs). The dynamics of IMs are unknown and are perturbed by the variation of rotor resistance and load changes. The control system has two stages. In the identification stage, the group method of data-handling (GMDH) neural network (NN) was designed for online modeling of the IM. In the control stage, the GMDH-NN was applied to compensate for the impacts of disturbances and uncertainties. The stability is shown by the Lyapunov approach. Simulations demonstrated the good accuracy of the suggested new control approach under disturbances and unknown dynamics. © 2022 by the authors.
DA  - 2022///
PY  - 2022
DO  - 10.3390/math10061003
VL  - 10
IS  - 6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129630561&doi=10.3390%2fmath10061003&partnerID=40&md5=e5e4cf1e137e4a97ec058dc48a1b31f0
DB  - Scopus
KW  - Machine learning
KW  - Robust control
KW  - Stability analysis
KW  - Neural control
KW  - Faulty conditions
KW  - Fractional calculus
KW  - Group method of data-handling neural network
KW  - Induction motor
ER  - 

TY  - JOUR
TI  - Machine learning-based data-driven robust optimization approach under uncertainty
AU  - Zhang, C.
AU  - Wang, Z.
AU  - Wang, X.
T2  - Journal of Process Control
AB  - On the basis of the machine learning ability to analyze massive data, we propose a new concept suitable for data-driven robust optimization, and design two new methods for constructing data-driven uncertainty sets. Partial least squares (PLS) or kernel principal component analysis (KPCA) is selected to capture the underlying uncertainties and correlation of uncertain data, and the projection of uncertain data on each principal component is obtained. Then, the probability distribution information of project data is extracted via robust kernel density estimation (RKDE). Considering the applicability of PLS to linear data for the idea of canonical correlation analysis and the bias of KPCA to nonlinear data due to kernel function, guidelines for selecting an appropriate method are presented in terms of the linear and nonlinear degree between data. The measurement indicators are Pearson correlation coefficient, mutual information and nonlinear coefficient. The induced robust counterpart framework not only alleviates excessive conservatism, but also significantly improves the robustness, which has the advantages of easy implementation and high computational efficiency. Through a numerical example and two application cases, the effectiveness of the proposed framework is illustrated. © 2022 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.jprocont.2022.04.013
VL  - 115
SP  - 1
EP  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129968052&doi=10.1016%2fj.jprocont.2022.04.013&partnerID=40&md5=aa06eba48b8d9d540af811bd645b1ee1
DB  - Scopus
KW  - Machine learning
KW  - Uncertainty
KW  - Least squares approximations
KW  - Uncertainty analysis
KW  - Optimization
KW  - Robust optimization
KW  - Principal component analysis
KW  - Probability distributions
KW  - Data driven
KW  - Computational efficiency
KW  - Nonlinear analysis
KW  - Correlation methods
KW  - Optimization approach
KW  - Kernel principal component analyses (KPCA)
KW  - Kernel principal component analysis
KW  - Massive data
KW  - Data-driven robust optimization
KW  - Partial least squares
KW  - Partial least-squares
KW  - Scheduling problem
KW  - Uncertain datas
ER  - 

TY  - CONF
TI  - Fair, Robust, and Data-Efficient Machine Learning in Healthcare
AU  - Singh, H.
T2  - AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society
AB  - While machine learning systems have shown improvements, often, in carefully curated settings, challenges still exist to their wider deployment, especially for making consequential decisions. The research described here explores three challenges, particularly, emphasizing the interesting issues that arise at their intersection. How do we design machine learning systems to account for the systemic biases of the world, to act reliably under unseen settings, and to handle limited availability of data? Human-facing applications of machine learning such as personalized health commonly encounter these challenges, thus, these are important to address. The research has three components addressing different parts of the above central question. Here, we describe the work done on two components of the above central question and highlight the future work planned as part of the third one. We draw from methods in causal inference, algorithmic fairness, and interactive learning, and apply them to applications in health.  © 2022 Owner/Author.
DA  - 2022///
PY  - 2022
DO  - 10.1145/3514094.3539552
SP  - 914
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137155055&doi=10.1145%2f3514094.3539552&partnerID=40&md5=ef4ba81f3ddc5bece995516a2be94e4a
DB  - Scopus
KW  - Machine learning
KW  - Algorithmic fairness
KW  - Machine-learning
KW  - Active Learning
KW  - Algorithmics
KW  - Machine learning systems
KW  - Robust learning
KW  - algorithmic fairness
KW  - robust learning
KW  - policy evaluation
KW  - Policy evaluation
KW  - active learning
KW  - Personalized healths
KW  - Three-component
KW  - Two-component
ER  - 

TY  - JOUR
TI  - A robust approach to pore pressure prediction applying petrophysical log data aided by machine learning techniques
AU  - Zhang, G.
AU  - Davoodi, S.
AU  - Shamshirband, S.
AU  - Ghorbani, H.
AU  - Mosavi, A.
AU  - Moslehpour, M.
T2  - Energy Reports
AB  - Determination of pore pressure (PP), a key reservoir parameter that is beneficial for evaluating geomechanical parameters of the reservoir, is so important in oil and gas fields development. Accurate estimation of PP is also essential for safe drilling of oil and gas wells since PP data are used as the input for safe mud window determination. In the present study, empirical equations along with machine learning methods, namely random forest algorithm, support vector regression (SVR) algorithm, artificial neural network (ANN) algorithm, and decision tree (DT) algorithm, are employed for PP prediction applying well log data. To this end, 2827 data records collected from three wells (Well A, Well B, and Well C) drilled in one of the Middle East oil fields are used. The dataset of Wells A and B is used for models’ training, validating, and testing, while Well C dataset is applied for evaluating the models’ generalizability in PP prediction in the field under study. To construct the predictive algorithms, 12 input variables are initially considered in the study. A feature selection analysis is conducted to find the most influential input variables set for developing PP predictive models. The results obtained suggest that the 9-input-variable set is the most efficient combination of inputs used in the ML models construction. Among all the four ML algorithms proposed, the DT algorithm presents the most accurate predictions for PP, delivering R2 and RMSE values of 0.9985 and 14.460 psi, respectively. Furthermore, the model generalization analysis results reveal that the 9-input-variable DT model developed can be used for PP prediction throughout the field of study since it presented an excellent accuracy performance in predicting PP when applied to Well C dataset. © 2022 The Author(s)
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.egyr.2022.01.012
VL  - 8
SP  - 2233
EP  - 2247
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123761800&doi=10.1016%2fj.egyr.2022.01.012&partnerID=40&md5=250a98fa3dee492bcd7faf3e9358cdc0
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Neural networks
KW  - Machine learning algorithms
KW  - Learning algorithms
KW  - Gas industry
KW  - Decision-tree algorithm
KW  - Forecasting
KW  - Statistical tests
KW  - Infill drilling
KW  - Robust approaches
KW  - Oil well logging
KW  - Log data
KW  - Decision tree algorithm
KW  - Input variables
KW  - Data-aided
KW  - Petrophysical data
KW  - Petrophysical datum
KW  - Petrophysical logs
KW  - Petrophysics
KW  - Pore pressure
KW  - Pore pressure prediction
KW  - Variable sets
ER  - 

TY  - JOUR
TI  - Fuzzy clustering algorithm for outlier-interval data based on the robust exponent distance
AU  - Phamtoan, D.
AU  - Nguyenhuu, K.
AU  - Vovan, T.
T2  - Applied Intelligence
AB  - The outlier elements of a data are ones that differs significantly from others. For many reasons, we have to face with outlier elements in data analysis for the different fields. Because an outlier element can cause the serious problems in statistical analyses, studying about it is interested in many researchers. This article proposes the fuzzy clustering algorithm for outlier - interval data based on the robust exponent distance to overcome the drawback of traditional clustering algorithm which to clean the outliers before performing. The outstanding advantage of this algorithm is to find the suitable number of clusters, to cluster for the interval data with outlier elements, and to determine the probability belonging to clusters for the intervals at the same time. The proposed algorithm is described step by step via numerical examples, and can be performed effectively by the Matlab procedure. In addition, it also applied in reality with the air pollution, mushroom, and image data sets. These real applications demonstrate the robustness of the proposed algorithm in comparison with the existing ones. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.
DA  - 2022///
PY  - 2022
DO  - 10.1007/s10489-021-02773-w
VL  - 52
IS  - 6
SP  - 6276
EP  - 6291
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114314167&doi=10.1007%2fs10489-021-02773-w&partnerID=40&md5=517f9fcd1559d9aed5b507858a3c1cc7
DB  - Scopus
KW  - Statistics
KW  - Clustering algorithms
KW  - Unsupervised learning
KW  - Fuzzy clustering
KW  - Real applications
KW  - Fuzzy clustering analysis
KW  - Image datasets
KW  - Interval data
KW  - Matlab procedures
KW  - Number of clusters
KW  - Outlier interval data
KW  - Robust exponential distance
KW  - Traditional clustering
ER  - 

TY  - JOUR
TI  - A comparison of neural and non-neural machine learning models for food safety risk prediction with European Union RASFF data
AU  - Nogales, A.
AU  - Díaz-Morón, R.
AU  - García-Tejedor, Á.J.
T2  - Food Control
AB  - European Union launched the RASFF portal in 1977 to ensure cross-border monitoring and a quick reaction when public health risks are detected in the food chain. There are not enough resources available to guarantee a comprehensive inspection policy, but RASFF data has enormous potential as a preventive tool. However, there are few studies of food and feed risk issues prediction and none with RASFF data. Although deep learning models are good prediction systems, it must be confirmed whether in this field they behave better than other machine learning techniques. The importance of categorical variables encoding as input for numerical models should be specially studied. Results in this paper show that deep learning with entity embedding is the best combination, with accuracies of 86.81%, 82.31%, and 88.94% in each of the three stages of the simplified RASFF process in which the tests were carried out. However, the random forest models with one hot encoding offer only slightly worse results, so it seems that in the quality of the results the coding has more weight than the prediction technique. Our work also demonstrates that the use of probabilistic predictions (an advantage of neural models) can also be used to optimize the number of inspections that can be carried out. © 2021 Elsevier Ltd
DA  - 2022///
PY  - 2022
DO  - 10.1016/j.foodcont.2021.108697
VL  - 134
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120846686&doi=10.1016%2fj.foodcont.2021.108697&partnerID=40&md5=c56668ff95d6dd95f1b9bc1d89f6e2d7
DB  - Scopus
KW  - Deep learning
KW  - Machine learning
KW  - Prediction
KW  - Random forest
KW  - Entity embedding
KW  - Food and feed safety
ER  - 

TY  - CONF
TI  - Training Confidence-Calibrated Classifier via Distributionally Robust Learning
AU  - Wu, H.
AU  - Wang, M.D.
T2  - Proceedings - 2020 IEEE 44th Annual Computers, Software, and Applications Conference, COMPSAC 2020
AB  - Supervised learning via empirical risk minimization, despite its solid theoretical foundations, faces a major challenge in generalization capability, which limits its application in real-world data science problems. In particular, current models fail to distinguish in-distribution and out-of-distribution and give over confident predictions for out-of-distribution samples. In this paper, we propose an distributionally robust learning method to train classifiers via solving an unconstrained minimax game between an adversary test distribution and a hypothesis. We showed the theoretical generalization performance guarantees, and empirically, our learned classifier when coupled with thresholded detectors, can efficiently detect out-of-distribution samples. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/COMPSAC48688.2020.0-230
SP  - 295
EP  - 304
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094166969&doi=10.1109%2fCOMPSAC48688.2020.0-230&partnerID=40&md5=e53bd9574a661a02bd4dd71eb7ac3a34
DB  - Scopus
KW  - Learning systems
KW  - supervised learning
KW  - Application programs
KW  - distributionally robust optimization
KW  - adversarial machine learning
KW  - Robust learning
KW  - ITS applications
KW  - Data Science
KW  - Generalization performance
KW  - Minimax games
KW  - Generalization capability
KW  - robust machine learning
KW  - Current models
KW  - Empirical risk minimization
KW  - Theoretical foundations
ER  - 

TY  - JOUR
TI  - Robust Coreset Construction for Distributed Machine Learning
AU  - Lu, H.
AU  - Li, M.-J.
AU  - He, T.
AU  - Wang, S.
AU  - Narayanan, V.
AU  - Chan, K.S.
T2  - IEEE Journal on Selected Areas in Communications
AB  - Coreset, which is a summary of the original dataset in the form of a small weighted set in the same sample space, provides a promising approach to enable machine learning over distributed data. Although viewed as a proxy of the original dataset, each coreset is only designed to approximate the cost function of a specific machine learning problem, and thus different coresets are often required to solve different machine learning problems, increasing the communication overhead. We resolve this dilemma by developing robust coreset construction algorithms that can support a variety of machine learning problems. Motivated by empirical evidence that suitably-weighted $k$ -clustering centers provide a robust coreset, we harden the observation by establishing theoretical conditions under which the coreset provides a guaranteed approximation for a broad range of machine learning problems, and developing both centralized and distributed algorithms to generate coresets satisfying the conditions. The robustness of the proposed algorithms is verified through extensive experiments on diverse datasets with respect to both supervised and unsupervised learning problems. © 1983-2012 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/JSAC.2020.3000373
VL  - 38
IS  - 10
SP  - 2400
EP  - 2417
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086740700&doi=10.1109%2fJSAC.2020.3000373&partnerID=40&md5=a969717ff8206332057d6e004a01df95
DB  - Scopus
KW  - Machine learning
KW  - Learning algorithms
KW  - Cost functions
KW  - Clustering algorithms
KW  - Approximation algorithms
KW  - Supervised and unsupervised learning
KW  - Distributed machine learning
KW  - Distributed database systems
KW  - Distributed data
KW  - Machine learning problem
KW  - Clustering centers
KW  - Communication overheads
KW  - Construction algorithms
KW  - Coreset
KW  - distributed k-means
KW  - distributed k-median
KW  - distributed machine learning
KW  - Weighted set
ER  - 

TY  - JOUR
TI  - Robust stochastic optimization made easy with RSOME
AU  - Chen, Z.
AU  - Sim, M.
AU  - Xiong, P.
T2  - Management Science
AB  - We present a new distributionally robust optimization model called robust stochastic optimization (RSO), which unifies both scenario-tree-based stochastic linear optimization and distributionally robust optimization in a practicable framework that can be solved using the state-of-the-art commercial optimization solvers. We also develop a new algebraic modeling package, Robust Stochastic Optimization Made Easy (RSOME), to facilitate the implementation of RSO models. The model of uncertainty incorporates both discrete and continuous random variables, typically assumed in scenario-tree-based stochastic linear optimization and distributionally robust optimization, respectively. To address the nonanticipativity of recourse decisions, we introduce the event-wise recourse adaptations, which integrate the scenario-tree adaptation originating from stochastic linear optimization and the affine adaptation popularized in distributionally robust optimization. Our proposed event-wise ambiguity set is rich enough to capture traditional statistic-based ambiguity sets with convex generalized moments, mixture distribution, φ-divergence, Wasserstein (Kantorovich-Rubinstein) metric, and also inspire machine-learning-based ones using techniques such as K-means clustering and classification and regression trees. Several interesting RSO models, including optimizing over the Hurwicz criterion and two-stage problems over Wasserstein ambiguity sets, are provided. © 2020 INFORMS
DA  - 2020///
PY  - 2020
DO  - 10.1287/mnsc.2020.3603
VL  - 66
IS  - 8
SP  - 3329
EP  - 3339
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090183802&doi=10.1287%2fmnsc.2020.3603&partnerID=40&md5=1019209d6d7e279517295bc3ccd9c34f
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Robust optimization
KW  - Stochastic models
KW  - Stochastic systems
KW  - Distributionally robust optimization
KW  - Mixture distributions
KW  - K-means clustering
KW  - Robust optimization models
KW  - Linear programming
KW  - Stochastic optimizations
KW  - Classification and regression tree
KW  - Linear optimization
KW  - Model of uncertainty
KW  - Optimization solvers
KW  - Stochastic linear optimization
ER  - 

TY  - CONF
TI  - Distribution aligning refinery of pseudo-label for imbalanced semi-supervised learning
AU  - Kim, J.
AU  - Hur, Y.
AU  - Park, S.
AU  - Yang, E.
AU  - Hwang, S.J.
AU  - Shin, J.
T2  - Advances in Neural Information Processing Systems
AB  - While semi-supervised learning (SSL) has proven to be a promising way for leveraging unlabeled data when labeled data is scarce, the existing SSL algorithms typically assume that training class distributions are balanced. However, these SSL algorithms trained under imbalanced class distributions can severely suffer when generalizing to a balanced testing criterion, since they utilize biased pseudo-labels of unlabeled data toward majority classes. To alleviate this issue, we formulate a convex optimization problem to softly refine the pseudo-labels generated from a biased model, and develop a simple iterative algorithm, named Distribution Aligning Refinery of Pseudo-label (DARP) that solves it provably and efficiently. Under various class-imbalanced semi-supervised scenarios, we demonstrate the effectiveness of DARP and its compatibility with state-of-the-art SSL schemes. © 2020 Neural information processing systems foundation. All rights reserved.
DA  - 2020///
PY  - 2020
VL  - 2020-December
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108455544&partnerID=40&md5=8a4b27aa6f1c2a38718a9d0aa746c518
DB  - Scopus
KW  - State of the art
KW  - Semi-supervised learning
KW  - Iterative methods
KW  - Semi-supervised
KW  - Convex optimization
KW  - Refining
KW  - Convex optimization problems
KW  - Semi-supervised learning (SSL)
KW  - Imbalanced class
KW  - Iterative algorithm
KW  - Testing criteria
KW  - Training class
ER  - 

TY  - CONF
TI  - Network intrusion detection method based on stacked denoising sparse autoencoder and extreme learning machine
AU  - Zhang, G.
AU  - Wang, X.
AU  - Li, R.
AU  - Lai, J.
AU  - Xiang, Q.
AU  - He, J.
T2  - Proceedings - 2020 2nd International Conference on Information Technology and Computer Application, ITCA 2020
AB  - Aiming at the problem of low detection accuracy and high false positive rate caused by noise doping in network data, and at the same time improving detection speed, a network intrusion detection based on stacked denoising sparse autoencoder and extreme learning machine (sDSAE-ELM) is proposed. First, the stacked denoising sparse autoencoder is used to automatically extract the robustness characteristics of the network data, and then the extreme learning machine is used for classification. Experiments on the NSL-KDD dataset show that the network intrusion detection method based on sDSAE-ELM has strong noise robustness when processing high-dimensional noisy data, while shortening the training time. And high detection accuracy and low false positive rate have been achieved. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ITCA52113.2020.00048
SP  - 194
EP  - 199
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106055454&doi=10.1109%2fITCA52113.2020.00048&partnerID=40&md5=171558ee919e119a98a5e37b7a6aa8af
DB  - Scopus
KW  - Machine learning
KW  - Intrusion detection
KW  - robustness
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - extreme learning machine
KW  - feature extraction
KW  - Noise robustness
KW  - High-dimensional
KW  - Detection accuracy
KW  - Network intrusion detection
KW  - False positive rates
KW  - intrusion detection
KW  - cyberspace security
KW  - denoising sparse autoencoder
KW  - Detection speed
KW  - Network intrusion detection method
KW  - training time
ER  - 

TY  - JOUR
TI  - Robust dimensionality reduction for data visualization with deep neural networks
AU  - Becker, M.
AU  - Lippel, J.
AU  - Stuhlsatz, A.
AU  - Zielke, T.
T2  - Graphical Models
AB  - We elaborate on the robustness assessment of a deep neural network (DNN) approach to dimensionality reduction for data visualization. The proposed DNN seeks to improve the class separability and compactness in a low-dimensional feature space, which is a natural strategy to obtain well-clustered visualizations. It consists of a DNN-based nonlinear generalization of Fisher's linear discriminant analysis and a DNN-based regularizer. Regarding data visualization, a well-regularized DNN guarantees to learn sufficiently similar data visualizations for different sets of samples that represent the data approximately equally well. Such a robustness against fluctuations in the data is essential for many real-world applications. Our results show that the combined DNN is considerably more robust than the generalized discriminant analysis alone. We further support this conclusion by examining feature representations from four comparative approaches. As a means of measuring the structural dissimilarity between different feature representations, we propose a hierarchical cluster analysis. © 2020
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.gmod.2020.101060
VL  - 108
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081299316&doi=10.1016%2fj.gmod.2020.101060&partnerID=40&md5=76d97eb1f3fc211bc0f42e575b52dd65
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Deep neural networks
KW  - Visualization
KW  - Learning systems
KW  - algorithm
KW  - Data visualization
KW  - artificial neural network
KW  - Hierarchical systems
KW  - discriminant analysis
KW  - cluster analysis
KW  - Clustering algorithms
KW  - Dimensionality reduction
KW  - Discriminant analysis
KW  - Cluster analysis
KW  - Auto encoders
KW  - data acquisition
KW  - High dimensional data
KW  - Regularization
KW  - instrumentation
KW  - Deep autoencoder
KW  - Gerda
KW  - GerDA
KW  - Hierarchical cluster analysis
KW  - Hierarchical clustering
KW  - High-dimensional data
KW  - Reduction
KW  - Robust feature extraction
KW  - Robust feature extractions
ER  - 

TY  - CONF
TI  - Assuring safe implementation of decision support functionality based on data-driven methods for ship navigation
AU  - Brandsæter, A.
AU  - Smefjell, G.
AU  - van de Merwe, K.
AU  - Kamsvåg, V.
T2  - Proceedings of the 30th European Safety and Reliability Conference and the 15th Probabilistic Safety Assessment and Management Conference
AB  - The rapid technology development related to machine learning and data-driven models for autonomous and unmanned vessels continues. Also manned vessels can make use of this technology, for example to enhance situational awareness of an on board navigator. Potentially, this can contribute to increase safety and to optimize operations by transferring tasks and functions to where they are most effectively handled, ashore and on board. However, the introduction of decision support systems and functionality to enhance situational awareness can have detrimental consequences, due to for example misunderstandings, wrong use of the functionality, malfunctioning user-interface, as well as bad or wrong decision proposals. This can be the case, even when manning levels are kept unchanged. To ensure safety, we argue that the system must be rigorously tested, and the system’s limitations, uncertainties and capabilities must be correctly conveyed to its users. Based on current regulations, including the International Maritime Organization (IMO) resolution Principles of minimum safe manning, we investigate how minimum safe manning of a vessel should be established considering relevant factors, including the ship’s level of automation and shore support. We also discuss challenges related to lack of specification, which is an inherent challenge to decision support systems based on object detection and image classification since these tasks rely on perception of the environment, which can only partially be specified using rules. Furthermore, challenges related to lack of explainability are discussed, and potential benefits of using methods for black-box explanation during operation and during testing are investigated. We emphasize the importance of testing and verification of the dataset used to train the models, ensuring that it sufficiently covers relevant scenarios. We also discuss challenges related to human factors, and emphasize the importance of safety management systems used to identify risks, responsibilities, resources and competencies ensuring compliance with rules and regulations. © ESREL2020-PSAM15 Organizers.Published by Research Publishing, Singapore.
DA  - 2020///
PY  - 2020
DO  - 10.3850/978-981-14-8593-0_4899-cd
SP  - 637
EP  - 643
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107267213&doi=10.3850%2f978-981-14-8593-0_4899-cd&partnerID=40&md5=39b3d9aeaf0e023658524dbdfb213a00
DB  - Scopus
KW  - Explainable AI
KW  - Machine learning
KW  - Machine Learning
KW  - Human machine interface
KW  - Situational awareness
KW  - User interfaces
KW  - Object detection
KW  - Human Machine Interface
KW  - Level of automations
KW  - Decision support systems
KW  - Safety engineering
KW  - Statistical tests
KW  - Ships
KW  - Data-driven methods
KW  - Safety management systems
KW  - Decision support
KW  - Assuring data-driven methods
KW  - Autonomous ships
KW  - Black-box testing
KW  - International maritime organizations
KW  - Rapid technology development
KW  - Resolution principle
KW  - Rules and regulations
KW  - Safe manning
KW  - Training data analysis
KW  - Safe Manning
KW  - Situational Awareness
ER  - 

TY  - CONF
TI  - Robust data driven well performance optimization assisted by machine learning techniques for natural flowing and gas-lift wells in Abu Dhabi
AU  - Al Selaiti, I.
AU  - Mata, C.
AU  - Saputelli, L.
AU  - Badmaev, D.
AU  - Alatrach, Y.
AU  - Rubio, E.
AU  - Mohan, R.
AU  - Quijada, D.
T2  - Proceedings - SPE Annual Technical Conference and Exhibition
AB  - Asset management success is accomplished when the integrated production system is operating close to its intended potential. Continuous awareness of wells and facility conditions are key factor in the realization of designed capacity. In contrast, unknown status and conditions can severely limit production capacity. The rise of instrumentation technologies over the last four decades have created new opportunities to understand well and reservoir behavior. However, despite of being proved as a cost-effective surveillance initiative, remote monitoring is still not adopted in over 60% of oil and gas fields around the world. Understanding the value of data through machine learning techniques is the basis for establishing a robust surveillance strategy. The objective of this paper is to develop a data-driven approach, enabled by Artificial Intelligence (AI) methodologies including machine learning (ML), to find optimal operating envelope for gas-lift wells. The process involves building ML models for generating instantaneous predictions of multiphase flow rates and other quantities of interest, such as GOR, WCT, using real-time sensor data at the surface, historical performance, and sporadic test data. Additionally, forecasting models were developed for generating short-term (30 days) forecast of cumulative oil, water, gas, and liquid production, multiphase flow rates, WCT, GOR, and reservoir pressure. Using time-series forecasting models, a sensitivity analysis was performed to generate short-term well response for a selected number of combinations of choke settings, and gas injection rates. Sensitivity analysis provides 2D maps of well response highlight an operating envelope, which are proposed to be combined with physical and operational constraints to arrive at optimal operating conditions, which may effortlessly add 2.5% net profit from optimum gas-lift alocation. The results of this work show encouraging results, and demonstrate value that AI-enabled methodologies can provide in instrumented wells by enabling automated workflows for virtual metering, production allocation, short-term production forecasting, and deriving optimal operating conditions. The developed AI methodology has tremendous potential of integration in an end-to-end workflow of autonomous well control by utilizing available data to produce easy to update ML models, with little to no human intervention. Copyright © 2020, Society of Petroleum Engineers
DA  - 2020///
PY  - 2020
VL  - 2020-October
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095696124&partnerID=40&md5=03a3f787e73cd5d42ae05258daf2e499
DB  - Scopus
KW  - Machine learning
KW  - Time series analysis
KW  - Multiphase flow
KW  - Gas industry
KW  - Forecasting
KW  - Cost effectiveness
KW  - Machine learning techniques
KW  - Sensitivity analysis
KW  - Operational constraints
KW  - Gases
KW  - Oil wells
KW  - Gas lifts
KW  - Injection (oil wells)
KW  - Instrumentation technologies
KW  - Integrated production systems
KW  - Natural gas wells
KW  - Optimal operating conditions
KW  - Quantities of interests
KW  - Surveillance strategies
KW  - Time series forecasting models
ER  - 

TY  - CONF
TI  - Data-driven robust voltage/var control using PV inverters in active distribution networks
AU  - Liu, H.
AU  - Zhang, C.
AU  - Guo, Q.
T2  - Proceedings - 2020 International Conference on Smart Grids and Energy Systems, SGES 2020
AB  - Modern power systems are heading towards a sustainable future with rapidly increasing penetration of distributed renewable energy sources such as solar photovoltaics (PV), especially in active distribution networks (ADNs). However, temporal and spatial variations and intermittency of renewable power generation bring challenges on voltage control. As controllable VAR sources, PV associated inverters can supply flexible and fast-responsive reactive power to achieve voltage/VAR control (VVC) in the ADNs. Conventional VVC mainly relies on rule-based, mathematical or heuristic methods, which can be inefficient or even infeasible as the system becomes large and when complex uncertainty conditions are considered. To this end, this paper proposes a deep reinforcement learning (DRL) based optimization model for the inverter-based VVC under uncertainties. The DRL agent learns to optimally determine inverter reactive power output setpoints through exploration in the virtual environment and neural network training, with multiple objectives of minimizing bus voltage deviations, PV active power curtailments and network power losses. Temporally and spatially uncertain PV power generation and loads are fully considered in the proposed DRL model. A numerical case study on the IEEE 123-bus test system has indicated the VVC decisions are efficiently obtained and are robust against uncertainty realization. © 2020 IEEE
DA  - 2020///
PY  - 2020
DO  - 10.1109/SGES51519.2020.00062
SP  - 314
EP  - 319
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102725735&doi=10.1109%2fSGES51519.2020.00062&partnerID=40&md5=ba44e6a13e67fe2518c0f9e437040992
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Deep reinforcement learning
KW  - Uncertainty
KW  - Electric power transmission networks
KW  - Smart power grids
KW  - Optimization
KW  - Heuristic methods
KW  - Renewable energy resources
KW  - Electric inverters
KW  - Renewable energy source
KW  - Reactive power
KW  - Solar power generation
KW  - Inverters
KW  - Neural network training
KW  - Optimization modeling
KW  - Active distribution networks
KW  - Operational robustness
KW  - Reactive power output
KW  - Renewable power generation
KW  - Temporal and spatial variation
KW  - Voltage/VAR control
KW  - Voltage/var controls
ER  - 

TY  - CONF
TI  - ß-variational classifiers under attack
AU  - Maggipinto, M.
AU  - Terzi, M.
AU  - Susto, G.A.
T2  - IFAC-PapersOnLine
AB  - Deep Neural networks have gained lots of attention in recent years thanks to the breakthroughs obtained in the field of Computer Vision. However, despite their popularity, it has been shown that they provide limited robustness in their predictions. In particular, it is possible to synthesise small adversarial perturbations that imperceptibly modify a correctly classified input data, making the network confidently misclassify it. This has led to a plethora of different methods to try to improve robustness or detect the presence of these perturbations. In this paper, we perform an analysis of ß-Variational Classifiers, a particular class of methods that not only solve a specific classification task, but also provide a generative component that is able to generate new samples from the input distribution. More in details, we study their robustness and detection capabilities, together with some novel insights on the generative part of the model. Copyright © 2020 The Authors.
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.ifacol.2020.12.1979
VL  - 53
SP  - 7903
EP  - 7908
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108023748&doi=10.1016%2fj.ifacol.2020.12.1979&partnerID=40&md5=91b209c6acf1d20e8e773f55cb72a8aa
DB  - Scopus
KW  - Deep neural networks
KW  - Deep Learning
KW  - Machine Learning
KW  - Robustness
KW  - Classification tasks
KW  - Input datas
KW  - Adversarial Training
KW  - Computer Vision
KW  - Class of methods
KW  - Detection capability
KW  - Input distributions
ER  - 

TY  - CONF
TI  - Enhanced Food Safety Through Deep Learning for Food Recalls Prediction
AU  - Makridis, G.
AU  - Mavrepis, P.
AU  - Kyriazis, D.
AU  - Polychronou, I.
AU  - Kaloudis, S.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Several application domains/sectors such as logistics, healthcare, industry and transportation, are exploiting the added value of deployed sensors to obtain information relevant to the domain and exploit it in different contexts (e.g. for processes optimization, for actions adaptation, for decision support, etc.). The same applies to the agriculture sector, through the deployment of smart devices and sensors that provide a wealth of datasets for irrigation tuning, crops assessment, food supply chain operations monitoring, etc. Furthermore, emerging machine and deep learning data analytics techniques are utilized as a means to obtain insights and optimize the aforementioned processes. In this context, one significant challenge refers to the enhancement of the food safety across the food supply chain given that goods and products can become unsafe for plenty of reasons, such as mislabeling allergens, contamination etc. To address this challenge, in this paper we introduce a set of deep and machine learning techniques employing time series forecasting to provide insights regarding the risk associated with each product category concerning potential food recalls. Additionally, we propose an approach based on reinforcement learning which utilizes historical recall announcements for predicting future recalls (by their type) that leads to timely recalls and contributes to enhanced food safety across the supply chain. We also evaluate and demonstrate the effectiveness and added-value of the proposed approaches through a real-world scenario that yields promising results. © 2020, Springer Nature Switzerland AG.
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-61527-7_37
VL  - 12323 LNAI
SP  - 566
EP  - 580
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094118660&doi=10.1007%2f978-3-030-61527-7_37&partnerID=40&md5=228dd2e86cd5632af7e6c2011716f1d5
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Forecasting
KW  - Decision support systems
KW  - Safety engineering
KW  - Smart devices
KW  - Data Analytics
KW  - Machine learning techniques
KW  - Food safety
KW  - Real-world scenario
KW  - Agricultural robots
KW  - Decision supports
KW  - Time series forecasting
KW  - Supply chains
KW  - Food supply
KW  - Added values
KW  - Agriculture sectors
KW  - Product categories
KW  - Surrogate data
ER  - 

TY  - CONF
TI  - Data Analytics and Application Challenges in the Childrenswear Market - A Case Study in Greece
AU  - Papachristou, E.
AU  - Bilalis, N.
T2  - IFIP Advances in Information and Communication Technology
AB  - Integrating technology solutions like PLM, 3D Prototyping, digital printing, automatic cutting, AR & VR into the fashion product development process can deliver continuous improvement in everyday business and empower fashion companies navigate the challenges and opportunities of Industry 4.0. Leveraging powerful artificial intelligence capabilities that guide the discovery of next-generation - in popularity- fashion product designs, can improve innovation and conceptual design exploration to the clothing companies. This study focuses in the market of childrenswear which is the fastest-growing and one of the most lucrative markets in the garment industry; a growth that had overtaken both menswear and womenswear. At the same time, childrenswear product consumers are fashion conscious, demanding more fashionable designer clothing. Predicting the best appealing and selling product maybe the recent demand of applying AI tools in the design generation phase or decision making process, however comfort, fit for play, rest and safety most of all, are requirements that childrenswear must comply with. This paper aims to identify the challenges that AI technology applications face regarding childrenswear, due to safety restriction and standards by taking into consideration a Greek childrenswear manufacturer and retailer. © 2020, IFIP International Federation for Information Processing.
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-62807-9_51
VL  - 594
SP  - 647
EP  - 658
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097076291&doi=10.1007%2f978-3-030-62807-9_51&partnerID=40&md5=4137ba6d6a1d056ad0960c570f7e2b6a
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Decision making
KW  - Data analytics
KW  - Life cycle
KW  - Data Analytics
KW  - Commerce
KW  - Product design
KW  - Safety standards
KW  - AI Technologies
KW  - Conceptual design
KW  - Decision making process
KW  - Childrenswear
KW  - Continuous improvements
KW  - Design Exploration
KW  - Design generation
KW  - Fashion companies
KW  - Garment industry
KW  - Integrating technology
KW  - Product development process
ER  - 

TY  - CONF
TI  - Real-time well monitoring and engineering analysis of drilling activities: Intelligent rig state detection and prediction with uncertainty
AU  - Kemajou, V.
AU  - Samuel, R.
T2  - Proceedings of the International Conference on Offshore Mechanics and Arctic Engineering - OMAE
AB  - Drilling activities are risky and costly, especially when performed offshore. Careful monitoring and real time data analysis are required for safe and efficient operations with minimized down-time. Drilling operations, being fast-paced and not visible, often lead to transient and unforeseen issues. The synchronous assessment and prediction of drilling quality has historically been a challenge. It relies on a prompt collection, analysis and prediction of the multiple sensors data, as well as an immediate comparison to the original drilling plan. Another challenge is achieving real-time well engineering, and automatically and instantaneously providing valuable insights to the engineering and operations teams. A system was successfully developed to tackle these challenges. It is a cloud-based application, made with an event-driven streaming architecture to automatically retrieve real-time drilling data and compare it with planned data. The real-time data is automatically made available to determine the current well operation or rig state, and trigger the subsequent engineering analysis. Next, a forecast model is trained with the engineering calculation outputs and it returns predictions on these outputs while considering their inherent uncertainty. As a result, these predictions enable alerts to be sent when the system detects approaching anomalous conditions. The proposed system is a DecisionSpace® 365 cloud-native application on an open architecture. It is flexible, accessible from anywhere, can be automatically updated for continuous improvement, and can be deployed easily and quickly. It can also be extended to further applications. Copyright © 2020 ASME
DA  - 2020///
PY  - 2020
DO  - 10.1115/OMAE2020-18060
VL  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092670721&doi=10.1115%2fOMAE2020-18060&partnerID=40&md5=2066b6664b373d68c5899d784fe0d7d0
DB  - Scopus
KW  - Safety
KW  - Artificial intelligence
KW  - Machine learning
KW  - Automation
KW  - Software
KW  - Computer architecture
KW  - Data analytics
KW  - Anomaly detection
KW  - Forecasting
KW  - Uncertainty analysis
KW  - Real-time
KW  - Infill drilling
KW  - Offshore oil well production
KW  - Drilling operation
KW  - Monitoring
KW  - Sensors
KW  - Cloud-based applications
KW  - Continuous improvements
KW  - Arctic engineering
KW  - Digital
KW  - Drilling engineering
KW  - Drilling operations
KW  - Engineering analysis
KW  - Engineering calculation
KW  - Logging
KW  - Offshore
KW  - Onshore
KW  - Predictive analysis
KW  - Real time data analysis
KW  - Rig activity
KW  - Rig state
KW  - Rig-state detection
KW  - Streaming architecture
ER  - 

TY  - CHAP
TI  - The Data Science Revolution: How Learning Machines Changed the Way We Work and Do Business
AU  - Aalst, W.M.P.
T2  - IFIP Advances in Information and Communication Technology
AB  - Data science technology is rapidly changing the role of information technology in society and all economic sectors. Artificial Intelligence (AI) and Machine Learning (ML) are at the forefront of attention. However, data science is much broader and also includes data extraction, data preparation, data exploration, data transformation, storage and retrieval, computing infrastructures, other types of mining and learning, presentation of explanations and predictions, and the exploitation of results taking into account ethical, social, legal, and business aspects. This paper provides an overview of the field of data science also showing the main developments, thereby focusing on (1) the growing importance of learning from data (rather than modeling or programming), (2) the transfer of tasks from humans to (software) robots, and (3) the risks associated with data science (e.g., privacy problems, unfair or nontransparent decision making, and the market dominance of a few platform providers). © 2020, IFIP International Federation for Information Processing.
DA  - 2020///
PY  - 2020
VL  - 555
SP  - 5
EP  - 19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097338394&doi=10.1007%2f978-3-030-64246-4_2&partnerID=40&md5=03361cc1c313349e2c5ccab08736e435
DB  - Scopus
KW  - Artificial Intelligence
KW  - Machine learning
KW  - Decision making
KW  - Data transformation
KW  - Privacy by design
KW  - Big data
KW  - Learning machines
KW  - Digital storage
KW  - Metadata
KW  - Robot programming
KW  - Responsible data science
KW  - Data science
KW  - Data Science
KW  - Professional aspects
KW  - Business aspects
KW  - Computing infrastructures
KW  - Data exploration
KW  - Science revolution
KW  - Science technologies
KW  - Storage and retrievals
ER  - 

TY  - CONF
TI  - First-order optimization for superquantile-based supervised learning
AU  - Laguel, Y.
AU  - Malick, J.
AU  - Harchaoui, Z.
T2  - IEEE International Workshop on Machine Learning for Signal Processing, MLSP
AB  - Classical supervised learning via empirical risk (or negative log-likelihood) minimization hinges upon the assumption that the testing distribution coincides with the training distribution. This assumption can be challenged in modern applications of machine learning in which learning machines may operate at prediction time with testing data whose distribution departs from the one of the training data. We revisit the su-perquantile regression method by proposing a first-order optimization algorithm to minimize a superquantile-based learning objective. The proposed algorithm is based on smoothing the superquantile function by infimal convolution. Promising numerical results illustrate the interest of the approach towards safer supervised learning.  © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/MLSP49062.2020.9231909
VL  - 2020-September
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096504349&doi=10.1109%2fMLSP49062.2020.9231909&partnerID=40&md5=829598e5d2da99b76ab9557ce8bf54d9
DB  - Scopus
KW  - Signal processing
KW  - Learning systems
KW  - Supervised learning
KW  - Risk perception
KW  - Regression analysis
KW  - Learning machines
KW  - Learning objectives
KW  - Numerical results
KW  - Regression method
KW  - Distributional robustness
KW  - Nonsmooth optimization
KW  - Risk measure
KW  - Empirical risks
KW  - Infimal convolution
KW  - Modern applications
KW  - Prediction time
ER  - 

TY  - CONF
TI  - REMIXMATCH: SEMI-SUPERVISED LEARNING WITH DISTRIBUTION ALIGNMENT AND AUGMENTATION ANCHORING
AU  - Berthelot, D.
AU  - Carlini, N.
AU  - Cubuk, E.D.
AU  - Kurakin, A.
AU  - Zhang, H.
AU  - Raffel, C.
AU  - Sohn, K.
T2  - 8th International Conference on Learning Representations, ICLR 2020
AB  - We improve the recently-proposed “MixMatch” semi-supervised learning algorithm by introducing two new techniques: distribution alignment and augmentation anchoring. Distribution alignment encourages the marginal distribution of predictions on unlabeled data to be close to the marginal distribution of ground-truth labels. Augmentation anchoring feeds multiple strongly augmented versions of an input into the model and encourages each output to be close to the prediction for a weakly-augmented version of the same input. To produce strong augmentations, we propose a variant of AutoAugment which learns the augmentation policy while the model is being trained. Our new algorithm, dubbed ReMixMatch, is significantly more data-efficient than prior work, requiring between 5× and 16× less data to reach the same accuracy. For example, on CIFAR-10 with 250 labeled examples we reach 93.73% accuracy (compared to MixMatch's accuracy of 93.58% with 4,000 examples) and a median accuracy of 84.92% with just four labels per class. We make our code and data open-source at https://github.com/google-research/remixmatch. © 2020 8th International Conference on Learning Representations, ICLR 2020. All rights reserved.
DA  - 2020///
PY  - 2020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150642697&partnerID=40&md5=af6658d3972b779666a6e58519085582
DB  - Scopus
KW  - Machine learning
KW  - Ground truth
KW  - Learning algorithms
KW  - Semi-supervised learning
KW  - Learn+
KW  - Alignment
KW  - Unlabeled data
KW  - Marginal distribution
KW  - Open systems
KW  - Anchorings
KW  - Open-source
ER  - 

TY  - JOUR
TI  - Towards robust voice pathology detection: Investigation of supervised deep learning, gradient boosting, and anomaly detection approaches across four databases
AU  - Harar, P.
AU  - Galaz, Z.
AU  - Alonso-Hernandez, J.B.
AU  - Mekyska, J.
AU  - Burget, R.
AU  - Smekal, Z.
T2  - Neural Computing and Applications
AB  - Automatic objective non-invasive detection of pathological voice based on computerized analysis of acoustic signals can play an important role in early diagnosis, progression tracking, and even effective treatment of pathological voices. In search towards such a robust voice pathology detection system, we investigated three distinct classifiers within supervised learning and anomaly detection paradigms. We conducted a set of experiments using a variety of input data such as raw waveforms, spectrograms, mel-frequency cepstral coefficients (MFCC), and conventional acoustic (dysphonic) features (AF). In comparison with previously published works, this article is the first to utilize combination of four different databases comprising normophonic and pathological recordings of sustained phonation of the vowel /a/ unrestricted to a subset of vocal pathologies. Furthermore, to our best knowledge, this article is the first to explore gradient-boosted trees and deep learning for this application. The following best classification performances measured by F1 score on dedicated test set were achieved: XGBoost (0.733) using AF and MFCC, DenseNet (0.621) using MFCC, and Isolation Forest (0.610) using AF. Even though these results are of exploratory character, conducted experiments do show promising potential of gradient boosting and deep learning methods to robustly detect voice pathologies. © 2018, The Natural Computing Applications Forum.
DA  - 2020///
PY  - 2020
DO  - 10.1007/s00521-018-3464-7
VL  - 32
IS  - 20
SP  - 15747
EP  - 15757
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044933261&doi=10.1007%2fs00521-018-3464-7&partnerID=40&md5=965899aa371419d02ac36d0c0426c3d4
DB  - Scopus
KW  - Deep learning
KW  - Speech recognition
KW  - Learning systems
KW  - Diagnosis
KW  - Anomaly detection
KW  - Classification (of information)
KW  - Gradient boosting
KW  - Database systems
KW  - Classification performance
KW  - Detection approach
KW  - Signal analysis
KW  - Computerized analysis
KW  - Mel-frequency cepstral coefficients
KW  - Non-invasive detection
KW  - Pathological voice
KW  - Pathology
KW  - Voice pathology detection
ER  - 

TY  - JOUR
TI  - Responsible Operations: Data Science, Machine Learning, and AI in Libraries
AU  - Macgregor, R.
T2  - American Archivist
DA  - 2020///
PY  - 2020
DO  - 10.17723/0360-9081-83.2.483
VL  - 83
IS  - 2
SP  - 483
EP  - 487
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161958180&doi=10.17723%2f0360-9081-83.2.483&partnerID=40&md5=004340fbe235dde0173019150a011403
DB  - Scopus
ER  - 

TY  - JOUR
TI  - Robust active flow control over a range of Reynolds numbers using an artificial neural network trained through deep reinforcement learning
AU  - Tang, H.
AU  - Rabault, J.
AU  - Kuhnle, A.
AU  - Wang, Y.
AU  - Wang, T.
T2  - Physics of Fluids
AB  - This paper focuses on the active flow control of a computational fluid dynamics simulation over a range of Reynolds numbers using deep reinforcement learning (DRL). More precisely, the proximal policy optimization (PPO) method is used to control the mass flow rate of four synthetic jets symmetrically located on the upper and lower sides of a cylinder immersed in a two-dimensional flow domain. The learning environment supports four flow configurations with Reynolds numbers 100, 200, 300, and 400, respectively. A new smoothing interpolation function is proposed to help the PPO algorithm learn to set continuous actions, which is of great importance to effectively suppress problematic jumps in lift and allow a better convergence for the training process. It is shown that the DRL controller is able to significantly reduce the lift and drag fluctuations and actively reduce the drag by ∼5.7%, 21.6%, 32.7%, and 38.7%, at Re = 100, 200, 300, and 400, respectively. More importantly, it can also effectively reduce drag for any previously unseen value of the Reynolds number between 60 and 400. This highlights the generalization ability of deep neural networks and is an important milestone toward the development of practical applications of DRL to active flow control.  © 2020 Author(s).
DA  - 2020///
PY  - 2020
DO  - 10.1063/5.0006492
VL  - 32
IS  - 5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087546536&doi=10.1063%2f5.0006492&partnerID=40&md5=fad8127dd94977882f588cb8d0ff83a0
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - Neural networks
KW  - Computer aided instruction
KW  - Training aircraft
KW  - Policy optimization
KW  - Flow control
KW  - Flow configurations
KW  - Learning environments
KW  - Generalization ability
KW  - Computational fluid dynamics
KW  - Computational fluid dynamics simulations
KW  - Active flow control
KW  - Drag
KW  - Gas dynamics
KW  - Interpolation function
KW  - Reynolds number
KW  - Two-dimensional flow
ER  - 

TY  - JOUR
TI  - UAV autonomous aerial combat maneuver strategy generation with observation error based on state-adversarial deep deterministic policy gradient and inverse reinforcement learning
AU  - Kong, W.
AU  - Zhou, D.
AU  - Yang, Z.
AU  - Zhao, Y.
AU  - Zhang, K.
T2  - Electronics (Switzerland)
AB  - With the development of unmanned aerial vehicle (UAV) and artificial intelligence (AI) technology, Intelligent UAV will be widely used in future autonomous aerial combat. Previous researches on autonomous aerial combat within visual range (WVR) have limitations due to simplifying assumptions, limited robustness, and ignoring sensor errors. In this paper, in order to consider the error of the aircraft sensors, we model the aerial combat WVR as a state-adversarial Markov decision process (SA-MDP), which introduce the small adversarial perturbations on state observations and these perturbations do not alter the environment directly, but can mislead the agent into making suboptimal decisions. Meanwhile, we propose a novel autonomous aerial combat maneuver strategy generation algorithm with high-performance and high-robustness based on state-adversarial deep deterministic policy gradient algorithm (SA-DDPG), which add a robustness regularizers related to an upper bound on performance loss at the actor-network. At the same time, a reward shaping method based on maximum entropy (MaxEnt) inverse reinforcement learning algorithm (IRL) is proposed to improve the aerial combat strategy generation algorithm’s efficiency. Finally, the efficiency of the aerial combat strategy generation algorithm and the performance and robustness of the resulting aerial combat strategy is verified by simulation experiments. Our main contributions are three-fold. First, to introduce the observation errors of UAV, we are modeling air combat as SA-MDP. Second, to make the strategy network of air combat maneuver more robust in the presence of observation errors, we introduce regularizers into the policy gradient. Third, to solve the problem that air combat’s reward function is too sparse, we use MaxEnt IRL to design a shaping reward to accelerate the convergence of SA-DDPG. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2020///
PY  - 2020
DO  - 10.3390/electronics9071121
VL  - 9
IS  - 7
SP  - 1
EP  - 24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087882996&doi=10.3390%2felectronics9071121&partnerID=40&md5=95f0a06385ca807210f56d889aab548a
DB  - Scopus
KW  - Reinforcement learning
KW  - UAV
KW  - Robustness
KW  - Aerial combat
KW  - Network training
KW  - Sensor errors
ER  - 

TY  - JOUR
TI  - Stress-Testing big data platform to extract smart and interoperable food safety analytics
AU  - Polychronou, I.
AU  - Stoitsis, G.
AU  - Papakonstantinou, M.
AU  - Manouselis, N.
T2  - International Journal of Metadata, Semantics and Ontologies
AB  - One of the significant challenges for the future is to guarantee safe food for all inhabitants of the planet. During the last 15 years, very important fraud issues like the 2013 horse meat scandal and the 2008 Chinese milk scandal have greatly affected the food industry and public health. One of the alternatives for this issue consists of increasing production, but to accomplish this, it is necessary that innovative options be applied to enhance the safety of the food supply chain. For this reason, it is quite important to have the right infrastructure in order to manage data of the food safety sector and provide useful analytics to Food Safety Experts. In this paper, we describe Agroknow s Big Data Platform architecture and examine its scalability for data management and experimentation. © 2020 Inderscience Enterprises Ltd.. All rights reserved.
DA  - 2020///
PY  - 2020
VL  - 14
IS  - 4
SP  - 306
EP  - 314
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108028069&partnerID=40&md5=25f3a3d795ed1819a3a0abb368beb5af
DB  - Scopus
KW  - big data
KW  - Big data
KW  - Information management
KW  - Safety testing
KW  - Food safety
KW  - food safety
KW  - predictive analytics
KW  - machine-learning
KW  - Interoperability
KW  - Supply chains
KW  - Food supply
KW  - data management
KW  - Food industries
KW  - data experimentation
KW  - data platform
KW  - Data platform
KW  - evaluation metrics.
KW  - Increasing production
KW  - infrastructure performance
KW  - Stress Testing
KW  - stress-Testing data
ER  - 

TY  - CONF
TI  - Strategic study of safety monitoring and control of low-voltage power distributive devices based on artificial intelligence
AU  - Wang, M.
AU  - Li, S.
AU  - Jia, J.
AU  - Qi, S.
T2  - 2020 IEEE 4th Conference on Energy Internet and Energy System Integration: Connecting the Grids Towards a Low-Carbon High-Efficiency Energy System, EI2 2020
AB  - This paper mainly focus on new-generation communications technique application on power distributive devices. First, we talk about the definition of low-voltage power grid and the overall safety situation of low-voltage power distributive devices. Then, we narrate the present safety issue of traditional low-voltage power distributive devices. Next, we mainly illustrate the specific requirement of application of artificial intelligence(AI) on low-voltage power distributive devices and make a detailed structure of safety monitoring and control system of low-voltage power distributive devices based on AI and give an introduction of the above structure. Last, we make analysis of some key communications technique of AI from low-voltage power distributive devices and finally make a brief conclusion for future application. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/EI250167.2020.9347318
SP  - 4222
EP  - 4226
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101620284&doi=10.1109%2fEI250167.2020.9347318&partnerID=40&md5=c50afaa11bb35284037a4efd7953c37e
DB  - Scopus
KW  - Deep learning
KW  - Artificial intelligence
KW  - Electric power transmission networks
KW  - Big data
KW  - Power grids
KW  - Safety monitoring
KW  - Safety issues
KW  - Future applications
KW  - Artificial intelligence(AI)
KW  - High-efficient calculation
KW  - Low voltages
KW  - Safety monitoring and control
KW  - Strategic study
ER  - 

TY  - JOUR
TI  - A sequential structure for water inflow forecasting in coal mines integrating feature selection and multi-objective optimization
AU  - Chen, S.
AU  - Dong, S.
T2  - IEEE Access
AB  - To construct an accurate and stable approach for water inflow forecasting, a series of advanced and effective techniques, such as variational mode decomposition (VMD), outlier robust extreme learning machine (ORELM) and multi-objective grey wolf optimizer (MOGWO), are appropriately integrated into this study. Considering that the influence of the mode number on theVMDdecomposition effectiveness, such an argument is determined by observing the converged centre frequency distribution among the components. Then the characteristic items of water inflow series are extracted by VMD, thus obtaining a series of sub- components. Afterwards, ORELM is applied to predict each component, where the parameters of ORELM are optimized by MOGWO with multi-objective functions including forecasting accuracy and stability. Correspondingly, the aggregation of all components' prediction values is considered as the final results. The experimental results obtained by performing eight various models on real-time data demonstrate that the supplementary modules achieve positive effects on the improvement of prediction accuracy, where the proposed model implements an average performance promotion of 48:43% compared with the contrastive models. © 2020 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.3028959
VL  - 8
SP  - 183619
EP  - 183632
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102755942&doi=10.1109%2fACCESS.2020.3028959&partnerID=40&md5=d787a196b506f8410420091f7cc7079b
DB  - Scopus
KW  - Learning systems
KW  - Forecasting
KW  - Extreme learning machine
KW  - Variational techniques
KW  - Variational mode decomposition
KW  - Outlier robust extreme learning machine
KW  - Multiobjective optimization
KW  - Multi objective
KW  - Coal mines
KW  - Prediction accuracy
KW  - Coal industry
KW  - Centre frequency
KW  - Centre frequency distribution
KW  - Forecasting accuracy
KW  - Mode decomposition
KW  - Multi-objective functions
KW  - Multi-objective grey wolf optimizer
KW  - Sequential structure
KW  - Water inflow prediction
ER  - 

TY  - CONF
TI  - An Empirical Analysis of Backward Compatibility in Machine Learning Systems
AU  - Srivastava, M.
AU  - Nushi, B.
AU  - Kamar, E.
AU  - Shah, S.
AU  - Horvitz, E.
T2  - Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
AB  - In many applications of machine learning (ML), updates are performed with the goal of enhancing model performance. However, current practices for updating models rely solely on isolated, aggregate performance analyses, overlooking important dependencies, expectations, and needs in real-world deployments. We consider how updates, intended to improve ML models, can introduce new errors that can significantly affect downstream systems and users. For example, updates in models used in cloud-based classification services, such as image recognition, can cause unexpected erroneous behavior in systems that make calls to the services. Prior work has shown the importance of "backward compatibility" for maintaining human trust. We study challenges with backward compatibility across different ML architectures and datasets, focusing on common settings including data shifts with structured noise and ML employed in inferential pipelines. Our results show that (i) compatibility issues arise even without data shift due to optimization stochasticity, (ii) training on large-scale noisy datasets often results in significant decreases in backward compatibility even when model accuracy increases, and (iii) distributions of incompatible points align with noise bias, motivating the need for compatibility aware de-noising and robustness methods. © 2020 ACM.
DA  - 2020///
PY  - 2020
DO  - 10.1145/3394486.3403379
SP  - 3272
EP  - 3280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090415543&doi=10.1145%2f3394486.3403379&partnerID=40&md5=c03835156d04ea2af102deec309a9c91
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Image recognition
KW  - Data mining
KW  - reliability
KW  - Large dataset
KW  - responsible data science
KW  - Current practices
KW  - Empirical analysis
KW  - Model performance
KW  - Aggregate performance
KW  - backward compatibility
KW  - Backward compatibility
KW  - Noisy datasets
KW  - Real world deployment
KW  - Structured noise
ER  - 

TY  - CONF
TI  - Robustifying Reinforcement Learning Agents via Action Space Adversarial Training
AU  - Tan, K.L.
AU  - Esfandiari, Y.
AU  - Lee, X.Y.
AU  - Sarkar, S.
T2  - Proceedings of the American Control Conference
AB  - Adoption of machine learning (ML)-enabled cyber-physical systems (CPS) are becoming prevalent in various sectors of modern society such as transportation, industrial, and power grids. Recent studies in deep reinforcement learning (DRL) have demonstrated its benefits in a large variety of data-driven decisions and control applications. As reliance on ML-enabled systems grows, it is imperative to study the performance of these systems under malicious state and actuator attacks. Traditional control systems employ resilient/fault-tolerant controllers that counter these attacks by correcting the system via error observations. However, in some applications, a resilient controller may not be sufficient to avoid a catastrophic failure. Ideally, a robust approach is more useful in these scenarios where a system is inherently robust (by design) to adversarial attacks. While robust control has a long history of development, robust ML is an emerging research area that has already demonstrated its relevance and urgency. However, the majority of robust ML research has focused on perception tasks and not on decision and control tasks, although the ML (specifically RL) models used for control applications are equally vulnerable to adversarial attacks. In this paper, we show that a well-performing DRL agent that is initially susceptible to action space perturbations (e.g. actuator attacks) can be robustified against similar perturbations through adversarial training. © 2020 AACC.
DA  - 2020///
PY  - 2020
DO  - 10.23919/ACC45564.2020.9147846
VL  - 2020-July
SP  - 3959
EP  - 3964
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089561387&doi=10.23919%2fACC45564.2020.9147846&partnerID=40&md5=501add6087ff53cc19dbca4920ba956e
DB  - Scopus
KW  - Intelligent agents
KW  - Deep learning
KW  - Reinforcement learning
KW  - Reinforcement learning agent
KW  - Controllers
KW  - Electric power transmission networks
KW  - Robust control
KW  - Embedded systems
KW  - Robust approaches
KW  - Actuators
KW  - Data driven decision
KW  - Catastrophic failures
KW  - Control applications
KW  - Cyber-physical systems (CPS)
KW  - Error observation
KW  - Resilient controller
ER  - 

TY  - JOUR
TI  - A robust machine learning approach to SDG data segmentation
AU  - Mwitondi, K.S.
AU  - Munyakazi, I.
AU  - Gatsheni, B.N.
T2  - Journal of Big Data
AB  - In the light of the recent technological advances in computing and data explosion, the complex interactions of the Sustainable Development Goals (SDG) present both a challenge and an opportunity to researchers and decision makers across fields and sectors. The deep and wide socio-economic, cultural and technological variations across the globe entail a unified understanding of the SDG project. The complexity of SDGs interactions and the dynamics through their indicators align naturally to technical and application specifics that require interdisciplinary solutions. We present a consilient approach to expounding triggers of SDG indicators. Illustrated through data segmentation, it is designed to unify our understanding of the complex overlap of the SDGs by utilising data from different sources. The paper treats each SDG as a Big Data source node, with the potential to contribute towards a unified understanding of applications across the SDG spectrum. Data for five SDGs was extracted from the United Nations SDG indicators data repository and used to model spatio-temporal variations in search of robust and consilient scientific solutions. Based on a number of pre-determined assumptions on socio-economic and geo-political variations, the data is subjected to sequential analyses, exploring distributional behaviour, component extraction and clustering. All three methods exhibit pronounced variations across samples, with initial distributional and data segmentation patterns isolating South Africa from the remaining five countries. Data randomness is dealt with via a specially developed algorithm for sampling, measuring and assessing, based on repeated samples of different sizes. Results exhibit consistent variations across samples, based on socio-economic, cultural and geo-political variations entailing a unified understanding, across disciplines and sectors. The findings highlight novel paths towards attaining informative patterns for a unified understanding of the triggers of SDG indicators and open new paths to interdisciplinary research. © 2020, The Author(s).
DA  - 2020///
PY  - 2020
DO  - 10.1186/s40537-020-00373-y
VL  - 7
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095823012&doi=10.1186%2fs40537-020-00373-y&partnerID=40&md5=f873c4d209e0228f56f81333654ad324
DB  - Scopus
KW  - Big Data
KW  - Principal Component Analysis
KW  - Data Science
KW  - K-Means
KW  - Consilience
KW  - Data randomness
KW  - Development Science Framework
KW  - Sample-Model-Assess
KW  - Sustainable Development Goals
KW  - Unsupervised Modelling
ER  - 

TY  - JOUR
TI  - Correction to: Towards robust voice pathology detection: Investigation of supervised deep learning, gradient boosting, and anomaly detection approaches across four databases (Neural Computing and Applications, (2020), 32, 20, (15747-15757), 10.1007/s00521-018-3464-7)
AU  - Harar, P.
AU  - Galaz, Z.
AU  - Alonso-Hernandez, J.B.
AU  - Mekyska, J.
AU  - Burget, R.
AU  - Smekal, Z.
T2  - Neural Computing and Applications
AB  - The Table 3 was published incorrectly in the original publication of the article. © 2019, Springer-Verlag London Ltd., part of Springer Nature.
DA  - 2020///
PY  - 2020
DO  - 10.1007/s00521-019-04469-2
VL  - 32
IS  - 20
SP  - 15759
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073948095&doi=10.1007%2fs00521-019-04469-2&partnerID=40&md5=ca1a35c24e7f76e2a140acfd54261687
DB  - Scopus
ER  - 

TY  - CONF
TI  - Robust multi-output learning with highly incomplete data via restricted boltzmann machines
AU  - Fissore, G.
AU  - Decelle, A.
AU  - Furtlehner, C.
AU  - Han, Y.
T2  - CEUR Workshop Proceedings
AB  - In this work we tackle the challenging problem of multi-output classification with partially observed features and labels. We show that a simple Restricted Boltzmann Machine can be trained with an adapted algorithm based on mean-field equations to efficiently solve problems of inductive and transductive learning in which both features and labels are missing at random. The effectiveness of the approach is demonstrated empirically on various dataseis, with particular focus on a real-world Internet-of-Things security dataset. © 2020 CEUR-WS. All rights reserved.
DA  - 2020///
PY  - 2020
VL  - 2655
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090912508&partnerID=40&md5=d5589f5423489f44bbb464ada25b98d2
DB  - Scopus
KW  - Artificial intelligence
KW  - Learning systems
KW  - Real-world
KW  - Restricted boltzmann machine
KW  - Incomplete data
KW  - Mean field equation
KW  - Missing at randoms
KW  - Multi-output
KW  - Stairs
KW  - Transductive learning
ER  - 

TY  - CONF
TI  - Using artificial intelligence and machine learning techniques to analyze incident reports
AU  - Sattari, F.
AU  - Kurian, D.
AU  - Lefsrud, L.
AU  - Macciotta, R.
T2  - Institution of Chemical Engineers Symposium Series
AB  - The consequences of failure for petrochemical separation and refining can be devastating as they deal with hazardous materials, at high temperatures and/or pressures. To prevent such incidents from recurring, we need to understand the causes and controls. Company incident databases contain substantial amounts of incident information that can be analyzed to determine trends, patterns, causal relationships and correlations between incident-causing factors and incidents. The aim of this research is to apply Artificial Intelligence (AI) and Machine Learning (ML) to reduce the human bias involved in providing a risk rating using a risk matrix and better understand the underlying causes of incidents and causal relationships that might be found between different incident types. These correlations could lead to an incident with compounding severity or simply cause other unexpected incidents over time. Over the course of this study, a total of 31,851 incident reports from an oil and gas company operating in northern Alberta were considered, and 8,199 were selected and analyzed. The selected incident reports provided an adequate description of the incident and included a completed root cause analysis. The research was completed by utilizing machine learning algorithms to classify incidents according to Process Safety Management (PSM) elements developed by the Center for Chemical Process Safety (CCPS). Risk severity was also calculated by utilizing a combination of a standardized risk matrix as a guideline and machine learning methods to assign a final risk score to incident reports. The classified incidents were then used as inputs for a Bayesian Network (BN) which determined causal relationships between incident types, human factors, and the total number of incidents. The three factors having the strongest causal relationship with total incident count were Asset Integrity and Reliability, Management Review & Continuous Improvement, and Hazard Identification & Risk Analysis. Previous research has explored the results of improving Asset Integrity and Reliability and Management Review & Continuous Improvement. This study will suggest how companies can improve Hazard Identification & Risk Analysis and the benefits of doing so. © 2021 IChemE.
DA  - 2021///
PY  - 2021
VL  - 2021-November
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120561485&partnerID=40&md5=f552cc9b0b0374562efd5c813245452c
DB  - Scopus
KW  - Machine learning
KW  - Machine Learning
KW  - Learning algorithms
KW  - Gas industry
KW  - Machine-learning
KW  - Bayesian networks
KW  - Risk assessment
KW  - Hazards
KW  - Artificial intelligence learning
KW  - Matrix algebra
KW  - Reliability analysis
KW  - Risk analysis
KW  - Chemical analysis
KW  - Process safety
KW  - Bayesia n networks
KW  - Incident reports
KW  - Incident data
KW  - Causal relationships
KW  - Continuous improvements
KW  - Bayesian Network
KW  - Incident Data
KW  - Lead compounds
KW  - Management review
KW  - Process Safety
KW  - Risk matrix
KW  - Risk Matrix
ER  - 

TY  - CONF
TI  - Improving Label Noise Robustness with Data Augmentation and Semi-Supervised Learning (Student Abstract)
AU  - Nishi, K.
AU  - Ding, Y.
AU  - Rich, A.
AU  - Höllerer, T.
T2  - 35th AAAI Conference on Artificial Intelligence, AAAI 2021
AB  - Modern machine learning algorithms typically require large amounts of labeled training data to fit a reliable model. To minimize the cost of data collection, researchers often employ techniques such as crowdsourcing and web scraping. However, web data and human annotations are known to exhibit high margins of error, resulting in sizable amounts of incorrect labels. Poorly labeled training data can cause models to overfit to the noise distribution, crippling performance in real-world applications. In this work, we investigate the viability of using data augmentation in conjunction with semi-supervised learning to improve the label noise robustness of image classification models. We conduct several experiments using noisy variants of the CIFAR-10 image classification dataset to benchmark our method against existing algorithms. Experimental results show that our augmentative SSL approach improves upon the state-of-the-art. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved
DA  - 2021///
PY  - 2021
VL  - 18
SP  - 15855
EP  - 15856
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113704115&partnerID=40&md5=a401022fc47943adad5a27bba8a3e9ad
DB  - Scopus
KW  - Machine learning algorithms
KW  - Supervised learning
KW  - Learning algorithms
KW  - Image classification
KW  - Classification (of information)
KW  - Image enhancement
KW  - Images classification
KW  - Semi-supervised learning
KW  - Data collection
KW  - Data augmentation
KW  - Noise robustness
KW  - Labeled training data
KW  - Web scrapings
KW  - Large amounts
KW  - Reliable models
ER  - 

TY  - JOUR
TI  - Machine learning-based predictive control using noisy data: evaluating performance and robustness via a large-scale process simulator
AU  - Wu, Z.
AU  - Luo, J.
AU  - Rincon, D.
AU  - Christofides, P.D.
T2  - Chemical Engineering Research and Design
AB  - Machine learning modeling of chemical processes using noisy data is a practically challenging task due to the occurrence of overfitting during learning. In this work, we propose a dropout method and a co-teaching learning algorithm that develop long short-term memory (LSTM) neural networks to capture the ground truth (i.e., underlying process dynamics) from noisy data. To evaluate the performance and robustness of the proposed modeling approaches, we consider an industrial chemical reactor example and use a large-scale process simulator, Aspen Plus Dynamics that does not employ assumptions on reactor properties typically made in the derivation of first-principles models, to generate process operational data that are corrupted by sensor noise which is determined using industrial data. The dropout method is first utilized to reduce the overfitting of LSTM models to noisy data. Then, another approach termed co-teaching method is used to train LSTM models with additional noise-free data generated from simulations of the reactor first-principles model that employs several standard modeling assumptions not made in the Aspen model. Through open-loop and closed-loop simulations, we demonstrate the improvement of model prediction accuracy and of the open- and closed-loop performances under model predictive controllers using dropout and co-teaching LSTM neural network models compared to the LSTM model developed from the standard training process from the noisy data. © 2021 Institution of Chemical Engineers
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.cherd.2021.02.011
VL  - 168
SP  - 275
EP  - 287
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101323729&doi=10.1016%2fj.cherd.2021.02.011&partnerID=40&md5=e098e87451228a436e837de1ad3138a2
DB  - Scopus
KW  - Machine learning
KW  - Learning algorithms
KW  - Predictive analytics
KW  - Neural network model
KW  - Machine learning models
KW  - Long short-term memory
KW  - Model predictive control
KW  - Predictive control
KW  - Computer software
KW  - Chemical processes
KW  - Closed-loop performance
KW  - Nonlinear systems
KW  - First principles models
KW  - Model predictive controllers
KW  - Closed-loop simulations
KW  - Long short-term memory neural networks
KW  - Noisy data
KW  - Process simulators
ER  - 

TY  - CONF
TI  - MLINSPECT: A Data Distribution Debugger for Machine Learning Pipelines
AU  - Grafberger, S.
AU  - Guha, S.
AU  - Stoyanovich, J.
AU  - Schelter, S.
T2  - Proceedings of the ACM SIGMOD International Conference on Management of Data
AB  - Machine Learning (ML) is increasingly used to automate impactful decisions, and the risks arising from this wide-spread use are garnering attention from policymakers, scientists, and the media. ML applications are often very brittle with respect to their input data, which leads to concerns about their reliability, accountability, and fairness. While bias detection cannot be fully automated, computational tools can help pinpoint particular types of data issues. We recently proposed mlinspect, a library that enables lightweight lineage-based inspection of ML preprocessing pipelines. In this demonstration, we show how mlinspect can be used to detect data distribution bugs in a representative pipeline. In contrast to existing work, mlinspect operates on declarative abstractions of popular data science libraries like estimator/transformer pipelines, can handle both relational and matrix data, and does not require manual code instrumentation. The library is publicly available at https://github.com/stefan-grafberger/mlinspect. © 2021 ACM.
DA  - 2021///
PY  - 2021
DO  - 10.1145/3448016.3452759
SP  - 2736
EP  - 2739
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108956175&doi=10.1145%2f3448016.3452759&partnerID=40&md5=6b4443cb7c2b75f993ac4f34685a543b
DB  - Scopus
KW  - Machine learning
KW  - Pipelines
KW  - Fully automated
KW  - Input datas
KW  - responsible data science
KW  - Data Science
KW  - Data distribution
KW  - Policy makers
KW  - Wide spreads
KW  - Science libraries
KW  - Computational tools
KW  - data distribution debugging
KW  - machine learning pipelines
KW  - Manual codes
KW  - technical bias
ER  - 

TY  - JOUR
TI  - scTenifoldNet: A Machine Learning Workflow for Constructing and Comparing Transcriptome-wide Gene Regulatory Networks from Single-Cell Data
AU  - Osorio, D.
AU  - Zhong, Y.
AU  - Li, G.
AU  - Huang, J.Z.
AU  - Cai, J.J.
T2  - Patterns
AB  - scTenifoldNet is a machine learning workflow built upon principal-component regression, low-rank tensor approximation, and manifold alignment. It uses single-cell RNA sequencing data to construct single-cell gene regulatory networks (scGRNs) and compares scGRNs of different samples to identify differentially regulated genes. Real-data applications demonstrate that scTenifoldNet accurately detects specific signatures of gene expression relevant to the cellular systems tested. © 2020 The Authors; We present scTenifoldNet—a machine learning workflow built upon principal-component regression, low-rank tensor approximation, and manifold alignment—for constructing and comparing single-cell gene regulatory networks (scGRNs) using data from single-cell RNA sequencing. scTenifoldNet reveals regulatory changes in gene expression between samples by comparing the constructed scGRNs. With real data, scTenifoldNet identifies specific gene expression programs associated with different biological processes, providing critical insights into the underlying mechanism of regulatory networks governing cellular transcriptional activities. © 2020 The Authors; Understanding the functions of genes requires the investigation of the structure of their regulatory networks of interactions. Single-cell RNA sequencing (scRNA-seq) brings new challenges and opportunities to the study of such networks. Here, we present a machine learning tool for constructing and comparing single-cell gene regulatory networks. Our algorithm, scTenifoldNet, can be used to identify differentially regulated genes between two scRNA-seq samples. It complements and enhances the commonly used differential expression analysis by revealing differences between samples in the regulatory relationships among genes, rather than the expression level. We anticipate that, by deciphering the complexity of data that surpasses human interpretative ability, scTenifoldNet can help achieve breakthroughs in understanding regulatory mechanisms underlying cell behaviors. © 2020 The Authors
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.patter.2020.100139
VL  - 1
IS  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096558897&doi=10.1016%2fj.patter.2020.100139&partnerID=40&md5=1574391a5222ce846e6f991aba056f54
DB  - Scopus
KW  - machine learning
KW  - tensor decomposition
KW  - manifold alignment
KW  - DSML 2: Proof-of-Concept: Data science output has been formulated, implemented, and tested for one domain/problem
KW  - gene regulatory network
KW  - scRNA-seq
KW  - single-cell RNA sequencing
KW  - principal-component regression
KW  - scTenifoldNet
ER  - 

TY  - CONF
TI  - Ensuring data privacy using machine learning for responsible data science
AU  - Jena, M.D.
AU  - Singhar, S.S.
AU  - Mohanta, B.K.
AU  - Ramasubbareddy, S.
T2  - Advances in Intelligent Systems and Computing
AB  - With the advancement use of computers extensively the use of data has also grown to big data level. Nowadays data is collected without any specific purpose, every activity of a machine or a human being is recorded, If needed in the future then the data will be analyzed. But here the question of trust arises as the data will go through many phases for the analysis by different parties. The data may contain some sensitive or private information which can be misutilized by the organizations involved in the analysis stages. So it is needed for the hour to consider the data privacy issues very seriously. Different types of methods have been proposed in this paper to ensure data privacy and also different machine learning algorithms have been discussed which have been used to design the proposed methods to ensure data privacy. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2021.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-981-15-5679-1_49
VL  - 1177
SP  - 507
EP  - 514
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091055970&doi=10.1007%2f978-981-15-5679-1_49&partnerID=40&md5=357fd77a37f58b2221cefcc01e49438d
DB  - Scopus
KW  - Machine learning
KW  - Privacy
KW  - AI
KW  - Data
KW  - Learning algorithms
KW  - Turing machines
KW  - Data privacy
KW  - Data Science
KW  - Cryptography
KW  - Private information
KW  - Intelligent computing
KW  - Data level
KW  - Human being
KW  - Privacy issue
KW  - Privacy issues
ER  - 

TY  - JOUR
TI  - Data Science in the Food Industry
AU  - Nychas, G.-J.
AU  - Sims, E.
AU  - Tsakanikas, P.
AU  - Mohareb, F.
T2  - Annual Review of Biomedical Data Science
AB  - Food safety is one of the main challenges of the agri-food industry that is expected to be addressed in the current environment of tremendous technological progress, where consumers' lifestyles and preferences are in a constant state of flux. Food chain transparency and trust are drivers for food integrity control and for improvements in efficiency and economic growth. Similarly, the circular economy has great potential to reduce wastage and improve the efficiency of operations in multi-stakeholder ecosystems. Throughout the food chain cycle, all food commodities are exposed to multiple hazards, resulting in a high likelihood of contamination. Such biological or chemical hazards may be naturally present at any stage of food production, whether accidentally introduced or fraudulently imposed, risking consumers' health and their faith in the food industry. Nowadays, a massive amount of data is generated, not only from the next generation of food safety monitoring systems and along the entire food chain (primary production included) but also from the Internet of things, media, and other devices. These data should be used for the benefit of society, and the scientific field of data science should be a vital player in helping to make this possible. © 2020 by Annual Reviews. All rights reserved.
DA  - 2021///
PY  - 2021
DO  - 10.1146/annurev-biodatasci-020221-123602
VL  - 4
SP  - 341
EP  - 367
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125419669&doi=10.1146%2fannurev-biodatasci-020221-123602&partnerID=40&md5=f23b24dce0daea54824569149af1ce97
DB  - Scopus
KW  - machine learning
KW  - big data
KW  - Technology
KW  - ecosystem
KW  - Ecosystem
KW  - Food Safety
KW  - technology
KW  - food safety
KW  - Data Science
KW  - food
KW  - Food
KW  - food microbiology
KW  - omics
ER  - 

TY  - JOUR
TI  - Flexible Auto-Weighted Local-Coordinate Concept Factorization: A Robust Framework for Unsupervised Clustering
AU  - Zhang, Z.
AU  - Zhang, Y.
AU  - Li, S.
AU  - Liu, G.
AU  - Zeng, D.
AU  - Yan, S.
AU  - Wang, M.
T2  - IEEE Transactions on Knowledge and Data Engineering
AB  - Concept Factorization (CF) and its variants may produce inaccurate representation and clustering results due to the sensitivity to noise, hard constraint on the reconstruction error, and pre-obtained approximate similarities. To improve the representation ability, a novel unsupervised Robust Flexible Auto-weighted Local-coordinate Concept Factorization (RFA-LCF) framework is proposed for clustering high-dimensional data. Specifically, RFA-LCF integrates the robust flexible CF by clean data space recovery, robust sparse local-coordinate coding, and adaptive weighting into a unified model. RFA-LCF improves the representations by enhancing the robustness of CF to noise and errors, providing a flexible constraint on the reconstruction error and optimizing the locality jointly. For robust learning, RFA-LCF clearly learns a sparse projection to recover the underlying clean data space, and then the flexible CF is performed in the projected feature space. RFA-LCF also uses a L2,1-norm based flexible residue to encode the mismatch between the recovered data and its reconstruction, and uses the robust sparse local-coordinate coding to represent data using a few nearby basis concepts. For auto-weighting, RFA-LCF jointly preserves the manifold structures in the basis concept space and new coordinate space in an adaptive manner by minimizing the reconstruction errors on clean data, anchor points and coordinates. By updating the local-coordinate preserving data, basis concepts and new coordinates alternately, the representation abilities can be potentially improved. Extensive results on public databases show that RFA-LCF delivers the state-of-the-art clustering results compared with other related methods. © 1989-2012 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/TKDE.2019.2940576
VL  - 33
IS  - 4
SP  - 1523
EP  - 1539
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072537226&doi=10.1109%2fTKDE.2019.2940576&partnerID=40&md5=6f8bb76448a882d5e1e55255c9e4cd9e
DB  - Scopus
KW  - Computer science
KW  - Learning systems
KW  - Recovery
KW  - Factorization
KW  - Data structures
KW  - Clustering algorithms
KW  - Error correction
KW  - Image reconstruction
KW  - Encoding (symbols)
KW  - Image coding
KW  - Theorem proving
KW  - High dimensional data
KW  - Laplace equation
KW  - auto-weighting learning
KW  - Automobile engine manifolds
KW  - high-dimensional data clustering
KW  - Local coordinate
KW  - Matrix decomposition
KW  - robust flexible concept factorization
KW  - robust sparse local coordinate coding
KW  - Unsupervised data
KW  - Unsupervised data representation
ER  - 

TY  - CONF
TI  - A Robust Training Signal Generator for Trainable Memristive Digital to Analog Converter
AU  - Shivdeep, S.
AU  - Vohra, S.K.
AU  - Goel, N.
AU  - Das, D.M.
T2  - Proceedings - 2021 IEEE International Symposium on Smart Electronic Systems, iSES 2021
AB  - There is a perpetual need of evolution in data converters to cater the demand of high speed and accurate data acquisition and processing. The trainable neural data converters can be trained using supervised learning techniques to produce precise data conversions. Such data converters are PVT immune and can be trained in real time using on-chip training signal generators. A trainable digital to analog converter needs accurate labeled analog signals as training signal. This paper proposes a CMOS-memristor hybrid training signal generator circuit and a memristive variable slope ramp generator circuit design. Proposed architecture is PVT immune and robust against mismatches and manufacturing imprecision in circuit component parameters. Proposed design is scalable to produce training signal for N-bit digital to analog converters. Proposed work is implemented and validated in standard CMOS 180nm technology node with SPICE model for the memristor. © 2021 IEEE.All rights reserved.
DA  - 2021///
PY  - 2021
DO  - 10.1109/iSES52644.2021.00014
SP  - 1
EP  - 5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126551461&doi=10.1109%2fiSES52644.2021.00014&partnerID=40&md5=aff2bc90bfc0c10fca2fc4c0f0813903
DB  - Scopus
KW  - Signal processing
KW  - Supervised learning
KW  - Data handling
KW  - Robust
KW  - Data acquisition
KW  - Reconfigurable
KW  - Memristor
KW  - Memristors
KW  - CMOS
KW  - CMOS integrated circuits
KW  - DAC
KW  - Data converter
KW  - Digital to analog conversion
KW  - Digital-to-analog converters
KW  - Generator circuits
KW  - Integrated circuit design
KW  - PVT immune
KW  - Ramp generator
KW  - Training signal
ER  - 

TY  - CONF
TI  - Finite-Sample Regret Bound for Distributionally Robust Offline Tabular Reinforcement Learning
AU  - Zhou, Z.
AU  - Zhou, Z.
AU  - Bai, Q.
AU  - Qiu, L.
AU  - Blanchet, J.
AU  - Glynn, P.
T2  - Proceedings of Machine Learning Research
AB  - While reinforcement learning has witnessed tremendous success recently in a wide range of domains, robustness-or the lack thereof-remains an important issue that has not been fully explored. In this paper, we provide a distributionally robust formulation of offline learning policy in tabular RL that aims to learn a policy from historical data (collected by some other behavior policy) that is robust to the future environment that can deviate from the training environment. We first develop a novel policy evaluation scheme that accurately estimates the robust value (i.e. how robust it is in a perturbed environment) of any given policy and establish its finite-sample estimation error. Building on this, we then develop a novel and minimax-optimal distributionally robust learning algorithm that achieves OP (1/√n) regret, meaning that with high probability, the policy learned from using n training data points will be O (1/√n) close to the optimal distributionally robust policy. Finally, our simulation results demonstrate the superiority of our distributionally robust approach compared to non-robust RL algorithms. Copyright © 2021 by the author(s)
DA  - 2021///
PY  - 2021
VL  - 130
SP  - 3331
EP  - 3339
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161803950&partnerID=40&md5=3e354696694d1c1ad523d0b1d83b1e75
DB  - Scopus
KW  - Reinforcement learning
KW  - Learning algorithms
KW  - Reinforcement learnings
KW  - Optimization
KW  - Learn+
KW  - Offline
KW  - Sampling
KW  - Historical data
KW  - Learning policy
KW  - Regret bounds
KW  - Finite samples
KW  - Robust formulations
KW  - Off-line learning
KW  - Behavior policy
ER  - 

TY  - JOUR
TI  - Over-the-Air Computation in Correlated Channels
AU  - Frey, M.
AU  - Bjelakovic, I.
AU  - Stanczak, S.
T2  - IEEE Transactions on Signal Processing
AB  - Over-the-Air (OTA) computation is the problem of computing functions of distributed data without transmitting the entirety of the data to a central point. By avoiding such costly transmissions, OTA computation schemes can achieve a better-than-linear (depending on the function, often logarithmic or even constant) scaling of the communication cost as the number of transmitters grows. In this work, we propose and analyze an analog OTA computation scheme for a class of functions that contains linear functions as well as some nonlinear functions such as $p$-norms of vectors. We prove error bounds that are valid for fast-fading channels and all distributions of fading and noise in the class of sub-Gaussian distributions. This class includes Gaussian distributions, but also many other practically relevant cases such as Class A Middleton noise and fading with dominant line-of-sight components. Moreover, there can be correlations in the fading and noise so that the presented results also apply to, for example, block fading channels and channels with bursty interference. There is no assumption that the distributed function arguments follow a particular probability law; in particular, they do not need to be independent or identically distributed. Our analysis is nonasymptotic and therefore provides error bounds that are valid for a finite number of channel uses. OTA computation has a huge potential for reducing communication cost in applications such as Machine Learning (ML)-based distributed anomaly detection in large wireless sensor networks. We illustrate this potential through extensive numerical simulations.  © 1991-2012 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/TSP.2021.3106115
VL  - 69
SP  - 5739
EP  - 5755
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113349814&doi=10.1109%2fTSP.2021.3106115&partnerID=40&md5=bada4827c677e569f32bd3259fc82703
DB  - Scopus
KW  - machine learning
KW  - robustness
KW  - Anomaly detection
KW  - Stochastic systems
KW  - Error analysis
KW  - Gaussian distribution
KW  - Gaussian noise (electronic)
KW  - Fading channels
KW  - Wireless sensor networks
KW  - Functions
KW  - wireless sensor networks
KW  - distributed computing
KW  - Trellis codes
KW  - Block fading channel
KW  - boosting
KW  - Calculations
KW  - Combined source-channel coding
KW  - Communication cost
KW  - Computing functions
KW  - Correlated channels
KW  - Distributed anomaly detection
KW  - fading channels
KW  - Fast fading channel
KW  - Line-of-sight components
KW  - Nonlinear functions
KW  - Power amplifiers
KW  - wireless communication
ER  - 

TY  - CONF
TI  - Multi-Modal Mutual Information (MuMMI) Training for Robust Self-Supervised Deep Reinforcement Learning
AU  - Chen, K.
AU  - Lee, Y.
AU  - Soh, H.
T2  - Proceedings - IEEE International Conference on Robotics and Automation
AB  - This work focuses on learning useful and robust deep world models using multiple, possibly unreliable, sensors. We find that current methods do not sufficiently encourage a shared representation between modalities; this can cause poor performance on downstream tasks and over-reliance on specific sensors. As a solution, we contribute a new multi-modal deep latent state-space model, trained using a mutual information lower-bound. The key innovation is a specially-designed density ratio estimator that encourages consistency between the latent codes of each modality. We tasked our method to learn policies (in a self-supervised manner) on multi-modal Natural MuJoCo benchmarks and a challenging Table Wiping task. Experiments show our method significantly outperforms state-of-the-art deep reinforcement learning methods, particularly in the presence of missing observations. © 2021 IEEE
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICRA48506.2021.9561187
VL  - 2021-May
SP  - 4274
EP  - 4280
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119129739&doi=10.1109%2fICRA48506.2021.9561187&partnerID=40&md5=22b8ddbec48150346ed766f970d0348e
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Computer vision
KW  - 'current
KW  - Multi-modal
KW  - State space methods
KW  - Down-stream
KW  - Mutual informations
KW  - Over reliance
KW  - Poor performance
KW  - Shared representations
KW  - Specific sensors
KW  - World model
ER  - 

TY  - JOUR
TI  - Robust fuzzy rough set based dimensionality reduction for big multimedia data hashing and unsupervised generative learning
AU  - Khanzadi, P.
AU  - Majidi, B.
AU  - Adabi, S.
AU  - Patra, J.C.
AU  - Movaghar, A.
T2  - Multimedia Tools and Applications
AB  - The amount of high dimensional data produced by visual sensors in the smart environments and by autonomous vehicles is increasing exponentially. In order to search and model this data for real-time applications, the dimensionality of the data should be reduced. In this paper, a novel dimensionality reduction algorithm based on fuzzy rough set theory, called Centralized Binary Mapping (CBM), is proposed. The fuzzy CBM kernel is used for extracting the central elements and the memory cells from the blocks of high dimensional data. The proposed applications of CBM in this paper include hashing and generative modelling of multimedia big data. The robustness of the proposed CBM based hashing algorithm is 10% higher than comparable methods. Furthermore, based on the CBM, a novel architecture for neural networks called Deep Root Dimensional Mapping (DRDM) is proposed. The DRDM is used for generative modelling of multimedia big data using a new autonomous vehicle visual navigation dataset as well as the standard datasets. The simulation results show that the proposed DRDM converges rapidly and the perceptual quality of the outputs at the same epoch is higher than generative adversarial networks. The proposed CBM can be used as a new data structures in various pattern recognition and machine learning tasks. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.
DA  - 2021///
PY  - 2021
DO  - 10.1007/s11042-021-10571-2
VL  - 80
IS  - 12
SP  - 17745
EP  - 17772
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100984064&doi=10.1007%2fs11042-021-10571-2&partnerID=40&md5=d2d8deb8864a042559398008d4c14d78
DB  - Scopus
KW  - Autonomous vehicles
KW  - Pattern recognition
KW  - Neural networks
KW  - Mapping
KW  - Clustering algorithms
KW  - Dimensionality reduction
KW  - Data reduction
KW  - Real-time application
KW  - Large dataset
KW  - Rough set theory
KW  - Adversarial networks
KW  - High dimensional data
KW  - Dimensionality reduction algorithms
KW  - Fuzzy rough set
KW  - Fuzzy rough set theory
KW  - Generative learning
KW  - Hashing algorithms
KW  - Image hashing
KW  - Multimedia big data
KW  - Novel architecture
KW  - Perceptual quality
ER  - 

TY  - JOUR
TI  - Robustness analysis of machine learning classifiers in predicting spatial gully erosion susceptibility with altered training samples
AU  - Hembram, T.K.
AU  - Saha, S.
AU  - Pradhan, B.
AU  - Abdul Maulud, K.N.
AU  - Alamri, A.M.
T2  - Geomatics, Natural Hazards and Risk
AB  - The present research intended to assess the robustness of three popular machine learning models, i.e. random forest (RF), boosted regression tree (BRT) and naïve bayes (NB) in spatial gully erosion susceptibility modelling in Jainti River basin, India. A gully inventory map of 208 gullies was prepared through field survey and Google earth imageries. Following the 70/30 ratio, three randomly sampled groups of altered training and validation gully sets G1, G2 and G3 were prepared for modelling gully erosion susceptibility. Using information gain ratio and multi-collinearity analysis, 14 gully conditioning factors (GCF) were selected. The discrimination ability and reliability of the models were measured through Kappa coefficient, efficiency, receiver operating characteristic curve, root-mean-square-error (RMSE) and mean-absolute-error (MAE). The stability of the machine learning models was estimated by comparing the accuracy statistics and the departure in areal outcomes among intra-model and inter-model. RF model was found as the most consistent. With the highest mean AUC (0.903), efficiency (91.17), Kappa coefficient (0.835) and lowest RMSE (0.192) and MAE (0.081), RF was found to be more consistent when the training and validation data sets were altered. The effectiveness of each input GCFs was determined using map removal sensitivity analysis technique. This study could be supportive in ascertaining model deployment for mapping gully erosion and managing the land resource. © 2021 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.
DA  - 2021///
PY  - 2021
DO  - 10.1080/19475705.2021.1890644
VL  - 12
IS  - 1
SP  - 794
EP  - 828
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102391117&doi=10.1080%2f19475705.2021.1890644&partnerID=40&md5=5c20bda50f5f40045abed71a4617dbf9
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Machine learning models
KW  - Efficiency
KW  - Landforms
KW  - Mean square error
KW  - Root mean square errors
KW  - Sensitivity analysis
KW  - India
KW  - GIS
KW  - Receiver operating characteristic curves
KW  - Erosion
KW  - altered gully samples
KW  - Boosted regression trees
KW  - Discrimination ability
KW  - gully erosion
KW  - Information gain ratio
KW  - Mean absolute error
KW  - Sensitivity analysis techniques
ER  - 

TY  - JOUR
TI  - Incorporating unlabeled data into distributionally-robust learning
AU  - Frogner, C.
AU  - Claici, S.
AU  - Chien, E.
AU  - Solomon, J.
T2  - Journal of Machine Learning Research
AB  - We study a robust alternative to empirical risk minimization called distributionally robust learning (DRL), in which one learns to perform against an adversary who can choose the data distribution from a specified set of distributions. We illustrate a problem with current DRL formulations, which rely on an overly broad definition of allowed distributions for the adversary, leading to learned classifiers that are unable to predict with any confidence. We propose a solution that incorporates unlabeled data into the DRL problem to further constrain the adversary. We show that this new formulation is tractable for stochastic gradient-based optimization and yields a computable guarantee on the future performance of the learned classifier, analogous to—but tighter than—guarantees from conventional DRL. We examine the performance of this new formulation on 14 real data sets and find that it often yields effective classifiers with nontrivial performance guarantees in situations where conventional DRL produces neither. Inspired by these results, we extend our DRL formulation to active learning with a novel, distributionally-robust version of the standard model-change heuristic. Our active learning algorithm often achieves superior learning performance to the original heuristic on real data sets. © 2021 Charlie Frogner, Sebastian Claici, Edward Chien, and Justin Solomon.
DA  - 2021///
PY  - 2021
VL  - 22
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105884069&partnerID=40&md5=773afc99be2a46cfaa693f8889a687eb
DB  - Scopus
KW  - Learning systems
KW  - Supervised learning
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Stochastic systems
KW  - Distributionally robust optimization
KW  - Learning performance
KW  - Wasserstein distance
KW  - Active learning
KW  - Data distribution
KW  - Performance guarantees
KW  - The standard model
KW  - Empirical risk minimization
KW  - Active-learning algorithm
KW  - Future performance
KW  - Optimal transport
KW  - Stochastic gradient
ER  - 

TY  - JOUR
TI  - Robust weighted Gaussian processes
AU  - Ramirez-Padron, R.
AU  - Mederos, B.
AU  - Gonzalez, A.J.
T2  - Computational Statistics
AB  - This paper presents robust weighted variants of batch and online standard Gaussian processes (GPs) to effectively reduce the negative impact of outliers in the corresponding GP models. This is done by introducing robust data weighers that rely on robust and quasi-robust weight functions that come from robust M-estimators. Our robust GPs are compared to various GP models on four datasets. It is shown that our batch and online robust weighted GPs are indeed robust to outliers, significantly outperforming the corresponding standard GPs and the recently proposed heteroscedastic GP method GPz. Our experiments also show that our methods are comparable to and sometimes better than a state-of-the-art robust GP that uses a Student-t likelihood. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.
DA  - 2021///
PY  - 2021
DO  - 10.1007/s00180-020-01011-0
VL  - 36
IS  - 1
SP  - 347
EP  - 373
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087661618&doi=10.1007%2fs00180-020-01011-0&partnerID=40&md5=3825bbaaabcd6c0ed09caeca5ecb0a79
DB  - Scopus
KW  - Machine learning
KW  - Online learning
KW  - Outlying data
KW  - Robust regression
ER  - 

TY  - JOUR
TI  - Robust CSEM data processing by unsupervised machine learning
AU  - Li, G.
AU  - He, Z.
AU  - Deng, J.
AU  - Tang, J.
AU  - Fu, Y.
AU  - Liu, X.
AU  - Shen, C.
T2  - Journal of Applied Geophysics
AB  - The ambient noise in controlled-source electromagnetic (CSEM) data seriously affects the accuracy and reliability of the exploration result. Traditional correlation-based data selection method requires manually setting the threshold. To overcome the deficiency, we analyze the typical noises in CSEM data and find that normalized cross-correlation (NCC), absolute maximum value of the amplitude (Max), and detrend fluctuation analysis (DFA) can be used to accurately identify high-quality time series. Based on this discovery, we replace traditional manually intervention with unsupervised machine learning and propose a novel CSEM data processing method. We applied the newly proposed method to synthetic and measured CSEM data to verify the feasibility and effectiveness. Experimental results demonstrate that the newly proposed method is superior to the conventional data selection method because it accurately selects the best data fragments from noisy data automatically. The newly proposed method requires no human intervention which makes the results obtained free of subjective distortion caused by the operator. © 2021 Elsevier B.V.
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.jappgeo.2021.104262
VL  - 186
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100390373&doi=10.1016%2fj.jappgeo.2021.104262&partnerID=40&md5=2e8e7454b377310f477559e2fa6715fb
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Time series analysis
KW  - Machine Learning
KW  - algorithm
KW  - Quality control
KW  - data processing
KW  - Data reduction
KW  - Human intervention
KW  - Unsupervised machine learning
KW  - signal-to-noise ratio
KW  - Data Selection
KW  - ambient noise
KW  - Controlled source electromagnetic (CSEM)
KW  - correlation
KW  - Correlation Analysis
KW  - CSEM data processing
KW  - Data fragments
KW  - Data processing methods
KW  - Fluctuation analysis
KW  - Fuzzy C-means clustering (FCM)
KW  - logging (geophysics)
KW  - Normalized cross correlation
KW  - Periodic signal de-noising
KW  - Signal-noise identification
ER  - 

TY  - CONF
TI  - Machine Learning Based on the Principle of Minimizing Robust Mean Estimates
AU  - Shibzukhov, Z.M.
T2  - Advances in Intelligent Systems and Computing
AB  - The classical approach in machine learning, based on the principle of minimizing the arithmetic mean of parameterized functions, is vulnerable if training is carried out on the basis of data containing outliers. The article considers the approach to the construction of robust methods and machine learning algorithms, which are based on the principle of minimizing estimates of average values that are insensitive to outliers. Proposed machine learning algorithms are based on the principle of iterative reweighting. Illustrative examples show the ability of the proposed approach and algorithms to overcome the effect of outliers. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-65596-9_56
VL  - 1310
SP  - 472
EP  - 477
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098150904&doi=10.1007%2f978-3-030-65596-9_56&partnerID=40&md5=0c69d3449719d57f1181924d13558b93
DB  - Scopus
KW  - Machine learning
KW  - Data analysis
KW  - Pattern recognition
KW  - Learning algorithms
KW  - Statistics
KW  - Iterative methods
KW  - Brain
KW  - Robust methods
KW  - Parameterized
KW  - Classical approach
KW  - Arithmetic mean
KW  - Average values
KW  - Iterative reweighting
KW  - Iteratively reweigting
KW  - Robust estimate
ER  - 

TY  - CONF
TI  - Machine Learning Based on Minimizing Robust Mean Estimates
AU  - Shibzukhov, Z.M.
AU  - Semenov, T.A.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - The article considers the approach to the construction of robust methods and machine learning algorithms, which are based on the principle of minimizing estimates of average values that are insensitive to outliers. Proposed machine learning algorithms are based on the principle of iterative reweighting. Illustrative examples show the ability of the proposed approach and algorithms to overcome the influense of outliers. © 2021, Springer Nature Switzerland AG.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-68821-9_11
VL  - 12665 LNCS
SP  - 112
EP  - 119
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104286067&doi=10.1007%2f978-3-030-68821-9_11&partnerID=40&md5=e1cf44b4e8dec08105d27f92b702aadc
DB  - Scopus
KW  - Machine learning
KW  - Data analysis
KW  - Pattern recognition
KW  - Learning algorithms
KW  - Statistics
KW  - Iterative methods
KW  - Robust methods
KW  - Image analysis
KW  - Average values
KW  - Iterative reweighting
KW  - Robust estimate
ER  - 

TY  - CONF
TI  - Robust Offline Deep Reinforcement Learning for Volt-Var Control in Active Distribution Networks
AU  - Liu, Q.
AU  - Guo, Y.
AU  - Deng, L.
AU  - Tang, W.
AU  - Sun, H.
AU  - Huang, W.
T2  - 5th IEEE Conference on Energy Internet and Energy System Integration: Energy Internet for Carbon Neutrality, EI2 2021
AB  - Deep reinforcement learning (DRL) is a promising data-driven method to deal with Volt-Var control (VVC) problems. However, training a DRL agent on a real ADN requires that voltage constraints never be violated. Meanwhile, training the DRL agent on a simulation environment cannot guarantee normal operations when applied to a real ADN because of the modeling errors in simulation. This paper proposes a robust offline DRL framework, where the DRL agent is trained through the historical operation data and ensures voltage operates within the normal range in the real environment. The framework consists of two steps: First, we propose a probabilistic ensemble deep neural network (PEDNN) to learn the power flow model and capture aleatoric and epistemic uncertainties of voltage; Second, a robust DRL agent is trained by interacting with the PEDNN using a deterministic mechanism. The mechanism transforms the probabilistic distribution of voltage to a deterministic voltage interval according to the 3-sigma rule. The objectives of the DRL agent are to minimize power loss and eliminate voltage violations. Numerical simulations on an IEEE 33-bus network demonstrate the effectiveness of our proposed method in avoiding voltage violation and minimizing power loss. © 2021 IEEE
DA  - 2021///
PY  - 2021
DO  - 10.1109/EI252483.2021.9712941
SP  - 442
EP  - 448
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128179925&doi=10.1109%2fEI252483.2021.9712941&partnerID=40&md5=151e50c6506b3b91b89920be44a3f737
DB  - Scopus
KW  - Reinforcement learning
KW  - Deep neural networks
KW  - Reinforcement learning agent
KW  - Uncertainty analysis
KW  - Electric load flow
KW  - Offline
KW  - Numerical methods
KW  - Probability distributions
KW  - Value engineering
KW  - VAR control
KW  - Volt-VAR control
KW  - offline deep reinforcement learning
KW  - Offline deep reinforcement learning
KW  - Active distribution network
KW  - Active distributions
KW  - Robust deep reinforcement learning
KW  - active distribution network
KW  - Probabilistic ensemble
KW  - robust deep reinforcement learning
KW  - Volt/var control
ER  - 

TY  - CONF
TI  - Improving loss prevention in high hazard industries through the evaluation of safety culture and error traps from structured and unstructured data using machine learning
AU  - Noë, N.
AU  - Tuzovic, E.
AU  - McArthur, F.S.
AU  - Carroll, A.T.
T2  - Institution of Chemical Engineers Symposium Series
AB  - Unplanned outages are the bane of operational life. They need immediate attention and often require production to shut down primarily for safety reasons, leading to significant loss of economic activity. Operations data and academic research show that about 56% of events are due to latent system weaknesses that "hide in plain view" and thus are notoriously difficult to spot in advance of an incident. Latent system weaknesses create the preconditions for errors and reduce the ability of an operator to mitigate the consequences. They lie dormant until uncovered, typically during incident investigations, and are often referred to as performance influencing factors or "error traps". An error trap is a situation where the circumstances in combination with human cognitive limitations make errors more likely. To understand error traps, we need to identify their presence, strength, and potential impact. To achieve this insight, we look for distinct markers for each error trap in a company's structured and unstructured datasets. The benefit of this approach is that it enables a high proportion of the overall datasets to be analysed. It allows us to describe the prevailing safety culture and extract, classify, and index the data into suitable data visualisation outputs, providing users with actionable insight. This analysis advances the current approach of identifying, assessing, and reporting error traps by using a wider pool of data and improving the visualisation of any findings. We believe this approach will help establish a more holistic view of safety culture applicable across a wide array of high hazard sectors. Suppose we can reduce unplanned outages resulting from error traps. In that case, there will be a beneficial impact on loss prevention by helping to reduce major accidents and unplanned outages. This, in turn, will help improve production and directly benefit bottom-line performance, safety, and reputational and societal risks. This paper reports on research in collaboration with Centrica Storage Ltd. © 2021 Institution of Chemical Engineers. All rights reserved.
DA  - 2021///
PY  - 2021
VL  - 2021-November
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120578819&partnerID=40&md5=a848b521b0172edf4070be19fcea7556
DB  - Scopus
KW  - Machine learning
KW  - Visualization
KW  - Natural language processing
KW  - Learning algorithms
KW  - Accident prevention
KW  - Economics
KW  - Data visualization
KW  - Natural language processing systems
KW  - Errors
KW  - Natural Language Processing
KW  - Hazards
KW  - Safety culture
KW  - Language processing
KW  - Natural languages
KW  - Organizational factors
KW  - Error trap
KW  - Hazard industries
KW  - Human & Organisational factors
KW  - Human & organizational factor
KW  - Unplanned outages
KW  - User testing
KW  - User Testing
ER  - 

TY  - CHAP
TI  - Sensors and Data Driven Approaches in Transport
AU  - Sadrani, M.
AU  - Antoniou, C.
T2  - International Encyclopedia of Transportation: Volume 1-7
AB  - Sensors play an important role in collecting real-time information for transportation systems. Nowadays, several different sensor technologies, ranging from traditional ones to mobile sensors in smartphones, are being used to collect a massive data volume on the real-time location and dynamics of users. For example, most of the modern smartphones are equipped with multiple motion sensors, such as accelerometer and magnetometer sensors, which can provide an unprecedented opportunity for the monitoring of the motion status of mobile phone users. On the other hand, there are a wide variety of data mining and prediction techniques, which can support transportation researchers in analyzing raw travel data collected from sensor technologies. This article provides a review of various applications of sensor technologies in transport networks, including travel time estimation, origin–destination matrices estimation, safety analysis, driver behavior monitoring, and transportation mode inference. © 2021 Elsevier Ltd. All rights reserved
DA  - 2021///
PY  - 2021
VL  - 6
SP  - 426
EP  - 431
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151197326&doi=10.1016%2fB978-0-08-102671-7.10790-0&partnerID=40&md5=dacb040fa219e2b4f617492ef38a3960
DB  - Scopus
KW  - Machine learning methods
KW  - Traffic data
KW  - Sensors
KW  - Safety analysis
KW  - Driver behavior monitoring
KW  - Origin–destination matrices estimation
KW  - Sensor fusion approaches
KW  - Smartphone-based sensors
KW  - Traffic network surveillance
KW  - Transportation mode inference
KW  - Travel time estimation
ER  - 

TY  - CONF
TI  - Robust Reinforcement Learning: A Constrained Game-theoretic Approach
AU  - Yu, J.
AU  - Gehring, C.
AU  - Schäfer, F.
AU  - Anandkumar, A.
T2  - Proceedings of Machine Learning Research
AB  - Reinforcement learning (RL) methods provide state-of-art performance in complex control tasks. However, it has been widely recognized that RL methods often fail to generalize due to unaccounted uncertainties. In this work, we propose a game theoretic framework for robust reinforcement learning that comprises many previous works as special cases. We formulate robust RL as a constrained minimax game between the RL agent and an environmental agent which represents uncertainties such as model parameter variations and adversarial disturbances. To solve the competitive optimization problems arising in our framework, we propose to use competitive mirror descent (CMD). This method accounts for the interactive nature of the game at each iteration while using Bregman divergences to adapt to the global structure of the constraint set. leveraging Lagrangian duality, we demonstrate an RRL policy gradient algorithm based on CMD. We empirically show that our algorithm is stable for large step sizes, resulting in faster convergence on constrained linear quadratic games. © 2021 J. Yu, C. Gehring, F. Schäfer & A. Anandkumar.
DA  - 2021///
PY  - 2021
VL  - 144
SP  - 1242
EP  - 1254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129673722&partnerID=40&md5=924f503e07b0d4790f2ca10f68012f4f
DB  - Scopus
KW  - Game theory
KW  - Reinforcement learning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Uncertainty
KW  - Optimisations
KW  - Iterative methods
KW  - robust reinforcement learning
KW  - Constrained optimization
KW  - Robust reinforcement learning
KW  - Reinforcement learning method
KW  - adversarial training
KW  - Policy gradient
KW  - Adversarial training
KW  - policy gradient
KW  - Zero-sum game
KW  - zero-sum game
KW  - Game-theoretic
KW  - competitive optimization
KW  - Competitive optimization
ER  - 

TY  - JOUR
TI  - Learning to Herd Agents Amongst Obstacles: Training Robust Shepherding Behaviors Using Deep Reinforcement Learning
AU  - Zhi, J.
AU  - Lien, J.-M.
T2  - IEEE Robotics and Automation Letters
AB  - Robotic shepherding problem considers the control and navigation of a group of coherent agents (e.g., a flock of bird or a fleet of drones) through the motion of an external robot, called shepherd. Machine learning based methods have successfully solved this problem in an environment with no obstacles. Rule-based methods, on the other hand, can handle more complex scenarios in which environments are cluttered with obstacles and allow multiple shepherds to work collaboratively. However, these rule-based methods are fragile due to the difficulty in defining a comprehensive set of behavioral rules. To overcome these limitations, we propose the first known learning-based method that can herd agents amongst obstacles. By using deep reinforcement learning techniques combined with the probabilistic roadmaps, we train a shepherding model using noisy but controlled environmental and behavioral parameters. Our experimental results show that the trained shepherding controller is robust, namely, it is insensitive to the uncertainties originated from either the group behavioral models or from environments with a small of path homotopy classes. Consequently, the proposed method has a higher success rate, shorter completion time and path length than the rule-based behavioral methods have. These advantages are particularly prominent in more challenging scenarios involving more difficult groups and strenuous passages.  © 2016 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/LRA.2021.3068955
VL  - 6
IS  - 2
SP  - 4163
EP  - 4168
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103291079&doi=10.1109%2fLRA.2021.3068955&partnerID=40&md5=47d6e83b1ce9f66a5e61289f4d12f51d
DB  - Scopus
KW  - Deep learning
KW  - Reinforcement learning
KW  - Robots
KW  - reinforcement learning
KW  - Learning systems
KW  - Learning-based methods
KW  - Rule-based method
KW  - Reinforcement learning techniques
KW  - Agricultural robots
KW  - Behavioral model
KW  - task and motion planning
KW  - Behavioral parameters
KW  - Behavioral rules
KW  - Motion and path planning
KW  - Probabilistic road maps
KW  - Shepherding behaviors
ER  - 

TY  - JOUR
TI  - Robust Electricity Theft Detection against Data Poisoning Attacks in Smart Grids
AU  - Takiddin, A.
AU  - Ismail, M.
AU  - Zafar, U.
AU  - Serpedin, E.
T2  - IEEE Transactions on Smart Grid
AB  - Data-driven electricity theft detectors rely on customers' reported energy consumption readings to detect malicious behavior. One common implicit assumption in such detectors is the correct labeling of the training data. Unfortunately, these detectors are vulnerable against data poisoning attacks that assume false labels during training. This article addresses three major problems: What is the impact of data poisoning attacks on the detector's performance? Which detector is more robust against data poisoning attacks, i.e., generalized or customer-specific detectors? How to improve the detector's robustness against data poisoning attacks? Our investigations reveal that: (a) Shallow and deep learning-based detectors suffer from data poisoning attacks that may lead to a significant deterioration of detection rate of up to 17%. Furthermore, deep detectors offer 12% performance improvement over shallow detectors. (b) Generalized detectors present 4% performance improvement over customer-specific detectors even in the presence of data poisoning attacks. To enhance the detectors' robustness against data poisoning attacks, we propose a sequential ensemble detector based on a deep auto-encoder with attention (AEA), gated recurrent units (GRUs), and feed forward neural networks. The proposed robust detector retains a stable detection performance that is deteriorated only by 1 - 3% in the presence of strong data poisoning attacks. © 2010-2012 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/TSG.2020.3047864
VL  - 12
IS  - 3
SP  - 2675
EP  - 2684
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099111306&doi=10.1109%2fTSG.2020.3047864&partnerID=40&md5=879720f3b53eb275e95ee752b64bfe49
DB  - Scopus
KW  - machine learning
KW  - Chemical detection
KW  - Electric power transmission networks
KW  - Smart power grids
KW  - Crime
KW  - Energy utilization
KW  - Recurrent neural networks
KW  - Feedforward neural networks
KW  - Deterioration
KW  - Electricity theft
KW  - Poisoning attacks
KW  - Detection rates
KW  - Sales
KW  - Electricity theft detection
KW  - Detection performance
KW  - data poisoning
KW  - data-driven detection
KW  - Generalized detector
KW  - Malicious behavior
KW  - robust detector
KW  - Significant deteriorations
ER  - 

TY  - CONF
TI  - Analysis of Smart Grid Stability and Security Management Based on Data Mining
AU  - Zhang, C.
AU  - Yuan, Z.
AU  - Yan, P.
T2  - IOP Conference Series: Earth and Environmental Science
AB  - In the process of the operation and construction of the smart grid, the development of science and technology and the improvement of social productive forces have put forward higher requirements for the development of the power system. In this process, the scale and form of the power system have also changed to a certain extent, and power security has also become the most concerned issue. In the information society, through the application of the Internet of things and big data technology in power security management and control. It can simplify the operation process of the staff and reduce the occurrence of accidents. Distributed smart grid is a new technology proposed for power networks with elastic nodes, which can realize dynamic electricity price demand response without large-scale transformation of infrastructure. In order to analyze the system stability of DSG, six representative machine learning classification models are applied to analyze the stability data of 10000 samples of 4-node system. Combined with the requirements of power system security, stability and economy, the effect of each classification model on the prediction of DSG system stability is tested. © Published under licence by IOP Publishing Ltd.
DA  - 2021///
PY  - 2021
DO  - 10.1088/1755-1315/651/2/022049
VL  - 651
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101699628&doi=10.1088%2f1755-1315%2f651%2f2%2f022049&partnerID=40&md5=5280e4d239412cc243093561fafa6120
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Planning
KW  - Classification models
KW  - Economic and social effects
KW  - Electric power transmission networks
KW  - Smart grid
KW  - Smart power grids
KW  - Sustainable development
KW  - System stability
KW  - Electricity prices
KW  - Machine learning classification
KW  - Industrial management
KW  - Security management
KW  - Big data technology
KW  - Development of science and technologies
KW  - Electric power safety
KW  - Grid stability
KW  - Information society
KW  - Power system security
KW  - Scale transformation
ER  - 

TY  - CONF
TI  - Implementation of big data and machine learning in smart grid with correlated safety considerations: Review
AU  - Solanki, S.D.
AU  - Solanki, A.D.
T2  - Proceedings - 2020 IEEE International Symposium on Sustainable Energy, Signal Processing and Cyber Security, iSSSC 2020
AB  - This report provides a systematic analysis of the implementation of massive information and machine learning in the electric energy grid, driven by the advent of the Smart Grid (SG), the succeeding energy generation infrastructure. Interconnection is established at the center of this modern grid network that the internet of things (IOT) offers. This connection and the frequent interaction needed in this framework also imposed a significant amount of information that requires methodology much preferable to traditional techniques for detailed evaluation and decision formation. The IOT-integrated SG framework can include cost-effective load prediction and information-gathering strategies. Large data processing and machine learning approaches are important to gain those advantages. Cybersecurity becomes a critical problem in SG's complex connected system; IOT machines and their information transform into big victims of threats. This document contains certain security breaches and their approaches. Essential expertise gathered across the literature review is aggregated in the subsequent parts to offer a simple description and the results of this comprehensive analysis are described to deliver a succinct perspective of this area of study and encouraging potential sectors of scholarly and technological development, with inherent restrictions along with feasible alternatives and their efficiency. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/iSSSC50941.2020.9358879
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102443149&doi=10.1109%2fiSSSC50941.2020.9358879&partnerID=40&md5=c84331ae1e8e4312b2187e467904618e
DB  - Scopus
KW  - Machine learning
KW  - Signal processing
KW  - Internet of things
KW  - Electric power transmission networks
KW  - Smart power grids
KW  - Security of data
KW  - Big data
KW  - Machine learning approaches
KW  - Cost effectiveness
KW  - Comprehensive analysis
KW  - Cyber security
KW  - IOT
KW  - Traditional techniques
KW  - Energy conservation
KW  - Amount of information
KW  - Technological development
KW  - Big data analysis
KW  - Feasible alternatives
KW  - Information transforms
KW  - Internet of thing (IOT)
KW  - Smart grid.
ER  - 

TY  - CONF
TI  - AlwaysSafe: Reinforcement learning without safety constraint violations during training
AU  - Simão, T.D.
AU  - Jansen, N.
AU  - Spaan, M.T.J.
T2  - Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS
AB  - Deploying reinforcement learning (RL) involves major concerns around safety. Engineering a reward signal that allows the agent to maximize its performance while remaining safe is not trivial. Safe RL studies how to mitigate such problems. For instance, we can decouple safety from reward using constrained Markov decision processes (CMDPs), where an independent signal models the safety aspects. In this setting, an RL agent can autonomously find tradeoffs between performance and safety. Unfortunately, most RL agents designed for CMDPs only guarantee safety after the learning phase, which might prevent their direct deployment. In this work, we investigate settings where a concise abstract model of the safety aspects is given, a reasonable assumption since a thorough understanding of safety-related matters is a prerequisite for deploying RL in typical applications. Factored CMDPs provide such compact models when a small subset of features describe the dynamics relevant for the safety constraints. We propose an RL algorithm that uses this abstract model to learn policies for CMDPs safely, that is without violating the constraints. During the training process, this algorithm can seamlessly switch from a conservative policy to a greedy policy without violating the safety constraints. We prove that this algorithm is safe under the given assumptions. Empirically, we show that even if safety and reward signals are contradictory, this algorithm always operates safely and, when they are aligned, this approach also improves the agent’s performance. © 2021 International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org). All rights reserved.
DA  - 2021///
PY  - 2021
VL  - 2
SP  - 1214
EP  - 1223
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103674313&partnerID=40&md5=359b14bfd08a91ba735c0f4b935475f4
DB  - Scopus
KW  - Reinforcement learning
KW  - Autonomous agents
KW  - Safety engineering
KW  - Markov processes
KW  - Multi agent systems
KW  - Constrained Markov decision process
KW  - Safe reinforcement learning
KW  - Safety constraint
KW  - Training process
KW  - Safety-Related
KW  - Abstract modeling
KW  - CMDP
KW  - Independent signals
KW  - Learning phase
KW  - Typical application
ER  - 

TY  - CONF
TI  - An Adversarial Training Method for Improving Model Robustness in Unsupervised Domain Adaptation
AU  - Nie, Z.
AU  - Lin, Y.
AU  - Yan, M.
AU  - Cao, Y.
AU  - Ning, S.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - The easily-perturbed nature of deep neural network makes it vulnerable to adversarial attacks, and such vulnerability has become a major threat to the security of machine learning. The transferability of adversarial samples further increases the threat. Adversarial training has made considerable progress in defending against adversarial samples. In transfer learning, unsupervised domain adaptation is an important research branch, however, due to the label of the target domain samples can’t be obtained, it is difficult to implement adversarial training. In this paper, we found that using source domain data for adversarial training and adding the generated adversarial perturbation to the target domain data could effectively enhance the robustness of the transferred model. Experimental results showed that our proposed method can not only ensure the model’s classification accuracy, but also greatly improve the model’s defense performance against adversarial attacks. In simple, our proposed method not only guarantees the transfer of knowledge, but also realizes the transfer of model robustness. It is the main contribution of this paper. © 2021, Springer Nature Switzerland AG.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-82153-1_1
VL  - 12817 LNAI
SP  - 3
EP  - 13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113779102&doi=10.1007%2f978-3-030-82153-1_1&partnerID=40&md5=cece8d66fb799aeb2aabc95146e3819c
DB  - Scopus
KW  - Deep learning
KW  - Deep neural networks
KW  - Transfer learning
KW  - Network security
KW  - Robustness
KW  - Classification accuracy
KW  - Adversarial attack
KW  - Model robustness
KW  - Training methods
KW  - Domain adaptation
KW  - Knowledge management
KW  - Adversarial training
KW  - Target domain
KW  - Transfer of knowledge
KW  - Unsupervised domain adaption
ER  - 

TY  - CHAP
TI  - Interval-Valued Data Learning for Robustness of Energy Recovery Systems
AU  - Ouaret, R.
AU  - Floquet, P.
AU  - Belaud, J.-P.
AU  - Negny, S.
T2  - Computer Aided Chemical Engineering
AB  - Modeling of energy recovery systems, Heat Exchanger Networks (HEN) as an example, are complex processes due to many parameters involved and the lack of knowledge on the impact of operational variables on the response. These variables are often affected by different types of uncertainty as to measurement errors, computation errors, or imprecision related to the underlying method. The uncertainty in the data may be treated by considering, rather than a single value for each variable, the interval of values in which it may fall, histograms, or other multi valued data: symbolic data. This work aims to use, when possible, the symbolic data analysis to adapt the classical mathematical HEN models. It deals with the study of continuous interval data through suitable Principal Component Analyses and Regression for two purposes: clustering exchanges (i) classification of exchangers to detect those impacted by uncertainty factors and (ii) evaluation of the relationship between the different process parameters (inlet temperature, heat transfer coefficient, etc.) on interval data. The new method has been tested on a real data set and the numerical results are reported. The symbolic approach provides a simple way to study a great number of scenarios. © 2021 Elsevier B.V.
DA  - 2021///
PY  - 2021
VL  - 50
SP  - 791
EP  - 797
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110295073&doi=10.1016%2fB978-0-323-88506-5.50124-8&partnerID=40&md5=0281d342b0276771daa27c4f91ce97c3
DB  - Scopus
KW  - Interval-valued data
KW  - Flexibility and Robustness
KW  - Heat Exchanger Networks (HEN)
KW  - Machine Learning for Symbolic Data
ER  - 

TY  - CONF
TI  - Analysis of Woman Safety Parameters in Smart and Non-Smart Cities
AU  - Kohli, P.
AU  - Singh, K.
T2  - 2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions), ICRITO 2021
AB  - Today's world is the era of Information and Communication Technology (ICT). Due to this the demands of people and industry is growing day by day. So quality of service in cities and urban area is greatly affected. Both Government and private organizations took initiatives to migrate traditional cities into Smart cities. Development of Smart cities is focused by parameters: Technology, Safety, Privacy, Education, Unemployment, Crime, Health, Social, Legal, Economic, Traffic and Sustainability. Smart cities are considered safer cities against non-smart cities. These cities utilizes 'enterprise' LTE (eLTE) technology, a private adaptation of the 4G/5G (LTE) networks, IoT technology, secure wireless broadband connectivity etc for their advancement. These Smart cities are providing best resources to the people but Women Safety, Crime and Violence is still a big challenge. Weather a city is smart or non-smart, the crime against women is never ended. However, in reality cases like rape, harassment, teasing, sexual assault, molestation, domestic violence etc. increases very rapidly. Many preventive laws and measures have been taken to stop these worst activities. Still the measures have not affected the growing rate of such crimes. India has entered into digital world, but still women are scared to employ safety measures that can help them in troubled situation. Many cities are now developed into Smart cities but safety of women safety is still a increasing concern. In this context, Government has developed various devices and applications but still there is a need to develop an efficient system using latest technology like Machine Learning, Data Science etc. The paper analysis various feature and dimensions of Women Safety and Smart city. © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICRITO51393.2021.9596437
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143997329&doi=10.1109%2fICRITO51393.2021.9596437&partnerID=40&md5=6eb411fa76af58d9080d19f56fba14b3
DB  - Scopus
KW  - Machine learning
KW  - Urban areas
KW  - Machine Learning
KW  - Internet of things
KW  - Smart city
KW  - Accident prevention
KW  - Machine-learning
KW  - Information and Communication Technologies
KW  - Crime
KW  - Quality of service
KW  - Engineering education
KW  - Woman safety
KW  - Data Science
KW  - Woman safety device
KW  - Women Safety Devices
KW  - Women Safety
KW  - Non-smart city
KW  - Non-Smart City
KW  - Quality-of-service
KW  - Safety parameters
KW  - Smart City
KW  - Violence
KW  - Women empowerment
KW  - Women Empowerment
ER  - 

TY  - JOUR
TI  - One modern culture of statistics. Comments on Statistical Modeling: The Two Cultures (Breiman, 2001b)
AU  - Bühlmann, P.
T2  - Observational Studies
AB  - We comment on Leo Breiman’s “Statistical Modeling: The Two Cultures” paper. We provide some thoughts on prediction from a broader perspective and argue that “aiming for one modern culture” is a highly embracing attempt for addressing key problems in data and information sciences. © 2021 Peter Bühlmann.
DA  - 2021///
PY  - 2021
DO  - 10.1353/obs.2021.0020
VL  - 7
IS  - 1
SP  - 33
EP  - 40
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169003536&doi=10.1353%2fobs.2021.0020&partnerID=40&md5=d27badcd2814c34ca154ace15d02b664
DB  - Scopus
KW  - Causality
KW  - Prediction
KW  - Generalization
KW  - Domain Adaptation
KW  - Distributional Robustness
KW  - Statistical Machine Learning
ER  - 

TY  - CONF
TI  - Towards a Novel Tiered Approach to Assess the Resilience Level in the Safety Domain
AU  - Stefana, E.
AU  - Strazzari, C.
AU  - Marciano, F.
AU  - Camevale, C.
T2  - Proceedings of the 31st European Safety and Reliability Conference, ESREL 2021
AB  - Resilience is the system ability to adjust its functioning prior to, during, or following changes and perturbations. Resilience Engineering represents a new paradigm to improve safety, focusing on how to create resilience in systems. The resilience measurement supports decision making processes, but it is not a trivial task. Therefore, the objectives of this paper are: (1) to critically analyze the literature about quantitative resilience assessments in the industrial safety domain, and (2) to propose a novel three-tier approach for measuring and assessing the resilience potential in any organization in the same domain. To achieve our objectives, we performed a narrative literature review about the existing approaches, frameworks, and methods quantifying and ranking resilience indicators, and/or estimating an overall resilience score. Multi-Criteria Decision Making and Bayesian Network approaches are frequently employed for such purposes. The results gathered through the narrative review represent a key source for developing a novel tiered approach. We propose an approach able to quantitatively assess the resilience potential in the industrial safety domain that consists of three tiers. A knowledge-driven tier assesses resilience by using the knowledge of decision makers through techniques involving judgements, a knowledge and data-driven tier incorporates methods considering both expert knowledge under uncertainty and objective data, while a data-driven tier includes models performing resilience assessments entirely based on data provided by devices and information systems in the organization. © ESREL 2021. Published by Research Publishing, Singapore.
DA  - 2021///
PY  - 2021
DO  - 10.3850/978-981-18-2016-8_266-cd
SP  - 2854
EP  - 2861
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135486006&doi=10.3850%2f978-981-18-2016-8_266-cd&partnerID=40&md5=fe11ab180d7244bb41fa9d27ecffa0fd
DB  - Scopus
KW  - Machine learning
KW  - Risk management
KW  - Decision making
KW  - Accident prevention
KW  - Machine-learning
KW  - Bayesian networks
KW  - Risk assessment
KW  - Safety factor
KW  - Occupational risks
KW  - Safety management
KW  - Data driven
KW  - Risks management
KW  - Process safety
KW  - Occupational safety
KW  - Data envelopment analysis
KW  - Analytic Hierarchy Process
KW  - Anticipation
KW  - Data Envelopment Analysis
KW  - Dynamic assessment
KW  - Human factor
KW  - Resilience quantification
KW  - Safety-II
ER  - 

TY  - CONF
TI  - Designing a Model to Handle Imbalance Data Classification Using SMOTE and Optimized Classifier
AU  - Nimankar, S.S.
AU  - Vora, D.
T2  - Advances in Intelligent Systems and Computing
AB  - Classification is a supervised learning process that is used to predict target class for an input variable. In an imbalanced dataset, the total count of examples of minority class is comparatively less than the total count of majority (negative) class. Various problems accompany during classification of imbalanced data. To eliminate this problem, there is a need to balance the dataset as well to achieve higher accuracy by optimizing the parameters of a classification model. The proposed system attempts to sample the imbalance dataset into a balanced dataset by using SLS (Safe-Level Synthetic Minority Oversampling Technique) and ADASYN (Adaptive Synthetic Sampling Approach) SMOTE techniques. On this balanced data, for classification, KNN (K-Nearest Neighbors) and SVM (Support Vector Machine) classifiers are used. The system proposes to improve the performance of the classifiers using metaheuristic Cuckoo Search optimization techniques for determining hyperparameters. © 2021, Springer Nature Singapore Pte Ltd.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-981-15-5616-6_23
VL  - 1174
SP  - 323
EP  - 334
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090095391&doi=10.1007%2f978-981-15-5616-6_23&partnerID=40&md5=f578f3418e1ca589cf9963b453810d75
DB  - Scopus
KW  - Machine learning
KW  - Support vector machines
KW  - Classification (of information)
KW  - Classification models
KW  - Optimization
KW  - Nearest neighbor search
KW  - Imbalanced dataset
KW  - Information management
KW  - Classification
KW  - Support vector machine
KW  - Imbalanced data
KW  - K-nearest neighbors
KW  - Hyperparameters
KW  - Cuckoo search optimization
KW  - SVM(support vector machine)
KW  - Synthetic minority over-sampling techniques
KW  - ADASYN SMOTE
KW  - Imbalance data
KW  - Imbalance datum
KW  - Safe-level SMOTE
ER  - 

TY  - CONF
TI  - A Robust Method for Emotion Recognition from Face Datasets using Machine Learning
AU  - Taneja, A.
AU  - Yadav, K.S.
AU  - Patra, S.
T2  - 2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions), ICRITO 2021
AB  - The fast advances in AI (ML) and data combination have made it conceivable to supply machines/PCs with the capacity of feeling getting, acknowledgment, and investigation. Feeling acknowledgment has pulled in progressively serious interest from specialists from assorted fields. Human feelings can be perceived from looks, discourse, conduct (motion/act), or physiological signs. Face identification has been around for a long time. Moving forward, human feeling shown by face and felt by the mind, caught in one or the other video, electric sign (EEG), or picture structure can be approximated. Human feeling identification is the need of great importance with the goal that cutting-edge counterfeit clever frameworks can copy and check responses from the face. This can be useful to settle on educated choices be it concerning distinguishing proof of expectation, advancement of offers, or security-related dangers. Perceiving feelings from pictures or video is an inconsequential errand for the natural eye, yet ends up being exceptionally trying for machines and requires many pictures preparing methods for highlight extraction. A few AI calculations are appropriate for this work. Any location or acknowledgment by AI requires preparing calculations and afterward testing them on a reasonable dataset. This paper a few AI calculations just as highlight extraction methods that would help us in the precise ID of the human feeling. In this paper, Machine learning, which is a subset of AI is drilled as a way to deal with outward appearance acknowledgment tasks. The research also includes work done on feature descriptors such as Histogram of Oriented Gradients. © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/ICRITO51393.2021.9596390
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123358829&doi=10.1109%2fICRITO51393.2021.9596390&partnerID=40&md5=a1581356680d053dfa368713156977e3
DB  - Scopus
KW  - Machine learning
KW  - Speech recognition
KW  - Machine Learning
KW  - Emotion recognition
KW  - Machine-learning
KW  - Extraction
KW  - MATLAB
KW  - Statistical tests
KW  - Graphic methods
KW  - Histogram of oriented gradients
KW  - Face recognition
KW  - Emotion Recognition
KW  - Robust methods
KW  - Cutting edges
KW  - Data combination
KW  - Electric signs
KW  - Extraction method
KW  - Face identification
KW  - Highlights extraction
KW  - Histogram of Oriented Gradients
KW  - Human feelings
ER  - 

TY  - CONF
TI  - Pairwise Learning for Imbalanced Data Classification
AU  - Liu, S.
AU  - Wu, Q.
T2  - Proceedings - 2021 International Conference on Computational Science and Computational Intelligence, CSCI 2021
AB  - Imbalanced data classification problems appear quite commonly in real-world applications and impose great challenges to traditional classification approaches which work well only on balanced data but usually perform poorly on the minority class when the data is imbalanced. Resampling preprocessing by oversampling the minority class or downsampling the majority class helps improve the performance but may suffer from overfitting or loss of information. In this paper we propose a novel method called pairwise robust support vector machine (PRSVM) to overcome the difficulty of imbalanced data classification. It adapts the non-convex robust support vector classification loss to the pairwise learning setting. In the training process, samples from the minority class and the majority class always appear as pairs. This automatically balances the impact of two classes. Simulations and real-world applications show that PRSVM is highly effective. © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/CSCI54926.2021.00102
SP  - 186
EP  - 189
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133901613&doi=10.1109%2fCSCI54926.2021.00102&partnerID=40&md5=8ac8771d406e214a3f00fd618a1417e0
DB  - Scopus
KW  - Support vector machines
KW  - Classification (of information)
KW  - Real-world
KW  - Support vectors machine
KW  - imbalanced data
KW  - Imbalanced data
KW  - Data classification
KW  - Classification approach
KW  - Data classification problems
KW  - pairwise learning
KW  - Pairwise learning
KW  - pairwise robust support vector machine
KW  - Pairwise robust support vector machine
KW  - Resampling
KW  - RSVC loss
KW  - Signal sampling
ER  - 

TY  - JOUR
TI  - Abnormal samples oversampling for anomaly detection based on uniform scale strategy and closed area
AU  - Shangguan, A.
AU  - Xie, G.
AU  - Mu, L.
AU  - Fei, R.
AU  - Hei, X.
T2  - IEEE Transactions on Knowledge and Data Engineering
AB  - The samples representing abnormal situation is usually very few in the dataset, which makes it difficult to learn the features of abnormal samples by machine-learning-based methods. To improve the accuracy of anomaly detection, the number of abnormal samples should be expanded to ensure the balance of the dataset. In this paper, a discrete synthetic minority oversampling technique (D-SMOTE) is proposed to generate new samples. A closed area is constructed using the three nearest abnormal samples in the dataset. The new samples are then uniformly interpolated in a closed area. By this means, the problem of the imbalance for the original dataset is handled, thus improving the data quality. Based on the expanded datasets, a two-dimensional convolutional neural network (2D CNN) is constructed to detect abnormal samples. In experiments, three cases and different machine learning methods are considered for comparison. Several indexes including accuracy, precision, confusion matrix, F1-score, and Recall have been used to evaluate the detection effectiveness. The results show that the abnormal samples can be detected accurately using oversampling data obtained from the proposed D-SMOTE method. IEEE
DA  - 2021///
PY  - 2021
DO  - 10.1109/TKDE.2021.3130595
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120551377&doi=10.1109%2fTKDE.2021.3130595&partnerID=40&md5=ae0215bb349ea897d98deb69ef638475
DB  - Scopus
KW  - Safety
KW  - Machine learning
KW  - Accidents
KW  - Neural networks
KW  - Convolutional neural networks
KW  - Interpolation
KW  - Learning systems
KW  - Anomaly detection
KW  - Convolution
KW  - Convolutional neural network
KW  - Learn+
KW  - Detectors
KW  - Over sampling
KW  - Anomaly Detection
KW  - Synthetic minority over-sampling techniques
KW  - Abnormal samples
KW  - Abnormal Samples
KW  - Oversampling
KW  - Unbalanced data
KW  - Unbalanced Data
KW  - Uniform scale
KW  - Uniform scale strategy
KW  - Uniform Scale Strategy
ER  - 

TY  - CONF
TI  - ROBUST REMOTE SENSING SCENE CLASSIFICATION BY ADVERSARIAL SELF-SUPERVISED LEARNING
AU  - Xu, Y.
AU  - Sun, H.
AU  - Chen, J.
AU  - Lei, L.
AU  - Kuang, G.
AU  - Ji, K.
T2  - International Geoscience and Remote Sensing Symposium (IGARSS)
AB  - Adversarial training is an effective method to enhance adversarial robustness for deep neural networks. However, it qequires large amounts of labeled data, which are often difficult to acquire. Recent research has shown that self-supervised learning can help to improve model performance and model uncertainty using unlabeled data. In this paper, we introduce a new adversarial self-supervised learning framework to learn a robust pretrained model for remote sensing scene classification. The proposed method exploits the advantage of dual network structure, and it requires neither labeled data for adversarial example generation nor negative samples for contrastive learning. Specifically, it consists of three major steps. Firstly, we train the online model and the target model to extract deep image features. Secondly, we generate two kinds of instance-wise adversarial examples. Finally, we iteratively learn a robust model by implicit comparing the difference between clean data and their perturbed counterpart. Preliminary experimental results on remote sensing scene classification dataset shows that our method can obtain higher robust accuracy. Our method can also be combined with other adversarial defense techniques to further promote model robustness. © 2021 IEEE
DA  - 2021///
PY  - 2021
DO  - 10.1109/IGARSS47720.2021.9553824
VL  - 2021-July
SP  - 4936
EP  - 4939
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119618307&doi=10.1109%2fIGARSS47720.2021.9553824&partnerID=40&md5=7cc607f0f35a9112a0ba48ffba9c50d2
DB  - Scopus
KW  - Deep learning
KW  - Self-supervised learning
KW  - Adversarial training
KW  - Adversarial robustness
ER  - 

TY  - JOUR
TI  - New York State's 100% renewable electricity transition planning under uncertainty using a data-driven multistage adaptive robust optimization approach with machine-learning
AU  - Zhao, N.
AU  - You, F.
T2  - Advances in Applied Energy
AB  - Power system decarbonization is critical for combating climate change, and handling systems uncertainties is essential for designing robust renewable transition pathways. In this study, a bottom-up data-driven multistage adaptive robust optimization (MARO) framework is proposed to address the power systems’ renewable transition under uncertainty. To illustrate the applicability of the proposed framework, a case study for New York State is presented. Machine learning techniques, including a variational algorithm for Dirichlet process mixture model, principal component analysis, and kernel density estimation, are applied for constructing data-driven uncertainty sets, which are integrated into the proposed MARO framework to systematically handle uncertainty. The results show that the total renewable electricity transition costs under uncertainty are 21%-42% higher than deterministic planning, and the costs under the data-driven uncertainty sets are 2%-17% lower than the conventional uncertainty sets. By 2035, on-land wind and offshore wind would be the major power source for the deterministic planning case and robust optimization cases, respectively. © 2021
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.adapen.2021.100019
VL  - 2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107544887&doi=10.1016%2fj.adapen.2021.100019&partnerID=40&md5=d5be6b856e2a5a116bcfe2a3a2191e88
DB  - Scopus
KW  - Big data
KW  - Optimization under uncertainty
KW  - Decarbonization
KW  - Multistage adaptive robust optimization
KW  - Renewable electricity transition
ER  - 

TY  - JOUR
TI  - Bayesian robust multi-extreme learning machine
AU  - Li, Y.
AU  - Wang, Y.
AU  - Chen, Z.
AU  - Zou, R.
T2  - Knowledge-Based Systems
AB  - Outliers usually exist in the collected data due to human or instrumentation errors. Their existence makes the regression error obey a non-Gaussian distribution. So, people assume that the regression error obeys finite mixture distributions, such as mixture of Gaussians and mixture of Student's t-distributions. This paper proposed two Bayesian robust regression models based on multiple extreme learning machines. First, the finite mixture error distributions are extended to their infinite counterparts according to the theory of stick-breaking construction, which can avoid selecting the optimal number of components in mixture models. Second, a multi-extreme learning machine, which combines many single extreme learning machines with different numbers of hidden nodes, is constructed, which can avoid the effects of different numbers of hidden nodes on the final regression performance. Besides, sparse Bayesian learning has also been derived to perform the sparse model weight and output weight inference automatically. The experimental results on artificial datasets and eight benchmark datasets show that the proposed two models outperform the other compared models under different rates of outliers. Also, they generate better multi-step ahead wind speed and traffic speed forecasts in real applications. © 2020 Elsevier B.V.
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.knosys.2020.106468
VL  - 210
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092367835&doi=10.1016%2fj.knosys.2020.106468&partnerID=40&md5=2ec59fb714cd1fc853238e3e820f652e
DB  - Scopus
KW  - Machine learning
KW  - Regression analysis
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - Statistics
KW  - Errors
KW  - Robust regression
KW  - Wind
KW  - Mixtures
KW  - Mixture of Gaussians
KW  - Student's t distribution
KW  - Artificial datasets
KW  - Finite mixture distribution
KW  - Infinite mixture of Gaussians
KW  - Infinite mixture of Student's t-distributions
KW  - Instrumentation error
KW  - Multi-extreme learning machine
KW  - Non-gaussian distribution
KW  - Sparse Bayesian learning
KW  - Sparse priors
KW  - Variational Bayesian
ER  - 

TY  - CONF
TI  - Open Source Robust Machine Learning Software for Medical Patient Data Analysis and Cloud Storage
AU  - Hossain, M.S.A.
AU  - Ashrafuzzaman, M.
T2  - IFMBE Proceedings
AB  - Big data and artificial intelligence-based researches in the health care arena have radically changed the sector with better preventive health care, early diagnosis of diseases, and advanced assistive technology along with numerous other areas. Health care facilities, academic research centers, and industries are collaborating in developed countries on such researches. Besides, developing and underdeveloped countries stay behind in this field of research due to infirm health and e-health infrastructure, insufficient technical manpower, low physicians to patient ratio, and other limitations. Our research focuses on developing an open-source and easy to use Machine Learning Software System that should uplift Big Data and data science researches focusing on health care in the developing and underdeveloped countries amid such obstacles. This pilot study is a part of that big project that helps to make sense about the working methodology and the expected outcomes by the end of the project. Apart from medical data analysis, it could serve as an efficient platform for storing patient data and we hope academicians, professionals, and physicians around the globe will be aided by such robust data analysis software, as it facilitates automated preprocessing of data, building and comparing different prediction models, cloud storage and data visualization techniques. This work visualizes most of the part of its concept to understand its facilities, although due to some restriction some techniques will be discussed only after completing this big project. © 2021, Springer Nature Switzerland AG.
DA  - 2021///
PY  - 2021
DO  - 10.1007/978-3-030-64610-3_104
VL  - 80
SP  - 932
EP  - 943
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097614420&doi=10.1007%2f978-3-030-64610-3_104&partnerID=40&md5=2e9049813c4c110500b24bfb01418542
DB  - Scopus
KW  - Machine learning
KW  - Diagnosis
KW  - Predictive analytics
KW  - Open source software
KW  - Data visualization
KW  - Big data
KW  - Developed countries
KW  - Health care
KW  - Digital storage
KW  - Hospital data processing
KW  - Open systems
KW  - Artificial intelligence in healthcare
KW  - Assistive technology
KW  - Biochemical engineering
KW  - E-health infrastructures
KW  - Health care informatics
KW  - Healthcare facility
KW  - Machine learning software
KW  - Medical data analysis
KW  - Open Data
KW  - Pre-processing of data
KW  - Visualization technique
ER  - 

TY  - JOUR
TI  - Design of personal mobility safety system using AI
AU  - Park, H.J.
AU  - Choi, K.-H.
AU  - Yu, J.-W.
T2  - International Journal on Informatics Visualization
AB  - In this paper, we propose the implementation of a safety device that generates an alarm sound or braking operation to reduce the risk of accidents. It reduces the exposure of risks due to non-wearing by supplementing the function of the helmet for safety. For machine learning, the safety state is learned by using two types of sensing data, and when an abnormal helmet use or speed or drinking driving is detected, an alarm sound is generated and motion is broken to maintain the safe state. By measuring data using a gas sensor, alcohol is checked and this is used as abnormal data. Users form a habit of wearing safety equipment with continuous safety alarm sound and speed braking and proper driving habit by driving in a normal state without drinking alcohol. In addition, the proposed system enables real-time monitoring, thereby reducing risks by continuously maintaining safe driving and wearing protective equipment. The proposed system uses artificial intelligence to discriminate data related to helmet wearing, speed, and drinking in making an electric kickboard for safety, and triggers an alarm or operates the brake to prevent abnormal driving. If the design and function are supplemented, it will become a basic function that can be applied to various equipment of transportation. © 2021, Politeknik Negeri Padang. All rights reserved.
DA  - 2021///
PY  - 2021
DO  - 10.30630/joiv.5.2.558
VL  - 5
IS  - 2
SP  - 127
EP  - 133
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111072654&doi=10.30630%2fjoiv.5.2.558&partnerID=40&md5=c2791ce0867948168ce69f0fbac7cf70
DB  - Scopus
KW  - Safety
KW  - Machine learning
KW  - AI
KW  - CNN image processing
KW  - Personal mobility
KW  - Sensing data
ER  - 

TY  - CONF
TI  - Bullseye polytope: A scalable clean-label poisoning attack with improved transferability
AU  - Aghakhani, H.
AU  - Meng, D.
AU  - Wang, Y.-X.
AU  - Kruegel, C.
AU  - Vigna, G.
T2  - Proceedings - 2021 IEEE European Symposium on Security and Privacy, Euro S and P 2021
AB  - A recent source of concern for the security of neural networks is the emergence of clean-label dataset poisoning attacks, wherein correctly labeled poison samples are injected into the training dataset. While these poison samples look legitimate to the human observer, they contain malicious characteristics that trigger a targeted misclassification during inference. We propose a scalable and transferable clean-label poisoning attack against transfer learning, which creates poison images with their center close to the target image in the feature space. Our attack, Bullseye Polytope, improves the attack success rate of the current state-of-the-art by 26.75% in end-to-end transfer learning, while increasing attack speed by a factor of 12. We further extend Bullseye Polytope to a more practical attack model by including multiple images of the same object (e.g., from different angles) when crafting the poison samples. We demonstrate that this extension improves attack transferability by over 16% to unseen images (of the same object) without using extra poison samples.  © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/EuroSP51992.2021.00021
SP  - 159
EP  - 178
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119113061&doi=10.1109%2fEuroSP51992.2021.00021&partnerID=40&md5=5329947511ad01222151c43dc05e8e58
DB  - Scopus
KW  - Machine learning
KW  - Transfer learning
KW  - Machine-learning
KW  - Computer vision
KW  - Image enhancement
KW  - Neural-networks
KW  - Training dataset
KW  - Poisoning attacks
KW  - Machine learning robustness
KW  - Bullseye
KW  - Dataset poisoning
KW  - Dataset Poisoning
KW  - Human observers
KW  - Machine Learning Robustness
KW  - Polytopes
ER  - 

TY  - CONF
TI  - Robust Optimization Based Extreme Learning Machine for Sentiment Analysis in Big Data
AU  - Menakadevi, P.
AU  - Ramkumar, J.
T2  - 2022 International Conference on Advanced Computing Technologies and Applications, ICACTA 2022
AB  - Increasing use of social media has increased consumer interest in reading product evaluations and ratings before making a purchase. There is now a mechanism to examine natural language processing, sentiment analysis, and domain adaptation separately. A classifier trained on one set of datasets may underperform when applied to another collection of data. Therefore, it's critical to retain an open mind while experimenting with new classifiers. Reviewing datasets in big data is currently taking place. When applied to large datasets, the sentiment analysis algorithm designed for single machines or small datasets will not perform well. Robust Optimization-based Extreme Learning Machine (ROELM) is a classifier proposed in this work for sentiment analysis in massive data. ROELM is using natural wolf-like behavior to analyze an enormous review database. The single-layer hidden layer of ELM improves classification performance by one factor. This classifier's accuracy and f-measure performance have been assessed. According to the results, the suggested classifier achieves a higher level of classification accuracy than current classifiers. © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ICACTA54488.2022.9753203
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129198616&doi=10.1109%2fICACTA54488.2022.9753203&partnerID=40&md5=097367c0a416bd23409d1cc31a37eee0
DB  - Scopus
KW  - Machine learning
KW  - Classification (of information)
KW  - Optimisations
KW  - Optimization
KW  - Knowledge acquisition
KW  - Robust optimization
KW  - Social media
KW  - Classification
KW  - Large dataset
KW  - Domain adaptation
KW  - Sentiment analysis
KW  - Product evaluation
KW  - Amazon
KW  - Consumer interests
KW  - Product ratings
KW  - Product Review
KW  - Product reviews
KW  - Sentiment Analysis
ER  - 

TY  - JOUR
TI  - Empirical likelihood-based estimation and inference in randomized controlled trials with high-dimensional covariates
AU  - Liang, W.
AU  - Yan, Y.
T2  - Statistics and its Interface
AB  - In this paper, we propose a data-adaptive empirical likelihood-based approach for treatment effect estimation and inference, which overcomes the obstacle of the traditional empirical likelihood-based approaches in the highdimensional setting by adopting penalized regression and machine learning methods to model the covariate-outcome relationship. In particular, we show that our procedure successfully recovers the true variance of Zhang’s treatment effect estimator [30] by utilizing a data-splitting technique. Our proposed estimator is proved to be asymptotically normal and semiparametric efficient under mild regularity conditions. Simulation studies indicate that our estimator is more efficient than the estimator proposed by Wager et al. [26] when random forest is employed to model the covariateoutcome relationship. Moreover, when multiple machine learning models are imposed, our estimator is at least as efficient as any regular estimator with a single machine learning model. We compare our method to existing ones using the ACTG175 data and the GSE118657 data, and confirm the outstanding performance of our approach. © 2021, Statistics and Its Interface. All Rights Reserved.
DA  - 2022///
PY  - 2022
DO  - 10.4310/21-SII686
VL  - 15
IS  - 3
SP  - 283
EP  - 301
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125233011&doi=10.4310%2f21-SII686&partnerID=40&md5=e4f51cafe9a39095582d57c051940f37
DB  - Scopus
KW  - Machine learning
KW  - Average treatment effect
KW  - Datasplitting
KW  - Multiple robustness
KW  - Semiparametric efficiency bound
ER  - 

TY  - CONF
TI  - Increasing Robustness for Machine Learning Services in Challenging Environments: Limited Resources and No Label Feedback
AU  - Baier, L.
AU  - Kühl, N.
AU  - Schmitt, J.
T2  - Lecture Notes in Networks and Systems
AB  - The importance of deployed machine learning solutions has increased significantly in the past years due to the availability of data sources, computing capabilities and convenient tooling. However, technical challenges such as limited resources and computing power arise in many applications. We consider a scenario where a machine learning model is deployed in an environment where all computations need to be performed on a local computing unit. Furthermore, after deployment, the model does not receive any ground truth labels as feedback. We develop a two-step prediction method which combines an outlier detection with a robust machine learning model. This approach is evaluated based on a data set from a large German OEM. We can show that the prediction performance is increased significantly with our approach while fulfilling the restrictions in terms of memory and computational power. This way, we contribute to the practical applicability of machine learning models for real-world applications. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-82193-7_57
VL  - 294
SP  - 837
EP  - 856
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113256117&doi=10.1007%2f978-3-030-82193-7_57&partnerID=40&md5=275389520fbb7389911a0d46402a9594
DB  - Scopus
KW  - Robustness
KW  - Concept drift
KW  - Limited resources
KW  - Machine learning deployment
KW  - No labels
ER  - 

TY  - CONF
TI  - Evaluating Patient Safety Drivers using Decision Trees
AU  - Alderei, B.
AU  - Nammari, R.
AU  - Alalami, M.A.
AU  - Rodrigues, C.
AU  - Qazi, A.
AU  - Emre Simsekler, M.C.
T2  - 2022 Advances in Science and Engineering Technology International Conferences, ASET 2022
AB  - This study aims to identify the drivers of patient safety challenges in healthcare. Hospital-level aggregate survey data from the UK hospital is used to identify what drives the number of reported incidents affecting patient safety. Leveraging a decision tree algorithm, our results suggest that the role of teamwork and safety culture in incident reporting and investigation are the most critical dimensions influencing the number of reported patient safety challenges. The decision tree algorithm can be useful for hospitals to enhance patient safety through data-driven approaches and direct resources towards service improvements.  © 2022 IEEE.
DA  - 2022///
PY  - 2022
DO  - 10.1109/ASET53988.2022.9735129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128434573&doi=10.1109%2fASET53988.2022.9735129&partnerID=40&md5=cb6eb0d7c9b8582fdb0c608556f7e4e6
DB  - Scopus
KW  - machine learning
KW  - Decision trees
KW  - Machine learning
KW  - Data analytics
KW  - Decision-tree algorithm
KW  - patient safety
KW  - Patient safety
KW  - Data-driven approach
KW  - Digital storage
KW  - Hospitals
KW  - Safety culture
KW  - Data Analytics
KW  - safety culture
KW  - Medical errors
KW  - data analytics
KW  - Survey data
KW  - decision trees
KW  - Critical dimension
KW  - medical errors
KW  - Service improvement
ER  - 

TY  - CONF
TI  - Methods for traffic data classification with regard to potential safety hazards
AU  - Obereigner, G.
AU  - Tkachenko, P.
AU  - del Re, L.
T2  - IFAC-PapersOnLine
AB  - Traffic data are a key element for setting up scenarios for Advanced Driver Assistant Systems (ADAS) safety and performance testing. Testing will thus reflect in some way the data used. However, there is no clear understanding in which way and how to choose the data so that the evaluation results are reliable and comprehensive. Therefore, the important scenarios in a traffic data set in view of safety analysis have to be determined. The paper presents a method with which traffic situations from a given data set are classified into different safety classes according to easily measurable features. It is shown that taking the Time To Collision (TTC) as a measure of safety and a linear Support Vector Machine (SVM) as a classifier, 64.7 % of traffic situations of a validation data set were classified to the correct safety class considering only three measurable features. Thus, traffic situations from a data set can be classified fast into different safety categories, providing information to the ADAS tester if the developed device has been tested in a safe or unsafe environment. © 2021 The Authors.
DA  - 2021///
PY  - 2021
DO  - 10.1016/j.ifacol.2021.08.367
VL  - 54
SP  - 250
EP  - 255
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118132419&doi=10.1016%2fj.ifacol.2021.08.367&partnerID=40&md5=6fb07e7bac6be86289620da933062510
DB  - Scopus
KW  - Intelligent systems
KW  - Support vector machines
KW  - Machine Learning
KW  - Advanced driver assistance systems
KW  - Automobile drivers
KW  - Machine-learning
KW  - Classification (of information)
KW  - Safety testing
KW  - Classification
KW  - Traffic data
KW  - Data set
KW  - Automotives
KW  - Safety analysis
KW  - Dataset
KW  - Safety Analysis
KW  - Automotive
KW  - Traffic situations
KW  - Advanced driver assistant systems
KW  - Classifieds
KW  - Datasets
KW  - Safety class
ER  - 

TY  - CHAP
TI  - Modifying the SMOTE and Safe-Level SMOTE Oversampling Method to Improve Performance
AU  - Dolo, K.M.
AU  - Mnkandla, E.
T2  - Lecture Notes on Data Engineering and Communications Technologies
AB  - Synthetic Minority Oversampling Technique (SMOTE) is a sampling method that oversamples the minority class by computing median feature vectors between nominal feature samples and its potential nearest neighbours by Euclidean distance of standard deviations. The objective of SMOTE is therefore to generate a new data instance between the two existing data instances of the minority class. However, the challenge is that the existing SMOTE and Safe-Level SMOTE techniques do not always generate new data instances between two given minority class data instances, which leads to the problem of the two algorithms violating the objective of the SMOTE algorithm. The Safe-Level SMOTE is a family of SMOTE oversampling techniques that generate a new data instance between two minority data instances at the safe level of the minority class. In this study, the SMOTE and Safe-Level SMOTE techniques were re-designed to always meet the objectives of the SMOTE while preserving or improving the capabilities of the algorithms. The study shows that the original Safe-Level SMOTE oversampling technique performs better than the SMOTE oversampling technique. Furthermore, the study shows that the rectified SMOTE oversampling technique performs better than Safe-Level SMOTE oversampling technique. The performances of the original SMOTE and Safe-Level SMOTE algorithms and the proposed algorithms were compared using artificial neural network, support vector machine, naïve Bayesian, decision tree and k-Nearest Neighbour machine learning techniques. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
VL  - 94
SP  - 47
EP  - 59
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124495331&doi=10.1007%2f978-3-030-89776-5_4&partnerID=40&md5=c465e8e1daddada8536af6c760f7f3e6
DB  - Scopus
KW  - Decision trees
KW  - Neural networks
KW  - Support vector machines
KW  - Machine Learning
KW  - Machine-learning
KW  - Nearest neighbor search
KW  - Support vectors machine
KW  - Support Vector Machine
KW  - K-near neighbor
KW  - Nearest-neighbour
KW  - SMOTE
KW  - Decision Tree
KW  - Data distribution
KW  - Artificial Neural Network
KW  - Synthetic minority over-sampling techniques
KW  - Class distributions
KW  - Class Distribution
KW  - Confusion matrix
KW  - Confusion Matrix
KW  - Data Distribution
KW  - K-Nearest Neighbour
KW  - Naive Bayesian
KW  - Safe-Level SMOTE
KW  - Safe-level synthetic minority oversampling technique
ER  - 

TY  - CONF
TI  - Adaptive Adversarial Training for Meta Reinforcement Learning
AU  - Chen, S.
AU  - Chen, Z.
AU  - Wang, D.
T2  - Proceedings of the International Joint Conference on Neural Networks
AB  - Meta Reinforcement Learning (MRL) enables an agent to learn from a limited number of past trajectories and extrapolate to a new task. In this paper, we attempt to improve the robustness of MRL. We build upon model-agnostic meta-learning (MAML) and propose a novel method to generate adversarial samples for MRL by using Generative Adversarial Network (GAN). That allows us to enhance the robustness of MRL to adversal attacks by leveraging these attacks during meta training process. © 2021 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/IJCNN52387.2021.9534316
VL  - 2021-July
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116488147&doi=10.1109%2fIJCNN52387.2021.9534316&partnerID=40&md5=d86f061bb7a42a76955d06cdce3fbcc2
DB  - Scopus
KW  - Reinforcement learning
KW  - Reinforcement learnings
KW  - Robustness
KW  - Learn+
KW  - GAN
KW  - Training process
KW  - Metalearning
KW  - Generative adversarial networks
KW  - Novel methods
KW  - Adversarial training
KW  - Adversarial Training
KW  - Meta reinforcement learning
KW  - Meta Reinforcement Learning
KW  - Meta-training
ER  - 

TY  - JOUR
TI  - LLAMA: a robust and scalable machine learning pipeline for analysis of large scale 4D microscopy data: analysis of cell ruffles and filopodia
AU  - Lefevre, J.G.
AU  - Koh, Y.W.H.
AU  - Wall, A.A.
AU  - Condon, N.D.
AU  - Stow, J.L.
AU  - Hamilton, N.A.
T2  - BMC Bioinformatics
AB  - Background: With recent advances in microscopy, recordings of cell behaviour can result in terabyte-size datasets. The lattice light sheet microscope (LLSM) images cells at high speed and high 3D resolution, accumulating data at 100 frames/second over hours, presenting a major challenge for interrogating these datasets. The surfaces of vertebrate cells can rapidly deform to create projections that interact with the microenvironment. Such surface projections include spike-like filopodia and wave-like ruffles on the surface of macrophages as they engage in immune surveillance. LLSM imaging has provided new insights into the complex surface behaviours of immune cells, including revealing new types of ruffles. However, full use of these data requires systematic and quantitative analysis of thousands of projections over hundreds of time steps, and an effective system for analysis of individual structures at this scale requires efficient and robust methods with minimal user intervention. Results: We present LLAMA, a platform to enable systematic analysis of terabyte-scale 4D microscopy datasets. We use a machine learning method for semantic segmentation, followed by a robust and configurable object separation and tracking algorithm, generating detailed object level statistics. Our system is designed to run on high-performance computing to achieve high throughput, with outputs suitable for visualisation and statistical analysis. Advanced visualisation is a key element of LLAMA: we provide a specialised tool which supports interactive quality control, optimisation, and output visualisation processes to complement the processing pipeline. LLAMA is demonstrated in an analysis of macrophage surface projections, in which it is used to i) discriminate ruffles induced by lipopolysaccharide (LPS) and macrophage colony stimulating factor (CSF-1) and ii) determine the autonomy of ruffle morphologies. Conclusions: LLAMA provides an effective open source tool for running a cell microscopy analysis pipeline based on semantic segmentation, object analysis and tracking. Detailed numerical and visual outputs enable effective statistical analysis, identifying distinct patterns of increased activity under the two interventions considered in our example analysis. Our system provides the capacity to screen large datasets for specific structural configurations. LLAMA identified distinct features of LPS and CSF-1 induced ruffles and it identified a continuity of behaviour between tent pole ruffling, wave-like ruffling and filopodia deployment. © 2021, The Author(s).
DA  - 2021///
PY  - 2021
DO  - 10.1186/s12859-021-04324-z
VL  - 22
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112868492&doi=10.1186%2fs12859-021-04324-z&partnerID=40&md5=a56b1fdbbfa20e0eb738bc819efc7f90
DB  - Scopus
KW  - machine learning
KW  - Semantics
KW  - Machine learning
KW  - Visualization
KW  - Machine Learning
KW  - Pipelines
KW  - Algorithms
KW  - Semantic segmentation
KW  - algorithm
KW  - Machine learning methods
KW  - Quality control
KW  - Object tracking
KW  - Image segmentation
KW  - microscopy
KW  - Microscopy
KW  - Turing machines
KW  - Statistical methods
KW  - Large dataset
KW  - Cytology
KW  - Object detection and tracking
KW  - High performance computing
KW  - Filopodia
KW  - Individual structures
KW  - Lipopolysaccharides
KW  - macrophage
KW  - Macrophage
KW  - Macrophage colony stimulating factors
KW  - Macrophages
KW  - Pseudopodia
KW  - pseudopodium
KW  - Ruffles
KW  - Scalable machine learning
KW  - Structural configurations
ER  - 

TY  - CONF
TI  - Unsupervised Integration of Single-Cell Multi-omics Datasets with Disproportionate Cell-Type Representation
AU  - Demetçi, P.
AU  - Santorella, R.
AU  - Sandstede, B.
AU  - Singh, R.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Integrated analysis of multi-omics data allows the study of how different molecular views in the genome interact to regulate cellular processes; however, with a few exceptions, applying multiple sequencing assays on the same single cell is not possible. While recent unsupervised algorithms align single-cell multi-omic datasets, these methods have been primarily benchmarked on co-assay experiments rather than the more common single-cell experiments taken from separately sampled cell populations. Therefore, most existing methods perform subpar alignments on such datasets. Here, we improve our previous work Single Cell alignment using Optimal Transport (SCOT) by using unbalanced optimal transport to handle disproportionate cell-type representation and differing sample sizes across single-cell measurements. We show that our proposed method, SCOTv2, consistently yields quality alignments on five real-world single-cell datasets with varying cell-type proportions and is computationally tractable. Additionally, we extend SCOTv2 to integrate multiple (M≥ 2 ) single-cell measurements and present a self-tuning heuristic process to select hyperparameters in the absence of any orthogonal correspondence information. Available at: http://rsinghlab.github.io/SCOT. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-031-04749-7_1
VL  - 13278 LNBI
SP  - 3
EP  - 19
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131149826&doi=10.1007%2f978-3-031-04749-7_1&partnerID=40&md5=dd37a459e013e9bc3f936b4e5c58b874
DB  - Scopus
KW  - Optimization
KW  - Unsupervised learning
KW  - Alignment
KW  - Data integration
KW  - Single cells
KW  - Cell proliferation
KW  - Cell culture
KW  - Optimal transport
KW  - 'omics'
KW  - Cell types
KW  - Cellular process
KW  - Integrated analysis
KW  - Multi-omic
KW  - Multi-omics
KW  - Single cell measurement
KW  - Single-cell sequencing
KW  - Unbalanced alignment
ER  - 

TY  - CONF
TI  - Safe Distributional Reinforcement Learning
AU  - Zhang, J.
AU  - Weng, P.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Safety in reinforcement learning (RL) is a key property in both training and execution in many domains such as autonomous driving or finance. In this paper, we formalize it with a constrained RL formulation in the distributional RL setting. Our general model accepts various definitions of safety (e.g., bounds on expected performance, CVaR). To ensure safety during learning, we extend a safe policy optimization method to solve our problem. The distributional RL perspective leads to a more efficient algorithm while additionally catering for natural safe constraints. We empirically validate our propositions against appropriate state-of-the-art safe RL algorithms. © 2022, Springer Nature Switzerland AG.
DA  - 2022///
PY  - 2022
DO  - 10.1007/978-3-030-94662-3_8
VL  - 13170 LNAI
SP  - 107
EP  - 128
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123444337&doi=10.1007%2f978-3-030-94662-3_8&partnerID=40&md5=864c6701a903f5c409aaa76976d554ce
DB  - Scopus
KW  - Reinforcement learning
KW  - Autonomous driving
KW  - Performance
KW  - Reinforcement learnings
KW  - Safety engineering
KW  - Policy optimization
KW  - Safe exploration
KW  - Property
KW  - Learning settings
KW  - Learning formulation
KW  - General model
KW  - Risk constraint
KW  - Risk constraints
ER  - 

TY  - JOUR
TI  - Anomaly Detection for Insider Threats Using Unsupervised Ensembles
AU  - Le, D.C.
AU  - Zincir-Heywood, N.
T2  - IEEE Transactions on Network and Service Management
AB  - Insider threat represents a major cybersecurity challenge to companies, organizations, and government agencies. Insider threat detection involves many challenges, including unbalanced data, limited ground truth, and possible user behavior changes. This research presents an unsupervised learning based anomaly detection approach for insider threat detection. We employ four unsupervised learning methods with different working principles, and explore various representations of data with temporal information. Furthermore, different computational intelligence schemes are explored to combine these models to create anomaly detection ensembles for improving the detection performance. Evaluation results show that the approach allows learning from unlabelled data under challenging conditions for insider threat detection. Insider threats are detected with high detection and low false positive rates. For example, 60% of malicious insiders are detected under 0.1% investigation budget, and all malicious insiders are detected at less than 5% investigation budget. Furthermore, we explore the ability of the proposed approach to generalize for detecting new anomalous behaviors in different datasets, i.e., robustness. Finally, results demonstrate that a voting-based ensemble of anomaly detection can be used to improve detection performance as well as the robustness. Comparisons with the state-of-the-art confirm the effectiveness of the proposed approach.  © 2004-2012 IEEE.
DA  - 2021///
PY  - 2021
DO  - 10.1109/TNSM.2021.3071928
VL  - 18
IS  - 2
SP  - 1152
EP  - 1164
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104195907&doi=10.1109%2fTNSM.2021.3071928&partnerID=40&md5=2799dabb5e1f8d9dd1e14124ec6ce3cd
DB  - Scopus
KW  - Learning systems
KW  - Anomaly detection
KW  - Behavioral research
KW  - anomaly detection
KW  - Security of data
KW  - Unsupervised learning
KW  - unsupervised learning
KW  - ensemble learning
KW  - Budget control
KW  - Detection approach
KW  - Intelligent computing
KW  - Unsupervised learning method
KW  - False positive rates
KW  - Detection performance
KW  - Evaluation results
KW  - Government agencies
KW  - Insider threat detections
KW  - dependable and robust learning
KW  - Insider threat detection
KW  - temporal data
KW  - Temporal information
ER  - 

TY  - JOUR
TI  - Robust and efficient semi-supervised estimation of average treatment effects with application to electronic health records data
AU  - Cheng, D.
AU  - Ananthakrishnan, A.N.
AU  - Cai, T.
T2  - Biometrics
AB  - We consider the problem of estimating the average treatment effect (ATE) in a semi-supervised learning setting, where a very small proportion of the entire set of observations are labeled with the true outcome but features predictive of the outcome are available among all observations. This problem arises, for example, when estimating treatment effects in electronic health records (EHR) data because gold-standard outcomes are often not directly observable from the records but are observed for a limited number of patients through small-scale manual chart review. We develop an imputation-based approach for estimating the ATE that is robust to misspecification of the imputation model. This effectively allows information from the predictive features to be safely leveraged to improve efficiency in estimating the ATE. The estimator is additionally doubly-robust in that it is consistent under correct specification of either an initial propensity score model or a baseline outcome model. It is also locally semiparametric efficient under an ideal semi-supervised model where the distribution of the unlabeled data is known. Simulations exhibit the efficiency and robustness of the proposed method compared to existing approaches in finite samples. We illustrate the method by comparing rates of treatment response to two biologic agents for treatment inflammatory bowel disease using EHR data from Partners' Healthcare. © 2020 The International Biometric Society
DA  - 2021///
PY  - 2021
DO  - 10.1111/biom.13298
VL  - 77
IS  - 2
SP  - 413
EP  - 423
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085566308&doi=10.1111%2fbiom.13298&partnerID=40&md5=edb58b13fb816113a474c181a18c92cc
DB  - Scopus
KW  - simulation
KW  - semi-supervised learning
KW  - Supervised learning
KW  - Learning algorithms
KW  - human
KW  - Humans
KW  - statistical model
KW  - Efficiency
KW  - computer simulation
KW  - Computer Simulation
KW  - Semi-supervised learning
KW  - detection method
KW  - estimation method
KW  - Patient treatment
KW  - supervised machine learning
KW  - Supervised Machine Learning
KW  - Sampling
KW  - Semi-supervised
KW  - Electronic health
KW  - electronic health record
KW  - Health records
KW  - Records management
KW  - propensity score
KW  - Propensity Score
KW  - data set
KW  - Average treatment effects
KW  - Double robustness
KW  - Models, Statistical
KW  - causal inference
KW  - Missing data
KW  - Electronic Health Records
KW  - Causal inferences
KW  - disease treatment
KW  - double-robustness
KW  - missing data
KW  - observational method
KW  - semiparametric efficiency
KW  - Semiparametric efficiency
KW  - Surrogate outcome
KW  - surrogate outcomes
ER  - 

TY  - JOUR
TI  - Trends and topics in research and development related to the improvement of signalling and telecommunication systems using information and communication technology
AU  - Kawasaki, K.
T2  - Quarterly Report of RTRI (Railway Technical Research Institute)
AB  - The purpose of the signalling and transport information division is to contribute to enhanced railway safety, reliability, and convenience through research and development into signalling systems, communication network technology, transportation planning and traffic operations technology, and condition monitoring technology for railway facilities. This paper outlines trends in research and development on improving the safety and availability of signalling systems and telecommunication systems using Information and Communication Technology (ICT) such as image analysis, artificial intelligence, cloud computing, and mobile communications networks. © 2019 Ken-yusha Inc..
DA  - 2019///
PY  - 2019
DO  - 10.2219/rtriqr.60.1_6
VL  - 60
IS  - 1
SP  - 6
EP  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062558022&doi=10.2219%2frtriqr.60.1_6&partnerID=40&md5=f0d578a362fc768cd016b2cb27cfff89
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine learning
KW  - Learning systems
KW  - Railroads
KW  - Information use
KW  - Information and Communication Technologies
KW  - Information services
KW  - Image enhancement
KW  - Railroad transportation
KW  - Mobile communications
KW  - Distributed computer systems
KW  - Condition monitoring
KW  - Transportation planning
KW  - Mobile telecommunication systems
KW  - Research and development
KW  - Image analysis
KW  - ICT
KW  - Image communication systems
KW  - Information network
KW  - Information networks
KW  - Monitoring technologies
KW  - Radio train control
KW  - Railroad traffic control
KW  - Signalling safety facilities
KW  - Signalling systems
KW  - Train control
ER  - 

TY  - JOUR
TI  - Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning
AU  - Miyato, T.
AU  - Maeda, S.-I.
AU  - Koyama, M.
AU  - Ishii, S.
T2  - IEEE Transactions on Pattern Analysis and Machine Intelligence
AB  - We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only virtually adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward- and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10. © 2018 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/TPAMI.2018.2858821
VL  - 41
IS  - 8
SP  - 1979
EP  - 1993
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050394425&doi=10.1109%2fTPAMI.2018.2858821&partnerID=40&md5=12bea2c9a86402523ef6cb9a0e1663a2
DB  - Scopus
KW  - deep learning
KW  - Neural networks
KW  - robustness
KW  - Backpropagation
KW  - Learning algorithms
KW  - E-learning
KW  - article
KW  - Personnel training
KW  - Robustness (control systems)
KW  - Semi- supervised learning
KW  - Semi-supervised learning
KW  - learning
KW  - Data structures
KW  - supervised learning
KW  - Entropy
KW  - Perturbation method
KW  - Perturbation techniques
KW  - adversarial training
KW  - Computational costs
KW  - entropy
KW  - back propagation
KW  - adversarial examples
KW  - State-of-the-art performance
KW  - Regularization methods
KW  - Computational model
KW  - Label distribution
KW  - Entropy minimization
ER  - 

TY  - CONF
TI  - Manifold alignment and distribution adaptation for unsupervised domain adaptation
AU  - Li, Y.
AU  - Cheng, L.
AU  - Peng, Y.
AU  - Wen, Z.
AU  - Ying, S.
T2  - Proceedings - IEEE International Conference on Multimedia and Expo
AB  - Unsupervised domain adaptation is a problem which exploits the knowledge learned from the resource-rich domain to obtain an accurate classifier for the resource-poor domain. Most of the existing methods lift performance by reducing the differences between distributions, such as the difference between marginal probability distributions, the difference between conditional probability distributions, or both. However, all these methods consider the two distributions to be equally important, which could lead to poor classification performance in practical applications. Therefore, a balanced factor is required to weigh the two distributions to compensate for the degraded performance. In this paper, we first introduce this balance factor to weigh the distribution importance. On this base, we utilize the marginal distribution, introduce the ideas of manifold regularization, and then preserve the neighboring structures of the data sets, with the dimension reduction as much as possible. By this way, we propose the manifold alignment and balanced distribution adaptation algorithm. A large number of experiments have also been conducted, showing that our algorithm behaves much better than the previous ones. © 2019 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/ICME.2019.00124
VL  - 2019-July
SP  - 688
EP  - 693
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070986696&doi=10.1109%2fICME.2019.00124&partnerID=40&md5=7e3d5c16e72550a6cf2b9b775d80f946
DB  - Scopus
KW  - Transfer learning
KW  - Classification performance
KW  - Probability distributions
KW  - Manifold regularizations
KW  - Domain adaptation
KW  - Unsupervised domain adaptation
KW  - Adaptation algorithms
KW  - Manifold alignment
KW  - Manifold alignments
KW  - Conditional probability distributions
KW  - Distribution adaptation
ER  - 

TY  - JOUR
TI  - Optimal Reconfiguration of Distribution Network Using \mu PMU Measurements: A Data-Driven Stochastic Robust Optimization
AU  - Akrami, A.
AU  - Doostizadeh, M.
AU  - Aminifar, F.
T2  - IEEE Transactions on Smart Grid
AB  - The proliferated penetration of renewable resources along with stochastic consumption pattern of electrical vehicles have arisen the prominence of real-time monitoring of the grid for the sake of obtaining the optimal topology of distribution network. This paper proposes a data-driven method based on the measurements of \mu PMUs to figure out the hourly optimal configuration of distribution grid in a real-time manner. First, the node voltage and injected current phasors measurements captured by \mu PMUs are processed via a linear state estimation to determine the net load at each node. Then, the real-time high resolution data of loads is turned into knowledge through a bi-level unsupervised information granulation technique. In the second stage, based on the uncertainty bounds obtained for each information granule, a stochastic robust optimization (SRO) is developed via second order conic programming method to find out the best network reconfiguration, while minimizing the corresponding objective cost function. The developed method is applied to IEEE 33-node distribution network and Brazilian 135-node test feeder. © 2010-2012 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/TSG.2019.2923740
VL  - 11
IS  - 1
SP  - 420
EP  - 428
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077390553&doi=10.1109%2fTSG.2019.2923740&partnerID=40&md5=c6e550642f23e44e04d1ea12692dfd12
DB  - Scopus
KW  - Cost functions
KW  - Optimization
KW  - Robust optimization
KW  - Stochastic systems
KW  - Unsupervised learning
KW  - unsupervised learning
KW  - stochastic robust optimization
KW  - Consumption patterns
KW  - data-driven analysis
KW  - Data-driven analysis
KW  - Granulation
KW  - Information granulation
KW  - Information granules
KW  - Linear state estimation
KW  - Network re-configuration
KW  - Network reconfiguration
KW  - Optimal reconfigurations
KW  - Second-order conic programming
KW  - Vehicle-to-grid
ER  - 

TY  - CONF
TI  - Mobile Mechanic - An innovative step towards Digital Automobile Service
AU  - Philip, J.
AU  - Nayak, S.
AU  - Patel, S.
AU  - Devashrayee, Y.
T2  - 2018 International Conference on Smart City and Emerging Technology, ICSCET 2018
AB  - In the 21                             st                              century's work engrossed environment, everyone is in a rush to reach their destination on time, nothing should be a hindrance to their way of achieving their goal. Considering a real-life problem where a person faces troubles when their car breaks down in the middle of the road, can really become a major problem especially when this occurs on highways or distant places. This can be solved by using our application which can help the users to find nearby location of service or a repairing center. The application would be subdivided into two main sections namely the Mechanic's portal and the User's portal. Both these portals would require the respective user to either login or register themselves up before using the application. The location can be provided or obtained using the GPS available in mobile phones. The User's portal would display a map with the current location of themselves along with all the available repair shops around them, which shall be consistently updated using the plethora of location services available on Microsoft Azure Cloud. User can get detailed information about these shops along with a route to reach the desired mechanic shop, using Google Map API. Further, the same data shall be utilized for providing interest/ choice based mechanic shops to future users, by implementing Data Analytics and Machine learning available as API's on Azure Cloud Services. This same data can be thereafter be cleansed and provided as employment opportunities for locations which have lesser mechanic reach and for various other assistance, by using Azure Big Data. The application will also be providing a SOS feature for women's safety and a DIY section consisting of videos and documents within the application would let the users try their hands at fixing their own vehicles on occasion of no network coverage or poor internet connectivity.                          © 2018 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/ICSCET.2018.8537243
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059410451&doi=10.1109%2fICSCET.2018.8537243&partnerID=40&md5=bbf6dacc30e06a18b74ad80ea40654a3
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine Learning
KW  - Learning systems
KW  - Data analytics
KW  - Smart city
KW  - Systems engineering
KW  - Big Data
KW  - Big data
KW  - Data Analytics
KW  - Cloud computing
KW  - Location
KW  - Global positioning system
KW  - Windows operating system
KW  - GPS
KW  - Women Safety
KW  - Repair
KW  - Cloud Computing
KW  - Digital India
KW  - DIY
KW  - Employment opportunities
KW  - Google map api
KW  - Google Map API
KW  - Internet connectivity
KW  - Location services
KW  - Machine shops
KW  - Mechanic Service
KW  - Mechanics
KW  - Real-life problems
KW  - SOS service
ER  - 

TY  - JOUR
TI  - Regularized aggregation of statistical parametric maps
AU  - Wang, L.-Y.
AU  - Chung, J.
AU  - Park, C.
AU  - Choi, H.
AU  - Rodrigue, A.L.
AU  - Pierce, J.E.
AU  - Clementz, B.A.
AU  - McDowell, J.E.
T2  - Human Brain Mapping
AB  - Combining statistical parametric maps (SPM) from individual subjects is the goal in some types of group-level analyses of functional magnetic resonance imaging data. Brain maps are usually combined using a simple average across subjects, making them susceptible to subjects with outlying values. Furthermore, t tests are prone to false positives and false negatives when outlying values are observed. We propose a regularized unsupervised aggregation method for SPMs to find an optimal weight for aggregation, which aids in detecting and mitigating the effect of outlying subjects. We also present a bootstrap-based weighted t test using the optimal weights to construct an activation map robust to outlying subjects. We validate the performance of the proposed aggregation method and test using simulated and real data examples. Results show that the regularized aggregation approach can effectively detect outlying subjects, lower their weights, and produce robust SPMs. © 2018 Wiley Periodicals, Inc.
DA  - 2019///
PY  - 2019
DO  - 10.1002/hbm.24355
VL  - 40
IS  - 1
SP  - 65
EP  - 79
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052932700&doi=10.1002%2fhbm.24355&partnerID=40&md5=c4903ec5f48f2335bbac544d1a03c6c9
DB  - Scopus
KW  - simulation
KW  - brain
KW  - robustness
KW  - adult
KW  - article
KW  - human
KW  - Humans
KW  - procedures
KW  - physiology
KW  - learning
KW  - image processing
KW  - Image Processing, Computer-Assisted
KW  - Brain
KW  - unsupervised machine learning
KW  - diagnostic imaging
KW  - nuclear magnetic resonance imaging
KW  - statistical analysis
KW  - Unsupervised Machine Learning
KW  - Magnetic Resonance Imaging
KW  - Data Interpretation, Statistical
KW  - bootstrapping
KW  - brain mapping
KW  - Brain Mapping
KW  - functional magnetic resonance imaging
KW  - functional magnetic resonance imaging data
KW  - penalized unsupervised learning
KW  - statistical parametric map
ER  - 

TY  - CONF
TI  - A Comparative Study of Feature Selection Methods for Biomarker Discovery
AU  - Mungloo-Dilmohamud, Z.
AU  - Marigliano, G.
AU  - Jaufeerally-Fakim, Y.
AU  - Peña-Reyes, C.
T2  - Proceedings - 2018 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2018
AB  - A major area of research is biomarker discovery using gene expression data. Such data is huge and often needs to be classified into classes or clustered, using different machine learning techniques, for further analysis. An important preprocessing step is feature selection (FS) and different such methods have been devised. However, applying different FS techniques to the same dataset do not always produce the same results. In this work, the robustness of FS methods will be looked into. Robustness is defined here as the stability of a given gene pool with respect to the data and the FS method used. Our approach is to investigate the resulting feature subset obtained when running diverse FS methods on different gene expression datasets. As a first step, 10 FS methods were executed using 2 different datasets. Based on the results obtained, 2 of these methods were further investigated using 10 different datasets. The effects of selecting an increasing number of features on the percentage similarity inter-methods were also studied. Our results show that the studied methods exhibit a high amount of variability in the resulting feature subset. The selected feature subsets differed both inter-methods and intra-methods for different datasets. The reason behind this is not clear and possible objective assessment on the ideal (best) subset should be further investigated. © 2018 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/BIBM.2018.8621267
SP  - 2789
EP  - 2791
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062541327&doi=10.1109%2fBIBM.2018.8621267&partnerID=40&md5=17014358b48d939ce8b386bcde9a8d6c
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Feature extraction
KW  - robustness
KW  - Learning systems
KW  - Robustness (control systems)
KW  - Feature selection methods
KW  - Gene expression
KW  - Bioinformatics
KW  - feature selection
KW  - Machine learning techniques
KW  - Pre-processing step
KW  - Set theory
KW  - Gene Expression Data
KW  - Biomarkers
KW  - Comparative studies
KW  - Bio-marker discovery
KW  - biomarker discovery
KW  - gene expression data
KW  - Gene expression datasets
KW  - Objective assessment
ER  - 

TY  - CONF
TI  - Recent progress in zeroth order optimization and its applications to adversarial robustness in data mining and machine learning
AU  - Chen, P.-Y.
AU  - Liu, S.
T2  - Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
AB  - Zeroth-order (ZO) optimization is increasingly embraced for solving big data and machine learning problems when explicit expressions of the gradients are difficult or infeasible to obtain. It achieves gradient-free optimization by approximating the full gradient via efficient gradient estimators. Some recent important applications include: a) generation of prediction-evasive, black-box adversarial attacks on deep neural networks, b) online network management with limited computation capacity, c) parameter inference of black-box/complex systems, and d) bandit optimization in which a player receives partial feedback in terms of loss function values revealed by her adversary. This tutorial aims to provide a comprehensive introduction to recent advances in ZO optimization methods in both theory and applications. On the theory side, we will cover convergence rate and iteration complexity analysis of ZO algorithms and make comparisons to their first-order counterparts. On the application side, we will highlight one appealing application of ZO optimization to studying the robustness of deep neural networks - practical and efficient adversarial attacks that generate adversarial examples from a black-box machine learning model. We will also summarize potential research directions regarding ZO optimization, big data challenges and some open-ended data mining and machine learning problems. © 2019 Association for Computing Machinery.
DA  - 2019///
PY  - 2019
DO  - 10.1145/3292500.3332288
SP  - 3233
EP  - 3234
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071176610&doi=10.1145%2f3292500.3332288&partnerID=40&md5=6cd446aa36c433998ba143664b9bd234
DB  - Scopus
KW  - Machine learning
KW  - Deep neural networks
KW  - Data mining
KW  - Online systems
KW  - Machine learning models
KW  - Big data
KW  - Iterative methods
KW  - Adversarial machine learning
KW  - Adversarial robustness
KW  - Optimization method
KW  - Machine learning problem
KW  - Complexity analysis
KW  - Computation capacity
KW  - Gradient-free optimization
KW  - Gradient-free optimizations
KW  - Order optimizations
KW  - Potential researches
KW  - Zeroth order optimization
ER  - 

TY  - CONF
TI  - Multi-agent Robust Time Differential Reinforcement Learning over Communicated Networks
AU  - Li, J.
AU  - Ma, N.
AU  - Han, X.
T2  - Chinese Control Conference, CCC
AB  - Recently, the researches on multi-agent reinforcement learning (MARL) have attracted tremendous interest in many applications, especially for autonomous driving. The main problem of MARL is how to deal with the uncertainty in the environment and the interaction between the connected agents. To solve the problem, a distributed robust temporal differential deep Q-network algorithm (MARTD-DQN) was developed in this paper. MARTD-DQN consists of two parts, the decentralized MARL algorithm (DMARL) and the robust TD deep Q-network algorithm (RTD-DQN). DMARL improves the robustness of the policy estimation by fusing the states from the neighbors over communicated networks. RTD- DQN improves the robustness to outliers through on-line estimation of the uncertainty. By combining the two algorithms, the proposed algorithm can be robust not only to node failures but also to the outliers. Then the proposed algorithm is applied to ACC simulations of autonomous cars. The simulation results are given to show the efficiency of the proposed algorithm. © 2018 Technical Committee on Control Theory, Chinese Association of Automation.
DA  - 2018///
PY  - 2018
DO  - 10.23919/ChiCC.2018.8483961
VL  - 2018-July
SP  - 7221
EP  - 7225
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056084531&doi=10.23919%2fChiCC.2018.8483961&partnerID=40&md5=4121bbdc89a01543d05c2a7b03122ad5
DB  - Scopus
KW  - Reinforcement learning
KW  - Autonomous agents
KW  - Autonomous driving
KW  - Robust estimation
KW  - Robustness (control systems)
KW  - Statistics
KW  - Multi agent systems
KW  - Autonomous car
KW  - Distributed Robust Estimation
KW  - Fertilizers
KW  - Interactive cognition
KW  - MDPs Parameters Uncertainty
KW  - Multi-agent reinforcement learning
KW  - Multi-agent Reinforcement Learning
KW  - Network algorithms
KW  - On-line estimation
KW  - Parameters uncertainties
ER  - 

TY  - BOOK
TI  - Advances in biometrics: Modern methods and implementation strategies
AU  - Sinha, G.R.
T2  - Advances in Biometrics: Modern Methods and Implementation Strategies
AB  - This book provides a framework for robust and novel biometric techniques, along with implementation and design strategies. The theory, principles, pragmatic and modern methods, and future directions of biometrics are presented, along with in-depth coverage of biometric applications in driverless cars, automated and AI-based systems, IoT, and wearable devices. Additional coverage includes computer vision and pattern recognition, cybersecurity, cognitive computing, soft biometrics, and the social impact of biometric technology. The book will be a valuable reference for researchers, faculty, and practicing professionals working in biometrics and related fields, such as image processing, computer vision, and artificial intelligence. Highlights robust and novel biometrics techniques Provides implementation strategies and future research directions in the field of biometrics Includes case studies and emerging applications. © Springer Nature Switzerland AG 2019.
DA  - 2019///
PY  - 2019
SP  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086185999&doi=10.1007%2f978-3-030-30436-2&partnerID=40&md5=4c5d9b08c9ff3a774f4f66a1abdb91be
DB  - Scopus
KW  - Machine learning
KW  - Signal processing
KW  - Computer vision
KW  - Image processing
KW  - Cybersecurity
KW  - Biometrics
KW  - Sensors
KW  - Pattern matching
KW  - 3D face detection
KW  - Biometric databases
KW  - Biometric standards
KW  - Cognitive computing
KW  - MEMS
KW  - Robust method of identification
KW  - Smart wearable devices
KW  - Soft biometrics
KW  - Template protection
KW  - Unique biometric method
ER  - 

TY  - CONF
TI  - Generative adversarial networks based data augmentation for noise robust speech recognition
AU  - Hu, H.
AU  - Tan, T.
AU  - Qian, Y.
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
AB  - Data augmentation is an effective method to increase the size of training data and reduce the mismatch between training and testing for noise robust speech recognition. Different from the traditional approaches by directly adding noise to the original waveform, in this work we utilize generative adversarial networks (GAN) for data generation to improve speech recognition under noise conditions. With this method, the generated speech samples are based on spectrum feature level and produced frame by frame without dependence among them, and the augmented data has no true labels. Then to effectively use these untranscribed augmented data, an unsupervised learning framework is designed for acoustic modeling. The proposed GAN-based data augmentation approach is evaluated on Aurora4. The experimental results show that a relative ∼ 7.0% WER reduction can be obtained by the proposed approach upon an advanced acoustic model. © 2018 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/ICASSP.2018.8462624
VL  - 2018-April
SP  - 5044
EP  - 5048
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054217579&doi=10.1109%2fICASSP.2018.8462624&partnerID=40&md5=fb9e613aae0d8a2202721045b6df2726
DB  - Scopus
KW  - Unsupervised learning
KW  - Data augmentation
KW  - Generative adversarial networks
KW  - Robust speech recognition
KW  - Very deep convolutional neural network
ER  - 

TY  - JOUR
TI  - Myoelectric control for upper limb prostheses
AU  - Igual, C.
AU  - Pardo, L.A.
AU  - Hahne, J.M.
AU  - Igual, J.
T2  - Electronics (Switzerland)
AB  - State-of-the-art high-end prostheses are electro-mechanically able to provide a great variety of movements. Nevertheless, in order to functionally replace a human limb, it is essential that each movement is properly controlled. This is the goal of prosthesis control, which has become a growing research field in the last decades, with the ultimate goal of reproducing biological limb control. Therefore, exploration and development of prosthesis control are crucial to improve many aspects of an amputee’s life. Nowadays, a large divergence between academia and industry has become evident in commercial systems. Although several studies propose more natural control systems with promising results, basic one degree of freedom (DoF), a control switching system is the most widely used option in industry because of simplicity, robustness and inertia. A few classification controlled prostheses have emerged in the last years but they are still a low percentage of the used ones. One of the factors that generate this situation is the lack of robustness of more advanced control algorithms in daily life activities outside of laboratory conditions. Because of this, research has shifted towards more functional prosthesis control. This work reviews the most recent literature in upper limb prosthetic control. It covers commonly used variants of possible biological inputs, its processing and translation to actual control, mostly focusing on electromyograms as well as the problems it will have to overcome in near future. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2019///
PY  - 2019
DO  - 10.3390/electronics8111244
VL  - 8
IS  - 11
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074427720&doi=10.3390%2felectronics8111244&partnerID=40&md5=70decc03be53f0182a518bb48c17c176
DB  - Scopus
KW  - Machine learning
KW  - Feature extraction
KW  - Review
KW  - Segmentation
KW  - Robustness
KW  - Electromyography
KW  - Feedback
KW  - Classification
KW  - Data acquisition
KW  - Regression
KW  - Usability
KW  - Co-adaptation
KW  - EMG
KW  - Human adaptation
KW  - Myoelectric control
KW  - Prosthesis
KW  - Sampling frequency
KW  - Upper limb
ER  - 

TY  - CONF
TI  - A 42pJ/decision 3.12TOPS/W robust in-memory machine learning classifier with on-chip training
AU  - Gonugondla, S.K.
AU  - Kang, M.
AU  - Shanbhag, N.
T2  - Digest of Technical Papers - IEEE International Solid-State Circuits Conference
AB  - Embedded sensory systems (Fig. 31.2.1) continuously acquire and process data for inference and decision-making purposes under stringent energy constraints. These always-ON systems need to track changing data statistics and environmental conditions, such as temperature, with minimal energy consumption. Digital inference architectures [1,2] are not well-suited for such energy-constrained sensory systems due to their high energy consumption, which is dominated (>75%) by the energy cost of memory read accesses and digital computations. In-memory architectures [3,4] significantly reduce the energy cost by embedding pitch-matched analog computations in the periphery of the SRAM bitcell array (BCA). However, their analog nature combined with stringent area constraints makes these architectures susceptible to process, voltage, and temperature (PVT) variation. Previously, off-chip training [4] has been shown to be effective in compensating for PVT variations of in-memory architectures. However, PVT variations are die-specific and data statistics in always-ON sensory systems can change over time. Thus, on-chip training is critical to address both sources of variation and to enable the design of energy efficient always-ON sensory systems based on in-memory architectures. The stochastic gradient descent (SGD) algorithm is widely used to train machine learning algorithms such as support vector machines (SVMs), deep neural networks (DNNs) and others. This paper demonstrates the use of on-chip SGD-based training to compensate for PVT and data statistics variation to design a robust in-memory SVM classifier. © 2018 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/ISSCC.2018.8310398
VL  - 61
SP  - 490
EP  - 492
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046487520&doi=10.1109%2fISSCC.2018.8310398&partnerID=40&md5=a2cd2094a2a3aebcb3c2a13d588e60fa
DB  - Scopus
KW  - Artificial intelligence
KW  - Decision making
KW  - Deep neural networks
KW  - Support vector machines
KW  - Learning algorithms
KW  - Energy efficiency
KW  - Network architecture
KW  - Energy utilization
KW  - Embedded systems
KW  - Stochastic systems
KW  - Memory architecture
KW  - Analog computers
KW  - Environmental conditions
KW  - Stochastic gradient descent algorithm
KW  - Support vector machine (SVMs)
KW  - High energy consumption
KW  - Analog computation
KW  - Digital computation
KW  - Energy-constrained
KW  - Sources of variation
KW  - Static random access storage
ER  - 

TY  - CONF
TI  - Distributionally robust semi-supervised learning for people-centric sensing
AU  - Chen, K.
AU  - Yao, L.
AU  - Zhang, D.
AU  - Chang, X.
AU  - Long, G.
AU  - Wang, S.
T2  - 33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019
AB  - Semi-supervised learning is crucial for alleviating la-belling burdens in people-centric sensing. However, human-generated data inherently suffer from distribution shift in semi-supervised learning due to the diverse biological conditions and behavior patterns of humans. To address this problem, we propose a generic distributionally robust model for semi-supervised learning on distributionally shifted data. Considering both the discrepancy and the consistency between the labeled data and the unlabeled data, we learn the latent features that reduce person-specific discrepancy and preserve task-specific consistency. We evaluate our model in a variety of people-centric recognition tasks on real-world datasets, including intention recognition, activity recognition, muscular movement recognition and gesture recognition. The experiment results demonstrate that the proposed model outperforms the state-of-the-art methods. © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org).
DA  - 2019///
PY  - 2019
SP  - 3321
EP  - 3328
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090808244&partnerID=40&md5=68a7c553d7f705a73dd28cb3ab222b33
DB  - Scopus
KW  - Semi-supervised learning
KW  - State-of-the-art methods
KW  - Activity recognition
KW  - Robust modeling
KW  - Motion estimation
KW  - Real-world datasets
KW  - Behavior patterns
KW  - Biological conditions
KW  - Intention recognition
KW  - Muscular movements
ER  - 

TY  - JOUR
TI  - Robust adaptive online sequential extreme learning machine for predicting nonstationary data streams with outliers
AU  - Guo, W.
T2  - Journal of Algorithms and Computational Technology
AB  - Data streams online modeling and prediction is an important research direction in the field of data mining. In practical applications, data streams are often of nonstationary nature and containing outliers, hence an online learning algorithm with dynamic tracking capability as well as anti-outlier capability is urgently needed. With this in mind, this paper proposes a novel robust adaptive online sequential extreme learning machine (RA-OSELM) algorithm for the online modeling and prediction of nonstationary data streams with outliers. The RA-OSELM is developed from the famous online sequential extreme learning machine algorithm, but it uses a more robust M-estimation loss function to replace the conventional least square loss function so as to suppress the incorrect online update of the learning algorithm with respect to outliers, and hence enhances its robustness in the presence of outliers. Moreover, the RA-OSELM adopts a variable forgetting factor method to automatically track the dynamic changes of the nonstationary data streams and timely eliminate the negative impacts of the outdated data, so it tends to produce satisfying tracking results in nonstationary environments. The performances of RA-OSELM are evaluated and compared with other representative algorithms with synthetic and real data sets, and the experimental results indicate that the proposed algorithm has better adaptive tracking capability with stronger robustness than its counterparts for predicting nonstationary data streams with outliers. © The Author(s) 2019.
DA  - 2019///
PY  - 2019
DO  - 10.1177/1748302619895421
VL  - 13
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077068373&doi=10.1177%2f1748302619895421&partnerID=40&md5=dab463c5fa13a54eca254b6991b625a8
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Learning algorithms
KW  - E-learning
KW  - Forecasting
KW  - Knowledge acquisition
KW  - Online sequential extreme learning machine
KW  - Statistics
KW  - Variable forgetting factors
KW  - M-estimation
KW  - Nonstationary data
KW  - nonstationary data streams
KW  - outliers
KW  - variable forgetting factor
ER  - 

TY  - CONF
TI  - Clinical safety incident taxonomy performance on C4.5 decision tree and random forest
AU  - Gupta, J.
AU  - Patrick, J.
AU  - Poon, S.
T2  - Studies in Health Technology and Informatics
AB  - The paper applies an artificial intelligence centered method to classify 12 clinical safety incident (CSI) classes. The paper aims to establish a taxonomy that classifies the CSI reports into their correct classes automatically and with high accuracy. The study investigates feasibility of applying the C4.5 decision tree (DT) classifier and the random forest (RF) classifier for this purpose. The classifiers were trained using randomly selected 3600 CSIs from an Incident Information Management System (IIMS) used by seven hospitals. The taxonomies investigated were the Generic Reference Model (GRM) and the World Health Organization (WHO) patient safety classification. The classifiers trained 13 GRM CSI classes and 9 WHO CSI classes using a bag-of-words approach. The overall taxonomies performance on the RF classifier was better than on the DT classifier. The performance achieved by the classifier applying the WHO taxonomy was better than the GRM taxonomy. Four of the five poorly performing classes in the GRM taxonomy significantly improved their performance on changing the taxonomy. To improve the WHO taxonomy performance the improved WHO (WHO-I) taxonomy was built by adding a new class that did not exist in WHO but existed in GRM. The performance of the RF classifier applied to the WHO-I taxonomy further improved. © 2019 The authors and IOS Press. This article is published online with Open Access by IOS Press and distributed under the terms of the Creative Commons Attribution Non-Commercial License 4.0 (CC BY-NC 4.0).
DA  - 2019///
PY  - 2019
DO  - 10.3233/SHTI190777
VL  - 266
SP  - 83
EP  - 88
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070951792&doi=10.3233%2fSHTI190777&partnerID=40&md5=b0512e70a66257ab71da989582e388b6
DB  - Scopus
KW  - Decision trees
KW  - Artificial Intelligence
KW  - artificial intelligence
KW  - Artificial intelligence
KW  - Decision tree
KW  - Data mining
KW  - Machine Learning
KW  - taxonomy
KW  - Learning systems
KW  - adult
KW  - controlled study
KW  - female
KW  - human
KW  - Humans
KW  - male
KW  - randomized controlled trial
KW  - major clinical study
KW  - patient safety
KW  - risk management
KW  - Risk Management
KW  - random forest
KW  - drug safety
KW  - Health
KW  - Patient safety
KW  - Random forests
KW  - data mining
KW  - classifier
KW  - Information management
KW  - decision tree
KW  - electronic health record
KW  - Electronic health record
KW  - Random forest
KW  - information system
KW  - Reference modeling
KW  - feasibility study
KW  - Taxonomies
KW  - Patient Safety
KW  - C4.5 decision trees
KW  - Information management systems
KW  - Electronic health records
KW  - Decision Trees
KW  - Safety incidents
KW  - conference paper
KW  - Medical informatics
KW  - World Health Organization
KW  - Hybrid integrated circuits
ER  - 

TY  - CONF
TI  - Comparing Automated vs. Manual Data Analytic Processing of Long Duration International Space Station Post Mission Crew Feedback
AU  - Bryant, C.
AU  - Schoenstein, N.
AU  - Schuh, S.
AU  - Meza, D.
T2  - Advances in Intelligent Systems and Computing
AB  - Qualitative data collected from International Space Station (ISS) postflight crew debriefs was used to evaluate the performance of a convolutional neural network (ConvNet) model. While the ISS postflight debriefs cover a broad range of spaceflight and on-orbit operations related topics, this model was specifically trained and tested to classify debrief comments as safety related or not, based on a previously coded subset of debrief comments that were manually evaluated by human factors engineers to determine if a comment had safety implications. This evaluation revealed that a ConvNet can adequately determine whether textual debrief comments contain safety data. These methods can potentially save large amounts of manual effort on the part of human factors engineers and improve the ability to identify and act on crew knowledge that informs or identifies risk to spaceflight crew. © Springer International Publishing AG, part of Springer Nature 2019.
DA  - 2019///
PY  - 2019
DO  - 10.1007/978-3-319-93885-1_20
VL  - 786
SP  - 215
EP  - 228
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049666046&doi=10.1007%2f978-3-319-93885-1_20&partnerID=40&md5=5a92c86726f4892f556d64ddcf56ad91
DB  - Scopus
KW  - Deep learning
KW  - Machine learning
KW  - Risk management
KW  - Neural networks
KW  - Human factors
KW  - Learning systems
KW  - Data handling
KW  - Human engineering
KW  - Convolution
KW  - Convolutional neural network
KW  - Risk assessment
KW  - Safety engineering
KW  - Space stations
KW  - Risk analysis
KW  - Knowledge management
KW  - Safety-Related
KW  - Habitability
KW  - International Space stations
KW  - Long duration
KW  - Qualitative data
KW  - Qualitative data analysis
KW  - Text analytics
ER  - 

TY  - JOUR
TI  - Automatic 3D illumination-diagnosis method for large- N arrays: Robust data scanner and machine-learning feature provider
AU  - Chamarczuk, M.
AU  - Malinowski, M.
AU  - Nishitsuji, Y.
AU  - Thorbecke, J.
AU  - Koivisto, E.
AU  - Heinonen, S.
AU  - Juurela, S.
AU  - Mȩzyk, M.
AU  - Draganov, D.
T2  - Geophysics
AB  - The main issues related to passive-source reflection imaging with seismic interferometry (SI) are inadequate acquisition parameters for sufficient spatial wavefield sampling and vulnerability of surface arrays to the dominant influence of the omnipresent surface-wave sources. Additionally, long recordings provide large data volumes that require robust and efficient processing methods. We address these problems by developing a two-step wavefield evaluation and event detection (TWEED) method of body waves in recorded ambient noise. TWEED evaluates the spatiotemporal characteristics of noise recordings by simultaneous analysis of adjacent receiver lines. We test our method on synthetic data representing transient ambient-noise sources at the surface and in the deeper subsurface. We discriminate between basic types of seismic events by using three adjacent receiver lines. Subsequently, we apply TWEED to 600 h of ambient noise acquired with an approximately 1000-receiver array deployed over an active underground mine in Eastern Finland. We develop the detection of body-wave events related to mine blasts and other routine mining activities using a representative 1 h noise panel. Using TWEED, we successfully detect 1093 body-wave events in the full data set. To increase the computational efficiency, we use slowness parameters derived from the first step of TWEED as input to a support vector machine (SVM) algorithm. Using this approach, we detect 94% of the TWEED-evaluated body-wave events indicating the possibility to limit the illumination analysis to only one step, and therefore increase the time efficiency at the price of lower detection rate. However, TWEED on a small volume of the recorded data followed by SVM on the rest of the data could be efficiently used for a quick and robust (real-time) scanning for body-wave energy in large data volumes for subsequent application of SI for retrieval of reflections. © 2019 Society of Exploration Geophysicists.
DA  - 2019///
PY  - 2019
DO  - 10.1190/geo2018-0504.1
VL  - 84
IS  - 3
SP  - Q13
EP  - Q25
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063082744&doi=10.1190%2fgeo2018-0504.1&partnerID=40&md5=8bc1bd5086904f6469c820ed9c5a0918
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Support vector machines
KW  - algorithm
KW  - support vector machine
KW  - seismic tomography
KW  - Computational efficiency
KW  - Mining
KW  - Lighting
KW  - Acoustic noise
KW  - Seismology
KW  - mining
KW  - arrays
KW  - illumination
KW  - Support vector machine algorithm
KW  - data acquisition
KW  - seismic data
KW  - ambient noise
KW  - Acquisition parameters
KW  - geophysical array
KW  - Illumination analysis
KW  - imaging
KW  - Imaging techniques
KW  - interferometry
KW  - Interferometry
KW  - Seismic interferometries
KW  - seismic reflection
KW  - Simultaneous analysis
KW  - Slowness parameters
KW  - Spatiotemporal characteristics
KW  - Surface waves
KW  - three-dimensional modeling
KW  - Wave energy conversion
KW  - wave field
ER  - 

TY  - JOUR
TI  - An exploration of machine learning methods for robust boredom classification using EEG and GSR data
AU  - Seo, J.
AU  - Laine, T.H.
AU  - Sohn, K.-A.
T2  - Sensors (Switzerland)
AB  - In recent years, affective computing has been actively researched to provide a higher level of emotion-awareness. Numerous studies have been conducted to detect the user’s emotions from physiological data. Among a myriad of target emotions, boredom, in particular, has been suggested to cause not only medical issues but also challenges in various facets of daily life. However, to the best of our knowledge, no previous studies have used electroencephalography (EEG) and galvanic skin response (GSR) together for boredom classification, although these data have potential features for emotion classification. To investigate the combined effect of these features on boredom classification, we collected EEG and GSR data from 28 participants using off-the-shelf sensors. During data acquisition, we used a set of stimuli comprising a video clip designed to elicit boredom and two other video clips of entertaining content. The collected samples were labeled based on the participants’ questionnaire-based testimonies on experienced boredom levels. Using the collected data, we initially trained 30 models with 19 machine learning algorithms and selected the top three candidate classifiers. After tuning the hyperparameters, we validated the final models through 1000 iterations of 10-fold cross validation to increase the robustness of the test results. Our results indicated that a Multilayer Perceptron model performed the best with a mean accuracy of 79.98% (AUC: 0.781). It also revealed the correlation between boredom and the combined features of EEG and GSR. These results can be useful for building accurate affective computing systems and understanding the physiological properties of boredom. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2019///
PY  - 2019
DO  - 10.3390/s19204561
VL  - 19
IS  - 20
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073657062&doi=10.3390%2fs19204561&partnerID=40&md5=f291bc960226bf08c6fc9e0067d05b03
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - Machine Learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Classification (of information)
KW  - adult
KW  - female
KW  - human
KW  - Humans
KW  - male
KW  - Male
KW  - questionnaire
KW  - Surveys and Questionnaires
KW  - young adult
KW  - Young Adult
KW  - procedures
KW  - Surveys
KW  - Adult
KW  - Female
KW  - receiver operating characteristic
KW  - Machine learning methods
KW  - discriminant analysis
KW  - Discriminant Analysis
KW  - Electroencephalography
KW  - Classification
KW  - Data acquisition
KW  - EEG
KW  - Electrophysiology
KW  - area under the curve
KW  - Sensors
KW  - Area Under Curve
KW  - ROC Curve
KW  - Sensor
KW  - Video cameras
KW  - Galvanic skin response
KW  - electroencephalography
KW  - electrodermal response
KW  - 10-fold cross-validation
KW  - Affective Computing
KW  - boredom
KW  - Boredom
KW  - Emotion
KW  - Emotion classification
KW  - Galvanic Skin Response
KW  - GSR
KW  - Physiological properties
ER  - 

TY  - JOUR
TI  - Data-Enabled Advancement of Computation in Engineering: A Robust Machine Learning Approach to Accelerating Variational Methods in Electromagnetics and Other Disciplines
AU  - Key, C.
AU  - Notaros, B.M.
T2  - IEEE Antennas and Wireless Propagation Letters
AB  - In this letter, we propose and demonstrate a data-driven machine learning-based approach to accelerate the finite element method (FEM), method of moments (MoM), finite difference (FD) method, and related variational methods, while maintaining the attractive properties that have allowed such methods to dominate computational science and engineering fields like computational electromagnetics. We use a neural network to predict a set of macro basis functions for a given problem, using only the solution to an extremely coarse description of the problem as input. We then solve the problem using the predicted macro basis. Unlike some existing methods, ours does not rely on the direct prediction of the solution. We show that our macro basis function approach corrects errors in the raw prediction of the network, achieving a far more accurate solution. Results are presented for a class of finite element scattering problems, with error statistics presented from 1000 validation examples and compared to standard and naïve approaches. These results suggest the described macro basis function approach is superior to machine learning approaches that directly predict the solution. Meanwhile, our method achieves comparable accuracy to the full solution while requiring only a fraction of the degrees of freedom. © 2002-2011 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/LAWP.2020.2973937
VL  - 19
IS  - 4
SP  - 626
EP  - 630
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083784439&doi=10.1109%2fLAWP.2020.2973937&partnerID=40&md5=b98a5bc700b8f7734c00b7d87614f832
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - neural networks
KW  - Learning algorithms
KW  - Forecasting
KW  - Machine learning approaches
KW  - Finite element method
KW  - Degrees of freedom (mechanics)
KW  - Functions
KW  - Electromagnetics
KW  - Computational electromagnetics
KW  - Computational electromagnetics (CEM)
KW  - Computational science and engineerings
KW  - Direct prediction
KW  - Error statistics
KW  - finite element method (FEM)
KW  - macro basis functions
KW  - Macro basis functions
KW  - Method of moments
KW  - method of moments (MoM)
KW  - Method of moments (MOM)
KW  - Scattering problems
KW  - variational methods
KW  - Variational methods
ER  - 

TY  - JOUR
TI  - Selective ensemble of uncertain extreme learning machine for pattern classification with missing features
AU  - Jing, S.
AU  - Wang, Y.
AU  - Yang, L.
T2  - Artificial Intelligence Review
AB  - Ensemble learning is an effective technique to improve performance and stability compared to single classifiers. This work proposes a selective ensemble classification strategy to handle missing data classification, where an uncertain extreme learning machine with probability constraints is used as individual (or base) classifiers. Then, three selective ensemble frameworks are developed to optimize ensemble margin distributions and aggregate individual classifiers. The first two are robust ensemble frameworks with the proposed loss functions. The third is a sparse ensemble classification framework with the zero-norm regularization, to automatically select the required individual classifiers. Moreover, the majority voting method is applied to produce ensemble classifier for missing data classification. We demonstrate some important properties of the proposed loss functions such as robustness, convexity and Fisher consistency. To verify the validity of the proposed methods for missing data, numerical experiments are implemented on benchmark datasets with missing feature values. In experiments, missing features are first imputed by using expectation maximization algorithm. Numerical experiments are simulated in filled datasets. With different probability lower bounds of classification accuracy, experimental results under different proportion of missing values show that the proposed ensemble methods have better or comparable generalization compared to the traditional methods in handling missing-value data classifications. © 2020, Springer Nature B.V.
DA  - 2020///
PY  - 2020
DO  - 10.1007/s10462-020-09836-3
VL  - 53
IS  - 8
SP  - 5881
EP  - 5905
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084039712&doi=10.1007%2fs10462-020-09836-3&partnerID=40&md5=9f0386ef00088277fc4ad3a5527ce717
DB  - Scopus
KW  - Machine learning
KW  - uncertainty
KW  - Data handling
KW  - Classification (of information)
KW  - Knowledge acquisition
KW  - Image segmentation
KW  - Extreme learning machine
KW  - Robustness
KW  - Classification accuracy
KW  - Numerical methods
KW  - DC programming
KW  - Maximum principle
KW  - Missing data
KW  - Expectation-maximization algorithms
KW  - Probability constraints
KW  - Ensemble classification
KW  - Handling missing values
KW  - Individual classifiers
KW  - Selective ensemble classifications
ER  - 

TY  - JOUR
TI  - A distributionally robust area under curve maximization model
AU  - Ma, W.
AU  - Lejeune, M.A.
T2  - Operations Research Letters
AB  - Area under ROC curve (AUC) is a performance measure for classification models. We propose new distributionally robust AUC models (DR-AUC) that rely on the Kantorovich metric and approximate AUC with the hinge loss function, and derive convex reformulations using duality. The DR-AUC models outperform deterministic AUC and support vector machine models and have superior worst-case out-of-sample performance, thereby showing their robustness. The results are encouraging since the numerical experiments are conducted with small-size training sets conducive to low out-of-sample performance. © 2020 Elsevier B.V.
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.orl.2020.05.012
VL  - 48
IS  - 4
SP  - 460
EP  - 466
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085273855&doi=10.1016%2fj.orl.2020.05.012&partnerID=40&md5=42c90efb1dbdda064b9e0dc063d4f808
DB  - Scopus
KW  - Machine learning
KW  - Support vector machines
KW  - Classification models
KW  - Loss functions
KW  - Distributionally robust optimization
KW  - Training sets
KW  - Operations research
KW  - Wasserstein distance
KW  - Support vector machine models
KW  - Numerical experiments
KW  - Performance measure
KW  - Area under roc curve (AUC)
KW  - Area under the curve
KW  - Kantorovich metric
ER  - 

TY  - CONF
TI  - AI as ally in hazard analysis
AU  - Garvin, T.
AU  - Kimbleton, S.
T2  - 2020 AIChE Virtual Spring Meeting and 16th Global Congress on Process Safety
AB  - Hazard analysis techniques have been around for many years, and have proven effective in the prevention of incidents and no doubt the saving of lives. Process Hazard Analysis (PHA) is now fairly robust and regulated, focused on overarching risks associated with the safe handling of hazardous materials and approaches to engineer-out such risks. Occupational Hazard Analysis (OHA) is keenly focused on human activity, and personal protection in hazardous working conditions. Both approaches are critical - but are often carried out separately, by different parts of an organization, which could result in an incomplete picture of the full set of operational risks in the field. Developing a holistic picture of both past and present dangers calls for a deep exploration of evidence. HAZOPs, PHA's, incident records and investigations provide expert analysis of hazards and mitigating strategies. Near-miss reports and safety observations add a large amount of information as well; the reporting frequency of these "leading indicators" can be both a blessing and a curse, as time and available resources constrain the ability to analyze and detect hazard signals within. As important as analyzing the historical record is for lessons learned, the more recent observations could indicate new hazards or highlight concerning trends. These could feed valuable "real time" information back to operations and maintenance teams to improve risk assessments and task planning. Enter artificial intelligence (AI) as a means to analyze the large amount of written hazard analyses, reports and observations to quickly extract insights around hazardous conditions, activities, incident causes and risk mitigation measures. Trained to understand concepts and contexts in both process and personal safety, AI can provide a natural-language information exploration environment for scanning thousands of documents in seconds and present common themes and related records. Not unlike us humans, AI learns from the past, informs the present and can help reduce risks in the future. © 2020 AIChE Virtual Spring Meeting and 16th Global Congress on Process Safety. All rights reserved.
DA  - 2020///
PY  - 2020
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106035308&partnerID=40&md5=f5d5f787aa22bef83c6a97726b4af4ac
DB  - Scopus
KW  - Safety
KW  - Artificial intelligence
KW  - Risk assessment
KW  - Hazards
KW  - Springs (components)
KW  - Natural languages
KW  - Leading indicators
KW  - Ai
KW  - Safe handling
KW  - Historical records
KW  - Occupational hazards
KW  - Operational risks
KW  - Operations and maintenance
KW  - Personal protection
KW  - Process hazard analysis
KW  - Artificial_intelligence
KW  - Hse
KW  - Machine_learning
KW  - Text_analytics
KW  - Unstructured_data
ER  - 

TY  - CONF
TI  - Applying Machine Learning to a Conventional Data Processing Task: A Quantitative Evaluation
AU  - Pree, W.
AU  - Hoerbinger, F.
T2  - ACM International Conference Proceeding Series
AB  - Though machine learning (ML) can be applied to a wide spectrum of applications, it has been hardly used and evaluated in the context of conventional data processing tasks. Such conventional data processing tasks are characterized by a set of calculations that follow strict rules, such as in accounting or banking applications. This paper quantitatively evaluates how software which is automatically generated by ML methods and tools compares to software programmed by hand. The assessment of poker hands according to Texas Hold'em rules is a representative example for conventional data processing tasks, because of the various exceptions how to assess and compare hands. For some hand values, the rank (two, three, ... king, ace) of the cards is relevant and the suit (club, diamond, heart, spade) irrelevant, and vice versa. This paper shows how an accuracy of 100% can be achieved for assessing poker hands according to Texas Hold'em rules, with a small set of labeled training data compared to the number of possible hands. We also evaluate quantitatively the effect of the labeling quality on accuracy. © 2020 ACM.
DA  - 2020///
PY  - 2020
DO  - 10.1145/3383972.3384042
SP  - 111
EP  - 115
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085932238&doi=10.1145%2f3383972.3384042&partnerID=40&md5=8661993e76bb347293acdaecd4f2335a
DB  - Scopus
KW  - Machine learning
KW  - robustness
KW  - convolutional neural networks
KW  - neural networks
KW  - Data handling
KW  - Quality control
KW  - supervised learning
KW  - Computer software
KW  - Automatically generated
KW  - Labeled training data
KW  - data labeling
KW  - feed-forward neural networks
KW  - labeling quality
KW  - Quantitative evaluation
KW  - Texas Hold'em
KW  - Wide spectrum
ER  - 

TY  - CONF
TI  - Data-led learning: Using natural language processing (NLP) and machine learning to learn from construction site safety failures
AU  - Baker, H.
AU  - Smith, S.
AU  - Masterton, G.
AU  - Hewlett, B.
T2  - ARCOM 2020 - Association of Researchers in Construction Management, 36th Annual Conference 2020 - Proceedings
AB  - Failures happen. Innumerable sources stress the importance of learning from these mistakes. However, within the construction industry, there is heavy reliance on learning from case-studies of catastrophic events and a lack of attention to the more frequent, lower consequence and yet repetitive failures. These smaller failures can have huge cumulative impact, not to mention their effects on the individual(s) involved. The Health and Safety Executive in their 2018 Annual Report estimated that safety injuries on site cost £490M to the UK economy. Part of this historic inattention is due to difficulties in analysis and sense-making of these failures. While information is collected about the failure event, the data tends to be in the form of free text, which is notoriously difficult to analyse. To begin addressing this, we present an attribute-based method which uses Natural Language Processing (NLP) and Machine Learning to structure text data collected after a safety failure on-site, including near misses and incidents. This structured data allows systematic analysis of these data to improve construction site practices and facilitate data driven decision-making that will reduce safety incidents. Using descriptions from 2345 safety reports, provided by a UK based construction company, we manually refine a set of attribute-based event descriptors from the text descriptions of the incidents and train an NLP model to automatically predict these in new descriptions. As well as presenting a working example of this method, factors affecting the prediction accuracy were also explored. This critique found four aspects which need deliberate consideration in application of NLP to construction safety text. These are (1) the number of attributes; (2) data class imbalance; (3) inclusion of near-miss data as well as incident reports; and (4) algorithm selection and optimisation. This method also anonymises the reports, allowing potential industry-wide data sharing and learning. © 2020 Association of Researchers in Construction Management.
DA  - 2020///
PY  - 2020
SP  - 356
EP  - 365
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096961633&partnerID=40&md5=2521ea7c5e88117decc8f8474cef482c
DB  - Scopus
KW  - Safety
KW  - Machine learning
KW  - Decision making
KW  - AI
KW  - Natural language processing systems
KW  - NAtural language processing
KW  - Natural language processing (NLP)
KW  - Construction industry
KW  - Project management
KW  - Algorithm selection
KW  - Data driven decision
KW  - Failure (mechanical)
KW  - Prediction accuracy
KW  - Data Sharing
KW  - Construction companies
KW  - Construction site safety
KW  - Health and safety executives
KW  - Potential industries
ER  - 

TY  - JOUR
TI  - Targeting prospective customers: Robustness of machine-learning methods to typical data challenges
AU  - Simester, D.
AU  - Timoshenko, A.
AU  - Zoumpoulis, S.I.
T2  - Management Science
AB  - We investigate how firms can use the results of field experiments to optimize the targeting of promotions when prospecting for new customers. We evaluate seven widely used machine-learning methods using a series of two large-scale field experiments. The first field experiment generates a common pool of training data for each of the seven methods. We then validate the seven optimized policies provided by each method together with uniform benchmark policies in a second field experiment. The findings not only compare the performance of the targeting methods, but also demonstrate how well the methods address common data challenges. Our results reveal that when the training data are ideal, model-driven methods perform better than distance-driven methods and classification methods. However, the performance advantage vanishes in the presence of challenges that affect the quality of the training data, including the extent to which the training data captures details of the implementation setting. The challenges we study are covariate shift, concept shift, information loss through aggregation, and imbalanced data. Intuitively, the model-driven methods make better use of the information available in the training data, but the performance of these methods is more sensitive to deterioration in the quality of this information. The classification methods we tested performed relatively poorly. We explain the poor performance of the classification methods in our setting and describe how the performance of these methods could be improved. © 2019 INFORMS
DA  - 2020///
PY  - 2020
DO  - 10.1287/mnsc.2019.3308
VL  - 66
IS  - 6
SP  - 2495
EP  - 2522
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090224028&doi=10.1287%2fmnsc.2019.3308&partnerID=40&md5=91bebcd3bbc4f64623f5354de7abfb33
DB  - Scopus
KW  - Machine learning
KW  - Classification (of information)
KW  - Machine learning methods
KW  - Classification methods
KW  - Deterioration
KW  - Covariate shift
KW  - Covariate shifts
KW  - Targeting
KW  - Poor performance
KW  - Concept shift
KW  - Field experiments
KW  - Information loss
KW  - Model-driven method
KW  - Optimized policies
KW  - Prospective customers
ER  - 

TY  - CONF
TI  - Parameter Optimization for Learning-based Control of Control-Affine Systems
AU  - Lederer, A.
AU  - Capone, A.
AU  - Hirche, S.
T2  - Proceedings of Machine Learning Research
AB  - Supervised machine learning is often applied to identify system dynamics where first principle methods fail. When combining learning with control methods, probabilistic regression is typically applied to increase robustness against learning errors. Although this combination of probabilistic regression and control theory allows to formulate performance guarantees for many control techniques, the bounds are usually conservative, and cannot be employed for efficient control parameter tuning. Therefore, we reformulate the parameter tuning problem using robust optimization with performance constraints based on Lyapunov theory. By relaxing the problem through scenario optimization, we derive a with high probability optimal method for control parameter tuning. We demonstrate its flexibility and efficiency on parameter tuning problems for a feedback linearizing and a computed torque controller. © 2020 A. Lederer, A. Capone & S. Hirche.
DA  - 2020///
PY  - 2020
VL  - 120
SP  - 465
EP  - 475
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161208725&partnerID=40&md5=ebc3eb7db0c6841ecd9eeaead441e40a
DB  - Scopus
KW  - Learning systems
KW  - Supervised learning
KW  - Machine-learning
KW  - Optimization
KW  - Control theory
KW  - Data-driven control
KW  - data-driven control
KW  - control parameter tuning
KW  - Control parameter tuning
KW  - Control parameters
KW  - Parameters tuning
KW  - probabilistic machine learning
KW  - Probabilistic machine learning
KW  - Probabilistic machines
KW  - Probabilistic regression
KW  - safe learning-based control
KW  - Safe learning-based control
KW  - scenario optimization
KW  - Scenario optimizations
ER  - 

TY  - JOUR
TI  - Geometric morphometric data augmentation using generative computational learning algorithms
AU  - Courtenay, L.A.
AU  - González-Aguilera, D.
T2  - Applied Sciences (Switzerland)
AB  - The fossil record is notorious for being incomplete and distorted, frequently conditioning the type of knowledge that can be extracted from it. In many cases, this often leads to issues when performing complex statistical analyses, such as classification tasks, predictive modelling, and variance analyses, such as those used in Geometric Morphometrics. Here different Generative Adversarial Network architectures are experimented with, testing the effects of sample size and domain dimensionality on model performance. For model evaluation, robust statistical methods were used. Each of the algorithms were observed to produce realistic data. Generative Adversarial Networks using different loss functions produced multidimensional synthetic data significantly equivalent to the original training data. Conditional Generative Adversarial Networks were not as successful. The methods proposed are likely to reduce the impact of sample size and bias on a number of statistical learning applications. While Generative Adversarial Networks are not the solution to all sample-size related issues, combined with other pre-processing steps these limitations may be overcome. This presents a valuable means of augmenting geometric morphometric datasets for greater predictive visualization. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2020///
PY  - 2020
DO  - 10.3390/app10249133
VL  - 10
IS  - 24
SP  - 1
EP  - 25
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098246024&doi=10.3390%2fapp10249133&partnerID=40&md5=9e8d5486e2395f8e7cbe6c9d2f9ebbc3
DB  - Scopus
KW  - Artificial intelligence
KW  - Unsupervised learning
KW  - Generative adversarial networks
KW  - Robust statistics
KW  - Archaeological data science
ER  - 

TY  - CONF
TI  - Improving Robustness via Risk Averse Distributional Reinforcement Learning
AU  - Singh, R.
AU  - Zhang, Q.
AU  - Chen, Y.
T2  - Proceedings of Machine Learning Research
AB  - One major obstacle that precludes the success of reinforcement learning in real-world applications is the lack of robustness, either to model uncertainties or external disturbances, of the trained policies. Robustness is critical when the policies are trained in simulations instead of real world environment. In this work, we propose a risk-aware algorithm to learn robust policies in order to bridge the gap between simulation training and real-world implementation. Our algorithm is based on recently discovered distributional RL framework. We incorporate CVaR risk measure in sample based distributional policy gradients (SDPG) for learning risk-averse policies to achieve robustness against a range of system disturbances. We validate the robustness of risk-aware SDPG on multiple environments. © 2020 R. Singh, Q. Zhang & Y. Chen.
DA  - 2020///
PY  - 2020
VL  - 120
SP  - 958
EP  - 968
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160153359&partnerID=40&md5=819ea330ab2feb455bbe62ea271c4e74
DB  - Scopus
KW  - Reinforcement learning
KW  - reinforcement learning
KW  - Learning systems
KW  - Reinforcement learnings
KW  - Risk assessment
KW  - Real-world
KW  - Robustness (control systems)
KW  - Uncertainty analysis
KW  - robust reinforcement learning
KW  - Robust reinforcement learning
KW  - Risk analysis
KW  - Policy gradient
KW  - Risk averse
KW  - Risk aware
KW  - distributional reinforcement learning
KW  - Distributional reinforcement learning
KW  - Risk sensitive control
ER  - 

TY  - CONF
TI  - FairMixRep: Self-supervised Robust Representation Learning for Heterogeneous Data with Fairness constraints
AU  - Chakraborty, S.
AU  - Verma, E.
AU  - Sahoo, S.
AU  - Datta, J.
T2  - IEEE International Conference on Data Mining Workshops, ICDMW
AB  - Representation Learning in a heterogeneous space with mixed variables of numerical and categorical types has interesting challenges due to its complex feature manifold. Moreover, feature learning in an unsupervised setup, without class labels and a suitable learning loss function, adds to the problem complexity. Further, the learned representation and subsequent predictions should not reflect discriminatory behavior towards certain sensitive groups or attributes. The proposed feature map should preserve maximum variations present in the data and needs to be fair with respect to the sensitive variables. We propose, in the first phase of our work, an efficient encoder-decoder framework to capture the mixed-domain information. The second phase of our work focuses on de-biasing the mixed space representations by adding relevant fairness constraints. This ensures minimal information loss between the representations before and after the fairness-preserving projections. Both the information content and the fairness aspect of the final representation learned has been validated through several metrics where it shows excellent performance. Our work (FairMixRep) addresses the problem of Mixed Space Fair Representation learning from an unsupervised perspective and learns a Universal representation which is timely, unique and a novel research contribution. 11This paper is accepted at ICDM'2020 DLC Workshop. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ICDMW51313.2020.00069
VL  - 2020-November
SP  - 458
EP  - 463
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101347891&doi=10.1109%2fICDMW51313.2020.00069&partnerID=40&md5=ec831606edd1047b939929f22266868f
DB  - Scopus
KW  - Data mining
KW  - Fairness
KW  - Robustness
KW  - Heterogeneous data
KW  - Fair representation
KW  - Fairness constraints
KW  - Information contents
KW  - Maximum variations
KW  - Minimal information
KW  - Mixed data types
KW  - Problem complexity
KW  - Self-supervised Representation Learning
KW  - Sensitive variables
KW  - Unbiased learning
ER  - 

TY  - JOUR
TI  - Robust semi-supervised traffic sign recognition via self-training and weakly-supervised learning
AU  - Nartey, O.T.
AU  - Yang, G.
AU  - Asare, S.K.
AU  - Wu, J.
AU  - Frempong, L.N.
T2  - Sensors (Switzerland)
AB  - Traffic sign recognition is a classification problem that poses challenges for computer vision and machine learning algorithms. Although both computer vision and machine learning techniques have constantly been improved to solve this problem, the sudden rise in the number of unlabeled traffic signs has become even more challenging. Large data collation and labeling are tedious and expensive tasks that demand much time, expert knowledge, and fiscal resources to satisfy the hunger of deep neural networks. Aside from that, the problem of having unbalanced data also poses a greater challenge to computer vision and machine learning algorithms to achieve better performance. These problems raise the need to develop algorithms that can fully exploit a large amount of unlabeled data, use a small amount of labeled samples, and be robust to data imbalance to build an efficient and high-quality classifier. In this work, we propose a novel semi-supervised classification technique that is robust to small and unbalanced data. The framework integrates weakly-supervised learning and self-training with self-paced learning to generate attention maps to augment the training set and utilizes a novel pseudo-label generation and selection algorithm to generate and select pseudo-labeled samples. The method improves the performance by: (1) normalizing the class-wise confidence levels to prevent the model from ignoring hard-to-learn samples, thereby solving the imbalanced data problem; (2) jointly learning a model and optimizing pseudo-labels generated on unlabeled data; and (3) enlarging the training set to satisfy the hunger of deep learning models. Extensive evaluations on two public traffic sign recognition datasets demonstrate the effectiveness of the proposed technique and provide a potential solution for practical applications. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.
DA  - 2020///
PY  - 2020
DO  - 10.3390/s20092684
VL  - 20
IS  - 9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084356541&doi=10.3390%2fs20092684&partnerID=40&md5=b8532f7cb91228f99997cd471836e36b
DB  - Scopus
KW  - Deep learning
KW  - deep learning
KW  - Deep neural networks
KW  - convolutional neural network
KW  - Learning systems
KW  - Learning algorithms
KW  - article
KW  - human
KW  - Computer vision
KW  - Traffic signs
KW  - Semi-supervised learning
KW  - Traffic sign recognition
KW  - computer vision
KW  - classifier
KW  - Machine learning techniques
KW  - Weakly supervised learning
KW  - Self-training
KW  - Self-paced learning
KW  - attention
KW  - Semi-supervised classification
KW  - Selection algorithm
KW  - Confidence levels
KW  - Deep convolutional neural networks
KW  - hunger
KW  - Imbalanced data problems
KW  - Weakly-supervised learning
ER  - 

TY  - CONF
TI  - Robust reinforcement learning via adversarial training with Langevin dynamics
AU  - Kamalaruban, P.
AU  - Huang, Y.-T.
AU  - Hsieh, Y.-P.
AU  - Rolland, P.
AU  - Shi, C.
AU  - Cevher, V.
T2  - Advances in Neural Information Processing Systems
AB  - We introduce a sampling perspective to tackle the challenging task of training robust Reinforcement Learning (RL) agents. Leveraging the powerful Stochastic Gradient Langevin Dynamics, we present a novel, scalable two-player RL algorithm, which is a sampling variant of the two-player policy gradient method. Our algorithm consistently outperforms existing baselines, in terms of generalization across different training and testing conditions, on several MuJoCo environments. Our experiments also show that, even for objective functions that entirely ignore potential environmental shifts, our sampling approach remains highly robust in comparison to standard RL algorithms. © 2020 Neural information processing systems foundation. All rights reserved.
DA  - 2020///
PY  - 2020
VL  - 2020-December
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104088882&partnerID=40&md5=c4d1f8bdcf47f337e3c90c03ad3e14c6
DB  - Scopus
KW  - Reinforcement learning
KW  - Reinforcement learning agent
KW  - Training and testing
KW  - Stochastic systems
KW  - Gradient methods
KW  - Objective functions
KW  - Policy gradient methods
KW  - Stochastic gradient
KW  - Environmental shifts
KW  - Langevin dynamics
ER  - 

TY  - CONF
TI  - A Machine Learning-based robust approach to identify Dementia progression employing Dimensionality Reduction in Cross-Sectional MRI data
AU  - Khan, A.
AU  - Zubair, S.
T2  - Proceedings - 2020 1st International Conference of Smart Systems and Emerging Technologies, SMART-TECH 2020
AB  - Timely uncovering of various dementia stages is vital in formulating effective treatment strategies for Alzheimer disease. The high-resolution MRI can be progressively exploited in the classification of various stages of dementia that in turn help in the development of efficient therapeutic stratagems. Considering the fact that analysis of the huge volume of data is a tenacious challenge, we explored the competence of machine learning (ML) based algorithms to identify stages of dementia in inflicted patients. The employed dimensionality reduction approach relied on the cross-sectional dataset of 434 MRI sessions of 416 subjects, aged between 18 to 96 years. A five-step strategy involving Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), Neighbourhood Component Analysis (NCA), Factor Analysis (FA), and Fast Independent Component Analysis (FastICA) was developed. Next, numerous supervised machine learning algorithms were explored to classify the input data. The as-developed method attained an overall accuracy of 87 percent, which means a noteworthy improvement over the existing classical ML approach.  © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/SMART-TECH49988.2020.00060
SP  - 237
EP  - 242
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099294760&doi=10.1109%2fSMART-TECH49988.2020.00060&partnerID=40&md5=cd7015525266b4504541727e05de1b54
DB  - Scopus
KW  - machine learning
KW  - Learning systems
KW  - Supervised learning
KW  - dementia
KW  - Learning algorithms
KW  - classification
KW  - Supervised machine learning
KW  - Dimensionality reduction
KW  - Robust approaches
KW  - Turing machines
KW  - Discriminant analysis
KW  - Neurodegenerative diseases
KW  - High resolution
KW  - Alzheimer disease
KW  - Overall accuracies
KW  - Linear discriminant analysis
KW  - dimensionality reduction
KW  - Fast independent component analysis
KW  - Independent component analysis
KW  - Component analysis
ER  - 

TY  - CONF
TI  - Robust Segmentation of 3D Brain MRI Images in Cross Datasets by Integrating Supervised and Unsupervised Learning
AU  - Wang, X.
AU  - Guo, C.
AU  - Zhou, X.
T2  - 10th International Conference on Information Science and Technology, ICIST 2020
AB  - With the rapid development of machine learning technology in recent years, image segmentation technology based on supervised learning or unsupervised learning has also made important progress and achieved many successful applications, such as the applications to medical imaging in the same time. However, both supervised and unsupervised segmentation methods have their own strong and weak points. In order to address this dilemma, in this paper, we proposed a robust method for 3D image segmentation that can not only maintain the advantages of the two kinds of learning methods, but also overcome their disadvantages, by integrating supervised and unsupervised learning technologies into one method effectively. The proposed method has been applied to brain MRI image segmentation with a variety of experiments on several open 3D brain MRI datasets. Experimental results obtained in the work show that the proposed method, with strong adaptability and robustness, outperforms other state of the art segmentation approaches including both the supervised and unsupervised ones when applied to a new MRI dataset or a cross dataset without needing to be retrained by using the annotation information of the dataset. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ICIST49303.2020.9202117
SP  - 194
EP  - 201
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093973382&doi=10.1109%2fICIST49303.2020.9202117&partnerID=40&md5=672c929c5317418568c3db7753187f29
DB  - Scopus
KW  - Learning systems
KW  - State of the art
KW  - Segmentation
KW  - Image segmentation
KW  - Medical imaging
KW  - Unsupervised learning
KW  - Supervised and unsupervised learning
KW  - Engineering education
KW  - Machine learning technology
KW  - Magnetic resonance imaging
KW  - Unsupervised segmentation method
KW  - MRI
KW  - 3D image segmentation
KW  - Brain mri images
KW  - Cross Datasets
KW  - Integration of Supervised and Unsupervised Learning
KW  - Robust segmentation
KW  - Robust Segmentation
KW  - Technology-based
ER  - 

TY  - CONF
TI  - AIS-Based Vessel Trajectory Reconstruction with U-Net Convolutional Networks
AU  - Li, S.
AU  - Liang, M.
AU  - Wu, X.
AU  - Liu, Z.
AU  - Liu, R.W.
T2  - 2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics, ICCCBDA 2020
AB  - The vessel trajectory data indicated by the Automatic Identification System (AIS) is important and useful in maritime data analysis, navigational safety and maritime risk assessment. However, the raw trajectory data contains noise, missing data and other errors which can lead to a wrong conclusion. Therefore, it is essential to develop a vessel trajectory reconstruction method, which is meaningful for enhancing the applicability of vessel trajectory and improving the navigation safety. In recent years, there have been many studies about vessel trajectory reconstruction, but the performance of these methods will degrade when they are faced with curved trajectories with high loss rate. In this paper, we propose a novel trajectory reconstruction method via U-net. Benefiting from the architecture of U-net, this method makes great use of historical trajectories and takes advantage of the rich skip connections in this network which help copy low-level features to corresponding high-level features. Consequently, this method is robust to the trajectories with different sampling rates, missing points, and noisy data. In addition, the proposed method is tested and compared with cubic spline interpolation. The results show that our method is capable of higher accuracy than the cubic spline interpolation especially when the trajectories are curved and have a high loss rate. © 2020 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ICCCBDA49378.2020.9095616
SP  - 157
EP  - 161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085729794&doi=10.1109%2fICCCBDA49378.2020.9095616&partnerID=40&md5=dedaeb1ff929bd2295d83916e02dd6ad
DB  - Scopus
KW  - Machine learning
KW  - Interpolation
KW  - Risk assessment
KW  - Traffic safety
KW  - Safety engineering
KW  - Big data
KW  - U-net
KW  - Advanced Analytics
KW  - Trajectories
KW  - Cloud computing
KW  - Convolutional networks
KW  - High-level features
KW  - AIS data
KW  - Automatic identification system
KW  - Automatic identification
KW  - Cubic-spline interpolation
KW  - Low-level features
KW  - Navigation safety
KW  - Navigational safeties
KW  - Trajectory reconstruction
ER  - 

TY  - CONF
TI  - Towards explaining adversarial examples phenomenon in artificial neural networks
AU  - Barati, R.
AU  - Safabakhsh, R.
AU  - Rahmati, M.
T2  - Proceedings - International Conference on Pattern Recognition
AB  - In this paper, we study the adversarial examples existence and adversarial training from the standpoint of convergence and provide evidence that pointwise convergence in ANNs can explain these observations. The main contribution of our proposal is that it relates the objective of the evasion attacks and adversarial training with concepts already defined in learning theory. Also, we extend and unify some of the other proposals in the literature and provide alternative explanations on the observations made in those proposals. Through different experiments, we demonstrate that the framework is valuable in the study of the phenomenon and is applicable to real-world problems. © 2021 IEEE
DA  - 2020///
PY  - 2020
DO  - 10.1109/ICPR48806.2021.9412367
SP  - 7036
EP  - 7042
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110413344&doi=10.1109%2fICPR48806.2021.9412367&partnerID=40&md5=f2bfa20c2935e4c7aacad297153ce745
DB  - Scopus
KW  - Pattern recognition
KW  - Neural networks
KW  - Supervised learning
KW  - Robustness
KW  - Adversarial attack
KW  - Real-world problem
KW  - Artificial neural network
KW  - Adversarial training
KW  - Classifier
KW  - Learning theory
KW  - Learning Theory
KW  - Pointwise convergence
ER  - 

TY  - JOUR
TI  - Stochastic parallel extreme artificial hydrocarbon networks: An implementation for fast and robust supervised machine learning in high-dimensional data
AU  - Ponce, H.
AU  - de Campos Souza, P.V.
AU  - Guimarães, A.J.
AU  - González-Mora, G.
T2  - Engineering Applications of Artificial Intelligence
AB  - Artificial hydrocarbon networks (AHN) – a supervised learning method inspired on organic chemical structures and mechanisms – have shown improvements in predictive power and interpretability in comparison with other well-known machine learning models. However, AHN are very time-consuming that are not able to deal with large data until now. In this paper, we introduce the stochastic parallel extreme artificial hydrocarbon networks (SPE-AHN), an algorithm for fast and robust training of supervised AHN models in high-dimensional data. This training method comprises a population-based meta-heuristic optimization with defined individual encoding and objective function related to the AHN-model, an implementation in parallel-computing, and a stochastic learning approach for consuming large data. We conducted three experiments with synthetic and real data sets to validate the training execution time and performance of the proposed algorithm. Experimental results demonstrated that the proposed SPE-AHN outperforms the original-AHN method, increasing the speed of training more than 10,000x times in the worst case scenario. Additionally, we present two case studies in real data sets for solar-panel deployment prediction (regression problem), and human falls and daily activities classification in healthcare monitoring systems (classification problem). These case studies showed that SPE-AHN improves the state-of-the-art machine learning models in both engineering problems. We anticipate our new training algorithm to be useful in many applications of AHN like robotics, finance, medical engineering, aerospace, and others, in which large amounts of data (e.g. big data) is essential. © 2019 Elsevier Ltd
DA  - 2020///
PY  - 2020
DO  - 10.1016/j.engappai.2019.103427
VL  - 89
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076620125&doi=10.1016%2fj.engappai.2019.103427&partnerID=40&md5=1a78d200d323d19852c6f69577f0b8f5
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Supervised learning
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Machine learning models
KW  - Big data
KW  - Extreme learning machine
KW  - Supervised machine learning
KW  - Heuristic methods
KW  - Clustering algorithms
KW  - Stochastic models
KW  - Stochastic systems
KW  - Classification
KW  - Population statistics
KW  - Regression
KW  - Hydrocarbons
KW  - Biomedical engineering
KW  - Supervised learning methods
KW  - Extreme learning machines
KW  - Meta-heuristic optimizations
KW  - Organic chemicals
KW  - Parallel computing
KW  - Parallel processing systems
KW  - Stochastic learning
KW  - Synthetic and real data
ER  - 

TY  - CONF
TI  - Intelligent data acquisition and processing using wavelet neural-networks
AU  - Kulakov, A.
AU  - Davcev, D.
T2  - Proceedings of the Third Workshop - 2005 IEEE Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, IDAACS 2005
AB  - Most of the problems for data management in today's wireless sensor networks were already dealt with during the past thirty years of the artificial neural-networks tradition and that kind of algorithms can be easily implemented to wireless sensor network platforms. These problems include the need for simple parallel distributed computation, possibility for distributed storage, fault-tolerance and in some cases the possibility of auto-classification of sensor readings. We will present data acquisition through hierarchical two-level architecture with algorithms which will use wavelets for initial data-processing of the sensory inputs and neural-networks which use unsupervised learning for categorization of the sensory inputs. They are tested on a data obtained from a set of 4 motes, equipped with seven sensors each. ©2005 IEEE.
DA  - 2005///
PY  - 2005
DO  - 10.1109/IDAACS.2005.283031
SP  - 491
EP  - 494
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-43549108354&doi=10.1109%2fIDAACS.2005.283031&partnerID=40&md5=c29ae29e144a5873dbf3b197e3383471
DB  - Scopus
KW  - Intelligent systems
KW  - Neural networks
KW  - Algorithms
KW  - Neural-networks
KW  - Data acquisition
KW  - Wireless sensor networks
KW  - Data clustering
KW  - Data robustness
KW  - Unsupervised pattern learning
KW  - Wavelets
ER  - 

TY  - JOUR
TI  - Metabolomics and machine learning: Explanatory analysis of complex metabolome data using genetic programming to produce simple, robust rules
AU  - Kell, D.B.
T2  - Molecular Biology Reports
DA  - 2002///
PY  - 2002
DO  - 10.1023/A:1020342216314
VL  - 29
IS  - 1-2
SP  - 237
EP  - 241
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036042222&doi=10.1023%2fA%3a1020342216314&partnerID=40&md5=f980726d6ec61ae72a0cbd6cad1bbc56
DB  - Scopus
KW  - Animals
KW  - Software
KW  - article
KW  - metabolism
KW  - animal
KW  - multivariate analysis
KW  - computer program
KW  - Gene Expression Profiling
KW  - gene expression profiling
KW  - gene
KW  - Genes, Plant
KW  - Multivariate Analysis
KW  - Organisms, Genetically Modified
KW  - plant
KW  - Plants
KW  - salicylic acid
KW  - Salicylic Acid
KW  - transgenic organism
ER  - 

TY  - CONF
TI  - Context analysis for semantic mapping of data sources Using a multi-strategy machine learning approach
AU  - Idrissi, Y.B.
AU  - Vachon, J.
T2  - ICEIS 2005 - Proceedings of the 7th International Conference on Enterprise Information Systems
AB  - Be it on a webwide or inter-entreprise scale, data integration has become a major necessity urged by the expansion of the Internet and of its widespread use for communication between business actors. However, since data sources are often heterogeneous, their integration remains an expensive procedure. Indeed, this task requires prior semantic alignment of all the data sources concepts. Doing this alignment manually is quite laborious especially if there is a large number of concepts to be matched. Various solutions have been proposed attempting to automatize this step. This paper introduces a new framework for data sources alignment which integrates context analysis to multi-strategy machine learning. Although their adaptability and extensibility are appreciated, actual machine learning systems often suffer from the low quality and the lack of diversity of training data sets. To overcome this limitation, we introduce a new notion called "informational context" of data sources. We therefore briefly explain the architecture of a context analyser to be integrated into a learning system combining multiple strategies to achieve data source mapping.
DA  - 2005///
PY  - 2005
SP  - 445
EP  - 448
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649295361&partnerID=40&md5=d50d25acf201c43e7eb7186d491f5290
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Data handling
KW  - Machine-learning
KW  - Information systems
KW  - Mapping
KW  - Semantic mapping
KW  - Semantic web
KW  - Semantic Web
KW  - Alignment
KW  - Context analysis
KW  - Data source
KW  - Data sources alignment
KW  - Multi-strategy
ER  - 

TY  - CONF
TI  - Application of neural networks to biological data mining: A case study in protein sequence classification
AU  - Wang, J.T.L.
AU  - Ma, Q.
AU  - Shasha, D.
AU  - Wu, C.H.
T2  - Proceeding of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
AB  - Biological data mining aims to extract significant information from DNA, RNA and proteins. The significant information may refer to motifs, functional sites, clustering and classification rules. This paper presents an example of biological data mining: The classification of protein sequences using neural networks. We propose new techniques to extract features from protein data and use them in combination with the Bayesian neural network to classify protein sequences obtained from the PIR protein database maintained at the National Biomedical Research Foundation. To evaluate the performance of the proposed approach, we compare it with other protein classifiers built based on sequence alignment and machine learning methods. Experimental results show the high precision of the proposed classifier and the complementarity of the tools studied in the paper.
DA  - 2000///
PY  - 2000
SP  - 305
EP  - 309
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034592803&partnerID=40&md5=f53a2ccc9f7c326555c4effeff090e9d
DB  - Scopus
KW  - Machine learning
KW  - Feature extraction
KW  - Data mining
KW  - Neural networks
KW  - Learning systems
KW  - Database systems
KW  - Proteins
KW  - RNA
KW  - Bioinformatics
KW  - Sequence alignment
KW  - DNA
KW  - Biological data mining
KW  - Feature extraction from protein data
KW  - Protein sequence classification
ER  - 

TY  - JOUR
TI  - A weighted support vector machine for data classification
AU  - Yang, X.
AU  - Song, Q.
AU  - Wang, Y.
T2  - International Journal of Pattern Recognition and Artificial Intelligence
AB  - This paper presents a weighted support vector machine (WSVM) to improve the outlier sensitivity problem of standard support vector machine (SVM) for two-class data classification. The basic idea is to assign different weights to different data points such that the WSVM training algorithm learns the decision surface according to the relative importance of data points in the training data set. The weights used in WSVM are generated by a robust fuzzy clustering algorithm, kernel-based possibilistic c-means (KPCM) algorithm, whose partition generates relative high values for important data points but low values for outliers. Experimental results indicate that the proposed method reduces the effect of outliers and yields higher classification rate than standard SVM does when outliers exist in the training data set. © World Scientific Publishing Company.
DA  - 2007///
PY  - 2007
DO  - 10.1142/S0218001407005703
VL  - 21
IS  - 5
SP  - 961
EP  - 976
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547816043&doi=10.1142%2fS0218001407005703&partnerID=40&md5=bc2bc254a141412f5d82eb713e954374
DB  - Scopus
KW  - Support vector machines
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Clustering algorithms
KW  - Fuzzy clustering
KW  - Problem solving
KW  - Possibilistic C-means
KW  - Data classification
KW  - Kernel based learning
KW  - Robust fuzzy clustering
ER  - 

TY  - CONF
TI  - Efficient mining of contrast patterns and their applications to classification
AU  - Ramamohanarao, K.
AU  - Bailey, J.
AU  - Fan, H.
T2  - Proceedings - 3rd International Conference on Intelligent Sensing and Information Processing, ICISIP 2005
AB  - Data mining is one of the most important areas in the 21 century with many wide ranging applications. These include medicine, finance, commerce and engineering. Pattern mining is amongst the most important and challenging techniques employed in data mining. Patterns are collections of items which satisfy certain properties. Emerging Patterns are those whose frequencies change significantly from one dataset to another. They represent strong contrast knowledge and have been shown to be very successful for constructing accurate and robust classifiers. In this paper, we examine various kinds of contrast patterns. We also investigate efficient pattern mining techniques and discuss how to exploit patterns to construct effective classifiers. © 2005 IEEE.
DA  - 2005///
PY  - 2005
DO  - 10.1109/ICISIP.2005.1619410
SP  - 39
EP  - 47
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011961896&doi=10.1109%2fICISIP.2005.1619410&partnerID=40&md5=5891a1533622ce464db2269e7e29e407
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Learning systems
KW  - Supervised learning
KW  - Frequency
KW  - Robustness (control systems)
KW  - Robustness
KW  - Statistics
KW  - Gene expression
KW  - Industry
KW  - Business
KW  - Contrast patterns
KW  - Emerging patterns
KW  - Finance
KW  - Item sets
KW  - Itemsets
KW  - Pattern mining
KW  - Strong contrast
KW  - Wide-ranging applications
ER  - 

TY  - JOUR
TI  - Robust machine learning applied to astronomical data sets. I. Star-galaxy classification of the sloan digital sky survey DR3 using decision trees
AU  - Ball, N.M.
AU  - Brunner, R.J.
AU  - Myers, A.D.
AU  - Tcheng, D.
T2  - Astrophysical Journal
AB  - We provide classifications for all 143 million nonrepeat photometric objects in the Third Data Release of the SDSS using decision trees trained on 477,068 objects with SDSS spectroscopic data. We demonstrate that these star/galaxy classifications are expected to be reliable for approximately 22 million objects with r ≲ 20. The general machine learning environment Data-to-Knowledge and supercomputing resources enabled extensive investigation of the decision tree parameter space. This work presents the first public release of objects classified in this way for an entire SDSS data release. The objects are classified as either galaxy, star, or nsng (neither star nor galaxy), with an associated probability for each class. To demonstrate how to effectively make use of these classifications, we perform several important tests. First, we detail selection criteria within the probability space defined by the three classes to extract samples of stars and galaxies to a given completeness and efficiency. Second, we investigate the efficacy of the classifications and the effect of extrapolating from the spectroscopic regime by performing blind tests on objects in the SDSS, 2dFGRS, and 2QZ surveys. Given the photometric limits of our spectroscopic training data, we effectively begin to extrapolate past our star-galaxy training set at r ∼ 18. By comparing the number counts of our training sample with the classified sources, however, we find that our efficiencies appear to remain robust to r ∼ 20. As a result, we expect our classifications to be accurate for 900,000 galaxies and 6.7 million stars and remain robust via extrapolation for a total of 8.0 million galaxies and 13.9 million stars. © 2006. The American Astronomical Society. All rights reserved.
DA  - 2006///
PY  - 2006
DO  - 10.1086/507440
VL  - 650
IS  - 1 I
SP  - 497
EP  - 509
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248212193&doi=10.1086%2f507440&partnerID=40&md5=33be8642b3f162f83906c6fb31be9b27
DB  - Scopus
KW  - Surveys
KW  - Astronomical data bases: miscellaneous
KW  - Catalogs
KW  - Methods: data analysis
ER  - 

TY  - JOUR
TI  - On a strategy to develop robust and simple tariffs from motor vehicle insurance data
AU  - Christmann, A.
T2  - Acta Mathematicae Applicatae Sinica
AB  - The goals of this paper are twofold: we describe common features in data sets from motor vehicle insurance companies and we investigate a general strategy which exploits the knowledge of such features. The results of the strategy are a basis to develop insurance tariffs. We use a nonparametric approach based on a combination of kernel logistic regression and ε-support vector regression which both have good robustness properties. The strategy is applied to a data set from motor vehicle insurance companies. © Springer-Verlag 2005.
DA  - 2005///
PY  - 2005
DO  - 10.1007/s10255-005-0229-8
VL  - 21
IS  - 2
SP  - 193
EP  - 208
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-18244386711&doi=10.1007%2fs10255-005-0229-8&partnerID=40&md5=b317bb19b94e231700b56820bd800aa4
DB  - Scopus
KW  - Data mining
KW  - Robustness
KW  - Support vector regression
KW  - Statistical machine learning
KW  - Kernel logistic regression
ER  - 

TY  - JOUR
TI  - Performance assessment of kernel density clustering for gene expression profile data
AU  - Shu, G.
AU  - Zeng, B.
AU  - Chen, Y.P.
AU  - Smith, O.H.
T2  - Comparative and Functional Genomics
AB  - Kernel density smoothing techniques have been used in classification or supervised learning of gene expression profile (GEP) data, but their applications to clustering or unsupervised learning of those data have not been explored and assessed. Here we report a kernel density clustering method for analysing GEP data and compare its performance with the three most widely-used clustering methods: hierarchical clustering, K-means clustering, and multivariate mixture model-based clustering. Using several methods to measure agreement, between-cluster isolation, and within-cluster coherence, such as the Adjusted Rand Index, the Pseudo F test, the r2 test, and the profile plot, we have assessed the effectiveness of kernel density clustering for recovering clusters, and its robustness against noise on clustering both simulated and real GEP data. Our results show that the kernel density clustering method has excellent performance in recovering clusters from simulated data and in grouping large real expression profile data sets into compact and well-isolated clusters, and that it is the most robust clustering method for analysing noisy expression profile data compared to the other three methods assessed. Copyright © 2003 John Wiley & Sons, Ltd.
DA  - 2003///
PY  - 2003
DO  - 10.1002/cfg.290
VL  - 4
IS  - 3
SP  - 287
EP  - 299
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037712008&doi=10.1002%2fcfg.290&partnerID=40&md5=190ed1a44fb284b53718587426482522
DB  - Scopus
KW  - simulation
KW  - article
KW  - controlled study
KW  - priority journal
KW  - intermethod comparison
KW  - mathematical computing
KW  - Robustness
KW  - cluster analysis
KW  - Gene expression
KW  - Unsupervised learning
KW  - signal noise ratio
KW  - multivariate analysis
KW  - Clustering analysis
KW  - genetic model
KW  - gene expression profiling
KW  - Noisy data
KW  - Expression profile
KW  - gene cluster
KW  - gene isolation
KW  - Kernel density
KW  - Pseudo F
KW  - Pseudo t test
KW  - r2
KW  - Rand Index
KW  - Smoothing
ER  - 

TY  - JOUR
TI  - Machine Learning and Robust Data Mining
AU  - Croux, C.
AU  - Gallopoulos, E.
AU  - Van Aelst, S.
AU  - Zha, H.
T2  - Computational Statistics and Data Analysis
DA  - 2007///
PY  - 2007
DO  - 10.1016/j.csda.2007.06.013
VL  - 52
IS  - 1
SP  - 151
EP  - 154
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548271759&doi=10.1016%2fj.csda.2007.06.013&partnerID=40&md5=c4ce14add9211dfa770c1459d0d741ba
DB  - Scopus
ER  - 

TY  - CONF
TI  - Trainable, scalable summarization using robust NLP and machine learning
AU  - Aone, C.
AU  - Okurowski, M.E.
AU  - Gorlinsky, J.
T2  - Proceedings of the Annual Meeting of the Association for Computational Linguistics
AB  - We describe a trainable and scalable summarization system which utilizes features derived from information retrieval, information extraction, and NLP techniques and on-line resources. The system combines these features using a trainable feature combiner learned from summary examples through a machine learning algorithm. We demonstrate system scalability by reporting results on the best combination of summarization features for different document sources. We also present preliminary results from a task-based evaluation on summarization output usability. © COLING-ACL 1998.All right reserved.
DA  - 1998///
PY  - 1998
VL  - 1
SP  - 62
EP  - 66
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086076212&partnerID=40&md5=d895afaf8b1ae708f8275e7914ae4b89
DB  - Scopus
KW  - Machine learning
KW  - Machine learning algorithms
KW  - Learning algorithms
KW  - Machine-learning
KW  - Natural language processing systems
KW  - Search engines
KW  - Computational linguistics
KW  - Online resources
KW  - Summarization systems
KW  - System scalability
KW  - Task-based
ER  - 

TY  - JOUR
TI  - A novel ensemble machine learning for robust microarray data classification
AU  - Peng, Y.
T2  - Computers in Biology and Medicine
AB  - Microarray data analysis and classification has demonstrated convincingly that it provides an effective methodology for the effective diagnosis of diseases and cancers. Although much research has been performed on applying machine learning techniques for microarray data classification during the past years, it has been shown that conventional machine learning techniques have intrinsic drawbacks in achieving accurate and robust classifications. This paper presents a novel ensemble machine learning approach for the development of robust microarray data classification. Different from the conventional ensemble learning techniques, the approach presented begins with generating a pool of candidate base classifiers based on the gene sub-sampling and then the selection of a sub-set of appropriate base classifiers to construct the classification committee based on classifier clustering. Experimental results have demonstrated that the classifiers constructed by the proposed method outperforms not only the classifiers generated by the conventional machine learning but also the classifiers generated by two widely used conventional ensemble learning methods (bagging and boosting). © 2005 Elsevier Ltd. All rights reserved.
DA  - 2006///
PY  - 2006
DO  - 10.1016/j.compbiomed.2005.04.001
VL  - 36
IS  - 6
SP  - 553
EP  - 573
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646181069&doi=10.1016%2fj.compbiomed.2005.04.001&partnerID=40&md5=d15ffeba97957067981c73c3ede72de3
DB  - Scopus
KW  - Artificial Intelligence
KW  - Machine learning
KW  - Learning systems
KW  - Diagnosis
KW  - Algorithms
KW  - Classification (of information)
KW  - article
KW  - Humans
KW  - classification
KW  - methodology
KW  - priority journal
KW  - Robustness (control systems)
KW  - Reproducibility of Results
KW  - intermethod comparison
KW  - learning
KW  - Classification
KW  - data analysis
KW  - Ensemble learning
KW  - Neoplasms
KW  - Diseases
KW  - sampling
KW  - microarray analysis
KW  - Microarray Analysis
KW  - Genes
KW  - Diagnosis, Computer-Assisted
KW  - Classifiers
KW  - Gene Expression Profiling
KW  - Microarray data
KW  - machine
KW  - gene
KW  - gene cluster
KW  - Base Sequence
KW  - Classifications
KW  - Data recording
KW  - DNA base
KW  - Experimental results
KW  - experimentation
KW  - genetic analysis
ER  - 

TY  - JOUR
TI  - Robust machine learning applied to astronomical data sets. II. Quantifying photometric redshifts for quasars using instance-based learning
AU  - Ball, N.M.
AU  - Brunner, R.J.
AU  - Myers, A.D.
AU  - Strand, N.E.
AU  - Alberts, S.L.
AU  - Tcheng, D.
AU  - Llorà, X.
T2  - Astrophysical Journal
AB  - We apply instance-based machine learning in the form of a k-nearest neighbor algorithm to the task of estimating photometric redshifts for 55,746 objects spectroscopically classified as quasars in the Fifth Data Release of the Sloan Digital Sky Survey. We compare the results obtained to those from an empirical color-redshift relation (CZR). In contrast to previously published results using CZRs, we find that the instance-based photometric redshifts are assigned with no regions of catastrophic failure. Remaining outliers are simply scattered about the ideal relation, in a manner similar to the pattern seen in the optical for normal galaxies at redshifts z ≲ 1. The instance-based algorithm is trained on a representative sample of the data and pseudo-blind-tested on the remaining unseen data. The variance between the photometric and spectroscopic redshifts is σ2 = 0.123 ± 0.002 (compared to σ2 = 0.265 ± 0.006 for the CZR), and 54.9% ± 0.7%, 73.3% ± 0.6%, and 80.7% ± 0.3% of the objects are within Δz < 0.1, 0.2, and 0.3, respectively. We also match our sample to the Second Data Release of the Galaxy Evolution Explorer legacy data, and the resulting 7642 objects show a further improvement, giving a variance of σ1 = 0.054 ± 0.005, with 70.8% ± 1.2%, 85.8% ± 1.0%, and 90.8% ± 0.7% of objects within Δz < 0.1,0.2, and 0.3. We show that the improvement is indeed due to the extra information provided by GALEX, by training on the same data set using purely SDSS photometry, which has a variance of σ2 = 0.090 ± 0.007. Each set of results represents a realistic standard for application to further data sets for which the spectra are representative. © 2007. The American Astronomical Society. All rights reserved.
DA  - 2007///
PY  - 2007
DO  - 10.1086/518362
VL  - 663
IS  - 2 I
SP  - 774
EP  - 780
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547433063&doi=10.1086%2f518362&partnerID=40&md5=5055fe60588282371c17650ebe4e4a93
DB  - Scopus
KW  - Catalogs
KW  - Methods: data analysis
KW  - Cosmology: miscellaneous
KW  - Quasars: general
ER  - 

TY  - CHAP
TI  - Big data applications in food safety and quality
AU  - Pollard, S.
AU  - Namazi, H.
AU  - Khaksar, R.
T2  - Encyclopedia of Food Chemistry
AB  - Big data and data analytics has evolved to become an indispensable facet across all industries, enabling new advances in management strategies, product development, and data insight that has never before been possible. Traditionally, scientists have approached scientific questions by formulating a hypothetical model and carefully designing experiments to accept or reject the proposed model. The more modern statistical method, fueled by the big data revolution, is to refrain from relying on hypothetical models and allow the data itself to identify pertinent variables and patterns that shape the observed outcome. © 2019 Elsevier Inc. All rights reserved.
DA  - 2018///
PY  - 2018
SP  - 356
EP  - 363
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065134431&doi=10.1016%2fB978-0-08-100596-5.21839-8&partnerID=40&md5=6901b1e445a982e7519ab11674a407b8
DB  - Scopus
KW  - Machine learning
KW  - Blockchain
KW  - Big data
KW  - Food safety
KW  - Food quality
KW  - Microbiome
KW  - Predictive microbiology
ER  - 

TY  - JOUR
TI  - Robust machine learning applied to astronomical data sets. III. Probabilistic photometric redshifts for galaxies and quasars in the SDSS and GALEX
AU  - Ball, N.M.
AU  - Brunner, R.J.
AU  - Myers, A.D.
AU  - Strand, N.E.
AU  - Alberts, S.L.
AU  - Tcheng, D.
T2  - Astrophysical Journal
AB  - We apply machine learning in the form of a nearest neighbor instance-based algorithm (NN) to generate full photometric redshift probability density functions (PDFs) for objects in the Fifth Data Release of the Sloan Digital Sky Survey (SDSS DR5). We use a conceptually simple but novel application of NN to generate the PDFs, perturbing the object colors by their measurement error and using the resulting instances of nearest neighbor distributions to generate numerous individual redshifts. When the redshifts are compared to existing SDSS spectroscopic data, we find that the mean value of each PDF has a dispersion between the photometric and spectroscopic redshift consistent with other machine learning techniques, being σ = 0.0207 ± 0.0001 for main sample galaxies to r < 17.77 mag, σ = 0.0243 ± 0.0002 for luminous red galaxies to r ≲ 19.2 mag, and σ = 0.343 ± 0.005 for quasars to i < 20:3 mag. The PDFs allow the selection of subsets with improved statistics. For quasars, the improvement is dramatic: for those with a single peak in their probability distribution, the dispersion is reduced from 0.343 to σ = 0.117 ± 0.010, and the photometric redshift is within 0.3 of the spectroscopic redshift for 99.3% ± 0.1% of the objects. Thus, for this optical quasar sample, we can virtually eliminate "catastrophic" photometric redshift estimates. In addition to the SDSS sample, we incorporate ultraviolet photometry from the Third Data Release of the Galaxy Evolution Explorer All-Sky Imaging Survey (GALEX AIS GR3) to create PDFs for objects seen in both surveys. For quasars, the increased coverage of the observed-frame UV of the SED results in significant improvement over the full SDSS sample, with σ = 0.234 ± 0.010. We demonstrate that this improvement is genuine and not an artifact of the SDSS-GALEX matching process. © 2008. The American Astronomical Society. All rights reserved.
DA  - 2008///
PY  - 2008
DO  - 10.1086/589646
VL  - 683
IS  - 1
SP  - 12
EP  - 21
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-49449118343&doi=10.1086%2f589646&partnerID=40&md5=a41e7aee165ab9ee127f53f7612c5758
DB  - Scopus
KW  - Catalogs
KW  - Methods: data analysis
KW  - Cosmology: miscellaneous
KW  - Quasars: general
ER  - 

TY  - CONF
TI  - Does distributionally robust supervised learning give robust classifiers?
AU  - Hu, W.
AU  - Niu, G.
AU  - Sato, I.
AU  - Sugiyama, M.
T2  - 35th International Conference on Machine Learning, ICML 2018
AB  - Distributionally Robust Supervised Learning (DRSL) is necessary for building reliable machine learning systems. When machine learning is deployed in the real world, its performance can be significantly degraded because test data may follow a different distribution from training data. DRSL with/-divergences explicitly considers the worst-case distribution shift by minimizing the adversarially reweighted training loss. In this paper, we analyze this DRSL, focusing on the classification scenario. Since the DRSL is explicitly formulated for a distribution shift scenario, we naturally expect it to give a robust classifier that can aggressively handle shifted distributions. However, surprisingly, we prove that the DRSL just ends up giving a classifier that exactly fits the given training distribution, which is too pessimistic. This pessimism comes from two sources: the particular losses used in classification and the fact that the variety of distributions to which the DRSL tries to be robust is too wide. Motivated by our analysis, we propose simple DRSL that overcomes this pessimism and empirically demonstrate its effectiveness. © 2018 by authors.All right reserved.
DA  - 2018///
PY  - 2018
VL  - 5
SP  - 3220
EP  - 3249
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057279674&partnerID=40&md5=290395557bb261b75f67b472cfddea3d
DB  - Scopus
KW  - Artificial intelligence
KW  - Training data
KW  - Supervised learning
KW  - Real-world
KW  - Different distributions
KW  - Test data
KW  - Two sources
ER  - 

TY  - JOUR
TI  - Robust Automated Detection of Microstructural White Matter Degeneration in Alzheimer's Disease Using Machine Learning Classification of Multicenter DTI Data
AU  - Dyrba, M.
AU  - Ewers, M.
AU  - Wegrzyn, M.
AU  - Kilimann, I.
AU  - Plant, C.
AU  - Oswald, A.
AU  - Meindl, T.
AU  - Pievani, M.
AU  - Bokde, A.L.W.
AU  - Fellgiebel, A.
AU  - Filippi, M.
AU  - Hampel, H.
AU  - Klöppel, S.
AU  - Hauenstein, K.
AU  - Kirste, T.
AU  - Teipel, S.J.
T2  - PLoS ONE
AB  - Diffusion tensor imaging (DTI) based assessment of white matter fiber tract integrity can support the diagnosis of Alzheimer's disease (AD). The use of DTI as a biomarker, however, depends on its applicability in a multicenter setting accounting for effects of different MRI scanners. We applied multivariate machine learning (ML) to a large multicenter sample from the recently created framework of the European DTI study on Dementia (EDSD). We hypothesized that ML approaches may amend effects of multicenter acquisition. We included a sample of 137 patients with clinically probable AD (MMSE 20.6±5.3) and 143 healthy elderly controls, scanned in nine different scanners. For diagnostic classification we used the DTI indices fractional anisotropy (FA) and mean diffusivity (MD) and, for comparison, gray matter and white matter density maps from anatomical MRI. Data were classified using a Support Vector Machine (SVM) and a Naïve Bayes (NB) classifier. We used two cross-validation approaches, (i) test and training samples randomly drawn from the entire data set (pooled cross-validation) and (ii) data from each scanner as test set, and the data from the remaining scanners as training set (scanner-specific cross-validation). In the pooled cross-validation, SVM achieved an accuracy of 80% for FA and 83% for MD. Accuracies for NB were significantly lower, ranging between 68% and 75%. Removing variance components arising from scanners using principal component analysis did not significantly change the classification results for both classifiers. For the scanner-specific cross-validation, the classification accuracy was reduced for both SVM and NB. After mean correction, classification accuracy reached a level comparable to the results obtained from the pooled cross-validation. Our findings support the notion that machine learning classification allows robust classification of DTI data sets arising from multiple scanners, even if a new data set comes from a scanner that was not part of the training sample. © 2013 Dyrba et al.
DA  - 2013///
PY  - 2013
DO  - 10.1371/journal.pone.0064925
VL  - 8
IS  - 5
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878582129&doi=10.1371%2fjournal.pone.0064925&partnerID=40&md5=66a5eb973347b04e8816cd80403bf7e1
DB  - Scopus
KW  - machine learning
KW  - Artificial Intelligence
KW  - automation
KW  - article
KW  - controlled study
KW  - female
KW  - human
KW  - Humans
KW  - male
KW  - Male
KW  - aged
KW  - Aged
KW  - Female
KW  - Middle Aged
KW  - disease classification
KW  - major clinical study
KW  - retrospective study
KW  - sensitivity and specificity
KW  - Reproducibility of Results
KW  - Bayes theorem
KW  - support vector machine
KW  - Principal Component Analysis
KW  - Brain
KW  - Retrospective Studies
KW  - nuclear magnetic resonance imaging
KW  - validation process
KW  - Alzheimer disease
KW  - Alzheimer Disease
KW  - Mini Mental State Examination
KW  - Case-Control Studies
KW  - central nervous system disease
KW  - diagnostic accuracy
KW  - brain mapping
KW  - analytical parameters
KW  - diffusion tensor imaging
KW  - Diffusion Tensor Imaging
KW  - fractional anisotropy
KW  - gray matter
KW  - Leukoencephalopathies
KW  - mean diffusivity
KW  - nuclear magnetic resonance scanner
KW  - white matter degeneration
ER  - 

TY  - CONF
TI  - About analysis and robust classification of searchlight fMRI-data using machine learning classifiers
AU  - Lange, M.
AU  - Kastner, M.
AU  - Villmann, T.
T2  - Proceedings of the International Joint Conference on Neural Networks
AB  - In the present paper we investigate the analysis of functional magnetic resonance image (fMRI) data based on voxel response analysis. All voxels in local spatial area (volume) of a considered voxel form its so-called searchlight. The searchlight for a presented task is taken as a complex pattern. Task dependent discriminant analysis of voxel is then performed by assessment of the discrimination behavior of the respective searchlight pattern for a given task. Classification analysis of these patterns is usually done using linear support vector machines (linSVMs) as a machine learning approach or another statistical classifier like linear discriminant classifier. The test classification accuracy determining the task sensitivity is interpreted as the discrimination ability of the related voxel. However, frequently, the number of voxels contributing to a searchlight is much larger than the number of available pattern samples in classification learning, i.e. the dimensionality of patterns is higher than the number of samples. Therefore, the respective underlying mathematical classification problem has not an unique solution such that a certain solution obtained by the machine learning classifier contains arbitrary (random) components. For this situation, the generalization ability of the classifier may drop down. We propose in this paper another data processing approach to reduce this problem. In particular, we reformulate the classification problem within the searchlight. Doing so, we avoid the dimensionality problem: We obtain a mathematically well-defined classification problem, such that generalization ability of a trained classifier is kept high. Hence, a better stability of the task discrimination is obtained. Additionally, we propose the utilization of generalized learning vector quantizers as an alternative machine learning classifier system compared to SVMs, to improve further the stability of the classifier model due to decreased model complexity. © 2013 IEEE.
DA  - 2013///
PY  - 2013
DO  - 10.1109/IJCNN.2013.6706990
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893611823&doi=10.1109%2fIJCNN.2013.6706990&partnerID=40&md5=5b7adf7bb62a902f89a972a952dfb2d9
DB  - Scopus
KW  - Neural networks
KW  - Learning systems
KW  - Machine learning approaches
KW  - Classification accuracy
KW  - Discriminant analysis
KW  - Classification analysis
KW  - Magnetic resonance imaging
KW  - Data processing
KW  - Linear Support Vector Machines
KW  - Classification learning
KW  - Functional magnetic resonance images (fMRI)
KW  - Learning classifier system
KW  - Linear discriminant classifier
KW  - Searchlights
ER  - 

TY  - JOUR
TI  - The Automatic Image Annotation Based on Monte-Carlo Data Set Balance and Robustness Incremental Extreme Learning Machine
AU  - Ke, X.
AU  - Zou, J.-W.
AU  - Du, M.-Z.
AU  - Zhou, M.-K.
T2  - Tien Tzu Hsueh Pao/Acta Electronica Sinica
AB  - Aiming at the problem that the traditional image annotation model has long training time, sensitive to low-frequency words and other issues, this paper proposes a new automatic image annotation method based on Monte-Carlo dataset balance and robustness incremental extreme learning machine. First of all, training images of the public image library are segmented into different areas by this model and corresponding seed markup words are selected after segmentation, the areas are matched automatically based on comprehensive distance algorithm and the different keywords represent different areas. Then, for the huge difference of different annotated words' sizes in the public database, the Monte Carlo data set equalization algorithm is proposed to make the data size of each annotated word much the same. And a multi-scale feature fusion algorithm is proposed to extract effective features from different annotated images. Finally, the robustness incremental limit learning is proposed to improve the accuracy of the discriminant model for the problems of the consistency of the hidden layer nodes and the input vector weights existing in the traditional limit learning machine. The experimental results show that: compared with traditional algorithms of image automatic annotation, the methods proposed in this paper can implement the automatic image annotation quickly, and it is robust to low frequency words, and it is higher than most popular models of automatic image annotation in terms of average recall rate, average accuracy rate, comprehensive value and so on. © 2017, Chinese Institute of Electronics. All right reserved.
DA  - 2017///
PY  - 2017
DO  - 10.3969/j.issn.0372-2112.2017.12.014
VL  - 45
IS  - 12
SP  - 2925
EP  - 2935
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046118666&doi=10.3969%2fj.issn.0372-2112.2017.12.014&partnerID=40&md5=76fa168f2098aa222643c8eb2ff73057
DB  - Scopus
KW  - Learning systems
KW  - Knowledge acquisition
KW  - Image segmentation
KW  - Extreme learning machine
KW  - Monte Carlo methods
KW  - Image annotation
KW  - Image analysis
KW  - Image fusion
KW  - Hidden layer nodes
KW  - Image retrieval
KW  - Automatic annotation
KW  - Automatic image annotation
KW  - Discriminant models
KW  - Equalization algorithms
KW  - Incremental extreme learning machine
KW  - Monte Carlo data
KW  - Monte-Carlo data set balance
KW  - Multi-scale feature fusion
KW  - Multi-scale features
ER  - 

TY  - JOUR
TI  - A machine learning-based algorithm for processing massive data collected from the mechanical components of movable bridges
AU  - Catbas, F.N.
AU  - Malekzadeh, M.
T2  - Automation in Construction
AB  - This paper presents a machine learning algorithm for processing of massive data collected from the mechanical components of movable bridges. The proposed approach consists of training and monitoring phases. The training phase was focused on the extracting statistical features and conducting cross correlation analysis (CCA) and robust regression analysis (RRA). The monitoring phase included tracking of errors associated with the derived models. The main goal was to analyze the efficiency of the developed system for health monitoring of the bridge mechanical components such as gearbox, motor and rack and pinion. To this aim, Sunrise Movable Bridge in Ft. Lauderdale, Florida was selected and instrumented. A comprehensive database was collected from the sensors installed on the mechanical and structural components of the Sunrise Bridge for about 4 years. The collected data were utilized to assess the performance of the algorithm under baseline and different common damage scenarios. Based on the results, the proposed health monitoring system has a satisfactory performance for the detection of the damage scenarios caused by leakage and lack of sufficient oil in gearbox, as well as bolt removal from rack and pinion. The introduced algorithm can be regarded as a valuable tool for the management and interpretation of the massive (big) data collected for structural health monitoring (SHM) of movable bridges. © 2016 Elsevier B.V.
DA  - 2016///
PY  - 2016
DO  - 10.1016/j.autcon.2016.02.008
VL  - 72
SP  - 269
EP  - 278
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003972483&doi=10.1016%2fj.autcon.2016.02.008&partnerID=40&md5=cd3cd6fb0f9ff457e4ae191232260f2c
DB  - Scopus
KW  - Artificial intelligence
KW  - Learning systems
KW  - Data handling
KW  - Algorithms
KW  - Learning algorithms
KW  - Machine-learning
KW  - Regression analysis
KW  - Machine components
KW  - Monitoring
KW  - Metadata
KW  - Damage detection
KW  - Bridges
KW  - Structural health monitoring
KW  - Statistical features
KW  - Gears
KW  - Cross-correlation analysis
KW  - Health monitoring system
KW  - Maintenance monitoring
KW  - Massive SHM data
KW  - Mechanical components
KW  - Movable bridge
KW  - Movable bridges
KW  - Robust regression analysis
KW  - Structural component
KW  - Structural health monitoring (SHM)
ER  - 

TY  - CONF
TI  - Automatically incorporating new sources in keyword search-based data integration
AU  - Talukdar, P.P.
AU  - Ives, Z.G.
AU  - Pereira, F.
T2  - Proceedings of the ACM SIGMOD International Conference on Management of Data
AB  - Scientific data offers some of the most interesting challenges in data integration today. Scientific fields evolve rapidly and accumulate masses of observational and experimental data that needs to be annotated, revised, interlinked, and made available to other scientists. From the perspective of the user, this can be a major headache as the data they seek may initially be spread across many databases in need of integration. Worse, even if users are given a solution that integrates the current state of the source databases, new data sources appear with new data items of interest to the user. Here we build upon recent ideas for creating integrated views over data sources using keyword search techniques, ranked answers, and user feedback [32] to investigate how to automatically discover when a new data source has content relevant to a user's view - in essence, performing automatic data integration for incoming data sets. The new architecture accommodates a variety of methods to discover related attributes, including label propagation algorithms from the machine learning community [2] and existing schema matchers [11]. The user may provide feedback on the suggested new results, helping the system repair any bad alignments or increase the cost of including a new source that is not useful. We evaluate our approach on actual bioinformatics schemas and data, using state-of-the-art schema matchers as components. We also discuss how our architecture can be adapted to more traditional settings with a mediated schema. Copyright 2010 ACM.
DA  - 2010///
PY  - 2010
DO  - 10.1145/1807167.1807211
SP  - 387
EP  - 398
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954711911&doi=10.1145%2f1807167.1807211&partnerID=40&md5=ca72ce8ebd690d5db82c797c779ccb6d
DB  - Scopus
KW  - machine learning
KW  - Learning systems
KW  - user feedback
KW  - Data handling
KW  - Learning algorithms
KW  - Machine-learning
KW  - Bioinformatics
KW  - Alignment
KW  - data integration
KW  - Data integration
KW  - Integration
KW  - Data flow analysis
KW  - keyword search
KW  - Keyword search
KW  - schema alignment
KW  - schema matching
KW  - Schema matching
KW  - User feedback
ER  - 

TY  - JOUR
TI  - A dynamic data stream classification algorithm based on MapReduce
AU  - Feng, L.
AU  - Yao, Y.
AU  - Chen, F.
AU  - Jin, B.
T2  - Dalian Ligong Daxue Xuebao/Journal of Dalian University of Technology
AB  - There are three difficulties in real-time dynamic data stream classification: real-time processing of massive data, tracking of concept drift and model updates, model's stability and robustness. To solve these problems, extreme support vector machine (ESVM) is combined with MapReduce framework, and a forgetting factor robust ESVM algorithm (FFR-ESVM) is proposed. The proposed algorithm amends the residuals by constructing a residual matrix, while improves the effect of new samples by forgetting factor. Experimental results show that the proposed algorithm can rapidly and effectively classify dynamic data stream, and the results are stable and less affected by noise interference.
DA  - 2014///
PY  - 2014
DO  - 10.7511/dllgxb201404014
VL  - 54
IS  - 4
SP  - 461
EP  - 468
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907089141&doi=10.7511%2fdllgxb201404014&partnerID=40&md5=00f56056013efbce3f8df4c92d322b3b
DB  - Scopus
KW  - Robustness
KW  - Forgetting factor
KW  - Incremental learning
KW  - Data stream classification
KW  - Extreme support vector machine (ESVM)
KW  - MapReduce
ER  - 

TY  - JOUR
TI  - Robust spike-train learning in spike-event based weight update
AU  - Shrestha, S.B.
AU  - Song, Q.
T2  - Neural Networks
AB  - Supervised learning algorithms in a spiking neural network either learn a spike-train pattern for a single neuron receiving input spike-train from multiple input synapses or learn to output the first spike time in a feedforward network setting. In this paper, we build upon spike-event based weight update strategy to learn continuous spike-train in a spiking neural network with a hidden layer using a dead zone on–off based adaptive learning rate rule which ensures convergence of the learning process in the sense of weight convergence and robustness of the learning process to external disturbances. Based on different benchmark problems, we compare this new method with other relevant spike-train learning algorithms. The results show that the speed of learning is much improved and the rate of successful learning is also greatly improved. © 2017 Elsevier Ltd
DA  - 2017///
PY  - 2017
DO  - 10.1016/j.neunet.2017.08.010
VL  - 96
SP  - 33
EP  - 46
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029784802&doi=10.1016%2fj.neunet.2017.08.010&partnerID=40&md5=25266cf05345dfa4308f726e6399a79f
DB  - Scopus
KW  - simulation
KW  - Neural networks
KW  - Neurons
KW  - Learning systems
KW  - Supervised learning
KW  - Algorithms
KW  - Learning algorithms
KW  - controlled study
KW  - human
KW  - Humans
KW  - algorithm
KW  - Article
KW  - priority journal
KW  - biological model
KW  - physiology
KW  - artificial neural network
KW  - Neural Networks (Computer)
KW  - benchmarking
KW  - supervised machine learning
KW  - Supervised Machine Learning
KW  - feedback system
KW  - learning algorithm
KW  - nerve cell plasticity
KW  - spiking neural network
KW  - Spiking neural network
KW  - back propagation
KW  - Robust stability
KW  - synapse
KW  - nerve cell
KW  - Models, Neurological
KW  - Spiking neural networks
KW  - action potential
KW  - Action Potentials
KW  - Adaptive learning rate
KW  - Adaptive learning rates
KW  - firing rate
KW  - membrane potential
KW  - Multilayer spike-train learning
KW  - refractory period
KW  - Spike train
KW  - spike wave
KW  - Synapses
KW  - Weight convergence
ER  - 

TY  - CONF
TI  - Fast and robust supervised learning in high dimensions using the geometry of the data
AU  - Mukherjee, U.K.
AU  - Majumdar, S.
AU  - Chatterjee, S.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - We develop a method for tracing out the shape of a cloud of sample observations, in arbitrary dimensions, called the data cloud wrapper (DCW). The DCW have strong theoretical properties, have algorithmic scalability and parallel computational features. We further use the DCW to develop a new fast, robust and accurate classification method in high dimensions, called the geometric learning algorithm (GLA). Two of the main features of the proposed algorithm are that there are no assumptions made about the geometric properties of the underlying data generating distribution, and that there are no parametric or other restrictive assumptions made either for the data or the algorithm. The proposed methods are typically faster and more robust than established classification techniques, while being comparably accurate in most cases. © Springer International Publishing Switzerland 2015.
DA  - 2015///
PY  - 2015
DO  - 10.1007/978-3-319-20910-4_9
VL  - 9165
SP  - 109
EP  - 123
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950121438&doi=10.1007%2f978-3-319-20910-4_9&partnerID=40&md5=1bddc38cdabced195d17af348b665a12
DB  - Scopus
KW  - Data mining
KW  - Algorithms
KW  - Learning algorithms
KW  - Classification methods
KW  - Geometry
KW  - Classification technique
KW  - Arbitrary dimension
KW  - Computational features
KW  - Data clouds
KW  - Geometric properties
KW  - High dimensions
ER  - 

TY  - CONF
TI  - Exact and Robust Conformal Inference Methods for Predictive Machine Learning with Dependent Data
AU  - Chernozhukov, V.
AU  - Wüthrich, K.
AU  - Zhu, Y.
T2  - Proceedings of Machine Learning Research
AB  - We extend conformal inference to general settings that allow for time series data. Our proposal is developed as a randomization method and accounts for potential serial dependence by including block structures in the permutation scheme such that the latter forms a group. As a result, the proposed method retains the exact, model-free validity when the data are i.i.d. or more generally exchangeable, similar to usual conformal inference methods. When exchangeability fails, as is the case for common time series data, the proposed approach is approximately valid under weak assumptions on the conformity score. © 2018 V. Chernozhukov, K. Wüthrich & Y. Zhu.
DA  - 2018///
PY  - 2018
VL  - 75
SP  - 732
EP  - 749
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076517408&partnerID=40&md5=601aad350364e63b68fb8c96ca4cab2f
DB  - Scopus
KW  - Machine learning
KW  - Machine-learning
KW  - Time series
KW  - Time-series data
KW  - Random processes
KW  - Randomisation
KW  - Block structures
KW  - Conformal inference
KW  - dependent data
KW  - Dependent data
KW  - Group
KW  - groups
KW  - Inference methods
KW  - permutation and randomization
KW  - Permutation and randomization
KW  - Serial dependence
ER  - 

TY  - JOUR
TI  - Robust activation function of extreme learning machine and linear dimensionality reduction in high-dimensional data
AU  - Feng, L.
AU  - Liu, S.
AU  - Zhang, J.
AU  - Wang, H.
T2  - Jisuanji Yanjiu yu Fazhan/Computer Research and Development
AB  - Extreme learning machine (ELM), with the advantage of fast training and high classification accuracy, has been widely used in practical applications (for example, face recognition) and got good result. While ELM algorithm is often severely affected by noise and outliers in high-dimensional real word datasets, which will reduce the accuracy rate of ELM. This should be attributed to the following two reasons: 1) the high dimensionalities of input samples; 2) improper selection of activation function. The two reasons above result in that the outputs of activation functions are approaching zero, which finally reduce the performance of ELM. As for the first problem, we propose a robust linear dimensionality reduction method, RAF-Global Embedding (RAF-GE), to preprocess the high dimensional data and then classify the data with ELM. While for the second one, we give an in-depth analysis of different activation function and propose a robust activation function (RAF) which can avoid the outputs of activation function approaching zero, thus it can improve the performance of RAF-GE and ELM as well. The experiment results show that the performance of face recognition method in this paper generally outperforms the comparing methods with other activation function.
DA  - 2014///
PY  - 2014
DO  - 10.7544/issn1000-1239.2014.20120943
VL  - 51
IS  - 6
SP  - 1331
EP  - 1340
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903897717&doi=10.7544%2fissn1000-1239.2014.20120943&partnerID=40&md5=4d3372dc486ea7df58eab6586f65534d
DB  - Scopus
KW  - Neural networks
KW  - Learning systems
KW  - Neural network
KW  - Knowledge acquisition
KW  - Extreme learning machine
KW  - Classification accuracy
KW  - Clustering algorithms
KW  - Face recognition
KW  - Chemical activation
KW  - Activation analysis
KW  - Activation functions
KW  - High dimensional data
KW  - High dimensionality
KW  - High-dimensional data
KW  - Face recognition methods
KW  - In-depth analysis
KW  - Linear dimensionality reduction
KW  - Robust activation function
ER  - 

TY  - JOUR
TI  - Semi-Supervised Learning for Indoor Hybrid Fingerprint Database Calibration with Low Effort
AU  - Zhou, M.
AU  - Tang, Y.
AU  - Tian, Z.
AU  - Geng, X.
T2  - IEEE Access
AB  - The interest of indoor localization based on the IEEE 802.11 wireless local area network signal increases remarkably to support pervasive computing applications, but the process of fingerprints calibration, which is point-by-point conducted manually, is time consuming and labor intensive. To address this problem, we propose to use a novel improved semi-supervised manifold alignment approach by integrating the execution characteristic function to reduce both the number of reference points (RPs) and sampling time involved in the radio map construction. Specifically, the radio map is constructed from a small number of calibrated fingerprints and a batch of user traces, which are sporadically collected in the target environment. The user traces enable to compensate for the effort of reducing the calibration cost as well as improving the effectiveness of radio map. In addition, the cubic spline interpolation approach is applied to enrich the radio map with the limited number of RPs. Extensive experiments show that the proposed approach is capable of not only reducing the effort of fingerprints calibration remarkably, but also guaranteeing the high localization accuracy. © 2013 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/ACCESS.2017.2678603
VL  - 5
SP  - 4388
EP  - 4400
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018945818&doi=10.1109%2fACCESS.2017.2678603&partnerID=40&md5=be79f13d835869b5d1880ebdd6afa4cd
DB  - Scopus
KW  - semi-supervised learning
KW  - Standards
KW  - Interpolation
KW  - Supervised learning
KW  - Semi- supervised learning
KW  - Calibration
KW  - Wireless local area networks (WLAN)
KW  - Indoor positioning systems
KW  - Ubiquitous computing
KW  - Indoor localization
KW  - Manifold alignments
KW  - manifold alignment
KW  - fingerprint database
KW  - Fingerprint database
KW  - indoor localization
KW  - WLAN
ER  - 

TY  - JOUR
TI  - GOexpress: An R/Bioconductor package for the identification and visualisation of robust gene ontology signatures through supervised learning of gene expression data
AU  - Rue-Albrecht, K.
AU  - McGettigan, P.A.
AU  - Hernández, B.
AU  - Nalpas, N.C.
AU  - Magee, D.A.
AU  - Parnell, A.C.
AU  - Gordon, S.V.
AU  - MacHugh, D.E.
T2  - BMC Bioinformatics
AB  - Background: Identification of gene expression profiles that differentiate experimental groups is critical for discovery and analysis of key molecular pathways and also for selection of robust diagnostic or prognostic biomarkers. While integration of differential expression statistics has been used to refine gene set enrichment analyses, such approaches are typically limited to single gene lists resulting from simple two-group comparisons or time-series analyses. In contrast, functional class scoring and machine learning approaches provide powerful alternative methods to leverage molecular measurements for pathway analyses, and to compare continuous and multi-level categorical factors. Results: We introduce GOexpress, a software package for scoring and summarising the capacity of gene ontology features to simultaneously classify samples from multiple experimental groups. GOexpress integrates normalised gene expression data (e.g., from microarray and RNA-seq experiments) and phenotypic information of individual samples with gene ontology annotations to derive a ranking of genes and gene ontology terms using a supervised learning approach. The default random forest algorithm allows interactions between all experimental factors, and competitive scoring of expressed genes to evaluate their relative importance in classifying predefined groups of samples. Conclusions: GOexpress enables rapid identification and visualisation of ontology-related gene panels that robustly classify groups of samples and supports both categorical (e.g., infection status, treatment) and continuous (e.g., time-series, drug concentrations) experimental factors. The use of standard Bioconductor extension packages and publicly available gene ontology annotations facilitates straightforward integration of GOexpress within existing computational biology pipelines. © 2016 Rue-Albrecht et al.
DA  - 2016///
PY  - 2016
DO  - 10.1186/s12859-016-0971-3
VL  - 17
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960360815&doi=10.1186%2fs12859-016-0971-3&partnerID=40&md5=878d37922ab8fc49b88b87aa43d6ca1f
DB  - Scopus
KW  - Decision trees
KW  - Artificial intelligence
KW  - Software
KW  - Time series analysis
KW  - Visualization
KW  - Learning systems
KW  - Supervised learning
KW  - Classification (of information)
KW  - biology
KW  - Computational Biology
KW  - procedures
KW  - software
KW  - Machine learning approaches
KW  - Gene expression
KW  - RNA
KW  - Bioinformatics
KW  - Gene ontology
KW  - Gene Ontology
KW  - supervised machine learning
KW  - Supervised Machine Learning
KW  - Supervised learning approaches
KW  - Classification
KW  - Time series
KW  - gene ontology
KW  - transcriptome
KW  - Transcriptome
KW  - Genes
KW  - Rna sequencing
KW  - Functional genomics
KW  - Microarray
KW  - Gene expression profiles
KW  - Gene ontology annotations
KW  - Gene set enrichment analysis
KW  - messenger RNA
KW  - Microarrays
KW  - RNA-sequencing
KW  - RNA, Messenger
ER  - 

TY  - CONF
TI  - Experiments in data management for wireless sensor networks
AU  - Davcev, D.
AU  - Kulakov, A.
AU  - Gancev, S.
T2  - Proceedings - 2nd Int. Conf. Sensor Technol. Appl., SENSORCOMM 2008, Includes: MESH 2008 Conf. Mesh Networks; ENOPT 2008 Energy Optim. Wireless Sensors Networks, UNWAT 2008 Under Water Sensors Systems
AB  - In this paper we present our experimental results in data management for wireless sensor networks when an adapted Fuzzy ART model of neural networks is applied. Our system provides high dimension reduction and transfer savings, sending only classified identification number instead of whole sample. The system implementation is based on MicaZ sensor motes and adapted Fuzzy ART model. It was applied in real-time environments and presents an efficient tool for monitoring and visualization of sensor data. Testing, debugging, data robustness and other implementation issues are also discussed. © 2008 IEEE.
DA  - 2008///
PY  - 2008
DO  - 10.1109/SENSORCOMM.2008.18
SP  - 191
EP  - 195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-55849131833&doi=10.1109%2fSENSORCOMM.2008.18&partnerID=40&md5=88a418ae53a4542c87868b7e6632b5f1
DB  - Scopus
KW  - Fuzzy neural networks
KW  - Neural networks
KW  - Visualization
KW  - Learning systems
KW  - Data visualization
KW  - Experiments
KW  - Neural-networks
KW  - Network management
KW  - Sensor networks
KW  - Sensors
KW  - Wireless sensor networks
KW  - Wireless telecommunication systems
KW  - Data robustness
KW  - Unsupervised pattern learning
KW  - Experimental results
KW  - High dimensions
KW  - Data managements
KW  - Data robustnesses
KW  - Fuzzy arts
KW  - Hybrid sensors
KW  - Identification numbers
KW  - Management information systems
KW  - OF sensors
KW  - Real time visualization
KW  - Sensor motes
KW  - System implementations
ER  - 

TY  - JOUR
TI  - A robust boosting algorithm for chemical modeling
AU  - Satopää, V.A.
AU  - de Veaux, R.D.
T2  - Current Analytical Chemistry
AB  - Bagging and boosting have become increasingly important ensemble methods for combining models in the data mining and machine learning literature. We review the basic ideas of these methods, propose a new robust boosting algorithm based on a non-convex loss function and compare the performance of these methods to both simulated and real data sets with and without contamination. © 2012 Bentham Science Publishers.
DA  - 2012///
PY  - 2012
DO  - 10.2174/157341112800392599
VL  - 8
IS  - 2
SP  - 254
EP  - 265
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860434134&doi=10.2174%2f157341112800392599&partnerID=40&md5=06e30ab2e8ab5a07ef1870dfd5c96d97
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Robust
KW  - Bagging
KW  - Boosting
ER  - 

TY  - JOUR
TI  - It’s time to scale the science in the social sciences
AU  - Raghavan, P.
T2  - Big Data and Society
AB  - The social sciences are at a remarkable confluence of events. Advances in computing have made it feasible to analyze data at the scale of the population of the world. How can we combine the depth of inquiry in the social sciences with the scale and robustness of statistics and computer science? Can we decompose complex questions in the social sciences into simpler, more robustly testable hypotheses? We discuss these questions and the role of machine learning in the social sciences. © The Author(s) 2014 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav.
DA  - 2014///
PY  - 2014
DO  - 10.1177/2053951714532240
VL  - 1
IS  - 1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946137348&doi=10.1177%2f2053951714532240&partnerID=40&md5=10d0627fa145fc9ecb650436245456df
DB  - Scopus
KW  - machine learning
KW  - Data analysis
KW  - computational aesthetics
KW  - robust methodology
KW  - scalable science
KW  - social sciences
ER  - 

TY  - CONF
TI  - Robust channel coding strategies for machine learning data
AU  - Mazooji, K.
AU  - Sala, F.
AU  - Van Den Broeck, G.
AU  - Dolecek, L.
T2  - 54th Annual Allerton Conference on Communication, Control, and Computing, Allerton 2016
AB  - Two important recent trends are the proliferation of learning algorithms along with the massive increase of data stored on unreliable storage mediums. These trends impact each other; noisy data can have an undesirable effect on the results provided by learning algorithms. Although traditional tools exist to improve the reliability of data storage devices, these tools operate at a different abstraction level and therefore ignore the data application, leading to an inefficient use of resources. In this paper we propose taking the operation of learning algorithms into account when deciding how to best protect data. Specifically, we examine several learning algorithms that operate on data that is stored on noisy mediums and protected by error-correcting codes with a limited budget of redundancy; we develop a principled way to allocate resources so that the harm on the output of the learning algorithm is minimized. © 2016 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/ALLERTON.2016.7852288
SP  - 609
EP  - 616
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015234127&doi=10.1109%2fALLERTON.2016.7852288&partnerID=40&md5=4777eb04e46b9119eefbaa1df993f73f
DB  - Scopus
KW  - Artificial intelligence
KW  - Machine Learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Optimization
KW  - Statistics
KW  - Digital storage
KW  - Virtual storage
KW  - Budget control
KW  - Channel coding
KW  - Codes (symbols)
KW  - Abstraction level
KW  - Channel Coding
KW  - Data application
KW  - Data storage devices
KW  - Error correcting code
KW  - Recent trends
KW  - Robust channel coding
KW  - Storage medium
KW  - Undesirable effects
ER  - 

TY  - CONF
TI  - A Robust Self-Organizing Approach to Effectively Clustering Incomplete Data
AU  - Chau, V.T.N.
T2  - Proceedings - 2015 IEEE International Conference on Knowledge and Systems Engineering, KSE 2015
AB  - In the real world, incomplete data are often encountered and located anywhere in a data set. Such incomplete data make a data clustering task more challenging. It's common practice to eliminate incomplete data from the input data set. If there are a large number of missing values, ignoring them may lead to the data insufficiency and ineffectiveness of the data clustering task. Hence, incomplete data clustering has been considered in many research works with many different approaches based on the well-known existing clustering algorithms such as k-means, fuzzy c-means, the self-organizing map (SOM), mean shift, etc. However, few of them have examined both effectiveness and robustness of the incomplete data clustering algorithms. Some of them are not practical due to a lot of parameters in hybrid approaches and/or cannot handle incomplete data which appear in any object at any dimension. In contrast, this paper aims at a SOM-based incomplete data clustering algorithm, iS nps, which is a robust and effective solution to clustering incomplete data in a simple but practical approach. Is nps can do clustering on incomplete data as well as estimate incomplete data using the nearest prototype strategy in an iterative manner. As compared to several different existing approaches, our proposed algorithm can produce the clusters of good quality and a better approximation of incomplete data via the experiments on benchmark data sets. © 2015 IEEE.
DA  - 2016///
PY  - 2016
DO  - 10.1109/KSE.2015.11
SP  - 150
EP  - 155
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964723137&doi=10.1109%2fKSE.2015.11&partnerID=40&md5=d35101e780f00bdfb125cdc59dd8e77f
DB  - Scopus
KW  - robustness
KW  - Algorithms
KW  - Systems engineering
KW  - Robustness (control systems)
KW  - Benchmarking
KW  - Clustering algorithms
KW  - Iterative methods
KW  - Hybrid approach
KW  - Approximation algorithms
KW  - Unsupervised learning
KW  - unsupervised learning
KW  - Cluster analysis
KW  - Conformal mapping
KW  - Self organizing maps
KW  - Benchmark data
KW  - self-organizing map
KW  - Incomplete data
KW  - Effective solution
KW  - Data clustering
KW  - incomplete data clustering
KW  - Missing values
KW  - nearest prototype
KW  - Nearest prototype
KW  - Self-organizing approaches
ER  - 

TY  - CONF
TI  - Robust web data extraction: A novel approach based on minimum cost script edit model
AU  - Liu, D.
AU  - Wang, X.
AU  - Yan, Z.
AU  - Li, Q.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - Many documents share common HTML tree structure on script generated websites, allowing us to effectively extract interested information from deep webpage by wrappers. Since tree structure evolves over time, the wrappers break frequently and need to be re-learned. In this paper, we explore the problem of constructing robust wrappers for deep web information extraction. In order to keep web extraction robust when webpage changes, a minimum cost script edit model based on machine learning techniques is proposed. With the method, we consider three edit operations under structural changes, i.e., inserting nodes, deleting nodes and substituting nodes' labels. Firstly, we obtain the change frequencies of three edit operations for each HTML label according to the frequency of webpage change on real web data with machine learning method. Then, we compute the corresponding edit costs for three edit operations on the basis of change frequencies and minimum cost model. Finally, we choose the most proper data to extract the interested information by applying the minimum cost script. Experimental results show that the proposed approach can accomplish robust web extraction with high accuracy. © Springer-Verlag Berlin Heidelberg 2012.
DA  - 2012///
PY  - 2012
DO  - 10.1007/978-3-642-33469-6_62
VL  - 7529 LNCS
SP  - 497
EP  - 509
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894350257&doi=10.1007%2f978-3-642-33469-6_62&partnerID=40&md5=5803dece1c1733a6392fe7bdc5c9a548
DB  - Scopus
KW  - Machine learning
KW  - Robust
KW  - Web data extraction
KW  - Minimum cost script
KW  - Wrapper
ER  - 

TY  - CONF
TI  - Botnet detection system analysis on the effect of botnet evolution and feature representation
AU  - Haddadi, F.
AU  - Zincir-Heywood, A.N.
T2  - GECCO 2015 - Companion Publication of the 2015 Genetic and Evolutionary Computation Conference
AB  - Botnets are known as one of the main destructive threats that have been active since 2003 in various forms. The ability to upgrade the structure and algorithms on the y is part of what causes botnets to survive for more than a decade. Hence, one of the main concerns in designing a botnet detection system is how long such a system can be effective and useful considering the evolution of a given botnet. Furthermore, the data representation and the feature extraction components have always been an important issue in order to design a robust detection system. In this work, we employ machine learning algorithms (genetic programming and decision trees) to explore two questions: (i) How can the representation of non-numeric features effect the detection system's performance? and (ii) How long can a machine learning based detection system can perform effectively? To this end, we gathered seven Zeus botnet data sets over a period of four years and analyzed three different data representation techniques to be able to explore aforementioned questions. © 2015 ACM.
DA  - 2015///
PY  - 2015
DO  - 10.1145/2739482.2768435
SP  - 893
EP  - 900
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959386654&doi=10.1145%2f2739482.2768435&partnerID=40&md5=a09b3eba95babf09714d00e070b18f1e
DB  - Scopus
KW  - Decision trees
KW  - Security
KW  - Artificial intelligence
KW  - Machine learning
KW  - Feature extraction
KW  - Learning systems
KW  - Learning algorithms
KW  - Robustness (control systems)
KW  - Feature representation
KW  - Robustness
KW  - Evolutionary algorithms
KW  - Detection system
KW  - Malware
KW  - Genetic algorithms
KW  - Genetic programming
KW  - Robust detection
KW  - Data representations
KW  - Data representation
KW  - Botnet detection
KW  - Botnet detections
KW  - Botnets
KW  - Zeus botnet
ER  - 

TY  - JOUR
TI  - A distributional interpretation of robust optimization
AU  - Xu, H.
AU  - Caramanis, C.
AU  - Mannor, S.
T2  - Mathematics of Operations Research
AB  - Motivated by data-driven decision making and sampling problems, we investigate probabilistic interpretations of robust optimization (RO). We establish a connection between RO and distributionally robust stochastic programming (DRSP), showing that the solution to any RO problem is also a solution to a DRSP problem. Specifically, we consider the case where multiple uncertain parameters belong to the same fixed dimensional space and find the set of distributions of the equivalent DRSP problem. The equivalence we derive enables us to construct RO formulations for sampled problems (as in stochastic programming and machine learning) that are statistically consistent, even when the original sampled problem is not. In the process, this provides a systematic approach for tuning the uncertainty set. The equivalence further provides a probabilistic explanation for the common shrinkage heuristic, where the uncertainty set used in an RO problem is a shrunken version of the original uncertainty set. © 2012 INFORMS.
DA  - 2012///
PY  - 2012
DO  - 10.1287/moor.1110.0531
VL  - 37
IS  - 1
SP  - 95
EP  - 110
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861364382&doi=10.1287%2fmoor.1110.0531&partnerID=40&md5=88b757ce7d0f268ab8ad269760a323e6
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Optimization
KW  - Robust optimization
KW  - Stochastic programming
KW  - Uncertain parameters
KW  - Consistency
KW  - Dimensional spaces
KW  - Distributionally robust stochastic programming
KW  - Kernel density estimator
KW  - Kernel density estimators
KW  - Probabilistic interpretation
KW  - Sampling problems
ER  - 

TY  - CONF
TI  - Identification of safety critical scenarios for airlines using machine learning in filter trees
AU  - Höhndorf, L.
AU  - Holzapfel, F.
T2  - PSAM 2018 - Probabilistic Safety Assessment and Management
AB  - During flight, civil aircraft record data that are analyzed within Flight Data Monitoring (FDM) activities of an airline. Based on the characteristics of the operation and network, the flights can be filtered according to aircraft types, departure and arrival airports, and runways. The considered criteria that describe a set of flights are called a filter. When several filters are considered, they often can be arranged according to their hierarchical structure in a filter tree. Subsequently, every filter in this tree can be assigned certain values that describe the performance, e.g. in terms of safety, of the underlying flights. For example, the mean and the standard deviation of the landing masses can be assigned to any available flights arriving at Munich airport on runway 08L. Finally, outstanding filters can be identified using machine learning algorithms for a (potentially very big) filter tree. © 2018 International Association for Probablistic Safety Assessment and Management (IAPSAM). All rights reserved.
DA  - 2018///
PY  - 2018
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063155047&partnerID=40&md5=d4c820250cd1d565cd8e42ce29ab09ba
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Safety engineering
KW  - Air transportation
KW  - Aircraft
KW  - Trees (mathematics)
KW  - Monitoring
KW  - Forestry
KW  - Standard deviation
KW  - Hierarchical structures
KW  - Flight data monitoring
KW  - Civil aircrafts
KW  - Filter trees
KW  - Flight Data Monitoring (FDM)
KW  - Munich airports
KW  - Safety critical scenarios
ER  - 

TY  - CONF
TI  - Fast and viewpoint robust human detection in uncluttered environments
AU  - Blondel, P.
AU  - Potelle, A.
AU  - Pegard, C.
AU  - Lozano, R.
T2  - 2014 IEEE Visual Communications and Image Processing Conference, VCIP 2014
AB  - Human detection is a very popular field of computer vision. Few works propose a solution for detecting people whatever the camera's viewpoint such as for UAV applications. In this context even state-of-the-art detectors can fail to detect people. We found that the Integral Channel Features detector (ICF) is inoperant in such a context. In this paper, we propose an approach to still benefit from the assets of the ICF while considerably extending the angular robustness during the detection. The main contributions of this work are: 1) a new framework based on the Cluster Boosting Tree and the ICF detector for viewpoint robust human detection, 2) a new training dataset for taking into account the human shape modifications occuring when the pitch angle of the camera changes. We showed that our detector (the PRD) is superior to the ICF for detecting people from complex viewpoints in uncluttered environments and that the computation time of the detector is real-time compatible. © 2014 IEEE.. © 2014 IEEE.
DA  - 2015///
PY  - 2015
DO  - 10.1109/VCIP.2014.7051621
SP  - 522
EP  - 525
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925436626&doi=10.1109%2fVCIP.2014.7051621&partnerID=40&md5=53029ff2b343a910b352dba3b44bcbbe
DB  - Scopus
KW  - machine learning
KW  - Learning systems
KW  - State of the art
KW  - Visual communication
KW  - Cameras
KW  - Image processing
KW  - Training dataset
KW  - Aircraft detection
KW  - Computation time
KW  - Supervised trainings
KW  - Boosting trees
KW  - human detection
KW  - Human detection
KW  - multi-viewpoint
KW  - Multi-viewpoints
KW  - supervised training
KW  - viewpoint robust
ER  - 

TY  - CONF
TI  - Robust facial feature localization using data-driven semi-supervised learning approach
AU  - Kim, Y.Y.
AU  - Hong, S.J.
AU  - Rhee, J.H.
AU  - Nam, M.Y.
AU  - Rhee, P.K.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - In this paper, we present a novel localization method of facial feature points with generalization ability based on a data-driven semi-supervised learning approach. Even though a powerful facial feature detector can be built using a number of human-annotated training data, the collection process is time-consuming and very often impractical due to the high cost and error-prone process of manual annotations. The proposed method takes advantage of a data-driven semi-supervised learning that optimizes a hybrid detector by interacting with a hierarchical data model to suppress and regularize noisy outliers. The competitive performance comparing to other state-of-the-art technology is also shown using benchmark datasets, Bosprous, BioID. © Springer International Publishing Switzerland 2015.
DA  - 2015///
PY  - 2015
DO  - 10.1007/978-3-319-20904-3_15
VL  - 9163
SP  - 157
EP  - 166
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948949979&doi=10.1007%2f978-3-319-20904-3_15&partnerID=40&md5=b2546f3091afb13f878f45b9fc2c86b4
DB  - Scopus
KW  - Feature extraction
KW  - Supervised learning
KW  - Computer vision
KW  - Benchmarking
KW  - Semi- supervised learning
KW  - Face recognition
KW  - Data-driven semi-supervised learning
KW  - Facial feature localization
KW  - Hierarchical data
KW  - Hierarchical data model
KW  - Hirerarchical soft K-means algorithm
KW  - Hybrid detector
KW  - Hybrid detectors
KW  - k-Means algorithm
ER  - 

TY  - JOUR
TI  - Categorisation of driving scenario complexity based on primary driving tasks and road characteristics
AU  - Galarza, M.A.
AU  - Paradells, J.
T2  - International Journal of Vehicle Safety
AB  - The increasing amount of infotainment services available in vehicles makes it necessary to devise a system capable of managing how information should be delivered and accessed in accordance with the driving complexity scenario. The objective of this study is to provide a useful model for categorising driving scenarios in terms of their complexity. For this purpose, data collected from driving tests are analysed employing data mining techniques and machine learning methods for finding the more influential variables of driving complexity. The input variables used are associated with primary driving tasks and road characteristics available in current vehicles. As a result, the most relevant variables that enable the categorisation of the driving scenario are identified and a model capable of predicting driving complexity in real time is constructed. Given the model accuracy obtained, a practical application could be the adaptation of Human Machine Interfaces (HMI). Copyright © 2018 Inderscience Enterprises Ltd.
DA  - 2018///
PY  - 2018
DO  - 10.1504/IJVS.2018.094176
VL  - 10
IS  - 2
SP  - 138
EP  - 161
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052506743&doi=10.1504%2fIJVS.2018.094176&partnerID=40&md5=5f356f521337e517d0a84bf1855d89eb
DB  - Scopus
KW  - Machine learning
KW  - Vehicle safety
KW  - Data mining
KW  - Vehicles
KW  - Learning systems
KW  - Human machine interface
KW  - Roads and streets
KW  - Human Machine Interface
KW  - Man machine systems
KW  - Machine learning methods
KW  - Input variables
KW  - Complexity based
KW  - Driving complexity
KW  - Model accuracy
KW  - Primary driving task
KW  - Primary driving tasks
ER  - 

TY  - JOUR
TI  - Integrating machine learning techniques into robust data enrichment approach and its application to gene expression data
AU  - Erdoǧdu, U.
AU  - Tan, M.
AU  - Alhajj, R.
AU  - Polat, F.
AU  - Rokne, J.
AU  - Demetrick, D.
T2  - International Journal of Data Mining and Bioinformatics
AB  - The availability of enough samples for effective analysis and knowledge discovery has been a challenge in the research community, especially in the area of gene expression data analysis. Thus, the approaches being developed for data analysis have mostly suffered from the lack of enough data to train and test the constructed models. We argue that the process of sample generation could be successfully automated by employing some sophisticated machine learning techniques. An automated sample generation framework could successfully complement the actual sample generation from real cases. This argument is validated in this paper by describing a framework that integrates multiple models (perspectives) for sample generation. We illustrate its applicability for producing new gene expression data samples, a highly demanding area that has not received attention. The three perspectives employed in the process are based on models that are not closely related. The independence eliminates the bias of having the produced approach covering only certain characteristics of the domain and leading to samples skewed towards one direction. The fi rst model is based on the Probabilistic Boolean Network (PBN) representation of the gene regulatory network underlying the given gene expression data. The second model integrates Hierarchical Markov Model (HIMM) and the third model employs a genetic algorithm in the process. Each model learns as much as possible characteristics of the domain being analysed and tries to incorporate the learned characteristics in generating new samples. In other words, the models base their analysis on domain knowledge implicitly present in the data itself. The developed framework has been extensively tested by checking how the new samples complement the original samples. The produced results are very promising in showing the effectiveness, usefulness and applicability of the proposed multi-model framework. Copyright © 2013 Inderscience Enterprises Ltd.
DA  - 2013///
PY  - 2013
DO  - 10.1504/IJDMB.2013.056090
VL  - 8
IS  - 3
SP  - 247
EP  - 281
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883511102&doi=10.1504%2fIJDMB.2013.056090&partnerID=40&md5=ef35fee177a18ee0e4c52c88b9220107
DB  - Scopus
KW  - Learning
KW  - Genetic algorithms
KW  - Gene expression data
KW  - Hierarchical markov models
KW  - HIMM
KW  - Multiple perspectives
KW  - PBN
KW  - Probabilistic boolean networks
KW  - Sample generation
ER  - 

TY  - JOUR
TI  - Robust learning from bites for data mining
AU  - Christmann, A.
AU  - Steinwart, I.
AU  - Hubert, M.
T2  - Computational Statistics and Data Analysis
AB  - Some methods from statistical machine learning and from robust statistics have two drawbacks. Firstly, they are computer-intensive such that they can hardly be used for massive data sets, say with millions of data points. Secondly, robust and non-parametric confidence intervals for the predictions according to the fitted models are often unknown. A simple but general method is proposed to overcome these problems in the context of huge data sets. An implementation of the method is scalable to the memory of the computer and can be distributed on several processors to reduce the computation time. The method offers distribution-free confidence intervals for the median of the predictions. The main focus is on general support vector machines (SVM) based on minimizing regularized risks. As an example, a combination of two methods from modern statistical machine learning, i.e. kernel logistic regression and ε{lunate}-support vector regression, is used to model a data set from several insurance companies. The approach can also be helpful to fit robust estimators in parametric models for huge data sets. © 2007 Elsevier B.V. All rights reserved.
DA  - 2007///
PY  - 2007
DO  - 10.1016/j.csda.2006.12.009
VL  - 52
IS  - 1
SP  - 347
EP  - 361
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548361937&doi=10.1016%2fj.csda.2006.12.009&partnerID=40&md5=0873fce5791bc19c001210f35be83244
DB  - Scopus
KW  - Data mining
KW  - Learning systems
KW  - Robustness
KW  - Scalability
KW  - Logistic regression
KW  - Distributed computer systems
KW  - Support vector machine
KW  - Statistical machine learning
KW  - Data sets
KW  - Binary codes
KW  - Breakdown point
KW  - Convex risk minimization
KW  - Data storage equipment
KW  - Distributed computing
KW  - Influence function
ER  - 

TY  - CONF
TI  - Statistically valid links and anti-links betweenwords and between documents: Applying tournebool randomization test to a reuters collection
AU  - Lelu, A.
AU  - Cadot, M.
T2  - Studies in Computational Intelligence
AB  - Neighborhood is a central concept in data mining, and a bunch of definitions have been implemented, mainly rooted in geometrical or topological considerations. We propose here a statistical definition of neighborhood: our TourneBool randomization test processes an objects × attributes binary table in order to establish which inter-attribute relations are fortuitous, and which ones are meaningful, without requiring any pre-defined statistical model, while taking into account the empirical distributions. It ensues a robust and statistically validated graph. We present a full-scale experiment on one of the public access Reuters test corpus. We characterize the resulting word graph by a series of indicators, such as clustering coefficients, degree distribution and correlation, cluster modularity and size distribution. Another graph structure stems from this process: the one conveying the negative "counter- relations" between words, i.e. words which "steer clear" one from another. We characterize in the same way the counter-relation graph. At last we generate the couple of valid document graphs (i.e. links and anti-links) and evaluate them by taking into account the Reuters document categories. © 2010 Springer-Verlag Berlin Heidelberg.
DA  - 2010///
PY  - 2010
DO  - 10.1007/978-3-642-00580-0_18
VL  - 292
SP  - 307
EP  - 324
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956688623&doi=10.1007%2f978-3-642-00580-0_18&partnerID=40&md5=63a7fb3a548c2b88989ef82f6aabf9d8
DB  - Scopus
KW  - Unsupervised Learning
KW  - Randomization Test
KW  - Robust Data Mining
KW  - Statistical Graph Extraction
KW  - Text Mining
ER  - 

TY  - CONF
TI  - A study on the application of big data analytics in railways systems
AU  - Lin, S.P.
AU  - Kimoto, K.
AU  - Suda, Y.
AU  - Iwamoto, A.
AU  - Saito, T.
AU  - Yano, K.
AU  - Mizuno, M.
AU  - Tanimoto, M.
AU  - Nagasawa, K.
T2  - Civil-Comp Proceedings
AB  - Recently, big data analytics has been applied in various fields with the development of information technology and analysis tools. However, there are few examples of big data analytics in the field of railway mechanical systems, because vehicle performance is evaluated using motion analysis or experiments under specific conditions. By contrast, condition monitoring systems are introduced in the railway systems, and these monitoring systems enable big data to be accumulated during commercial operations. In this paper, the big data of running records in railway systems are analyzed by using a naive Bayes classifier, one of the methods of big data analytics, and the individualities of railway vehicles are identified. © Civil-Comp Press, 2016.
DA  - 2016///
PY  - 2016
VL  - 110
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964389687&partnerID=40&md5=d09c2c93bf29d59b2d0e9c9a428036ad
DB  - Scopus
KW  - Safety
KW  - Artificial intelligence
KW  - Machine learning
KW  - Learning systems
KW  - Accident prevention
KW  - Vehicle performance
KW  - Transportation
KW  - Railroads
KW  - Big data
KW  - Railroad transportation
KW  - Monitoring
KW  - Condition monitoring
KW  - Monitoring system
KW  - Classifiers
KW  - Commercial operation
KW  - Condition monitoring systems
KW  - Lateral force
KW  - Mechanical systems
KW  - Naive Bayes classifier
KW  - Naive Bayes classifiers
KW  - Railway vehicles
KW  - Wheel load
KW  - Wheel loads
ER  - 

TY  - JOUR
TI  - On robust information extraction from highdimensional data
AU  - Kalina, J.
T2  - Serbian Journal of Management
AB  - Information extraction from high-dimensional data represents an important problem in current applications in management or econometrics. An important problem from a practical point of view is the sensitivity of machine learning methods with respect to the presence of outlying data values, while numerical stability represents another important aspect of data mining from high-dimensional data. This paper gives an overview of various types of data mining, discusses their suitability for high-dimensional data and critically discusses their properties from the robustness point of view, while we explain that the robustness itself is perceived differently in different contexts.Moreover, we investigate properties of a robust nonlinear regression estimator of Kalina (2013).
DA  - 2014///
PY  - 2014
DO  - 10.5937/sjm9-5520
VL  - 9
SP  - 131
EP  - 144
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899697874&doi=10.5937%2fsjm9-5520&partnerID=40&md5=73a3bc8250309c57e3a16dda3fc65faa
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Outliers
KW  - High-dimensional data
KW  - Robust econometrics
ER  - 

TY  - JOUR
TI  - SKYNET: An efficient and robust neural network training tool for machine learning in astronomy
AU  - Graff, P.
AU  - Feroz, F.
AU  - Hobson, M.P.
AU  - Lasenby, A.
T2  - Monthly Notices of the Royal Astronomical Society
AB  - We present the first public release of our generic neural network training algorithm, called SKYNET. This efficient and robust machine learning tool is able to train large and deep feedforward neural networks, including autoencoders, for use in a wide range of supervised and unsupervised learning applications, such as regression, classification, density estimation, clustering and dimensionality reduction. SKYNET uses a 'pre-training' method to obtain a set of network parameters that has empirically been shown to be close to a good solution, followed by further optimization using a regularized variant of Newton's method, where the level of regularization is determined and adjusted automatically; the latter uses second-order derivative information to improve convergence, but without the need to evaluate or store the full Hessian matrix, by using a fast approximate method to calculate Hessian-vector products. This combination of methods allows for the training of complicated networks that are difficult to optimize using standard backpropagation techniques. SKYNET employs convergence criteria that naturally prevent overfitting, and also includes a fast algorithm for estimating the accuracy of network outputs. The utility and flexibility of SKYNET are demonstrated by application to a number of toy problems, and to astronomical problems focusing on the recovery of structure from blurred and noisy images, the identification of gamma-ray bursters, and the compression and denoising of galaxy images. The SKYNET software,which is implemented in standard ANSI C and fully parallelized using MPI, is available at http://www.mrao.cam.ac.uk/software/skynet/. © 2014 The Authors Published by Oxford University Press on behalf of the Royal Astronomical Society.
DA  - 2014///
PY  - 2014
DO  - 10.1093/mnras/stu642
VL  - 441
IS  - 2
SP  - 1741
EP  - 1759
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900526711&doi=10.1093%2fmnras%2fstu642&partnerID=40&md5=c4d80093a501be4de9992acd80d24003
DB  - Scopus
KW  - Feedforward neural networks
KW  - Dimensionality reduction
KW  - Gamma rays
KW  - Supervised and unsupervised learning
KW  - Methods. Data analysis
KW  - Clusterings
KW  - C (programming language)
KW  - Methods:statistical
KW  - Auto encoders
KW  - Training algorithms
KW  - Newton-Raphson method
KW  - Methods: data analysis
KW  - Density estimation
KW  - Methods: statistical
KW  - Neural networks trainings
KW  - Toys
KW  - Training tools
ER  - 

TY  - JOUR
TI  - Coherence Pursuit: Fast, simple, and robust principal component analysis
AU  - Rahmani, M.
AU  - Atia, G.K.
T2  - IEEE Transactions on Signal Processing
AB  - This paper presents a remarkably simple, yet powerful, algorithm termed coherence pursuit (CoP) to robust principal component analysis (PCA). As inliers lie in a low-dimensional subspace and are mostly correlated, an inlier is likely to have strong mutual coherence with a large number of data points. By contrast, outliers either do not admit low-dimensional structures or form small clusters. In either case, an outlier is unlikely to bear strong resemblance to a large number of data points. Given that, CoP sets an outlier apart from an inlier by comparing their coherence with the rest of the data points. The mutual coherences are computed by forming the Gram matrix of the normalized data points. Subsequently, the sought subspace is recovered from the span of the subset of the data points that exhibit strong coherence with the rest of the data. As CoP only involves one simple matrix multiplication, it is significantly faster than the state-of-the-art robust PCA algorithms.We derive analytical performance guarantees for CoP under different models for the distributions of inliers and outliers in both noise-free and noisy settings. CoP is the first robust PCA algorithm that is simultaneously non-iterative, provably robust to both unstructured and structured outliers, and can tolerate a large number of unstructured outliers. © 2017 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/TSP.2017.2749215
VL  - 65
IS  - 23
SP  - 6260
EP  - 6275
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029161360&doi=10.1109%2fTSP.2017.2749215&partnerID=40&md5=95e97646da7d55e2206ca87cda0010bf
DB  - Scopus
KW  - Signal processing
KW  - Signal processing algorithms
KW  - Analytical models
KW  - Big Data
KW  - Robustness (control systems)
KW  - Big data
KW  - Optimization
KW  - Statistics
KW  - Data structures
KW  - Robust control
KW  - Robust PCA
KW  - Principal component analysis
KW  - Iterative methods
KW  - Unsupervised learning
KW  - Matrix algebra
KW  - Robust principal component analysis
KW  - Outlier Detection
KW  - Unsupervised Learning
KW  - Low dimensional structure
KW  - Low-dimensional subspace
KW  - Subspace recoveries
KW  - Analytical performance
KW  - Coherent light
KW  - Subspace Recovery
ER  - 

TY  - CONF
TI  - Robust Support Vector Machine using Least Median Loss Penalty
AU  - Ma, Y.
AU  - Li, L.
AU  - Huang, X.
AU  - Wang, S.
T2  - IFAC Proceedings Volumes (IFAC-PapersOnline)
AB  - It is found that data points used for training may contain outliers that can generate unpredictable disturbance for some Support Vector Machines (SVMs) classification problems. No theoretical limit for such bad influence is held in traditional convex SVM methods. We present a novel robust misclassification penalty function for SVM which is inspired by the concept of "Least Median Regression". In our approach, total loss penalty in training is measured by the summation of two median hinge losses, each for a different class. We also propose a "Rank and Convex Procedure" to optimize our tasks. Though our approach is heuristic, it is faster than other known robust methods, such as SVM with Ramp Loss Penalty. © 2011 IFAC.
DA  - 2011///
PY  - 2011
DO  - 10.3182/20110828-6-IT-1002.03467
VL  - 44
SP  - 11208
EP  - 11213
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866749269&doi=10.3182%2f20110828-6-IT-1002.03467&partnerID=40&md5=21518c36cc565c7a29367397f3dff4f9
DB  - Scopus
KW  - Pattern recognition
KW  - Support vector machines
KW  - Heuristic methods
KW  - Support vector machine
KW  - Misclassifications
KW  - Learning theory
KW  - Learning Theory
KW  - Support vector machine (SVMs)
KW  - Statistical data analysis
KW  - Different class
KW  - Penalty function
KW  - Robustidentification
KW  - Theoretical limits
ER  - 

TY  - JOUR
TI  - A robust state estimator for medium voltage distribution networks
AU  - Wu, J.
AU  - He, Y.
AU  - Jenkins, N.
T2  - IEEE Transactions on Power Systems
AB  - A closed-loop robust distribution state estimator was investigated. An approach that is suitable for medium voltage distribution networks which are either under-determined with limited real-time measurements or over-determined but with delayed information fromsmart meters was developed. The state estimator was designed to be robust against the effect of measurement errors, the type, location and accuracy of measurements, as well as temporary failure of the smart metering communication system. A machine learning function provides reliable input information to a robust state estimation algorithm. The output of the state estimator is then fed back to the machine learning function creating a closed-loop information flow which improves the performance of the state estimator. Test results and analysis on a 33-node system are provided. © 2012 IEEE.
DA  - 2013///
PY  - 2013
DO  - 10.1109/TPWRS.2012.2215927
VL  - 28
IS  - 2
SP  - 1008
EP  - 1016
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885426576&doi=10.1109%2fTPWRS.2012.2215927&partnerID=40&md5=a703a60b77ff90322b8361249bf614a5
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Electric power distribution
KW  - State estimation
KW  - Robust statistics
KW  - Distribution network
KW  - Accuracy of measurements
KW  - Distribution state estimators
KW  - Effect of measurements
KW  - Electric measuring instruments
KW  - Medium-voltage distribution networks
KW  - Real time measurements
KW  - Robust state estimation
KW  - Smart metering
ER  - 

TY  - CONF
TI  - Efficient distributed decision trees for robust regression
AU  - Guo, T.
AU  - Kutzkov, K.
AU  - Ahmed, M.
AU  - Calbimonte, J.-P.
AU  - Aberer, K.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - The availability of massive volumes of data and recent advances in data collection and processing platforms have motivated the development of distributed machine learning algorithms. In numerous real-world applications large datasets are inevitably noisy and contain outliers. These outliers can dramatically degrade the performance of standard machine learning approaches such as regression trees. To this end, we present a novel distributed regression tree approach that utilizes robust regression statistics, statistics that are more robust to outliers, for handling large and noisy data. We propose to integrate robust statistics based error criteria into the regression tree. A data summarization method is developed and used to improve the efficiency of learning regression trees in the distributed setting. We implemented the proposed approach and baselines based on Apache Spark, a popular distributed data processing platform. Extensive experiments on both synthetic and real datasets verify the effectiveness and efficiency of our approach. The data and software related to this paper are available at https://github.com/ weilai0980/DRSquare tree/tree/master/. © Springer International Publishing AG 2016.
DA  - 2016///
PY  - 2016
DO  - 10.1007/978-3-319-46227-1_6
VL  - 9852 LNAI
SP  - 79
EP  - 95
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988622262&doi=10.1007%2f978-3-319-46227-1_6&partnerID=40&md5=11065572ab42e159740e22690be04378
DB  - Scopus
KW  - Decision trees
KW  - Artificial intelligence
KW  - Decision tree
KW  - Learning systems
KW  - Data handling
KW  - Learning algorithms
KW  - Regression analysis
KW  - Efficiency
KW  - Statistics
KW  - Robust regression
KW  - Trees (mathematics)
KW  - Distributed machine learning
KW  - Effectiveness and efficiencies
KW  - Robust regressions
KW  - Error statistics
KW  - Data summarization
KW  - Data summarizations
KW  - Distributed data processing
KW  - Distributed decision
KW  - Distributed regressions
KW  - Processing platform
ER  - 

TY  - CONF
TI  - A robust random forest-based tri-training algorithm for early in-trouble student prediction
AU  - Chau, V.T.N.
AU  - Phung, N.H.
T2  - 2017 4th NAFOSTED Conference on Information and Computer Science, NICS 2017 - Proceedings
AB  - Educational data mining has received much attention worldwide due to its significance in the education domain. Among a large number of the educational data mining tasks, early in-trouble student prediction is a popular one. This task focuses on identifying the students who are at risk in their study as soon as possible before the end of the permitted period of study time. For early detection, data shortage is a challenge for the task at both instance and set levels. Indeed, at the instance level, incomplete data could be gathered for each student at his/her early study period and also at the set level, many labeled data could not be collected for their final study status. Therefore, a solution to the task in such a context is required. In this paper, we propose a robust random forest-based Tri-training algorithm that can overcome that data shortage challenge. In particular, based on the semi-supervised learning process of the original Tritraining algorithm, an incomplete data handling method is integrated into its iterative mechanism so that the Tri-training algorithm can be more robust. In addition, a new combination of the Tri-training algorithm and a random forest model is examined so that each classifier of the Tri-training model can be enhanced for more accurate predictions. As a result, the proposed algorithm is an effective solution to the early in-trouble student prediction task. Its effectiveness has been confirmed with the better experimental results on real data sets in comparison with the existing methods using the preprocessing approach. © 2017 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/NAFOSTED.2017.8108043
VL  - 2017-January
SP  - 84
EP  - 89
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043364403&doi=10.1109%2fNAFOSTED.2017.8108043&partnerID=40&md5=9ce70f42c1f5bdbdb1342d6799ed7ba4
DB  - Scopus
KW  - Decision trees
KW  - Data mining
KW  - Supervised learning
KW  - Data handling
KW  - Learning algorithms
KW  - Forecasting
KW  - Robustness (control systems)
KW  - Robustness
KW  - Semi- supervised learning
KW  - Iterative methods
KW  - Random forest modeling
KW  - Accurate prediction
KW  - Students
KW  - Education computing
KW  - Educational data mining
KW  - Tri-training
KW  - K-nearest neighbors
KW  - Educational data classification
KW  - Educational datum
KW  - Knearest neighbors
KW  - Preprocessing approaches
KW  - Random forest-based tri-training
KW  - Semi-supervised learning paradigm
ER  - 

TY  - JOUR
TI  - Feature selection via embedded learning based on tangent space alignment for microarray data
AU  - Ye, X.
AU  - Sakurai, T.
T2  - Journal of Computing Science and Engineering
AB  - Feature selection has been widely established as an efficient technique for microarray data analysis. Feature selection aims to search for the most important feature/gene subset of a given dataset according to its relevance to the current target. Unsupervised feature selection is considered to be challenging due to the lack of label information. In this paper, we propose a novel method for unsupervised feature selection, which incorporates embedded learning and l2,1-norm sparse regression into a framework to select genes in microarray data analysis. Local tangent space alignment is applied during embedded learning to preserve the local data structure. The l2,1-norm sparse regression acts as a constraint to aid in learning the gene weights correlatively, by which the proposed method optimizes for selecting the informative genes which better capture the interesting natural classes of samples. We provide an effective algorithm to solve the optimization problem in our method. Finally, to validate the efficacy of the proposed method, we evaluate the proposed method on real microarray gene expression datasets. The experimental results demonstrate that the proposed method obtains quite promising performance. © 2017. The Korean Institute of Information Scientists and Engineers.
DA  - 2017///
PY  - 2017
DO  - 10.5626/JCSE.2017.11.4.121
VL  - 11
IS  - 4
SP  - 121
EP  - 129
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039560866&doi=10.5626%2fJCSE.2017.11.4.121&partnerID=40&md5=582518f268cd300e77e08bb8b637904d
DB  - Scopus
KW  - Feature extraction
KW  - Data handling
KW  - Regression analysis
KW  - Optimization
KW  - Gene expression
KW  - Information analysis
KW  - Alignment
KW  - Sparse regression
KW  - Unsupervised feature selection
KW  - Genes
KW  - Tangent space
KW  - Embedded learning
KW  - Microarray gene expression data
KW  - Tangent space alignment
ER  - 

TY  - CONF
TI  - Speech representation learning using unsupervised data-driven modulation filtering for robust ASR
AU  - Agrawal, P.
AU  - Ganapathy, S.
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
AB  - The performance of an automatic speech recognition (ASR) system degrades severely in noisy and reverberant environments in part due to the lack of robustness in the underlying representations used in the ASR system. On the other hand, the auditory processing studies have shown the importance of modulation filtered spectrogram representations in robust human speech recognition. Inspired by these evidences, we propose a speech representation learning paradigm using data-driven 2- D spectro-temporal modulation filter learning. In particular, multiple representations are derived using the convolutional restricted Boltzmann machine (CRBM) model in an unsupervised manner from the input speech spectrogram. A filter selection criteria based on average number of active hidden units is also employed to select the representations for ASR. The experiments are performed on Wall Street Journal (WSJ) Aurora-4 database with clean and multi condition training setup. In these experiments, the ASR results obtained from the proposed modulation filtering approach shows significant robustness to noise and channel distortions compared to other feature extraction methods (average relative improvements of 19% over baseline features in clean training). Furthermore, the ASR experiments performed on reverberant speech data from the REVERB challenge corpus highlight the benefits of the proposed representation learning scheme for far field speech recognition. Copyright © 2017 ISCA.
DA  - 2017///
PY  - 2017
DO  - 10.21437/Interspeech.2017-901
VL  - 2017-August
SP  - 2446
EP  - 2450
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039170514&doi=10.21437%2fInterspeech.2017-901&partnerID=40&md5=a5fbd0051500af9f086f79eb61291e54
DB  - Scopus
KW  - Speech recognition
KW  - Convolution
KW  - Modulation
KW  - Speech
KW  - Unsupervised learning
KW  - Restricted boltzmann machine
KW  - Speech communication
KW  - Feature extraction methods
KW  - Automatic speech recognition system
KW  - Convolutional restricted Boltzmann machine
KW  - Data-driven modulation filtering
KW  - Modulation filtering
KW  - Multi-condition trainings
KW  - Multiple representation
KW  - Reverberant environment
KW  - Reverberation
KW  - Spectro-temporal modulations
KW  - Spectrographs
ER  - 

TY  - CONF
TI  - Integration of machine learning and human learning for training optimization in robust linear regression
AU  - Li, X.
AU  - Chen, Y.
AU  - Zeng, K.
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
AB  - In this paper machine learning and human learning are applied jointly to optimize the training of linear regression. Human learning is exploited to label extra training data so as to resolve problems such as insufficient training and over-fitting. Considering the inevitable human errors in labeling, two machine learning algorithms are developed which optimize the selection of the extra training data and detect human errors during linear regression. The first algorithm assumes sparse human errors and implements a sparse optimization within a sequential active learning procedure. The second algorithm deals with non-sparse human errors. By exploiting the IRT (item response theory) to model the distribution of human errors, it reconstructs the training data set so that the human labeling errors become sparse. Simulations are conducted to show that the two algorithms are effective in resolving the insufficient training and human labeling error problems. © 2016 IEEE.
DA  - 2016///
PY  - 2016
DO  - 10.1109/ICASSP.2016.7472150
VL  - 2016-May
SP  - 2613
EP  - 2617
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973335020&doi=10.1109%2fICASSP.2016.7472150&partnerID=40&md5=8adeb96681b04c8aff6a9e31e8b69795
DB  - Scopus
KW  - machine learning
KW  - training
KW  - active learning
KW  - human learning
KW  - item response theory
KW  - linear regression
ER  - 

TY  - CONF
TI  - Optimal sparse L1-norm principal-component analysis
AU  - Chamadia, S.
AU  - Pados, D.A.
T2  - ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings
AB  - We present an algorithm that computes exactly (optimally) the S-sparse (1≤S<D) maximum-L1-norm-projection principal component of a real-valued data matrix X E D×N that contains N samples of dimension D. For fixed sample support N, the optimal L1-sparse algorithm has linear complexity in data dimension, O(D). For fixed dimension D (thus, fixed sparsity S), the optimal L1-sparse algorithm has polynomial complexity in sample support, O(NS). Numerical studies included in this paper illustrate the theoretical developments and demonstrate the remarkable robustness to faulty data/measurements of the calculated sparse-L1 principal components. © 2017 IEEE.
DA  - 2017///
PY  - 2017
DO  - 10.1109/ICASSP.2017.7952644
SP  - 2686
EP  - 2690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023768755&doi=10.1109%2fICASSP.2017.7952644&partnerID=40&md5=b6a7ba1dceed8a7e0637daded235c30f
DB  - Scopus
KW  - machine learning
KW  - principal component analysis
KW  - feature extraction
KW  - Faulty measurements
KW  - L1-norm
KW  - outlier resistance
KW  - robust data processing
KW  - sparsity
ER  - 

TY  - JOUR
TI  - Distributed reinforcement learning for adaptive and robust network intrusion response
AU  - Malialis, K.
AU  - Devlin, S.
AU  - Kudenko, D.
T2  - Connection Science
AB  - Distributed denial of service (DDoS) attacks constitute a rapidly evolving threat in the current Internet. Multiagent Router Throttling is a novel approach to defend against DDoS attacks where multiple reinforcement learning agents are installed on a set of routers and learn to rate-limit or throttle traffic towards a victim server. The focus of this paper is on online learning and scalability. We propose an approach that incorporates task decomposition, team rewards and a form of reward shaping called difference rewards. One of the novel characteristics of the proposed system is that it provides a decentralised coordinated response to the DDoS problem, thus being resilient to DDoS attacks themselves. The proposed system learns remarkably fast, thus being suitable for online learning. Furthermore, its scalability is successfully demonstrated in experiments involving 1000 learning agents. We compare our approach against a baseline and a popular state-of-the-art throttling technique from the network security literature and show that the proposed approach is more effective, adaptive to sophisticated attack rate dynamics and robust to agent failures. © 2015 Taylor & Francis.
DA  - 2015///
PY  - 2015
DO  - 10.1080/09540091.2015.1031082
VL  - 27
IS  - 3
SP  - 234
EP  - 252
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943198439&doi=10.1080%2f09540091.2015.1031082&partnerID=40&md5=93ee29a5c68b6538d49c3aad3146dc7b
DB  - Scopus
KW  - Intelligent agents
KW  - Reinforcement learning
KW  - E-learning
KW  - Reinforcement learning agent
KW  - Network security
KW  - Scalability
KW  - Denial-of-service attack
KW  - Distributed control
KW  - Distributed parameter control systems
KW  - Decentralised
KW  - network security
KW  - Distributed denial of service attack
KW  - Distributed reinforcement learning
KW  - DDoS Attack
KW  - DDoS attacks
KW  - decentralised coordination
KW  - distributed control
KW  - Router throttling
KW  - Task decomposition
ER  - 

TY  - JOUR
TI  - Feature extraction for robust physical activity recognition
AU  - Zhu, J.
AU  - San-Segundo, R.
AU  - Pardo, J.M.
T2  - Human-centric Computing and Information Sciences
AB  - This paper presents the development of a Human Activity Recognition (HAR) system that uses a network of nine inertial measurement units situated in different body parts. Every unit provides 3D (3-dimension) acceleration, 3D angular velocity, 3D magnetic field orientation, and 4D quaternions. This system identifies 33 different physical activities (walking, running, cycling, lateral elevation of arms, etc.). The system is composed of two main modules: a feature extractor for obtaining the most relevant characteristics from the inertial signals every second, and a machine learning algorithm for classifying between the different activities. This paper focuses on the feature extractor module, evaluating several types of features and proposing different normalization approaches. This paper also analyses the performance of every sensor included in the inertial measurement units. The main experiments have been done using a public available dataset named REALDISP Activity Recognition dataset. This dataset includes recordings from 17 subjects performing 33 different activities in three different scenarios. Final results demonstrate that the proposed HAR system significantly improves the classification accuracy compared to previous works on this dataset. For the best configuration, the system accuracy is 99.1%. This system has been also evaluated with the OPPORTUNITY dataset obtaining competitive results. © 2017, The Author(s). All rights reserved.
DA  - 2017///
PY  - 2017
DO  - 10.1186/s13673-017-0097-2
VL  - 7
IS  - 1
SP  - 1
EP  - 16
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032953871&doi=10.1186%2fs13673-017-0097-2&partnerID=40&md5=114639624e93a592057bb25935a494a2
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Feature extraction
KW  - Pattern recognition
KW  - Learning systems
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Extraction
KW  - Random forests
KW  - Random forest
KW  - Activity recognition
KW  - Human activity recognition
KW  - Physical activity
KW  - Feature extraction robustness
KW  - OPPORTUNITY dataset
KW  - Physical activity recognition
KW  - REALDISP activity recognition dataset
KW  - Signal normalization
KW  - Type of sensor
ER  - 

TY  - CONF
TI  - Comparison of unsupervised modulation filter learning methods for ASR
AU  - Agrawal, P.
AU  - Ganapathy, S.
T2  - Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH
AB  - The widespread deployment of automatic speech recognition (ASR) system in consumer centric applications such as voice interaction and voice search demands the need for noise robustness in such systems. One approach to this problem is to achieve the desired robustness in speech representations used in the ASR. Motivated from studies on robust human speech recognition, we analyse the unsupervised data-driven temporal modulation filter learning for robust feature extraction. In this paper, we compare various unsupervised models for data driven filter learning like convolutional autoencoder (CAE), generative adversarial network (GAN) and convolutional restricted Boltzmann machine (CRBM). The unsupervised models are designed to learn a set of filters from long temporal trajectories of speech sub-band energy. The filters learnt from these models are used for modulation filtering of the input spectrogram before the ASR training. The ASR experiments are performed on Wall Street Journal (WSJ) Aurora-4 database with clean and multi condition training setup. The experimental results obtained from the modulation filtered representations shows considerable robustness to noise, channel distortions and reverberant conditions compared to other feature extraction methods. Among the three approaches compared in this paper, the GAN approach provides the most consistent improvements in ASR accuracy in different training scenarios. © 2018 International Speech Communication Association. All rights reserved.
DA  - 2018///
PY  - 2018
DO  - 10.21437/Interspeech.2018-1972
VL  - 2018-September
SP  - 2908
EP  - 2912
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054993396&doi=10.21437%2fInterspeech.2018-1972&partnerID=40&md5=dd37d1dca9f56512748e0b5bcc52a51f
DB  - Scopus
KW  - Feature extraction
KW  - Speech recognition
KW  - Learning systems
KW  - Convolution
KW  - Extraction
KW  - Modulation
KW  - Speech
KW  - Unsupervised learning
KW  - Financial markets
KW  - Auto encoders
KW  - Adversarial networks
KW  - Restricted boltzmann machine
KW  - Speech communication
KW  - Generative adversarial network
KW  - Robust feature extractions
KW  - Feature extraction methods
KW  - Robust speech recognition
KW  - Automatic speech recognition system
KW  - Data-driven modulation filtering
KW  - Modulation filtering
KW  - Convolutional autoencoder
ER  - 

TY  - CONF
TI  - Ml.Lib: Robust, cross-platform, open-source machine learning for max and pure data
AU  - Bullock, J.
AU  - Momeni, A.
T2  - Proceedings of the International Conference on New Interfaces for Musical Expression
AB  - This paper documents the development of ml.lib: a set of open-source tools designed for employing a wide range of machine learning techniques within two popular real-time programming environments, namely Max and Pure Data. ml.lib is a cross-platform, lightweight wrapper around Nick Gillian’s Gesture Recognition Toolkit, a C++ library that includes a wide range of data processing and machine learning techniques. ml.lib adapts these techniques for real-time use within popular data-flow IDEs, allowing instrument designers and performers to integrate robust learning, classification and mapping approaches within their existing workflows. ml.lib has been carefully designed to allow users to experiment with and incorporate machine learning techniques within an interactive arts context with minimal prior knowledge. A simple, logical and consistent, scalable interface has been provided across over sixteen externals in order to maximize learnability and discoverability. A focus on portability and maintainability has enabled ml.lib to support a range of computing architectures—including ARM— and operating systems such as Mac OS, GNU/Linux and Windows, making it the most comprehensive machine learning implementation available for Max and Pure Data. © 2015, Steering Committee of the International Conference on New Interfaces for Musical Expression. All rights reserved.
DA  - 2015///
PY  - 2015
SP  - 265
EP  - 270
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160335837&partnerID=40&md5=d03447679e94224ee53137dfc7f04a88
DB  - Scopus
KW  - Neural networks
KW  - Support vector machines
KW  - Machine Learning
KW  - Computer architecture
KW  - Data handling
KW  - Learning algorithms
KW  - Machine-learning
KW  - Classification (of information)
KW  - Open source software
KW  - Mapping
KW  - Machine learning techniques
KW  - Classification
KW  - Support vectors machine
KW  - Music
KW  - Artificial Neural Networks
KW  - Regression
KW  - Open-source
KW  - C++ (programming language)
KW  - Cross-platform
KW  - Gesture
KW  - Max
KW  - Paper documents
KW  - Pure data
KW  - Pure Data
KW  - Support Vector Machines
ER  - 

TY  - CONF
TI  - A supervised learning approach for the robust detection of heart beat in plethysmographic data
AU  - Grisan, E.
AU  - Cantisani, G.
AU  - Tarroni, G.
AU  - Yoon, S.K.
AU  - Rossi, M.
T2  - Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS
AB  - Wearable devices equipped with photoplethysmography (PPG) sensors are gaining an increased interest in the context of biometric signal monitoring within clinical, e-health and fitness settings. When used in everyday life and during exercise, PPG traces are heavily affected by artifacts originating from motion and from a non constant positioning and contact of the PPG sensor with the skin. Many algorithms have been developed for the estimation of heart-rate from photoplethysmography signals. We remark that they were mainly conceived and tested in controlled settings and, in turn, do not provide robust performance, even during moderate exercise. Only a few of them have been designed for signals acquired at rest and during fitness. However, they provide the required resilience to motion artifacts at the cost of using computationally demanding signal processing tools. At variance with other methods from the literature, we propose a supervised learning approach, where a classifier is trained on a set of labelled data to detect the presence of heart beats at each position of a PPG signal, with only little preprocessing and postprocessing. We show that the results obtained on the TROIKA dataset using our approach are comparable with those shown in the original paper, providing a classification error of 14% in the detection of heart beat positions, that reduces to 2.86% on the heart-rate estimates after the postprocessing step. © 2015 IEEE.
DA  - 2015///
PY  - 2015
DO  - 10.1109/EMBC.2015.7319716
VL  - 2015-November
SP  - 5825
EP  - 5828
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953243447&doi=10.1109%2fEMBC.2015.7319716&partnerID=40&md5=00cce96a02c833ace2f85793d1ed7d10
DB  - Scopus
KW  - signal processing
KW  - Algorithms
KW  - algorithm
KW  - supervised machine learning
KW  - Supervised Machine Learning
KW  - Signal Processing, Computer-Assisted
KW  - heart rate
KW  - artifact
KW  - Artifacts
KW  - photoelectric plethysmography
KW  - Heart Rate
KW  - Photoplethysmography
ER  - 

TY  - CONF
TI  - An innovative approach to safe surgical suturing Part II: Data machine learning predictive analysis
AU  - Levy, A.
AU  - Msellati, J.
AU  - De Muer, A.
T2  - ACM International Conference Proceeding Series
AB  - Non-invasive robotized surgery is nowadays largely in action for most interventions because of its very beneficial advantages in terms of patient health and material efficiency. However, the still recurrent problem of guaranteeing the quality of suturing action (ie avoiding thread breaking) in all robotized interventions is recurrently impairing the overall results from this approach, mainly due to defective haptic information on threads available to the surgeons from the robot. To improve the efficiency of robot-surgeon collaboration, the problem of communicating relevant and reliable information on threads used by surgeons during suturing is addressed in present paper. From collected data on an experimental setup designed for the study described in Part I, machine learning predictive analysis is built-up in present Part. The approach helps understand the influence of different parameters on the suture ruptures and determine the safety zone in which the surgeon can pull the thread without danger. A display can be added to give the surgeon a visual return during the operations. Results obtained for different types of threads show up to 99% predictive accuracy, especially concerning maximum strength and maximum elongation of a suture before breaking. © 2019 Association for Computing Machinery.
DA  - 2019///
PY  - 2019
DO  - 10.1145/3326172.3326193
SP  - 285
EP  - 288
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069211737&doi=10.1145%2f3326172.3326193&partnerID=40&md5=758ae21d85fa162e8e8f567a4d2a9f99
DB  - Scopus
KW  - Machine learning
KW  - Robots
KW  - Learning systems
KW  - Predictive analytics
KW  - Efficiency
KW  - Transplantation (surgical)
KW  - Predictive accuracy
KW  - Robotic surgery
KW  - Innovative approaches
KW  - Biomedical engineering
KW  - Haptic interaction
KW  - Haptic interactions
KW  - Material efficiency
KW  - Maximum strength
KW  - Minimally invasive
KW  - Minimally invasive robotic surgery
KW  - Predictive algorithm
KW  - Predictive algorithms
KW  - Surgical suturing
ER  - 

TY  - CONF
TI  - Review of machine learning algorithms in differential expression analysis
AU  - Kuznetsova, I.
AU  - Karpievitch, Y.V.
AU  - Filipovska, A.
AU  - Lugmayr, A.
AU  - Holzinger, A.
T2  - International series on information systems and management in creative eMedia
AB  - In biological research machine learning algorithms are part of nearly every analytical process. They are used to identify new insights into biological phenomena, interpret data, provide molecular diagnosis for diseases and develop personalized medicine that will enable future treatments of diseases. In this paper we (1) illustrate the importance of machine learning in the analysis of large scale sequencing data, (2) present an illustrative standardized workflow of the analysis process, (3) perform a Differential Expression (DE) analysis of a publicly available RNA sequencing (RNA-Seq) data set to demonstrate the capabilities of various algorithms at each step of the workflow, and (4) show a machine learning solution in improving the computing time, storage requirements, and minimize utilization of computer memory in analyses of RNA-Seq datasets. The source code of the analysis pipeline and associated scripts are presented in the paper appendix to allow replication of experiments.
DA  - 2016///
PY  - 2016
VL  - 2016
SP  - 11
EP  - 24
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026273873&partnerID=40&md5=ae6d139f53bc618b4d851a167805fdf6
DB  - Scopus
KW  - Semantics
KW  - Artificial intelligence
KW  - Machine learning
KW  - Data mining
KW  - Learning systems
KW  - Diagnosis
KW  - Learning algorithms
KW  - Big data
KW  - Education
KW  - RNA
KW  - Bioinformatics
KW  - Digital storage
KW  - Clustering
KW  - RNA-Seq
KW  - Molecular biology
KW  - Biological phenomena
KW  - Biology
KW  - Burrows Wheeler transform
KW  - Burrows-Wheeler transform
KW  - Molecular diagnosis
KW  - Next Generation Sequencing
KW  - Next-generation sequencing
KW  - Personalized medicines
KW  - Pipeline codes
KW  - Semi-global
KW  - Semiglobal alignment
KW  - Storage requirements
ER  - 

TY  - CONF
TI  - Differentially Private Robust ADMM for Distributed Machine Learning
AU  - Ding, J.
AU  - Zhang, X.
AU  - Chen, M.
AU  - Xue, K.
AU  - Zhang, C.
AU  - Pan, M.
T2  - Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019
AB  - To embrace the era of big data, there has been growing interest in designing distributed machine learning to exploit the collective computing power of the local computing nodes. Alternating Direction Method of Multipliers (ADMM) is one of the most popular methods. This method applies iterative local computations over local datasets at each agent and computation results exchange between the neighbors. During this iterative process, data privacy leakage arises when performing local computation over sensitive data. Although many differentially private ADMM algorithms have been proposed to deal with such privacy leakage, they still have to face many challenging issues such as low model accuracy over strict privacy constraints and requiring strong assumptions of convexity of the objective function. To address those issues, in this paper, we propose a differentially private robust ADMM algorithm (PR-ADMM) with Gaussian mechanism. We employ two kinds of noise variance decay schemes to carefully adjust the noise addition in the iterative process and utilize a threshold to eliminate the too noisy results from neighbors. We also prove that PR-ADMM satisfies dynamic zero-concentrated differential privacy (dynamic zCDP) and a total privacy loss is given by (\epsilon, \delta)-differential privacy. From a theoretical point of view, we analyze the convergence rate of PR-ADMM for general convex objectives, which is \mathcal{O}(1 /K) with K being the number of iterations. The performance of the proposed algorithm is evaluated on real-world datasets. The experimental results show that the proposed algorithm outperforms other differentially private ADMM based algorithms under the same total privacy loss. © 2019 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/BigData47090.2019.9005716
SP  - 1302
EP  - 1311
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081308883&doi=10.1109%2fBigData47090.2019.9005716&partnerID=40&md5=d4b73c002dc4f57c5d8863be58ea9319
DB  - Scopus
KW  - Machine learning
KW  - Big data
KW  - Iterative methods
KW  - Data privacy
KW  - Objective functions
KW  - Alternating direction method of multipliers
KW  - Distributed machine learning
KW  - Differential privacies
KW  - differential privacy
KW  - ADMM
KW  - distributed machine learning
KW  - Collective computing power
KW  - decentralized optimization
KW  - Decentralized optimization
KW  - Number of iterations
ER  - 

TY  - JOUR
TI  - A Comparative Study of Machine Learning Classification for Color-based Safety Vest Detection on Construction-Site Images
AU  - Seong, H.
AU  - Son, H.
AU  - Kim, C.
T2  - KSCE Journal of Civil Engineering
AB  - Detecting the safety vests is an important foundation for various applications in safety management and productivity measurement. The fluorescent yellow-green color and fluorescent orange-red color of safety vests are generally considered as the most distinctive colors which represent workers in construction-site images. The objective of this study is to provide an evaluation of the safety vest detection using color information in construction-site images. The data sets of two colors of safety vests and the background were generated and used in this study. A comparative analysis of combinations of five color spaces (RGB, nRGB, HSV, Lab, and YCbCr) and six classifiers (ANN, C4.5, KNN, LR, NB, and SVM) was conducted. The performance of each combination was assessed in terms of the precision, recall, and F-measure. Moreover, an evaluation of the effects of color space conversion and the absence of luminance components on the detection performance was conducted. The comparison results showed that C4.5 classifier combined with YCbCr and SVM classifier combined with Lab, respectively, outperformed other combinations on each data set of safety vest colors. Furthermore, RGB color space transformation into non-RGB color spaces enhanced the classification performance. The evaluation also showed that the removal of luminance components did not help to improve the performance. © 2018, Korean Society of Civil Engineers.
DA  - 2018///
PY  - 2018
DO  - 10.1007/s12205-017-1730-3
VL  - 22
IS  - 11
SP  - 4254
EP  - 4262
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053761918&doi=10.1007%2fs12205-017-1730-3&partnerID=40&md5=33b1cb0b81c2093d0fd46b1adb2ef8da
DB  - Scopus
KW  - machine learning
KW  - Artificial intelligence
KW  - Data mining
KW  - Learning systems
KW  - Image classification
KW  - Classification (of information)
KW  - Pixel level
KW  - Image processing
KW  - Productivity
KW  - image processing
KW  - Classification performance
KW  - Occupational risks
KW  - Metadata
KW  - Fluorescence
KW  - Color
KW  - Machine learning classification
KW  - Comparative analysis
KW  - Detection performance
KW  - Color space conversion
KW  - color space transformation
KW  - Color space transformation
KW  - data mining techniques
KW  - Luminance
KW  - pixel-level classification
KW  - Productivity measurements
KW  - safety vest detection
KW  - worker detection
ER  - 

TY  - CONF
TI  - Robust coreset construction for distributed machine learning
AU  - Lu, H.
AU  - Li, M.-J.
AU  - He, T.
AU  - Wang, S.
AU  - Narayanan, V.
AU  - Chan, K.S.
T2  - 2019 IEEE Global Communications Conference, GLOBECOM 2019 - Proceedings
AB  - Motivated by the need of solving machine learning problems over distributed datasets, we explore the use of emph{coreset} to reduce the communication overhead. Coreset is a summary of the original dataset in the form of a small weighted set in the same sample space. Compared to other data summaries, coreset has the advantage that it can be used as a proxy of the original dataset. However, existing coreset construction algorithms are each tailor-made for a specific machine learning problem. Thus, to solve different machine learning problems, one has to collect coresets of different types, defeating the purpose of saving communication overhead. We resolve this dilemma by developing robust coreset construction algorithms based on k-means/median clustering, that give a provably good approximation for a broad range of machine learning problems with sufficiently continuous cost functions. Through evaluations on diverse datasets and machine learning problems, we verify the robust performance of the proposed algorithms. © 2019 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/GLOBECOM38437.2019.9013625
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081965994&doi=10.1109%2fGLOBECOM38437.2019.9013625&partnerID=40&md5=8bf9fbf8fa989fe52138246e58d22ac8
DB  - Scopus
KW  - Machine learning
KW  - Learning systems
KW  - Learning algorithms
KW  - Cost functions
KW  - Approximation algorithms
KW  - K-means clustering
KW  - Distributed machine learning
KW  - Robust performance
KW  - K-means
KW  - Machine learning problem
KW  - Communication overheads
KW  - Construction algorithms
KW  - Coreset
KW  - K-median
ER  - 

TY  - JOUR
TI  - Modified Autoencoder Training and Scoring for Robust Unsupervised Anomaly Detection in Deep Learning
AU  - Merrill, N.
AU  - Eskandarian, A.
T2  - IEEE Access
AB  - The autoencoder (AE) is a fundamental deep learning approach to anomaly detection. AEs are trained on the assumption that abnormal inputs will produce higher reconstruction errors than normal ones. In practice, however, this assumption is unreliable in the unsupervised case, where the training data may contain anomalous examples. Given sufficient capacity and training time, an AE can generalize to such an extent that it reliably reconstructs anomalies. Consequently, the ability to distinguish anomalies via reconstruction errors is diminished. We respond to this limitation by introducing three new methods to more reliably train AEs for unsupervised anomaly detection: cumulative error scoring (CES), percentile loss (PL), and early stopping via knee detection. We demonstrate significant improvements over conventional AE training on image, remote-sensing, and cybersecurity datasets. © 2013 IEEE.
DA  - 2020///
PY  - 2020
DO  - 10.1109/ACCESS.2020.2997327
VL  - 8
SP  - 101824
EP  - 101833
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086717062&doi=10.1109%2fACCESS.2020.2997327&partnerID=40&md5=09a316f56784fdc24e8eaa97ccfa8156
DB  - Scopus
KW  - Deep learning
KW  - Training data
KW  - Learning systems
KW  - Anomaly detection
KW  - Learning approach
KW  - Image enhancement
KW  - Errors
KW  - Cyber security
KW  - Remote sensing
KW  - Unsupervised anomaly detection
KW  - Condition monitoring
KW  - Unsupervised
KW  - Reconstruction error
KW  - Autoencoder
KW  - Hyperspectral
KW  - Early stopping
KW  - Abnormal input
KW  - Cumulative errors
KW  - HSI
KW  - Outlier detection
ER  - 

TY  - JOUR
TI  - Robust CFAR detection for multiple targets in K-distributed sea clutter based on machine learning
AU  - Zhao, J.
AU  - Jiang, R.
AU  - Wang, X.
AU  - Gao, H.
T2  - Symmetry
AB  - For K-distributed sea clutter, a constant false alarm rate (CFAR) is crucial as a desired property for automatic target detection in an unknown and non-stationary background. In multiple-target scenarios, the target masking effect reduces the detection performance of CFAR detectors evidently. A machine learning based processor, associating the artificial neural network (ANN) and a clustering algorithm of density-based spatial clustering of applications with noise (DBSCAN), namely, DBSCAN-CFAR, is proposed herein to address this issue. ANN is trained with a symmetrical structure to estimate the shape parameter of background clutter, whereas DBSCAN is devoted to excluding interference targets and sea spikes as outliers in the leading and lagging windows that are symmetrical about the cell under test (CUT). Simulation results verified that the ANN-based method provides the optimal parameter estimation results in the range of 0.1 to 30, which facilitates the control of actual false alarm probability. The effectiveness and robustness of DBSCAN-CFAR are also confirmed by the comparisons of conventional CFAR processors in different clutter conditions, comprised of varying target numbers, shape parameters, and false alarm probabilities. Although the proposed ANN-based DBSCAN-CFAR processor incurs more elapsed time, it achieves superior CFAR performance without a prior knowledge on the number and distribution of interference targets. © 2019 by the authors.
DA  - 2019///
PY  - 2019
DO  - 10.3390/SYM11121482
VL  - 11
IS  - 12
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079635891&doi=10.3390%2fSYM11121482&partnerID=40&md5=05678e352875f5a12f6077d060976114
DB  - Scopus
KW  - Machine learning
KW  - Neural network
KW  - CFAR detection
KW  - Clustering algorithm
KW  - K-distribution
KW  - Multiple targets
KW  - Sea clutter
ER  - 

TY  - JOUR
TI  - Semi-supervised variational Bayesian Student's t mixture regression and robust inferential sensor application
AU  - Wang, J.
AU  - Shao, W.
AU  - Song, Z.
T2  - Control Engineering Practice
AB  - Data-driven inferential sensor has been widely adopted to estimate key quality relevant variables. However, industrial dataset usually presents many characteristics such as nonlinearity, non-Gaussianity, insufficiency of labeled samples, contamination of outliers, etc. These intractable characteristics have rendered significant difficulties in developing high-performance inferential sensor. This paper deals with these issues in the probabilistic way by proposing a robust semi-supervised variational Bayesian Student's t mixture regression (referred to as the ‘SSVBSMR’). Specifically, in the SSVBSMR, the nonlinear and non-Gaussian characteristics are handled by Bayesian finite mixture models (FMM), and the Student's t distribution is employed to constitute the components of FMM, which makes the SSVBSMR robust against outliers. In addition, the SSVBSMR exploits unlabeled samples to remedy the insufficiency of labeled samples. Furthermore, the SSVBSMR treats all model parameters as stochastic rather than deterministic such that the model selection can be automatically and efficiently completed and some limitations of the maximum likelihood method (such as overfitting and singular covariance) can be alleviated. A variational Bayesian expectation–maximization-based learning algorithm is also developed to train the SSVBSMR. Two cases are carried out to investigate the performance of the SSVBSMR, and the results demonstrate its effectiveness and feasibility compared to several state-of-the-art methods. © 2019
DA  - 2019///
PY  - 2019
DO  - 10.1016/j.conengprac.2019.104155
VL  - 92
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072273409&doi=10.1016%2fj.conengprac.2019.104155&partnerID=40&md5=ab3e1ed0bf01df61f167bafda5bc1f4b
DB  - Scopus
KW  - Machine learning
KW  - Supervised learning
KW  - Learning algorithms
KW  - Regression analysis
KW  - Semi- supervised learning
KW  - Semi-supervised learning
KW  - Statistics
KW  - Stochastic models
KW  - Stochastic systems
KW  - Students
KW  - Mixtures
KW  - Maximum likelihood
KW  - Heavy-tailed distribution
KW  - Variational inference
KW  - Bayesian Student's t mixture regression
KW  - Heavy-tailed distribution outliers
KW  - Inferential sensors
KW  - Mixture regression
KW  - Robust inferential sensor
ER  - 

TY  - CONF
TI  - Robust semi-supervised representation learning for graph-structured data
AU  - Guo, L.-Z.
AU  - Han, T.
AU  - Li, Y.-F.
T2  - Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)
AB  - The success of machine learning algorithms generally depends on data representation and recently many representation learning methods have been proposed. However, learning a good representation may not always benefit the classification tasks. It sometimes even hurt the performance as the learned representation maybe not related to the ultimate tasks, especially when the labeled examples are few to afford a reliable model selection. In this paper, we propose a novel robust semi-supervised graph representation learning method based on graph convolutional network. To make the learned representation more related to the ultimate classification task, we propose to extend label information based on the smooth assumption and obtain pseudo-labels for unlabeled nodes. Moreover, to make the model robust with noise in the pseudo-label, we propose to apply a large margin classifier to the learned representation. Influenced by the pseudo-label and the large-margin principle, the learned representation can not only exploit the label information encoded in the graph-structure sufficiently but also can produce a more rigorous decision boundary. Experiments demonstrate the superior performance of the proposal over many related methods. © Springer Nature Switzerland AG 2019.
DA  - 2019///
PY  - 2019
DO  - 10.1007/978-3-030-16142-2_11
VL  - 11441 LNAI
SP  - 131
EP  - 143
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065032165&doi=10.1007%2f978-3-030-16142-2_11&partnerID=40&md5=cdb26d866f80e05e4bd463563214ae0c
DB  - Scopus
KW  - Machine learning
KW  - Data mining
KW  - Supervised learning
KW  - Learning algorithms
KW  - Classification (of information)
KW  - Convolution
KW  - Representation learning
KW  - Graphic methods
KW  - Semi- supervised learning
KW  - Semi-supervised learning
KW  - Robust
KW  - Convolutional networks
KW  - Graph convolutional network
KW  - Graph structured data
KW  - Large margin classifiers
KW  - Large margin principle
KW  - Semi-supervised graphs
ER  - 

TY  - JOUR
TI  - RoCoLe: A robusta coffee leaf images dataset for evaluation of machine learning based methods in plant diseases recognition
AU  - Parraga-Alava, J.
AU  - Cusme, K.
AU  - Loor, A.
AU  - Santander, E.
T2  - Data in Brief
AB  - In this article we introduce a robusta coffee leaf images dataset called RoCoLe. The dataset contains 1560 leaf images with visible red mites and spots (denoting coffee leaf rust presence) for infection cases and images without such structures for healthy cases. In addition, the data set includes annotations regarding objects (leaves), state (healthy and unhealthy) and the severity of disease (leaf area with spots). Images were all obtained in real-world conditions in the same coffee plants field using a smartphone camera. RoCoLe data set facilitates the evaluation of the performance of machine learning algorithms used in image segmentation and classification problems related to plant diseases recognition. The current dataset is freely and publicly available at https://doi.org/10.17632/c5yvn32dzg.2. © 2019 The Author(s)
DA  - 2019///
PY  - 2019
DO  - 10.1016/j.dib.2019.104414
VL  - 25
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071396965&doi=10.1016%2fj.dib.2019.104414&partnerID=40&md5=e67e02314a988930262622f9e44b0d83
DB  - Scopus
KW  - Machine learning
KW  - Learning algorithms
KW  - Machine-learning
KW  - Classification (of information)
KW  - Image segmentation
KW  - Leaf images
KW  - Plants (botany)
KW  - Coffee leaf rust
KW  - Hemileia vastatrix
KW  - Leaf rust
KW  - Plant disease
KW  - Plant disease recognition
KW  - Plant diseases recognition
KW  - Red spider mite
KW  - Spider mite
KW  - Tetranychus urticae
ER  - 

TY  - CONF
TI  - ColANet: A UAV Collision Avoidance Dataset
AU  - Pedro, D.
AU  - Mora, A.
AU  - Carvalho, J.
AU  - Azevedo, F.
AU  - Fonseca, J.
T2  - IFIP Advances in Information and Communication Technology
AB  - Artificial Intelligence is evolving at an accelerating pace alongside the increasing number of large datasets due to vast number of image data on the Internet. Unnamed Aircraft Vehicles (UAVs) are also a new trend that will have a huge impact over the next years. The use of UAVs arises some safety issues, such as collisions with dynamic obstacles like birds, other planes, or random thrown objects. Those are complex and sometimes impossible to avoid with state-of-the-art algorithms, representing a threat to the applications. In this article, a new video dataset of collisions, entitled ColANet, aims to provide a base for training new Machine Learning algorithms for handling the problem of avoiding collisions with high efficiency and robustness. It is also shown that using this dataset is easy to build new neural network models and test them. © IFIP International Federation for Information Processing 2020.
DA  - 2020///
PY  - 2020
DO  - 10.1007/978-3-030-45124-0_5
VL  - 577
SP  - 53
EP  - 62
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084861094&doi=10.1007%2f978-3-030-45124-0_5&partnerID=40&md5=776ee0e54badb801960cf8a583b879d4
DB  - Scopus
KW  - Artificial Intelligence
KW  - Safety
KW  - Machine learning
KW  - Machine Learning
KW  - UAV
KW  - Collision avoidance
KW  - Neural network
KW  - Learning algorithms
KW  - Neural network model
KW  - Statistical tests
KW  - Unmanned aerial vehicles (UAV)
KW  - Aircraft accidents
KW  - Training aircraft
KW  - Dynamic obstacles
KW  - Large dataset
KW  - Large datasets
KW  - Safety issues
KW  - UAS
KW  - Dataset
KW  - Video dataset
KW  - State-of-the-art algorithms
KW  - Aircraft vehicles
KW  - High-efficiency
ER  - 

TY  - CONF
TI  - Robust Data-Driven Optimization Using Machine Learning and Monte-Carlo Simulation
AU  - Bechard, V.
T2  - Proceedings - Winter Simulation Conference
AB  - This paper presents a framework that was developed to achieve data-driven robust optimization of processes. The main idea is to automatically build a single and global predictive model using a machine learning technique (random forests), and then to use a derivative-free black-box optimization technique (MADS) to maximize a performance criterion. Monte-Carlo simulation is used to estimate pointwise prediction variance. This automated framework is designed to find optimal variance-stabilizing solutions while preserving the noisiness, non-smoothness, non-linearity, non-convexity and disjoint nature of real-life data. The time it takes to prepare the dataset depends on the volume of data, but this step occurs only once in the procedure. The time it takes to iterate during optimization depends on three user-specified quantities; therefore, the iterative portion is insensitive to data volume. Implementation was done using the R programming language which offers a wide variety of data processing, modelling and optimization capabilities. © 2019 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/WSC40007.2019.9004745
VL  - 2019-December
SP  - 3575
EP  - 3586
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081134181&doi=10.1109%2fWSC40007.2019.9004745&partnerID=40&md5=c154c7f70439cee01254bd62cf16fd08
DB  - Scopus
KW  - Decision trees
KW  - Machine learning
KW  - Intelligent systems
KW  - Predictive modeling
KW  - Data handling
KW  - Optimization
KW  - Robust optimization
KW  - Random forests
KW  - Iterative methods
KW  - Machine learning techniques
KW  - Monte Carlo methods
KW  - Modeling languages
KW  - Black-box optimization
KW  - Performance criterion
KW  - Optimization capabilities
KW  - Prediction Variance
KW  - Stabilizing solutions
ER  - 

TY  - CONF
TI  - Distributed Robust Bayesian Cluster Enumeration Criterion for Unsupervised Learning
AU  - Zhang, Y.
AU  - Teklehaymanot, F.K.
AU  - Muma, M.
AU  - Zoubir, A.M.
T2  - 2019 IEEE 8th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing, CAMSAP 2019 - Proceedings
AB  - Wireless sensor networks have been widely deployed for industrial and consumer applications. The amount of data in such applications is large, and as a results a result, the automatic discovery of the underlying structure in the data (cluster analysis) becomes of prominent interest. A challenging task in cluster analysis is the estimation of the number of clusters. To this end, we propose a robust decentralized diffusion-based cluster enumeration method that enables distributed sensor nodes to estimate the number of clusters in their respective data sets through cooperation with their immediate neighbors. The proposed method is robust to the presence of heavy-tailed noise and outliers, which is useful for sensor networks as outliers can occur due to measurement errors or sensor failure. Through experiments, we show that the proposed method is promising, and achieves the performance of a centralized network using a fusion center. © 2019 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/CAMSAP45676.2019.9022457
SP  - 176
EP  - 180
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082401631&doi=10.1109%2fCAMSAP45676.2019.9022457&partnerID=40&md5=9caec5a0d7749b2d2da9758edd2e43e1
DB  - Scopus
KW  - Machine learning
KW  - Statistics
KW  - Outlier
KW  - Clustering
KW  - Sensor networks
KW  - Spurious signal noise
KW  - Cluster analysis
KW  - Sensor nodes
KW  - Heavy-tailed noise
KW  - Diffusion
KW  - Array processing
KW  - Automatic discovery
KW  - Centralized networks
KW  - Consumer applications
KW  - Distributed Robust Cluster Enumeration
KW  - Enumeration method
KW  - Sensor Networks
ER  - 

TY  - JOUR
TI  - Low-Rank Matrix Recovery With Simultaneous Presence of Outliers and Sparse Corruption
AU  - Rahmani, M.
AU  - Atia, G.K.
T2  - IEEE Journal on Selected Topics in Signal Processing
AB  - We study a data model in which the data matrix D ∈ ℝN1 × N2 can be expressed as D = L + S + C, where L is a low-rank matrix, S is an elementwise sparse matrix, and C is a matrix whose nonzero columns are outlying data points. To date, robust principal component analysis (PCA) algorithms have solely considered models with either S or C, but not both. As such, existing algorithms cannot account for simultaneous elementwise and columnwise corruptions. In this paper, a new robust PCA algorithm that is robust to simultaneous types of corruption is proposed. Our approach hinges on the sparse approximation of a sparsely corrupted column so that the sparse expansion of a column with respect to the other data points is used to distinguish a sparsely corrupted inlier column from an outlying data point. We also develop a randomized design that provides a scalable implementation of the proposed approach. The core idea of sparse approximation is analyzed analytically where we show that the underlying ℓ1-norm minimization can obtain the representation of an inlier in presence of sparse corruptions. © 2018 IEEE.
DA  - 2018///
PY  - 2018
DO  - 10.1109/JSTSP.2018.2876604
VL  - 12
IS  - 6
SP  - 1170
EP  - 1181
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055148671&doi=10.1109%2fJSTSP.2018.2876604&partnerID=40&md5=e6bb76d2f2992e06fea1a7ec8d9d75bb
DB  - Scopus
KW  - big data
KW  - Crime
KW  - Big data
KW  - Statistics
KW  - Robust PCA
KW  - Principal component analysis
KW  - Unsupervised learning
KW  - unsupervised learning
KW  - Matrix algebra
KW  - outlier detection
KW  - Subspace learning
KW  - Outlier Detection
KW  - Sparse matrices
KW  - Matrix decomposition
KW  - data sketching
KW  - Data Sketching
KW  - matrix decomposition
KW  - randomization
KW  - Randomization
KW  - sparse corruption
KW  - Sparse Corruption
KW  - sparse matrix
KW  - subspace learning
ER  - 

TY  - CONF
TI  - Application of Machine Learning and Big data Analytics in Pharmacovigilance and Drug Safety
AU  - Sarangi, S.C.
AU  - Dash, Y.
T2  - 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies, ICICICT 2019
AB  - Machine learning technique is revolutionizing in all stages of drug discovery and developments starting from drug design, pivotal clinical trials to clinical practice. Application of machine learning techniques and big data analytics for looking upon the unintended effects of new or commonly prescribed medicines would enhance new technical approaches to generate and test 'signals' related to drug safety. It would craft as a path finder for pharmacovigilance resources, time, and skills for transforming the efforts from a volume-based focus to a value-based focus. This article provides a comprehensive overview of the current scenario of pharmacovigilance programme, the importance of real world data, and machine learning analytics in the conduct of pharmacovigilance for better reproducibility and reliability. Precise and in-depth evaluation and prediction of drug safety database using machine learning techniques were also discussed in this paper. The utilization of these techniques in pharmacovigilance programme will improve its accuracy and reproducibility, and will boost this drug safety surveillance system's role as a pillar in patient safety. © 2019 IEEE.
DA  - 2019///
PY  - 2019
DO  - 10.1109/ICICICT46008.2019.8993265
SP  - 555
EP  - 559
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080119416&doi=10.1109%2fICICICT46008.2019.8993265&partnerID=40&md5=75af7a433dbf1e6430ec89519fe8c954
DB  - Scopus
KW  - machine learning
KW  - Machine learning
KW  - big data
KW  - Learning systems
KW  - Learning algorithms
KW  - Predictive analytics
KW  - Big data
KW  - Drug products
KW  - drug safety
KW  - Drug safety
KW  - pharmacovigilance
KW  - Pharmacovigilance
KW  - Patient safety
KW  - Reproducibilities
KW  - Data Analytics
KW  - Machine learning techniques
KW  - Controlled drug delivery
KW  - predictive analytics
KW  - Clinical practices
KW  - Intelligent computing
KW  - Depth evaluations
KW  - Surveillance systems
ER  - 

